neural_compressor.torch.algorithms.autoround.autoround
======================================================

.. py:module:: neural_compressor.torch.algorithms.autoround.autoround

.. autoapi-nested-parse::

   AutoRound quantization.



Classes
-------

.. autoapisummary::

   neural_compressor.torch.algorithms.autoround.autoround.AutoRoundQuantizer


Functions
---------

.. autoapisummary::

   neural_compressor.torch.algorithms.autoround.autoround.get_dataloader
   neural_compressor.torch.algorithms.autoround.autoround.get_mllm_dataloader
   neural_compressor.torch.algorithms.autoround.autoround.dump_model_op_stats


Module Contents
---------------

.. py:class:: AutoRoundQuantizer(quant_config: Optional[dict] = None, **kwargs)



   AutoRound Quantizer.


.. py:function:: get_dataloader(tokenizer, seqlen, dataset_name='NeelNanda/pile-10k', seed=42, bs=8, nsamples=128)

   Generate a DataLoader for calibration using specified parameters.

   :param tokenizer: The tokenizer to use for tokenization.
   :type tokenizer: Tokenizer
   :param seqlen: The exact sequence length. samples < seqlen will be dropped,
                  samples longer than seqlen will be truncated
   :type seqlen: int
   :param dataset_name: The name of the dataset or datasets separated by commas.
                        Defaults to "NeelNanda/pile-10k".
   :type dataset_name: str, optional
   :param split: The data split to use. Defaults to None.
   :type split: str, optional
   :param seed: The random seed for reproducibility. Defaults to 42.
   :type seed: int, optional
   :param bs: The batch size. Defaults to 4.
   :type bs: int, optional
   :param nsamples: The total number of samples to include. Defaults to 128.
   :type nsamples: int, optional

   :returns: The DataLoader for the calibrated dataset.
   :rtype: DataLoader


.. py:function:: get_mllm_dataloader(model, tokenizer, template=None, processor=None, image_processor=None, dataset=None, extra_data_dir=None, seqlen=None, batch_size=8, split=None, apply_template=None, truncation=None, seed=42, nsamples=128, gradient_accumulate_steps=1, quant_nontext_module=False)

   Generate a DataLoader for calibration using specified parameters.

   :param template: The template to specify process for different mllms.
   :type template: Template
   :param model: The model to quantized.
   :type model: Model
   :param tokenizer: The tokenizer to use for tokenization.
   :type tokenizer: Tokenizer
   :param Dataset_name: The name or path of the dataset.
   :type Dataset_name: str
   :param extra_data_dir: The path for extra data such as images, audio or videos.
   :type extra_data_dir: str
   :param seqlen: The exact sequence length. samples < seqlen will be dropped,
                  samples longer than seqlen will be truncated
   :type seqlen: int
   :param bs: The batch size. Defaults to 4.
   :type bs: int, optional
   :param split: The data split to use. Defaults to None.
   :type split: str, optional
   :param apply_template: Whether to apply chat template in tokenization.

   :returns: The DataLoader for the calibrated datasets.
   :rtype: DataLoader


.. py:function:: dump_model_op_stats(layer_config)

   Dump quantizable ops stats of model to user.


