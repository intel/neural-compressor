Search.setIndex({"alltitles":{"1 Quantization":[[249,"quantization"],[250,"quantization"],[251,"quantization"],[252,"quantization"]],"1. Create Environment":[[219,null],[220,null],[237,"create-environment"],[238,"create-environment"],[239,"create-environment"]],"1. Environment":[[222,"environment"],[224,"environment"],[226,"environment"],[229,"environment"],[230,"environment"],[243,"environment"],[246,"environment"],[247,"environment"],[248,"environment"],[249,"environment"],[250,"environment"],[251,"environment"],[252,"environment"],[253,"environment"],[254,"environment"],[255,"environment"],[256,"environment"],[257,"environment"],[260,"environment"],[261,"environment"],[262,"environment"],[263,"environment"],[264,"environment"],[265,"environment"]],"1. Installation":[[259,"installation"]],"1. Performance":[[240,"id4"]],"1. Quantization":[[230,"quantization"],[248,"quantization"],[253,"quantization"],[260,"quantization"],[261,"quantization"],[262,"quantization"],[263,"quantization"]],"1. Quantization with CPU":[[243,"quantization-with-cpu"]],"1. ResNet18 With Intel PyTorch Extension":[[229,"resnet18-with-intel-pytorch-extension"],[229,"id1"]],"1. Setup Environment":[[196,"setup-environment"]],"1. prepare_qat and Module Replacement":[[196,"prepare-qat-and-module-replacement"]],"2. Accuracy":[[240,"id5"]],"2. Baseline Fine-Tuning (BF16)":[[196,"baseline-fine-tuning-bf16"]],"2. Benchmark":[[230,"benchmark"],[248,"benchmark"],[249,"benchmark"],[250,"benchmark"],[251,"benchmark"],[252,"benchmark"],[253,"benchmark"],[260,"benchmark"],[261,"benchmark"],[262,"benchmark"],[263,"benchmark"]],"2. Download Frozen PB":[[264,"download-frozen-pb"]],"2. Install Intel-Pytorch-Extension":[[229,"install-intel-pytorch-extension"]],"2. Install Tensorflow":[[259,"install-tensorflow"]],"2. Install modules":[[219,"install-modules"],[220,"install-modules"]],"2. Prepare Dataset":[[222,"prepare-dataset"],[226,"prepare-dataset"],[246,"prepare-dataset"],[247,"prepare-dataset"]],"2. Prepare Model":[[224,"prepare-model"],[230,"prepare-model"],[248,"prepare-model"],[260,"prepare-model"],[261,"prepare-model"],[262,"prepare-model"]],"2. Prepare Pre-trained model":[[265,"prepare-pre-trained-model"]],"2. Prepare Pretrained model":[[253,"prepare-pretrained-model"],[254,"prepare-pretrained-model"],[255,"prepare-pretrained-model"],[256,"prepare-pretrained-model"],[257,"prepare-pretrained-model"],[266,"prepare-pretrained-model"]],"2. Prepare model":[[263,"prepare-model"]],"2. Prepare pre-trained model":[[249,"prepare-pre-trained-model"],[250,"prepare-pre-trained-model"],[251,"prepare-pre-trained-model"],[252,"prepare-pre-trained-model"]],"2. QuantLinear":[[196,"quantlinear"]],"2. Quantization with Intel GPU":[[243,"quantization-with-intel-gpu"]],"2. ResNet50 With Intel PyTorch Extension":[[229,"resnet50-with-intel-pytorch-extension"]],"2.1 Environment Setting":[[243,"environment-setting"]],"2.2 Quantization Command":[[243,"quantization-command"]],"2018 - 2020 (4)":[[273,"id6"]],"2021 (15)":[[273,"id5"]],"2022 (35)":[[273,"id4"]],"2023 (25)":[[273,"id3"]],"2024 (7)":[[273,"id2"]],"2025 (5)":[[273,"id1"]],"3. Download model":[[219,"download-model"],[220,"download-model"]],"3. Install Intel Extension for Tensorflow":[[259,"install-intel-extension-for-tensorflow"]],"3. Install TensorFlow 2.11.dev202242":[[257,"install-tensorflow-2-11-dev202242"]],"3. Prepare Dataset":[[224,"prepare-dataset"],[229,"prepare-dataset"],[248,"prepare-dataset"],[249,"prepare-dataset"],[250,"prepare-dataset"],[251,"prepare-dataset"],[252,"prepare-dataset"],[253,"prepare-dataset"],[254,"prepare-dataset"],[255,"prepare-dataset"],[256,"prepare-dataset"],[260,"prepare-dataset"],[261,"prepare-dataset"],[262,"prepare-dataset"],[263,"prepare-dataset"],[264,"prepare-dataset"],[266,"prepare-dataset"]],"3. Prepare dataset":[[265,"prepare-dataset"]],"3. Prepare pretrained model":[[226,"prepare-pretrained-model"],[246,"prepare-pretrained-model"],[247,"prepare-pretrained-model"]],"3. QAT Fine-Tuning":[[196,"qat-fine-tuning"]],"3. ResNext101_32x16d With Intel PyTorch Extension":[[229,"resnext101-32x16d-with-intel-pytorch-extension"]],"3. TensorQuantizer":[[196,"tensorquantizer"]],"4. Evaluation and Deployment":[[196,"evaluation-and-deployment"]],"4. Prepare Dataset":[[257,"prepare-dataset"]],"4. Prepare Dataset & Pretrained model":[[259,"prepare-dataset-pretrained-model"]],"4. Process Dataset":[[264,"process-dataset"]],"4. QAT-Specific Trainer (QATTrainer)":[[196,"qat-specific-trainer-qattrainer"]],"4. Quantize model":[[219,"quantize-model"],[220,"quantize-model"]],"5. Save and load quantized model":[[219,"save-and-load-quantized-model"],[220,"save-and-load-quantized-model"]],"6. Some debug":[[219,"some-debug"],[220,"some-debug"]],"API":[[206,null]],"API for TensorFlow":[[204,"api-for-tensorflow"]],"AWQ":[[199,"awq"]],"Accuracy":[[239,"accuracy"],[240,"accuracy"]],"Accuracy Aware Tuning":[[274,"accuracy-aware-tuning"]],"Accuracy Issues":[[196,"accuracy-issues"]],"Accuracy-driven mixed precision":[[194,"accuracy-driven-mixed-precision"]],"Additional Content":[[205,"additional-content"]],"Advantages of MX Quantization":[[193,"advantages-of-mx-quantization"]],"Algorithm: Auto-tuning of $\\alpha$.":[[275,"algorithm-auto-tuning-of-alpha"]],"Architecture":[[216,"architecture"]],"Attribution":[[188,"attribution"]],"AutoRound":[[199,"autoround"]],"AutoRound Quantization Schemes":[[196,"autoround-quantization-schemes"]],"AutoTune":[[213,null]],"AutoTune with Multiple Target Bits":[[193,"autotune-with-multiple-target-bits"]],"Automated approach":[[262,"automated-approach"],[266,"automated-approach"]],"Automatic dataset & model download":[[259,"automatic-dataset-model-download"]],"Automatic dataset download":[[256,"automatic-dataset-download"],[260,"automatic-dataset-download"],[261,"automatic-dataset-download"],[262,"automatic-dataset-download"]],"Automatic download":[[263,"automatic-download"],[263,"id1"]],"Autotune API":[[200,"autotune-api"]],"BF16":[[225,"bf16"]],"Backend and Device":[[190,"backend-and-device"],[204,"backend-and-device"]],"Background":[[215,"background"]],"Basic Usage":[[193,"basic-usage"]],"Basic quantization":[[258,"basic-quantization"]],"Benchmark":[[222,"benchmark"],[254,"benchmark"],[255,"benchmark"],[256,"benchmark"],[257,"benchmark"],[257,"id1"],[258,"benchmark"],[259,"benchmark"],[259,"id1"],[264,"benchmark"],[265,"benchmark"],[266,"benchmark"]],"Benchmark the fp32 model":[[253,"benchmark-the-fp32-model"]],"Benchmark the int8 model":[[253,"benchmark-the-int8-model"]],"Benefits of Mix Precision":[[193,"benefits-of-mix-precision"]],"Best Practices and Tips":[[193,"best-practices-and-tips"]],"Best Practices and Troubleshooting":[[196,"best-practices-and-troubleshooting"]],"CLIP evaluation":[[227,"clip-evaluation"]],"Check neural_compressor code":[[192,"check-neural-compressor-code"]],"Choosing the Right Data Type":[[193,"choosing-the-right-data-type"]],"Citation":[[271,"citation"]],"Classes":[[0,"classes"],[1,"classes"],[3,"classes"],[4,"classes"],[6,"classes"],[8,"classes"],[14,"classes"],[15,"classes"],[17,"classes"],[19,"classes"],[20,"classes"],[23,"classes"],[24,"classes"],[25,"classes"],[28,"classes"],[29,"classes"],[30,"classes"],[34,"classes"],[37,"classes"],[38,"classes"],[39,"classes"],[41,"classes"],[42,"classes"],[43,"classes"],[44,"classes"],[45,"classes"],[46,"classes"],[47,"classes"],[48,"classes"],[49,"classes"],[50,"classes"],[51,"classes"],[52,"classes"],[53,"classes"],[54,"classes"],[55,"classes"],[56,"classes"],[57,"classes"],[58,"classes"],[59,"classes"],[60,"classes"],[61,"classes"],[62,"classes"],[63,"classes"],[65,"classes"],[66,"classes"],[67,"classes"],[68,"classes"],[69,"classes"],[70,"classes"],[71,"classes"],[72,"classes"],[73,"classes"],[74,"classes"],[76,"classes"],[77,"classes"],[78,"classes"],[79,"classes"],[80,"classes"],[81,"classes"],[83,"classes"],[84,"classes"],[85,"classes"],[86,"classes"],[88,"classes"],[89,"classes"],[90,"classes"],[91,"classes"],[94,"classes"],[95,"classes"],[96,"classes"],[97,"classes"],[98,"classes"],[99,"classes"],[100,"classes"],[102,"classes"],[103,"classes"],[104,"classes"],[105,"classes"],[106,"classes"],[107,"classes"],[108,"classes"],[109,"classes"],[110,"classes"],[111,"classes"],[112,"classes"],[114,"classes"],[115,"classes"],[118,"classes"],[120,"classes"],[121,"classes"],[122,"classes"],[123,"classes"],[125,"classes"],[130,"classes"],[131,"classes"],[133,"classes"],[135,"classes"],[136,"classes"],[137,"classes"],[138,"classes"],[143,"classes"],[145,"classes"],[148,"classes"],[149,"classes"],[152,"classes"],[153,"classes"],[154,"classes"],[155,"classes"],[156,"classes"],[157,"classes"],[158,"classes"],[161,"classes"],[162,"classes"],[164,"classes"],[165,"classes"],[166,"classes"],[167,"classes"],[168,"classes"],[175,"classes"],[179,"classes"],[182,"classes"]],"Code Update":[[257,"code-update"]],"Code of Conduct":[[244,null]],"Code update":[[246,"code-update"],[248,"code-update"],[259,"code-update"],[260,"code-update"],[261,"code-update"],[262,"code-update"],[266,"code-update"]],"Coding Style":[[245,"coding-style"]],"Command-Line Arguments (from main.py)":[[196,"command-line-arguments-from-main-py"]],"Comments":[[215,"comments"]],"Common Build Issues":[[267,"common-build-issues"]],"Common Issues and Solutions":[[193,"common-issues-and-solutions"]],"Common Problems":[[200,"common-problems"]],"Common arguments":[[199,"common-arguments"]],"Communication":[[205,"communication"]],"Configuration and Key Parameters":[[196,"configuration-and-key-parameters"]],"Contents":[[196,"contents"]],"Contributing to DLRM":[[245,null]],"Contribution Guidelines":[[189,null]],"Contributor Covenant Code of Conduct":[[188,null],[189,"contributor-covenant-code-of-conduct"]],"Contributor License Agreement (\u201dCLA\u201d)":[[245,"contributor-license-agreement-cla"]],"Convert the dataset to TF Record format":[[256,"convert-the-dataset-to-tf-record-format"]],"Core Components":[[196,"core-components"]],"Create Environment\u200b":[[240,"create-environment"],[240,"id2"]],"Create Pull Request":[[189,"create-pull-request"]],"DPQ":[[199,"dpq"]],"Datasets":[[228,"datasets"]],"Demo (MXFP4, MXFP8, NVFP4, uNVFP4)":[[232,"demo-mxfp4-mxfp8-nvfp4-unvfp4"]],"Dependencies":[[240,"dependencies"]],"Design":[[216,null]],"Details of enabling Intel\u00ae Neural Compressor on faster_rcnn_resnet50 for Tensorflow.":[[260,"details-of-enabling-intel-neural-compressor-on-faster-rcnn-resnet50-for-tensorflow"]],"Details of enabling Intel\u00ae Neural Compressor on gpt-j-6B for TensorFlow":[[257,"details-of-enabling-intel-neural-compressor-on-gpt-j-6b-for-tensorflow"]],"Details of enabling Intel\u00ae Neural Compressor on graphsage for Tensorflow.":[[248,"details-of-enabling-intel-neural-compressor-on-graphsage-for-tensorflow"]],"Details of enabling Intel\u00ae Neural Compressor on mask_rcnn_inception_v2 for Tensorflow.":[[261,"details-of-enabling-intel-neural-compressor-on-mask-rcnn-inception-v2-for-tensorflow"]],"Details of enabling Intel\u00ae Neural Compressor on ssd_mobilenet_v1 for Tensorflow.":[[262,"details-of-enabling-intel-neural-compressor-on-ssd-mobilenet-v1-for-tensorflow"]],"Details of enabling Intel\u00ae Neural Compressor on style transfer for Tensorflow.":[[266,"details-of-enabling-intel-neural-compressor-on-style-transfer-for-tensorflow"]],"Details of enabling Intel\u00ae Neural Compressor on transformer-lt for Tensorflow.":[[259,"details-of-enabling-intel-neural-compressor-on-transformer-lt-for-tensorflow"]],"Detecting Quantization Format":[[196,"detecting-quantization-format"]],"Determining the alpha through auto-tuning":[[203,"determining-the-alpha-through-auto-tuning"]],"Documentation":[[205,"documentation"]],"Download BraTS 2019 dataset":[[265,"download-brats-2019-dataset"]],"Dynamic Quantization":[[191,null],[274,"dynamic-quantization"]],"Efficient Usage on Client-Side":[[199,"efficient-usage-on-client-side"]],"EleutherAI/gpt-j-6b":[[241,"eleutherai-gpt-j-6b"]],"Enforcement":[[188,"enforcement"]],"Environment":[[227,"environment"]],"Evaluate Accuracy":[[257,"evaluate-accuracy"]],"Evaluate Performance":[[257,"evaluate-performance"]],"Evaluation":[[224,"evaluation"],[231,"evaluation"],[231,"id1"],[233,"evaluation"],[233,"id1"],[235,"evaluation"]],"Evaluation (CPU)":[[242,"evaluation-cpu"]],"Evaluation (HPU)":[[242,"evaluation-hpu"]],"Evaluation Part Adaption":[[259,"evaluation-part-adaption"],[266,"evaluation-part-adaption"]],"Example: QAT with MXFP4":[[196,"example-qat-with-mxfp4"]],"Examples":[[190,"examples"],[191,"examples"],[193,"examples"],[194,"examples"],[199,"examples"],[202,"examples"],[203,"examples"],[217,null],[276,"examples"]],"Examples of enabling Intel\u00ae Neural Compressor":[[246,"examples-of-enabling-intel-neural-compressor"]],"Exceptions":[[129,"exceptions"]],"FID evaluation":[[228,"fid-evaluation"]],"FP8 Accuracy":[[192,"fp8-accuracy"]],"FP8 KV cache":[[192,"fp8-kv-cache"],[192,"id3"]],"FP8 Quantization":[[192,null]],"Feature Matrix":[[269,"feature-matrix"]],"Fixed Alpha":[[197,"fixed-alpha"]],"Folder structure":[[215,"folder-structure"]],"For PB format":[[261,"for-pb-format"],[262,"for-pb-format"]],"For ckpt format":[[261,"for-ckpt-format"],[262,"for-ckpt-format"]],"Frequently Asked Questions":[[267,null]],"Full Publications/Events (91)":[[273,null]],"Functions":[[0,"functions"],[1,"functions"],[7,"functions"],[8,"functions"],[23,"functions"],[24,"functions"],[25,"functions"],[28,"functions"],[29,"functions"],[30,"functions"],[32,"functions"],[33,"functions"],[34,"functions"],[36,"functions"],[55,"functions"],[56,"functions"],[58,"functions"],[116,"functions"],[118,"functions"],[121,"functions"],[122,"functions"],[123,"functions"],[128,"functions"],[130,"functions"],[136,"functions"],[138,"functions"],[140,"functions"],[141,"functions"],[144,"functions"],[147,"functions"],[148,"functions"],[149,"functions"],[151,"functions"],[153,"functions"],[155,"functions"],[160,"functions"],[162,"functions"],[166,"functions"],[168,"functions"],[169,"functions"],[171,"functions"],[173,"functions"],[174,"functions"],[175,"functions"],[177,"functions"],[178,"functions"],[179,"functions"],[180,"functions"],[181,"functions"],[183,"functions"],[185,"functions"]],"GPT-J-6b":[[237,"gpt-j-6b"],[238,"gpt-j-6b"]],"GPTQ":[[199,"gptq"]],"Get Start with FP8 Quantization":[[192,"get-start-with-fp8-quantization"]],"Get Started":[[198,"get-started"],[199,"get-started"],[202,"get-started"],[214,"get-started"]],"Get Started with Microscaling Quantization API":[[193,"get-started-with-microscaling-quantization-api"]],"Get Started with NVFP4 Quantization API":[[195,"get-started-with-nvfp4-quantization-api"]],"Get Started with autotune API":[[194,"get-started-with-autotune-api"]],"Get the FP32 performance":[[258,"get-the-fp32-performance"]],"Get the INT8 performance":[[258,"get-the-int8-performance"]],"Getting Started":[[205,"getting-started"],[235,"getting-started"],[269,null]],"Getting Started with Dynamic Quantization":[[191,"getting-started-with-dynamic-quantization"]],"HQQ":[[199,"hqq"]],"Hardware and Software requests for BF16":[[194,"hardware-and-software-requests-for-bf16"]],"Hardware and Software requests for FP16":[[194,"hardware-and-software-requests-for-fp16"]],"High-Level Workflow":[[196,"high-level-workflow"]],"How it Works":[[213,"how-it-works"]],"Hugging Face QAT":[[235,"hugging-face-qat"]],"INC Coding Conventions":[[215,null]],"Image Generated":[[227,"image-generated"]],"ImageNet FP8 Quantization":[[221,null]],"ImageNet Quantization":[[223,null]],"Imports":[[215,"imports"]],"Inference":[[232,"inference"]],"Install Additional Dependency packages":[[264,"install-additional-dependency-packages"],[266,"install-additional-dependency-packages"]],"Install Dependency Package":[[253,"install-dependency-package"]],"Install Framework":[[205,"install-framework"],[270,"install-framework"]],"Install IPEX CPU":[[229,"install-ipex-cpu"]],"Install IPEX Intel GPU":[[229,"install-ipex-intel-gpu"]],"Install Intel Extension for Tensorflow":[[248,"install-intel-extension-for-tensorflow"],[249,"install-intel-extension-for-tensorflow"],[250,"install-intel-extension-for-tensorflow"],[251,"install-intel-extension-for-tensorflow"],[252,"install-intel-extension-for-tensorflow"],[253,"install-intel-extension-for-tensorflow"],[256,"install-intel-extension-for-tensorflow"],[260,"install-intel-extension-for-tensorflow"],[261,"install-intel-extension-for-tensorflow"],[262,"install-intel-extension-for-tensorflow"],[263,"install-intel-extension-for-tensorflow"],[264,"install-intel-extension-for-tensorflow"],[265,"install-intel-extension-for-tensorflow"],[266,"install-intel-extension-for-tensorflow"]],"Install Intel Tensorflow":[[248,"install-intel-tensorflow"],[256,"install-intel-tensorflow"],[260,"install-intel-tensorflow"],[261,"install-intel-tensorflow"],[262,"install-intel-tensorflow"],[264,"install-intel-tensorflow"],[266,"install-intel-tensorflow"]],"Install Intel Tensorflow 1.15 up2":[[250,"install-intel-tensorflow-1-15-up2"],[251,"install-intel-tensorflow-1-15-up2"],[252,"install-intel-tensorflow-1-15-up2"]],"Install Intel\u00ae Neural Compressor":[[248,"install-intel-neural-compressor"],[260,"install-intel-neural-compressor"],[261,"install-intel-neural-compressor"],[262,"install-intel-neural-compressor"],[263,"install-intel-neural-compressor"]],"Install Neural Compressor from pypi":[[205,"install-neural-compressor-from-pypi"]],"Install Protocol Buffer Compiler":[[260,"install-protocol-buffer-compiler"],[261,"install-protocol-buffer-compiler"],[262,"install-protocol-buffer-compiler"]],"Install Requirements":[[254,"install-requirements"],[255,"install-requirements"]],"Install Tensorflow":[[263,"install-tensorflow"]],"Install deepspeed":[[234,"install-deepspeed"]],"Install from Binary":[[270,"install-from-binary"]],"Install from Source":[[270,"install-from-source"]],"Install requirements":[[265,"install-requirements"]],"Install tensorflow":[[270,"install-tensorflow"]],"Install torch for CPU":[[270,"install-torch-for-cpu"]],"Install torch for other platform":[[270,"install-torch-for-other-platform"]],"Install torch/intel_extension_for_pytorch for Intel GPU":[[270,"install-torch-intel-extension-for-pytorch-for-intel-gpu"]],"Installation":[[192,"installation"],[192,"id2"],[205,"installation"],[249,"installation"],[250,"installation"],[251,"installation"],[252,"installation"],[254,"installation"],[255,"installation"],[256,"installation"],[257,"installation"],[264,"installation"],[265,"installation"],[266,"installation"],[270,null],[270,"id1"]],"Installation Dependency packages":[[248,"installation-dependency-packages"],[260,"installation-dependency-packages"],[261,"installation-dependency-packages"],[262,"installation-dependency-packages"],[263,"installation-dependency-packages"]],"Intel\u00ae Neural Compressor":[[205,null]],"Intel\u00ae Neural Compressor Documentation":[[187,null],[277,null]],"Intel\u00ae Neural Compressor supports CPUs based on Intel 64 architecture or compatible processors:":[[270,"intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors"]],"Intel\u00ae Neural Compressor supports GPUs built on Intel\u2019s Xe architecture:":[[270,"intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture"]],"Intel\u00ae Neural Compressor supports HPUs based on heterogeneous architecture with two compute engines (MME and TPC):":[[270,"intel-neural-compressor-supports-hpus-based-on-heterogeneous-architecture-with-two-compute-engines-mme-and-tpc"]],"Introduction":[[190,"introduction"],[191,"introduction"],[192,"introduction"],[193,"introduction"],[194,"introduction"],[195,"introduction"],[197,"introduction"],[198,"introduction"],[199,"introduction"],[200,"introduction"],[202,"introduction"],[203,"introduction"],[204,"introduction"],[214,"introduction"],[274,"introduction"],[275,"introduction"],[276,"introduction"]],"Issue 1:":[[267,"issue-1"]],"Issue 2:":[[267,"issue-2"]],"Issue 3:":[[267,"issue-3"]],"Issue 4:":[[267,"issue-4"]],"Issue 5:":[[267,"issue-5"]],"Issue 6:":[[267,"issue-6"]],"Issue 7:":[[267,"issue-7"]],"Issue 8:":[[267,"issue-8"]],"Issues":[[245,"issues"]],"JAX":[[190,null]],"Key Parameters for Mix Precision":[[193,"key-parameters-for-mix-precision"]],"LLAMA2-7b/13b/70b":[[237,"llama2-7b-13b-70b"],[238,"llama2-7b-13b-70b"]],"LLMs Quantization Recipes":[[272,null]],"Large Language Models Accuracy":[[272,"large-language-models-accuracy"]],"Large Language Models Recipes":[[272,"large-language-models-recipes"]],"Layer Wise Quantization":[[199,"layer-wise-quantization"]],"Legal Information":[[271,null]],"License":[[245,"license"],[271,"license"]],"Llama 3.1 70B MXFP8":[[232,"llama-3-1-70b-mxfp8"]],"Llama 3.1 70B NVFP4":[[232,"llama-3-1-70b-nvfp4"]],"Llama 3.1 70B uNVFP4":[[232,"llama-3-1-70b-unvfp4"]],"Llama 3.1 8B MXFP4 (Mixed with MXFP8, Target_bits=7.8)":[[232,"llama-3-1-8b-mxfp4-mixed-with-mxfp8-target-bits-7-8"]],"Llama 3.1 8B MXFP8":[[232,"llama-3-1-8b-mxfp8"]],"Llama 3.3 70B MXFP4 (Mixed with MXFP8, Target_bits=5.8)":[[232,"llama-3-3-70b-mxfp4-mixed-with-mxfp8-target-bits-5-8"]],"Llama 3.3 70B MXFP8":[[232,"llama-3-3-70b-mxfp8"]],"Llama3 Quantization Recipes":[[232,"llama3-quantization-recipes"]],"Load API":[[200,"load-api"]],"Logger":[[215,"logger"]],"MXFP Benchmark Script":[[232,"mxfp-benchmark-script"]],"MXFP4 & MXFP8":[[232,"mxfp4-mxfp8"]],"MXFP8 or FP8":[[225,"mxfp8-or-fp8"]],"Manual approach":[[256,"manual-approach"],[262,"manual-approach"],[266,"manual-approach"]],"Manual dataset download":[[260,"manual-dataset-download"],[261,"manual-dataset-download"],[262,"manual-dataset-download"]],"Manual download":[[263,"manual-download"]],"Matmul quantization example":[[274,"matmul-quantization-example"],[275,"matmul-quantization-example"]],"Memory / Performance Issues":[[196,"memory-performance-issues"]],"Microscaling Quantization":[[193,null]],"Mix Precision (MXFP4 + MXFP8)":[[193,"mix-precision-mxfp4-mxfp8"]],"Mixed Precision":[[204,"mixed-precision"]],"Mixed Precision Support Matrix":[[194,"mixed-precision-support-matrix"]],"MixedPrecision":[[222,"mixedprecision"]],"Model Examples":[[198,"model-examples"]],"Model Examples with PT2E":[[198,"model-examples-with-pt2e"]],"Model Information":[[228,"model-information"]],"Module Contents":[[0,"module-contents"],[1,"module-contents"],[3,"module-contents"],[4,"module-contents"],[6,"module-contents"],[7,"module-contents"],[8,"module-contents"],[14,"module-contents"],[15,"module-contents"],[17,"module-contents"],[19,"module-contents"],[20,"module-contents"],[23,"module-contents"],[24,"module-contents"],[25,"module-contents"],[28,"module-contents"],[29,"module-contents"],[30,"module-contents"],[32,"module-contents"],[33,"module-contents"],[34,"module-contents"],[36,"module-contents"],[37,"module-contents"],[38,"module-contents"],[39,"module-contents"],[41,"module-contents"],[42,"module-contents"],[43,"module-contents"],[44,"module-contents"],[45,"module-contents"],[46,"module-contents"],[47,"module-contents"],[48,"module-contents"],[49,"module-contents"],[50,"module-contents"],[51,"module-contents"],[52,"module-contents"],[53,"module-contents"],[54,"module-contents"],[55,"module-contents"],[56,"module-contents"],[57,"module-contents"],[58,"module-contents"],[59,"module-contents"],[60,"module-contents"],[61,"module-contents"],[62,"module-contents"],[63,"module-contents"],[65,"module-contents"],[66,"module-contents"],[67,"module-contents"],[68,"module-contents"],[69,"module-contents"],[70,"module-contents"],[71,"module-contents"],[72,"module-contents"],[73,"module-contents"],[74,"module-contents"],[76,"module-contents"],[77,"module-contents"],[78,"module-contents"],[79,"module-contents"],[80,"module-contents"],[81,"module-contents"],[83,"module-contents"],[84,"module-contents"],[85,"module-contents"],[86,"module-contents"],[88,"module-contents"],[89,"module-contents"],[90,"module-contents"],[91,"module-contents"],[94,"module-contents"],[95,"module-contents"],[96,"module-contents"],[97,"module-contents"],[98,"module-contents"],[99,"module-contents"],[100,"module-contents"],[102,"module-contents"],[103,"module-contents"],[104,"module-contents"],[105,"module-contents"],[106,"module-contents"],[107,"module-contents"],[108,"module-contents"],[109,"module-contents"],[110,"module-contents"],[111,"module-contents"],[112,"module-contents"],[114,"module-contents"],[115,"module-contents"],[116,"module-contents"],[118,"module-contents"],[120,"module-contents"],[121,"module-contents"],[122,"module-contents"],[123,"module-contents"],[125,"module-contents"],[128,"module-contents"],[129,"module-contents"],[130,"module-contents"],[131,"module-contents"],[133,"module-contents"],[135,"module-contents"],[136,"module-contents"],[137,"module-contents"],[138,"module-contents"],[140,"module-contents"],[141,"module-contents"],[143,"module-contents"],[144,"module-contents"],[145,"module-contents"],[147,"module-contents"],[148,"module-contents"],[149,"module-contents"],[151,"module-contents"],[152,"module-contents"],[153,"module-contents"],[154,"module-contents"],[155,"module-contents"],[156,"module-contents"],[157,"module-contents"],[158,"module-contents"],[160,"module-contents"],[161,"module-contents"],[162,"module-contents"],[164,"module-contents"],[165,"module-contents"],[166,"module-contents"],[167,"module-contents"],[168,"module-contents"],[169,"module-contents"],[171,"module-contents"],[173,"module-contents"],[174,"module-contents"],[175,"module-contents"],[177,"module-contents"],[178,"module-contents"],[179,"module-contents"],[180,"module-contents"],[181,"module-contents"],[182,"module-contents"],[183,"module-contents"],[185,"module-contents"]],"NVFP4":[[232,"nvfp4"]],"NVFP4 Quantization":[[195,null]],"OPT-125m":[[237,"opt-125m"],[238,"opt-125m"],[239,"opt-125m"]],"Optimum-habana LLM example":[[192,"optimum-habana-llm-example"]],"Other":[[264,"other"]],"Our Pledge":[[188,"our-pledge"]],"Our Responsibilities":[[188,"our-responsibilities"]],"Our Standards":[[188,"our-standards"]],"Our enhancement:":[[275,"our-enhancement"]],"Overview":[[192,"overview"],[192,"id1"],[196,"overview"],[213,"overview"]],"Per-channel example":[[274,"per-channel-example"],[275,"per-channel-example"]],"Per-channel limitation":[[274,"per-channel-limitation"],[275,"per-channel-limitation"]],"Per-tensor & Per-channel":[[274,"per-tensor-per-channel"],[275,"per-tensor-per-channel"]],"Per-tensor example":[[274,"per-tensor-example"],[275,"per-tensor-example"]],"Performance":[[239,"performance"],[240,"performance"]],"Post Training Static Quantization":[[204,"post-training-static-quantization"]],"Post-Training Static Quantization":[[190,"post-training-static-quantization"]],"Pre-Requisite":[[228,"pre-requisite"]],"Pre-Requisites":[[235,"pre-requisites"]],"Prepare Calibration set":[[265,"prepare-calibration-set"]],"Prepare Dependency Packages":[[276,"prepare-dependency-packages"]],"Prerequisite":[[222,"prerequisite"],[224,"prerequisite"],[225,"prerequisite"],[226,"prerequisite"],[227,"prerequisite"],[229,"prerequisite"],[230,"prerequisite"],[232,"prerequisite"],[237,"prerequisite"],[238,"prerequisite"],[239,"prerequisite"],[241,"prerequisite"],[242,"prerequisite"],[243,"prerequisite"],[246,"prerequisite"],[247,"prerequisite"],[248,"prerequisite"],[249,"prerequisite"],[250,"prerequisite"],[251,"prerequisite"],[252,"prerequisite"],[253,"prerequisite"],[254,"prerequisite"],[255,"prerequisite"],[256,"prerequisite"],[257,"prerequisite"],[258,"prerequisite"],[259,"prerequisite"],[260,"prerequisite"],[261,"prerequisite"],[262,"prerequisite"],[263,null],[264,"prerequisite"],[265,"prerequisite"],[266,"prerequisite"],[266,"id1"]],"Prerequisites":[[270,"prerequisites"]],"Prerequisite\u200b":[[240,"prerequisite"],[240,"id1"]],"Profiling":[[192,"profiling"]],"Prompt Tests":[[231,"prompt-tests"],[233,"prompt-tests"]],"Public and Internal Interfaces":[[215,"public-and-internal-interfaces"]],"Pull Request Acceptance Criteria":[[189,"pull-request-acceptance-criteria"]],"Pull Request Checklist":[[189,"pull-request-checklist"]],"Pull Request Status Checks Overview":[[189,"pull-request-status-checks-overview"]],"Pull Request Template":[[189,"pull-request-template"]],"Pull Requests":[[245,"pull-requests"]],"PyTorch Examples":[[193,"pytorch-examples"],[217,"pytorch-examples"]],"PyTorch Mixed Precision":[[194,null]],"PyTorch Quantization-Aware Training (QAT)":[[196,null]],"PyTorch Smooth Quantization":[[197,null]],"PyTorch Static Quantization":[[198,null]],"PyTorch Weight Only Quantization":[[199,null]],"Pytorch Quantization AutoTune":[[210,null]],"Pytorch Quantization Base API":[[211,null]],"Pytorch Quantization Config":[[212,null]],"QAT":[[235,"qat"]],"QAT Workflow and Benefits":[[196,"qat-workflow-and-benefits"]],"Quantizaiton":[[221,"quantizaiton"],[223,"quantizaiton"]],"Quantization":[[217,"quantization"],[217,"id1"],[224,"quantization"],[232,"quantization"],[237,"quantization"],[237,"id1"],[237,"id2"],[238,"quantization"],[238,"id1"],[238,"id2"],[239,"quantization"],[243,"quantization"],[254,"quantization"],[255,"quantization"],[256,"quantization"],[259,"quantization"],[264,"quantization"],[265,"quantization"],[266,"quantization"],[274,null]],"Quantization (CPU & HPU)":[[242,"quantization-cpu-hpu"]],"Quantization API":[[190,"quantization-api"]],"Quantization APIs":[[200,"quantization-apis"]],"Quantization Approaches":[[204,"quantization-approaches"]],"Quantization Aware Training":[[274,"quantization-aware-training"]],"Quantization Aware Training (QAT)":[[235,null]],"Quantization Config":[[266,"quantization-config"]],"Quantization Fundamentals":[[274,"quantization-fundamentals"],[275,"quantization-fundamentals"]],"Quantization Scheme":[[204,"quantization-scheme"]],"Quantization Scheme in IPEX":[[274,"quantization-scheme-in-ipex"]],"Quantization Scheme in PyTorch":[[274,"quantization-scheme-in-pytorch"]],"Quantization Scheme in TensorFlow":[[274,"quantization-scheme-in-tensorflow"]],"Quantization and Inference":[[228,"quantization-and-inference"]],"Quantization for CPU device":[[240,"quantization-for-cpu-device"]],"Quantization for GPU device":[[240,"quantization-for-gpu-device"]],"Quantization on Client":[[214,null]],"Quantize Model":[[231,"quantize-model"],[233,"quantize-model"]],"Quantize model with AutoRound on HPU":[[242,"quantize-model-with-autoround-on-hpu"]],"Quantizing the model on Intel CPU(Optional to install ITEX)":[[248,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[249,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[250,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[251,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[252,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[253,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[256,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[259,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[260,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[261,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[262,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[263,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[264,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[265,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"],[266,"quantizing-the-model-on-intel-cpu-optional-to-install-itex"]],"Quantizing the model on Intel GPU(Mandatory to install ITEX)":[[248,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[249,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[250,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[251,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[252,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[253,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[256,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[259,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[260,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[261,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[262,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[263,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[264,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[265,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"],[266,"quantizing-the-model-on-intel-gpu-mandatory-to-install-itex"]],"Quick Samples":[[269,"quick-samples"]],"Quick Start":[[196,"quick-start"]],"Qwen/Qwen2-7B-Instruct":[[241,"qwen-qwen2-7b-instruct"]],"RTN":[[199,"rtn"]],"Recommend VS Code settings.json":[[215,"recommend-vs-code-settings-json"]],"Recommended Workflow":[[196,"recommended-workflow"]],"Reference":[[193,"reference"],[195,"reference"],[199,"reference"],[215,"reference"],[274,"reference"],[275,"reference"]],"References":[[196,"references"]],"Report a Vulnerability":[[201,"report-a-vulnerability"]],"Requirement":[[231,null],[232,"requirement"],[233,null]],"Requirements":[[221,"requirements"],[223,"requirements"]],"Results":[[227,"results"]],"Rules":[[215,"rules"]],"Run":[[222,"run"],[224,"run"],[225,"run"],[227,"run"],[230,"run"],[234,"run"],[236,null],[237,"run"],[238,"run"],[239,"run"],[240,"run"],[240,"id3"],[242,"run"],[246,"run"],[248,"run"],[249,"run"],[250,"run"],[251,"run"],[252,"run"],[253,"run"],[257,"run"],[258,"run"],[260,"run"],[261,"run"],[263,"run"]],"Run Command":[[254,"run-command"],[255,"run-command"],[256,"run-command"],[259,"run-command"],[262,"run-command"],[264,"run-command"],[266,"run-command"]],"Run FP8 calibration":[[192,"run-fp8-calibration"]],"Run Quantization and evaluate INT8/INT4 accuracy":[[241,"run-quantization-and-evaluate-int8-int4-accuracy"]],"Run WOQ MX FP4 model":[[236,"run-woq-mx-fp4-model"]],"Run benchmark":[[192,"run-benchmark"]],"Run command":[[265,"run-command"]],"Run with CPU":[[226,"run-with-cpu"],[229,"run-with-cpu"],[247,"run-with-cpu"]],"Run with Intel GPU":[[229,"run-with-intel-gpu"]],"Running with FP8":[[192,"running-with-fp8"]],"Saving and Loading":[[199,"saving-and-loading"]],"Scope":[[188,"scope"]],"Sections":[[187,"sections"],[277,"sections"]],"Security Policy":[[201,null]],"Selected Publications/Events":[[205,"selected-publications-events"]],"Smooth Quant":[[203,null],[275,null]],"Smooth Quantization":[[204,"smooth-quantization"],[257,"smooth-quantization"],[274,"smooth-quantization"]],"Smooth quant":[[258,"smooth-quant"]],"SmoothQuant":[[275,"smoothquant"]],"SmoothQuant and Our Enhancement":[[275,"smoothquant-and-our-enhancement"]],"Specify Quantization Rules":[[197,"specify-quantization-rules"],[198,"specify-quantization-rules"],[199,"specify-quantization-rules"],[202,"specify-quantization-rules"]],"Stable Diffusion":[[228,null]],"Start client to test":[[192,"start-client-to-test"]],"Start vllm server":[[192,"start-vllm-server"]],"Static Quantization":[[274,"static-quantization"]],"Static Quantization with IPEX Backend":[[198,"static-quantization-with-ipex-backend"]],"Static Quantization with PT2E Backend":[[198,"static-quantization-with-pt2e-backend"]],"Step 1:":[[235,"step-1"]],"Step 2:":[[235,"step-2"]],"Step 3:":[[235,"step-3"]],"Step-by-Step":[[222,null],[224,null],[225,null],[226,null],[227,null],[229,null],[230,null],[237,null],[238,null],[239,null],[240,null],[243,null],[246,null],[247,null],[248,null],[249,null],[250,null],[251,null],[252,null],[253,null],[254,null],[255,null],[256,null],[257,null],[258,null],[259,null],[260,null],[261,null],[262,null],[264,null],[265,null],[266,null]],"Step-by-Step guidelines":[[189,"step-by-step-guidelines"]],"Step-by-Step recipes for LLM quantization":[[241,null]],"Step-by-step":[[232,null],[234,null]],"Strings":[[215,"strings"]],"Submodules":[[2,"submodules"],[5,"submodules"],[10,"submodules"],[12,"submodules"],[13,"submodules"],[16,"submodules"],[18,"submodules"],[21,"submodules"],[22,"submodules"],[26,"submodules"],[31,"submodules"],[35,"submodules"],[40,"submodules"],[64,"submodules"],[75,"submodules"],[82,"submodules"],[87,"submodules"],[92,"submodules"],[93,"submodules"],[101,"submodules"],[113,"submodules"],[119,"submodules"],[124,"submodules"],[126,"submodules"],[127,"submodules"],[132,"submodules"],[134,"submodules"],[139,"submodules"],[142,"submodules"],[146,"submodules"],[150,"submodules"],[159,"submodules"],[163,"submodules"],[170,"submodules"],[172,"submodules"],[176,"submodules"],[184,"submodules"]],"Support":[[189,"support"]],"Support Matrix":[[192,"support-matrix"],[204,"support-matrix"]],"Support status on CPU":[[242,"support-status-on-cpu"]],"Support status on HPU":[[242,"support-status-on-hpu"]],"Supported Algorithms":[[276,"supported-algorithms"]],"Supported Framework Matrix":[[197,"supported-framework-matrix"],[275,"supported-framework-matrix"]],"Supported Matrix":[[199,"supported-matrix"],[200,"supported-matrix"]],"Supported Parameters":[[192,"supported-parameters"]],"Symmetric & Asymmetric":[[274,"symmetric-asymmetric"]],"System Requirements":[[270,"system-requirements"]],"TEQ":[[199,"teq"]],"THUDM/chatglm2-6b":[[241,"thudm-chatglm2-6b"]],"THUDM/chatglm3-6b":[[241,"thudm-chatglm3-6b"]],"TODO Comments":[[215,"todo-comments"]],"Target Bits Configuration":[[193,"target-bits-configuration"]],"Target_bits":[[232,"target-bits"]],"TensorFlow":[[204,null]],"TensorFlow Examples":[[217,"tensorflow-examples"]],"TensorFlow Quantization":[[202,null]],"Tensorflow Quantization AutoTune":[[207,null]],"Tensorflow Quantization Base API":[[208,null]],"Tensorflow Quantization Config":[[209,null]],"Torch":[[200,null]],"Torch-like APIs":[[200,"torch-like-apis"]],"Trademarks":[[271,"trademarks"]],"Transformers-like API":[[276,null]],"Tune":[[257,"tune"],[259,"tune"]],"Type Annotations":[[215,"type-annotations"]],"Understanding the Scaling Mechanism":[[195,"understanding-the-scaling-mechanism"]],"Usage":[[197,"usage"],[199,"usage"],[203,"usage"]],"Usage Example":[[193,"usage-example"]],"Usage For CPU":[[276,"usage-for-cpu"]],"Usage For Intel GPU":[[276,"usage-for-intel-gpu"]],"Usage Sample with IPEX":[[198,"usage-sample-with-ipex"]],"Usage Sample with PT2E":[[198,"usage-sample-with-pt2e"]],"Usage demo:":[[218,null]],"Usage examples for CPU device":[[276,"usage-examples-for-cpu-device"]],"Use Docker Image with torch installed for HPU":[[270,"use-docker-image-with-torch-installed-for-hpu"]],"Use Dummy Data":[[223,"use-dummy-data"]],"User Code Analysis":[[248,"user-code-analysis"],[257,"user-code-analysis"],[260,"user-code-analysis"],[261,"user-code-analysis"],[262,"user-code-analysis"],[266,"user-code-analysis"]],"Using a Fixed alpha":[[203,"using-a-fixed-alpha"]],"VLLM example":[[192,"vllm-example"]],"Validated Hardware Environment":[[270,"validated-hardware-environment"]],"Validated Models":[[241,"validated-models"]],"Validated Software Environment":[[270,"validated-software-environment"]],"Version mapping between Intel Neural Compressor to Gaudi Software Stack":[[268,null]],"Weight Only Quantization":[[274,"weight-only-quantization"]],"Weight-Only Quantization":[[241,"weight-only-quantization"],[241,"id1"],[241,"id2"],[241,"id3"],[241,"id4"],[241,"id5"],[241,"id6"],[241,"id7"],[241,"id8"],[241,"id9"],[241,"id10"],[241,"id11"],[241,"id12"]],"Weight-only quantization":[[242,null]],"What\u2019s New":[[205,"what-s-new"]],"Why QAT?":[[196,"why-qat"]],"With Accuracy Aware Tuning":[[202,"with-accuracy-aware-tuning"]],"Without Accuracy Aware Tuning":[[202,"without-accuracy-aware-tuning"]],"Workflows":[[216,"workflows"]],"Working with Autotune":[[213,"working-with-autotune"]],"Working with PyTorch Model":[[213,"working-with-pytorch-model"]],"Working with Tensorflow Model":[[213,"working-with-tensorflow-model"]],"baichuan-inc/Baichuan2-13B-Chat":[[241,"baichuan-inc-baichuan2-13b-chat"]],"baichuan-inc/Baichuan2-7B-Chat":[[241,"baichuan-inc-baichuan2-7b-chat"]],"benchmark":[[246,"benchmark"]],"calib_dataloader Part Adaption":[[257,"calib-dataloader-part-adaption"]],"facebook/opt-30b":[[241,"facebook-opt-30b"]],"meta-llama/Llama-2-13b-hf":[[241,"meta-llama-llama-2-13b-hf"]],"meta-llama/Llama-2-70b-hf":[[234,"meta-llama-llama-2-70b-hf"]],"meta-llama/Llama-2-7b-hf":[[241,"meta-llama-llama-2-7b-hf"]],"meta-llama/Llama-3.1-405B-Instruct":[[234,"meta-llama-llama-3-1-405b-instruct"]],"meta-llama/Meta-Llama-3.1-8B-Instruct":[[241,"meta-llama-meta-llama-3-1-8b-instruct"]],"microsoft/Phi-3-medium-128k-instruct":[[241,"microsoft-phi-3-medium-128k-instruct"]],"microsoft/Phi-3-mini-128k-instruct":[[241,"microsoft-phi-3-mini-128k-instruct"]],"mistralai/Mistral-7B-v0.1":[[241,"mistralai-mistral-7b-v0-1"]],"neural_compressor":[[10,null]],"neural_compressor.common":[[2,null]],"neural_compressor.common.base_config":[[0,null]],"neural_compressor.common.base_tuning":[[1,null]],"neural_compressor.common.tuning_param":[[3,null]],"neural_compressor.common.utils":[[5,null]],"neural_compressor.common.utils.constants":[[4,null]],"neural_compressor.common.utils.logger":[[6,null]],"neural_compressor.common.utils.save_load":[[7,null]],"neural_compressor.common.utils.utility":[[8,null]],"neural_compressor.common.version":[[9,null]],"neural_compressor.jax":[[12,null]],"neural_compressor.jax.algorithms":[[11,null]],"neural_compressor.tensorflow":[[21,null]],"neural_compressor.tensorflow.algorithms":[[13,null]],"neural_compressor.tensorflow.algorithms.smoother":[[16,null]],"neural_compressor.tensorflow.algorithms.smoother.calibration":[[14,null]],"neural_compressor.tensorflow.algorithms.smoother.core":[[15,null]],"neural_compressor.tensorflow.algorithms.smoother.scaler":[[17,null]],"neural_compressor.tensorflow.algorithms.static_quant":[[18,null]],"neural_compressor.tensorflow.algorithms.static_quant.keras":[[19,null]],"neural_compressor.tensorflow.algorithms.static_quant.tensorflow":[[20,null]],"neural_compressor.tensorflow.keras":[[22,null]],"neural_compressor.tensorflow.keras.layers":[[26,null]],"neural_compressor.tensorflow.keras.layers.conv2d":[[23,null]],"neural_compressor.tensorflow.keras.layers.dense":[[24,null]],"neural_compressor.tensorflow.keras.layers.depthwise_conv2d":[[25,null]],"neural_compressor.tensorflow.keras.layers.layer_initializer":[[27,null]],"neural_compressor.tensorflow.keras.layers.pool2d":[[28,null]],"neural_compressor.tensorflow.keras.layers.separable_conv2d":[[29,null]],"neural_compressor.tensorflow.keras.quantization":[[31,null]],"neural_compressor.tensorflow.keras.quantization.config":[[30,null]],"neural_compressor.tensorflow.quantization":[[35,null]],"neural_compressor.tensorflow.quantization.algorithm_entry":[[32,null]],"neural_compressor.tensorflow.quantization.autotune":[[33,null]],"neural_compressor.tensorflow.quantization.config":[[34,null]],"neural_compressor.tensorflow.quantization.quantize":[[36,null]],"neural_compressor.tensorflow.quantization.utils":[[92,null]],"neural_compressor.tensorflow.quantization.utils.graph_converter":[[37,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter":[[75,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16":[[40,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert":[[38,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer":[[39,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic":[[64,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd":[[41,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout":[[42,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu":[[43,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random":[[44,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const":[[45,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction":[[46,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd":[[47,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer":[[48,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape":[[49,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm":[[50,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant":[[51,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add":[[52,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul":[[53,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math":[[54,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn":[[55,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in":[[56,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu":[[57,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm":[[58,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv":[[59,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv":[[60,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose":[[61,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer":[[62,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass":[[63,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node":[[65,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu":[[66,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize":[[67,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes":[[68,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm":[[69,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input":[[70,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes":[[71,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes":[[72,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer":[[73,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base":[[74,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8":[[82,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant":[[76,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value":[[77,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize":[[78,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize":[[79,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize":[[80,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize":[[81,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer":[[83,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter":[[84,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse":[[85,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation":[[86,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq":[[87,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern":[[88,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq":[[89,null]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern":[[90,null]],"neural_compressor.tensorflow.quantization.utils.graph_util":[[91,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph":[[93,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq":[[101,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn":[[94,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2":[[95,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv":[[96,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv":[[97,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in":[[98,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul":[[99,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling":[[100,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq":[[102,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base":[[103,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn":[[104,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2":[[105,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv":[[106,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu":[[107,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul":[[108,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling":[[109,null]],"neural_compressor.tensorflow.quantization.utils.quantize_graph_common":[[110,null]],"neural_compressor.tensorflow.quantization.utils.transform_graph":[[113,null]],"neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction":[[111,null]],"neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base":[[112,null]],"neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging":[[114,null]],"neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat":[[115,null]],"neural_compressor.tensorflow.quantization.utils.utility":[[116,null]],"neural_compressor.tensorflow.utils":[[119,null]],"neural_compressor.tensorflow.utils.constants":[[117,null]],"neural_compressor.tensorflow.utils.data":[[118,null]],"neural_compressor.tensorflow.utils.model":[[120,null]],"neural_compressor.tensorflow.utils.model_wrappers":[[121,null]],"neural_compressor.tensorflow.utils.utility":[[122,null]],"neural_compressor.torch":[[172,null]],"neural_compressor.torch.algorithms":[[126,null]],"neural_compressor.torch.algorithms.autoround":[[124,null]],"neural_compressor.torch.algorithms.autoround.autoround":[[123,null]],"neural_compressor.torch.algorithms.base_algorithm":[[125,null]],"neural_compressor.torch.algorithms.layer_wise":[[127,null]],"neural_compressor.torch.algorithms.layer_wise.load":[[128,null]],"neural_compressor.torch.algorithms.layer_wise.modified_pickle":[[129,null]],"neural_compressor.torch.algorithms.layer_wise.utils":[[130,null]],"neural_compressor.torch.algorithms.mixed_precision":[[132,null]],"neural_compressor.torch.algorithms.mixed_precision.half_precision_convert":[[131,null]],"neural_compressor.torch.algorithms.mixed_precision.module_wrappers":[[133,null]],"neural_compressor.torch.algorithms.mx_quant":[[134,null]],"neural_compressor.torch.algorithms.mx_quant.mx":[[135,null]],"neural_compressor.torch.algorithms.mx_quant.utils":[[136,null]],"neural_compressor.torch.algorithms.pt2e_quant":[[139,null]],"neural_compressor.torch.algorithms.pt2e_quant.core":[[137,null]],"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter":[[138,null]],"neural_compressor.torch.algorithms.pt2e_quant.save_load":[[140,null]],"neural_compressor.torch.algorithms.pt2e_quant.utility":[[141,null]],"neural_compressor.torch.algorithms.qat":[[142,null]],"neural_compressor.torch.algorithms.qat.quant_linear":[[143,null]],"neural_compressor.torch.algorithms.qat.quant_utils":[[144,null]],"neural_compressor.torch.algorithms.qat.tensor_quantizer":[[145,null]],"neural_compressor.torch.algorithms.smooth_quant":[[146,null]],"neural_compressor.torch.algorithms.smooth_quant.save_load":[[147,null]],"neural_compressor.torch.algorithms.smooth_quant.smooth_quant":[[148,null]],"neural_compressor.torch.algorithms.smooth_quant.utility":[[149,null]],"neural_compressor.torch.algorithms.static_quant":[[150,null]],"neural_compressor.torch.algorithms.static_quant.save_load":[[151,null]],"neural_compressor.torch.algorithms.static_quant.static_quant":[[152,null]],"neural_compressor.torch.algorithms.static_quant.utility":[[153,null]],"neural_compressor.torch.algorithms.weight_only":[[163,null]],"neural_compressor.torch.algorithms.weight_only.awq":[[154,null]],"neural_compressor.torch.algorithms.weight_only.gptq":[[155,null]],"neural_compressor.torch.algorithms.weight_only.hqq":[[159,null]],"neural_compressor.torch.algorithms.weight_only.hqq.bitpack":[[156,null]],"neural_compressor.torch.algorithms.weight_only.hqq.config":[[157,null]],"neural_compressor.torch.algorithms.weight_only.hqq.core":[[158,null]],"neural_compressor.torch.algorithms.weight_only.hqq.optimizer":[[160,null]],"neural_compressor.torch.algorithms.weight_only.hqq.qtensor":[[161,null]],"neural_compressor.torch.algorithms.weight_only.hqq.quantizer":[[162,null]],"neural_compressor.torch.algorithms.weight_only.modules":[[164,null]],"neural_compressor.torch.algorithms.weight_only.rtn":[[165,null]],"neural_compressor.torch.algorithms.weight_only.save_load":[[166,null]],"neural_compressor.torch.algorithms.weight_only.teq":[[167,null]],"neural_compressor.torch.algorithms.weight_only.utility":[[168,null]],"neural_compressor.torch.export":[[170,null]],"neural_compressor.torch.export.export_hf":[[169,null]],"neural_compressor.torch.export.pt2e_export":[[171,null]],"neural_compressor.torch.quantization":[[176,null]],"neural_compressor.torch.quantization.algorithm_entry":[[173,null]],"neural_compressor.torch.quantization.autotune":[[174,null]],"neural_compressor.torch.quantization.config":[[175,null]],"neural_compressor.torch.quantization.quantize":[[177,null]],"neural_compressor.torch.quantization.save_load_entry":[[178,null]],"neural_compressor.torch.utils":[[184,null]],"neural_compressor.torch.utils.auto_accelerator":[[179,null]],"neural_compressor.torch.utils.bit_packer":[[180,null]],"neural_compressor.torch.utils.block_wise":[[181,null]],"neural_compressor.torch.utils.constants":[[182,null]],"neural_compressor.torch.utils.environ":[[183,null]],"neural_compressor.torch.utils.utility":[[185,null]],"neural_compressor.version":[[186,null]],"one step to get quantized model":[[218,"one-step-to-get-quantized-model"]],"q_dataloader Part Adaption":[[259,"q-dataloader-part-adaption"]],"tiiuae/falcon-40b":[[241,"tiiuae-falcon-40b"]],"tiiuae/falcon-7b":[[241,"tiiuae-falcon-7b"]],"tune with INC":[[246,"tune-with-inc"]],"two steps to get quantized model":[[218,"two-steps-to-get-quantized-model"]],"uNVFP4":[[232,"unvfp4"]]},"docnames":["autoapi/neural_compressor/common/base_config/index","autoapi/neural_compressor/common/base_tuning/index","autoapi/neural_compressor/common/index","autoapi/neural_compressor/common/tuning_param/index","autoapi/neural_compressor/common/utils/constants/index","autoapi/neural_compressor/common/utils/index","autoapi/neural_compressor/common/utils/logger/index","autoapi/neural_compressor/common/utils/save_load/index","autoapi/neural_compressor/common/utils/utility/index","autoapi/neural_compressor/common/version/index","autoapi/neural_compressor/index","autoapi/neural_compressor/jax/algorithms/index","autoapi/neural_compressor/jax/index","autoapi/neural_compressor/tensorflow/algorithms/index","autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index","autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index","autoapi/neural_compressor/tensorflow/algorithms/smoother/index","autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index","autoapi/neural_compressor/tensorflow/algorithms/static_quant/index","autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index","autoapi/neural_compressor/tensorflow/algorithms/static_quant/tensorflow/index","autoapi/neural_compressor/tensorflow/index","autoapi/neural_compressor/tensorflow/keras/index","autoapi/neural_compressor/tensorflow/keras/layers/conv2d/index","autoapi/neural_compressor/tensorflow/keras/layers/dense/index","autoapi/neural_compressor/tensorflow/keras/layers/depthwise_conv2d/index","autoapi/neural_compressor/tensorflow/keras/layers/index","autoapi/neural_compressor/tensorflow/keras/layers/layer_initializer/index","autoapi/neural_compressor/tensorflow/keras/layers/pool2d/index","autoapi/neural_compressor/tensorflow/keras/layers/separable_conv2d/index","autoapi/neural_compressor/tensorflow/keras/quantization/config/index","autoapi/neural_compressor/tensorflow/keras/quantization/index","autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index","autoapi/neural_compressor/tensorflow/quantization/autotune/index","autoapi/neural_compressor/tensorflow/quantization/config/index","autoapi/neural_compressor/tensorflow/quantization/index","autoapi/neural_compressor/tensorflow/quantization/quantize/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/bf16_convert/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/dequantize_cast_optimizer/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_fake_quant/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_requantize/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_requantize/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/meta_op_optimizer/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_hostconst_converter/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_quantized_op_cse/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/scale_propagation/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/insert_qdq_pattern/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/merge_duplicated_qdq/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/share_qdq_y_pattern/index","autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index","autoapi/neural_compressor/tensorflow/quantization/utils/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_bn/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_concatv2/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_conv/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_deconv/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_in/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_matmul/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_pooling/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/optimize_qdq/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_base/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_bn/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_concatv2/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_conv/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_for_intel_cpu/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_matmul/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_pooling/index","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/bias_correction/index","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/graph_transform_base/index","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/index","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/insert_logging/index","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/rerange_quantized_concat/index","autoapi/neural_compressor/tensorflow/quantization/utils/utility/index","autoapi/neural_compressor/tensorflow/utils/constants/index","autoapi/neural_compressor/tensorflow/utils/data/index","autoapi/neural_compressor/tensorflow/utils/index","autoapi/neural_compressor/tensorflow/utils/model/index","autoapi/neural_compressor/tensorflow/utils/model_wrappers/index","autoapi/neural_compressor/tensorflow/utils/utility/index","autoapi/neural_compressor/torch/algorithms/autoround/autoround/index","autoapi/neural_compressor/torch/algorithms/autoround/index","autoapi/neural_compressor/torch/algorithms/base_algorithm/index","autoapi/neural_compressor/torch/algorithms/index","autoapi/neural_compressor/torch/algorithms/layer_wise/index","autoapi/neural_compressor/torch/algorithms/layer_wise/load/index","autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index","autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index","autoapi/neural_compressor/torch/algorithms/mixed_precision/half_precision_convert/index","autoapi/neural_compressor/torch/algorithms/mixed_precision/index","autoapi/neural_compressor/torch/algorithms/mixed_precision/module_wrappers/index","autoapi/neural_compressor/torch/algorithms/mx_quant/index","autoapi/neural_compressor/torch/algorithms/mx_quant/mx/index","autoapi/neural_compressor/torch/algorithms/mx_quant/utils/index","autoapi/neural_compressor/torch/algorithms/pt2e_quant/core/index","autoapi/neural_compressor/torch/algorithms/pt2e_quant/half_precision_rewriter/index","autoapi/neural_compressor/torch/algorithms/pt2e_quant/index","autoapi/neural_compressor/torch/algorithms/pt2e_quant/save_load/index","autoapi/neural_compressor/torch/algorithms/pt2e_quant/utility/index","autoapi/neural_compressor/torch/algorithms/qat/index","autoapi/neural_compressor/torch/algorithms/qat/quant_linear/index","autoapi/neural_compressor/torch/algorithms/qat/quant_utils/index","autoapi/neural_compressor/torch/algorithms/qat/tensor_quantizer/index","autoapi/neural_compressor/torch/algorithms/smooth_quant/index","autoapi/neural_compressor/torch/algorithms/smooth_quant/save_load/index","autoapi/neural_compressor/torch/algorithms/smooth_quant/smooth_quant/index","autoapi/neural_compressor/torch/algorithms/smooth_quant/utility/index","autoapi/neural_compressor/torch/algorithms/static_quant/index","autoapi/neural_compressor/torch/algorithms/static_quant/save_load/index","autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index","autoapi/neural_compressor/torch/algorithms/static_quant/utility/index","autoapi/neural_compressor/torch/algorithms/weight_only/awq/index","autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index","autoapi/neural_compressor/torch/algorithms/weight_only/index","autoapi/neural_compressor/torch/algorithms/weight_only/modules/index","autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index","autoapi/neural_compressor/torch/algorithms/weight_only/save_load/index","autoapi/neural_compressor/torch/algorithms/weight_only/teq/index","autoapi/neural_compressor/torch/algorithms/weight_only/utility/index","autoapi/neural_compressor/torch/export/export_hf/index","autoapi/neural_compressor/torch/export/index","autoapi/neural_compressor/torch/export/pt2e_export/index","autoapi/neural_compressor/torch/index","autoapi/neural_compressor/torch/quantization/algorithm_entry/index","autoapi/neural_compressor/torch/quantization/autotune/index","autoapi/neural_compressor/torch/quantization/config/index","autoapi/neural_compressor/torch/quantization/index","autoapi/neural_compressor/torch/quantization/quantize/index","autoapi/neural_compressor/torch/quantization/save_load_entry/index","autoapi/neural_compressor/torch/utils/auto_accelerator/index","autoapi/neural_compressor/torch/utils/bit_packer/index","autoapi/neural_compressor/torch/utils/block_wise/index","autoapi/neural_compressor/torch/utils/constants/index","autoapi/neural_compressor/torch/utils/environ/index","autoapi/neural_compressor/torch/utils/index","autoapi/neural_compressor/torch/utils/utility/index","autoapi/neural_compressor/version/index","docs/build_docs/source/index","docs/source/CODE_OF_CONDUCT","docs/source/CONTRIBUTING","docs/source/JAX","docs/source/PT_DynamicQuant","docs/source/PT_FP8Quant","docs/source/PT_MXQuant","docs/source/PT_MixedPrecision","docs/source/PT_NVFP4Quant","docs/source/PT_QAT","docs/source/PT_SmoothQuant","docs/source/PT_StaticQuant","docs/source/PT_WeightOnlyQuant","docs/source/PyTorch","docs/source/SECURITY","docs/source/TF_Quant","docs/source/TF_SQ","docs/source/TensorFlow","docs/source/Welcome","docs/source/api-doc/apis","docs/source/api-doc/tf_quantization_autotune","docs/source/api-doc/tf_quantization_common","docs/source/api-doc/tf_quantization_config","docs/source/api-doc/torch_quantization_autotune","docs/source/api-doc/torch_quantization_common","docs/source/api-doc/torch_quantization_config","docs/source/autotune","docs/source/client_quant","docs/source/coding_style","docs/source/design","docs/source/examples/README","docs/source/examples/helloworld/fp8_example/README","docs/source/examples/jax/keras/gemma/README","docs/source/examples/jax/keras/vit/README","docs/source/examples/pytorch/cv/fp8_quant/README","docs/source/examples/pytorch/cv/mixed_precision/README","docs/source/examples/pytorch/cv/static_quant/README","docs/source/examples/pytorch/diffusion_model/diffusers/flux/README","docs/source/examples/pytorch/diffusion_model/diffusers/framepack/README","docs/source/examples/pytorch/diffusion_model/diffusers/stable_diffusion/fp8_quant/README","docs/source/examples/pytorch/diffusion_model/diffusers/stable_diffusion/smooth_quant/README","docs/source/examples/pytorch/diffusion_model/diffusers/stable_diffusion/static_quant/README","docs/source/examples/pytorch/image_recognition/torchvision_models/quantization/static_quant/ipex/README","docs/source/examples/pytorch/multimodal-modeling/quantization/auto_round/llama4/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/auto_round/deepseek/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/auto_round/llama3/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/auto_round/qwen/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/fp8_quant/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/llm_qat/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/mx_quant/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/smooth_quant/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/static_quant/ipex/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/static_quant/pt2e/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/transformers/weight_only/text-generation/README","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/transformers/weight_only/text-generation/llm_quantization_recipes","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/weight_only/README","docs/source/examples/pytorch/nlp/huggingface_models/question-answering/quantization/static_quant/ipex/README","docs/source/examples/pytorch/recommendation/dlrm/static_quant/ipex/CODE_OF_CONDUCT","docs/source/examples/pytorch/recommendation/dlrm/static_quant/ipex/CONTRIBUTING","docs/source/examples/pytorch/recommendation/dlrm/static_quant/ipex/README","docs/source/examples/pytorch/recommendation/dlrm_v2/fp8_quant/cpu/README","docs/source/examples/tensorflow/graph_networks/graphsage/quantization/ptq/README","docs/source/examples/tensorflow/image_recognition/inception_v3/quantization/ptq/README","docs/source/examples/tensorflow/image_recognition/mobilenet_v2/quantization/ptq/README","docs/source/examples/tensorflow/image_recognition/resnet_v2_50/quantization/ptq/README","docs/source/examples/tensorflow/image_recognition/vgg16/quantization/ptq/README","docs/source/examples/tensorflow/image_recognition/vision_transformer/quantization/ptq/README","docs/source/examples/tensorflow/keras/image_recognition/inception_v3/quantization/ptq/README","docs/source/examples/tensorflow/keras/image_recognition/resnet_v2_50/quantization/ptq/README","docs/source/examples/tensorflow/nlp/bert_large_squad_model_zoo/quantization/ptq/README","docs/source/examples/tensorflow/nlp/large_language_models/quantization/ptq/gpt-j/README","docs/source/examples/tensorflow/nlp/large_language_models/quantization/ptq/smoothquant/README","docs/source/examples/tensorflow/nlp/transformer_lt/quantization/ptq/README","docs/source/examples/tensorflow/object_detection/faster_rcnn_resnet50/quantization/ptq/README","docs/source/examples/tensorflow/object_detection/mask_rcnn_inception_v2/quantization/ptq/README","docs/source/examples/tensorflow/object_detection/ssd_mobilenet_v1/quantization/ptq/README","docs/source/examples/tensorflow/object_detection/yolo_v5/quantization/ptq/README","docs/source/examples/tensorflow/recommendation/wide_deep_large_ds/quantization/ptq/README","docs/source/examples/tensorflow/semantic_image_segmentation/3dunet-mlperf/quantization/ptq/README","docs/source/examples/tensorflow/style_transfer/arbitrary_style_transfer/quantization/ptq/README","docs/source/faq","docs/source/gaudi_version_map","docs/source/get_started","docs/source/installation_guide","docs/source/legal_information","docs/source/llm_recipes","docs/source/publication_list","docs/source/quantization","docs/source/smooth_quant","docs/source/transformers_like_api","index"],"envversion":{"sphinx":65,"sphinx.domains.c":3,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":9,"sphinx.domains.index":1,"sphinx.domains.javascript":3,"sphinx.domains.math":2,"sphinx.domains.python":4,"sphinx.domains.rst":2,"sphinx.domains.std":2},"filenames":["autoapi/neural_compressor/common/base_config/index.rst","autoapi/neural_compressor/common/base_tuning/index.rst","autoapi/neural_compressor/common/index.rst","autoapi/neural_compressor/common/tuning_param/index.rst","autoapi/neural_compressor/common/utils/constants/index.rst","autoapi/neural_compressor/common/utils/index.rst","autoapi/neural_compressor/common/utils/logger/index.rst","autoapi/neural_compressor/common/utils/save_load/index.rst","autoapi/neural_compressor/common/utils/utility/index.rst","autoapi/neural_compressor/common/version/index.rst","autoapi/neural_compressor/index.rst","autoapi/neural_compressor/jax/algorithms/index.rst","autoapi/neural_compressor/jax/index.rst","autoapi/neural_compressor/tensorflow/algorithms/index.rst","autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index.rst","autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index.rst","autoapi/neural_compressor/tensorflow/algorithms/smoother/index.rst","autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index.rst","autoapi/neural_compressor/tensorflow/algorithms/static_quant/index.rst","autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index.rst","autoapi/neural_compressor/tensorflow/algorithms/static_quant/tensorflow/index.rst","autoapi/neural_compressor/tensorflow/index.rst","autoapi/neural_compressor/tensorflow/keras/index.rst","autoapi/neural_compressor/tensorflow/keras/layers/conv2d/index.rst","autoapi/neural_compressor/tensorflow/keras/layers/dense/index.rst","autoapi/neural_compressor/tensorflow/keras/layers/depthwise_conv2d/index.rst","autoapi/neural_compressor/tensorflow/keras/layers/index.rst","autoapi/neural_compressor/tensorflow/keras/layers/layer_initializer/index.rst","autoapi/neural_compressor/tensorflow/keras/layers/pool2d/index.rst","autoapi/neural_compressor/tensorflow/keras/layers/separable_conv2d/index.rst","autoapi/neural_compressor/tensorflow/keras/quantization/config/index.rst","autoapi/neural_compressor/tensorflow/keras/quantization/index.rst","autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index.rst","autoapi/neural_compressor/tensorflow/quantization/autotune/index.rst","autoapi/neural_compressor/tensorflow/quantization/config/index.rst","autoapi/neural_compressor/tensorflow/quantization/index.rst","autoapi/neural_compressor/tensorflow/quantization/quantize/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/bf16_convert/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/dequantize_cast_optimizer/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_fake_quant/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_requantize/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_requantize/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/meta_op_optimizer/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_hostconst_converter/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_quantized_op_cse/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/scale_propagation/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/insert_qdq_pattern/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/merge_duplicated_qdq/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/share_qdq_y_pattern/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_bn/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_concatv2/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_conv/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_deconv/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_in/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_matmul/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_pooling/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/optimize_qdq/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_base/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_bn/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_concatv2/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_conv/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_for_intel_cpu/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_matmul/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_pooling/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/bias_correction/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/graph_transform_base/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/insert_logging/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/rerange_quantized_concat/index.rst","autoapi/neural_compressor/tensorflow/quantization/utils/utility/index.rst","autoapi/neural_compressor/tensorflow/utils/constants/index.rst","autoapi/neural_compressor/tensorflow/utils/data/index.rst","autoapi/neural_compressor/tensorflow/utils/index.rst","autoapi/neural_compressor/tensorflow/utils/model/index.rst","autoapi/neural_compressor/tensorflow/utils/model_wrappers/index.rst","autoapi/neural_compressor/tensorflow/utils/utility/index.rst","autoapi/neural_compressor/torch/algorithms/autoround/autoround/index.rst","autoapi/neural_compressor/torch/algorithms/autoround/index.rst","autoapi/neural_compressor/torch/algorithms/base_algorithm/index.rst","autoapi/neural_compressor/torch/algorithms/index.rst","autoapi/neural_compressor/torch/algorithms/layer_wise/index.rst","autoapi/neural_compressor/torch/algorithms/layer_wise/load/index.rst","autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index.rst","autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index.rst","autoapi/neural_compressor/torch/algorithms/mixed_precision/half_precision_convert/index.rst","autoapi/neural_compressor/torch/algorithms/mixed_precision/index.rst","autoapi/neural_compressor/torch/algorithms/mixed_precision/module_wrappers/index.rst","autoapi/neural_compressor/torch/algorithms/mx_quant/index.rst","autoapi/neural_compressor/torch/algorithms/mx_quant/mx/index.rst","autoapi/neural_compressor/torch/algorithms/mx_quant/utils/index.rst","autoapi/neural_compressor/torch/algorithms/pt2e_quant/core/index.rst","autoapi/neural_compressor/torch/algorithms/pt2e_quant/half_precision_rewriter/index.rst","autoapi/neural_compressor/torch/algorithms/pt2e_quant/index.rst","autoapi/neural_compressor/torch/algorithms/pt2e_quant/save_load/index.rst","autoapi/neural_compressor/torch/algorithms/pt2e_quant/utility/index.rst","autoapi/neural_compressor/torch/algorithms/qat/index.rst","autoapi/neural_compressor/torch/algorithms/qat/quant_linear/index.rst","autoapi/neural_compressor/torch/algorithms/qat/quant_utils/index.rst","autoapi/neural_compressor/torch/algorithms/qat/tensor_quantizer/index.rst","autoapi/neural_compressor/torch/algorithms/smooth_quant/index.rst","autoapi/neural_compressor/torch/algorithms/smooth_quant/save_load/index.rst","autoapi/neural_compressor/torch/algorithms/smooth_quant/smooth_quant/index.rst","autoapi/neural_compressor/torch/algorithms/smooth_quant/utility/index.rst","autoapi/neural_compressor/torch/algorithms/static_quant/index.rst","autoapi/neural_compressor/torch/algorithms/static_quant/save_load/index.rst","autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index.rst","autoapi/neural_compressor/torch/algorithms/static_quant/utility/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/awq/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/modules/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/save_load/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/teq/index.rst","autoapi/neural_compressor/torch/algorithms/weight_only/utility/index.rst","autoapi/neural_compressor/torch/export/export_hf/index.rst","autoapi/neural_compressor/torch/export/index.rst","autoapi/neural_compressor/torch/export/pt2e_export/index.rst","autoapi/neural_compressor/torch/index.rst","autoapi/neural_compressor/torch/quantization/algorithm_entry/index.rst","autoapi/neural_compressor/torch/quantization/autotune/index.rst","autoapi/neural_compressor/torch/quantization/config/index.rst","autoapi/neural_compressor/torch/quantization/index.rst","autoapi/neural_compressor/torch/quantization/quantize/index.rst","autoapi/neural_compressor/torch/quantization/save_load_entry/index.rst","autoapi/neural_compressor/torch/utils/auto_accelerator/index.rst","autoapi/neural_compressor/torch/utils/bit_packer/index.rst","autoapi/neural_compressor/torch/utils/block_wise/index.rst","autoapi/neural_compressor/torch/utils/constants/index.rst","autoapi/neural_compressor/torch/utils/environ/index.rst","autoapi/neural_compressor/torch/utils/index.rst","autoapi/neural_compressor/torch/utils/utility/index.rst","autoapi/neural_compressor/version/index.rst","docs/build_docs/source/index.rst","docs/source/CODE_OF_CONDUCT.md","docs/source/CONTRIBUTING.md","docs/source/JAX.md","docs/source/PT_DynamicQuant.md","docs/source/PT_FP8Quant.md","docs/source/PT_MXQuant.md","docs/source/PT_MixedPrecision.md","docs/source/PT_NVFP4Quant.md","docs/source/PT_QAT.md","docs/source/PT_SmoothQuant.md","docs/source/PT_StaticQuant.md","docs/source/PT_WeightOnlyQuant.md","docs/source/PyTorch.md","docs/source/SECURITY.md","docs/source/TF_Quant.md","docs/source/TF_SQ.md","docs/source/TensorFlow.md","docs/source/Welcome.md","docs/source/api-doc/apis.rst","docs/source/api-doc/tf_quantization_autotune.rst","docs/source/api-doc/tf_quantization_common.rst","docs/source/api-doc/tf_quantization_config.rst","docs/source/api-doc/torch_quantization_autotune.rst","docs/source/api-doc/torch_quantization_common.rst","docs/source/api-doc/torch_quantization_config.rst","docs/source/autotune.md","docs/source/client_quant.md","docs/source/coding_style.md","docs/source/design.md","docs/source/examples/README.md","docs/source/examples/helloworld/fp8_example/README.md","docs/source/examples/jax/keras/gemma/README.md","docs/source/examples/jax/keras/vit/README.md","docs/source/examples/pytorch/cv/fp8_quant/README.md","docs/source/examples/pytorch/cv/mixed_precision/README.md","docs/source/examples/pytorch/cv/static_quant/README.md","docs/source/examples/pytorch/diffusion_model/diffusers/flux/README.md","docs/source/examples/pytorch/diffusion_model/diffusers/framepack/README.md","docs/source/examples/pytorch/diffusion_model/diffusers/stable_diffusion/fp8_quant/README.md","docs/source/examples/pytorch/diffusion_model/diffusers/stable_diffusion/smooth_quant/README.md","docs/source/examples/pytorch/diffusion_model/diffusers/stable_diffusion/static_quant/README.md","docs/source/examples/pytorch/image_recognition/torchvision_models/quantization/static_quant/ipex/README.md","docs/source/examples/pytorch/multimodal-modeling/quantization/auto_round/llama4/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/auto_round/deepseek/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/auto_round/llama3/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/auto_round/qwen/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/fp8_quant/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/llm_qat/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/mx_quant/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/smooth_quant/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/static_quant/ipex/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/static_quant/pt2e/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/transformers/weight_only/text-generation/README.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/transformers/weight_only/text-generation/llm_quantization_recipes.md","docs/source/examples/pytorch/nlp/huggingface_models/language-modeling/quantization/weight_only/README.md","docs/source/examples/pytorch/nlp/huggingface_models/question-answering/quantization/static_quant/ipex/README.md","docs/source/examples/pytorch/recommendation/dlrm/static_quant/ipex/CODE_OF_CONDUCT.md","docs/source/examples/pytorch/recommendation/dlrm/static_quant/ipex/CONTRIBUTING.md","docs/source/examples/pytorch/recommendation/dlrm/static_quant/ipex/README.md","docs/source/examples/pytorch/recommendation/dlrm_v2/fp8_quant/cpu/README.md","docs/source/examples/tensorflow/graph_networks/graphsage/quantization/ptq/README.md","docs/source/examples/tensorflow/image_recognition/inception_v3/quantization/ptq/README.md","docs/source/examples/tensorflow/image_recognition/mobilenet_v2/quantization/ptq/README.md","docs/source/examples/tensorflow/image_recognition/resnet_v2_50/quantization/ptq/README.md","docs/source/examples/tensorflow/image_recognition/vgg16/quantization/ptq/README.md","docs/source/examples/tensorflow/image_recognition/vision_transformer/quantization/ptq/README.md","docs/source/examples/tensorflow/keras/image_recognition/inception_v3/quantization/ptq/README.md","docs/source/examples/tensorflow/keras/image_recognition/resnet_v2_50/quantization/ptq/README.md","docs/source/examples/tensorflow/nlp/bert_large_squad_model_zoo/quantization/ptq/README.md","docs/source/examples/tensorflow/nlp/large_language_models/quantization/ptq/gpt-j/README.md","docs/source/examples/tensorflow/nlp/large_language_models/quantization/ptq/smoothquant/README.md","docs/source/examples/tensorflow/nlp/transformer_lt/quantization/ptq/README.md","docs/source/examples/tensorflow/object_detection/faster_rcnn_resnet50/quantization/ptq/README.md","docs/source/examples/tensorflow/object_detection/mask_rcnn_inception_v2/quantization/ptq/README.md","docs/source/examples/tensorflow/object_detection/ssd_mobilenet_v1/quantization/ptq/README.md","docs/source/examples/tensorflow/object_detection/yolo_v5/quantization/ptq/README.md","docs/source/examples/tensorflow/recommendation/wide_deep_large_ds/quantization/ptq/README.md","docs/source/examples/tensorflow/semantic_image_segmentation/3dunet-mlperf/quantization/ptq/README.md","docs/source/examples/tensorflow/style_transfer/arbitrary_style_transfer/quantization/ptq/README.md","docs/source/faq.md","docs/source/gaudi_version_map.md","docs/source/get_started.md","docs/source/installation_guide.md","docs/source/legal_information.md","docs/source/llm_recipes.md","docs/source/publication_list.md","docs/source/quantization.md","docs/source/smooth_quant.md","docs/source/transformers_like_api.md","index.rst"],"indexentries":{"acceleratorregistry (class in neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.AcceleratorRegistry",false]],"apply_inlining() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.apply_inlining",false]],"apply_single_pattern_pair() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.apply_single_pattern_pair",false]],"auto_accelerator (class in neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.Auto_Accelerator",false]],"auto_detect_accelerator() (in module neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.auto_detect_accelerator",false]],"autoalpha (class in neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.AutoAlpha",false]],"autoround_quantize_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.autoround_quantize_entry",false]],"autoroundconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.AutoRoundConfig",false]],"autoroundquantizer (class in neural_compressor.torch.algorithms.autoround.autoround)":[[123,"neural_compressor.torch.algorithms.autoround.autoround.AutoRoundQuantizer",false]],"autotune() (in module neural_compressor.tensorflow.quantization.autotune)":[[33,"neural_compressor.tensorflow.quantization.autotune.autotune",false]],"autotune() (in module neural_compressor.torch.quantization.autotune)":[[174,"neural_compressor.torch.quantization.autotune.autotune",false]],"awq_quantize_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.awq_quantize_entry",false]],"awqconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.AWQConfig",false]],"awqquantizer (class in neural_compressor.torch.algorithms.weight_only.awq)":[[154,"neural_compressor.torch.algorithms.weight_only.awq.AWQQuantizer",false]],"axis (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)":[[161,"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.axis",false]],"baseconfig (class in neural_compressor.common.base_config)":[[0,"neural_compressor.common.base_config.BaseConfig",false]],"basedataloader (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.BaseDataLoader",false]],"basemodel (class in neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.BaseModel",false]],"batchsampler (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.BatchSampler",false]],"bf16convert (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert)":[[38,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert.BF16Convert",false]],"biascorrection (class in neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction)":[[111,"neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction.BiasCorrection",false]],"block_wise_calibration() (in module neural_compressor.torch.utils.block_wise)":[[181,"neural_compressor.torch.utils.block_wise.block_wise_calibration",false]],"build_captured_dataloader() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.build_captured_dataloader",false]],"bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)":[[55,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.bypass_reshape",false]],"bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)":[[56,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.bypass_reshape",false]],"cal_scale() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.cal_scale",false]],"calibration (class in neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.Calibration",false]],"call_counter() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.call_counter",false]],"can_pack_with_numba() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.can_pack_with_numba",false]],"captureoutputtofile (class in neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.CaptureOutputToFile",false]],"cfg_to_qconfig() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.cfg_to_qconfig",false]],"cfg_to_qconfig() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.cfg_to_qconfig",false]],"change_config_to_hf_format() (in module neural_compressor.torch.algorithms.weight_only.save_load)":[[166,"neural_compressor.torch.algorithms.weight_only.save_load.change_config_to_hf_format",false]],"check_cfg_and_qconfig() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.check_cfg_and_qconfig",false]],"check_cfg_and_qconfig() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.check_cfg_and_qconfig",false]],"checkpoint_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.checkpoint_session",false]],"clean_module_weight() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.clean_module_weight",false]],"collate_tf_preds() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.collate_tf_preds",false]],"combine_histogram() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.combine_histogram",false]],"composableconfig (class in neural_compressor.common.base_config)":[[0,"neural_compressor.common.base_config.ComposableConfig",false]],"config_list (neural_compressor.common.base_config.composableconfig attribute)":[[0,"neural_compressor.common.base_config.ComposableConfig.config_list",false]],"config_list (neural_compressor.common.base_tuning.configset attribute)":[[1,"neural_compressor.common.base_tuning.ConfigSet.config_list",false]],"configloader (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.ConfigLoader",false]],"configregistry (class in neural_compressor.common.base_config)":[[0,"neural_compressor.common.base_config.ConfigRegistry",false]],"configset (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.ConfigSet",false]],"construct_function_from_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.construct_function_from_graph_def",false]],"convert() (in module neural_compressor.torch.algorithms.qat.quant_utils)":[[144,"neural_compressor.torch.algorithms.qat.quant_utils.convert",false]],"convert() (in module neural_compressor.torch.quantization.quantize)":[[177,"neural_compressor.torch.quantization.quantize.convert",false]],"convert_model_with_mapping() (in module neural_compressor.torch.algorithms.qat.quant_utils)":[[144,"neural_compressor.torch.algorithms.qat.quant_utils.convert_model_with_mapping",false]],"convertaddtobiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd)":[[41,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd.ConvertAddToBiasAddOptimizer",false]],"convertlayoutoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout)":[[42,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout.ConvertLayoutOptimizer",false]],"convertleakyreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu)":[[43,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu.ConvertLeakyReluOptimizer",false]],"convertnantorandom (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random)":[[44,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random.ConvertNanToRandom",false]],"convertplaceholdertoconst (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const)":[[45,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const.ConvertPlaceholderToConst",false]],"cpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.CPU_Accelerator",false]],"cpuinfo (class in neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.CpuInfo",false]],"cpuinfo (class in neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.CpuInfo",false]],"create_quant_spec_from_config() (in module neural_compressor.torch.algorithms.pt2e_quant.utility)":[[141,"neural_compressor.torch.algorithms.pt2e_quant.utility.create_quant_spec_from_config",false]],"create_xiq_quantizer_from_pt2e_config() (in module neural_compressor.torch.algorithms.pt2e_quant.utility)":[[141,"neural_compressor.torch.algorithms.pt2e_quant.utility.create_xiq_quantizer_from_pt2e_config",false]],"cuda_accelerator (class in neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.CUDA_Accelerator",false]],"deep_get() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.deep_get",false]],"default_collate() (in module neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.default_collate",false]],"dequantizecastoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer)":[[39,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer.DequantizeCastOptimizer",false]],"detect_device() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.detect_device",false]],"detect_processor_type_based_on_hw() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.detect_processor_type_based_on_hw",false]],"device_synchronize() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.device_synchronize",false]],"dilatedcontraction (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction)":[[46,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction.DilatedContraction",false]],"disable_random() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.disable_random",false]],"dowload_hf_model() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.dowload_hf_model",false]],"dummydataset (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.DummyDataset",false]],"dummydatasetv2 (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.DummyDatasetV2",false]],"dump_elapsed_time() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.dump_elapsed_time",false]],"dump_elapsed_time() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.dump_elapsed_time",false]],"dump_model_op_stats() (in module neural_compressor.torch.algorithms.autoround.autoround)":[[123,"neural_compressor.torch.algorithms.autoround.autoround.dump_model_op_stats",false]],"dump_model_op_stats() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.dump_model_op_stats",false]],"dump_model_op_stats() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.dump_model_op_stats",false]],"dump_model_op_stats() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.dump_model_op_stats",false]],"dynamicquantconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.DynamicQuantConfig",false]],"elemformat (class in neural_compressor.torch.algorithms.mx_quant.utils)":[[136,"neural_compressor.torch.algorithms.mx_quant.utils.ElemFormat",false]],"enough_memo_store_scale() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.enough_memo_store_scale",false]],"estimator_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.estimator_session",false]],"evaluationfuncwrapper (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.EvaluationFuncWrapper",false]],"evaluator (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.Evaluator",false]],"expanddimsoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer)":[[48,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer.ExpandDimsOptimizer",false]],"export() (in module neural_compressor.torch.export.pt2e_export)":[[171,"neural_compressor.torch.export.pt2e_export.export",false]],"export_hf2compressored_model() (in module neural_compressor.torch.export.export_hf)":[[169,"neural_compressor.torch.export.export_hf.export_hf2compressored_model",false]],"export_model_for_pt2e_quant() (in module neural_compressor.torch.export.pt2e_export)":[[171,"neural_compressor.torch.export.pt2e_export.export_model_for_pt2e_quant",false]],"fakeaffinetensorquantfunction (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.FakeAffineTensorQuantFunction",false]],"fetch_module() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.fetch_module",false]],"fetch_module() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.fetch_module",false]],"fetchweightfromreshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape)":[[49,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape.FetchWeightFromReshapeOptimizer",false]],"filter_fn() (in module neural_compressor.torch.algorithms.weight_only.hqq.quantizer)":[[162,"neural_compressor.torch.algorithms.weight_only.hqq.quantizer.filter_fn",false]],"finalize_calibration() (in module neural_compressor.torch.quantization.quantize)":[[177,"neural_compressor.torch.quantization.quantize.finalize_calibration",false]],"find_all_layers() (in module neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.find_all_layers",false]],"find_layers() (in module neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.find_layers",false]],"find_layers_name() (in module neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.find_layers_name",false]],"find_matching_blocks() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.find_matching_blocks",false]],"fix_ref_type_of_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.fix_ref_type_of_graph_def",false]],"fn (neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.patternpair attribute)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair.fn",false]],"foldbatchnormnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm)":[[50,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm.FoldBatchNormNodesOptimizer",false]],"forward_wrapper() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.forward_wrapper",false]],"forward_wrapper() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.forward_wrapper",false]],"forward_wrapper() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.forward_wrapper",false]],"fp8_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.fp8_entry",false]],"fp8config (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.FP8Config",false]],"freezefakequantopoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant)":[[76,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant.FreezeFakeQuantOpOptimizer",false]],"freezevaluetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value)":[[77,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value.FreezeValueTransformer",false]],"frozen_pb_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.frozen_pb_session",false]],"fusebiasaddandaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add)":[[52,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add.FuseBiasAddAndAddOptimizer",false]],"fusecolumnwisemuloptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul)":[[53,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul.FuseColumnWiseMulOptimizer",false]],"fuseconvredundantdequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize)":[[78,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize.FuseConvRedundantDequantizeTransformer",false]],"fuseconvrequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize)":[[79,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize.FuseConvRequantizeTransformer",false]],"fuseconvwithmathoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math)":[[54,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math.FuseConvWithMathOptimizer",false]],"fusedecomposedbnoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)":[[55,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.FuseDecomposedBNOptimizer",false]],"fusedecomposedinoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)":[[56,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.FuseDecomposedINOptimizer",false]],"fusegeluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu)":[[57,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu.FuseGeluOptimizer",false]],"fuselayernormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)":[[58,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.FuseLayerNormOptimizer",false]],"fusematmulredundantdequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize)":[[80,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize.FuseMatMulRedundantDequantizeTransformer",false]],"fusematmulrequantizedequantizenewapitransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)":[[81,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeNewAPITransformer",false]],"fusematmulrequantizedequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)":[[81,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeTransformer",false]],"fusematmulrequantizenewapitransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)":[[81,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeNewAPITransformer",false]],"fusematmulrequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)":[[81,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeTransformer",false]],"fusenodestartwithconcatv2 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2)":[[95,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2.FuseNodeStartWithConcatV2",false]],"fusenodestartwithconcatv2 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2)":[[105,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2.FuseNodeStartWithConcatV2",false]],"fusenodestartwithconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv)":[[96,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv.FuseNodeStartWithConv2d",false]],"fusenodestartwithconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv)":[[106,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv.FuseNodeStartWithConv2d",false]],"fusenodestartwithdeconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv)":[[97,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv.FuseNodeStartWithDeconv2d",false]],"fusenodestartwithfusedbatchnormv3 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn)":[[94,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn.FuseNodeStartWithFusedBatchNormV3",false]],"fusenodestartwithfusedbatchnormv3 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn)":[[104,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn.FuseNodeStartWithFusedBatchNormV3",false]],"fusenodestartwithfusedinstancenorm (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in)":[[98,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in.FuseNodeStartWithFusedInstanceNorm",false]],"fusenodestartwithmatmul (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul)":[[99,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul.FuseNodeStartWithMatmul",false]],"fusenodestartwithmatmul (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul)":[[108,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul.FuseNodeStartWithMatmul",false]],"fusenodestartwithpooling (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling)":[[100,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling.FuseNodeStartWithPooling",false]],"fusenodestartwithpooling (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling)":[[109,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling.FuseNodeStartWithPooling",false]],"fusepadwithconv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv)":[[59,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv.FusePadWithConv2DOptimizer",false]],"fusepadwithfp32conv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv)":[[60,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv.FusePadWithFP32Conv2DOptimizer",false]],"fusetransposereshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose)":[[61,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose.FuseTransposeReshapeOptimizer",false]],"generate_activation_observer() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.generate_activation_observer",false]],"generate_feed_dict() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.generate_feed_dict",false]],"generate_xpu_qconfig() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.generate_xpu_qconfig",false]],"generategraphwithqdqpattern (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern)":[[88,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern.GenerateGraphWithQDQPattern",false]],"get_absorb_layers() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.get_absorb_layers",false]],"get_accelerator() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.get_accelerator",false]],"get_all_config_set() (in module neural_compressor.tensorflow.quantization.autotune)":[[33,"neural_compressor.tensorflow.quantization.autotune.get_all_config_set",false]],"get_all_config_set() (in module neural_compressor.torch.quantization.autotune)":[[174,"neural_compressor.torch.quantization.autotune.get_all_config_set",false]],"get_all_config_set_from_config_registry() (in module neural_compressor.common.base_config)":[[0,"neural_compressor.common.base_config.get_all_config_set_from_config_registry",false]],"get_all_fp32_data() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.get_all_fp32_data",false]],"get_all_registered_configs() (in module neural_compressor.tensorflow.keras.quantization.config)":[[30,"neural_compressor.tensorflow.keras.quantization.config.get_all_registered_configs",false]],"get_all_registered_configs() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_all_registered_configs",false]],"get_block_names() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_block_names",false]],"get_block_prefix() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.get_block_prefix",false]],"get_block_prefix() (in module neural_compressor.torch.utils.block_wise)":[[181,"neural_compressor.torch.utils.block_wise.get_block_prefix",false]],"get_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.get_children",false]],"get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)":[[55,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.get_const_dim_count",false]],"get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)":[[56,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.get_const_dim_count",false]],"get_dataloader() (in module neural_compressor.torch.algorithms.autoround.autoround)":[[123,"neural_compressor.torch.algorithms.autoround.autoround.get_dataloader",false]],"get_default_autoround_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_AutoRound_config",false]],"get_default_awq_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_awq_config",false]],"get_default_double_quant_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_double_quant_config",false]],"get_default_dynamic_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_dynamic_config",false]],"get_default_fp8_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_fp8_config",false]],"get_default_fp8_config_set() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_fp8_config_set",false]],"get_default_gptq_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_gptq_config",false]],"get_default_hqq_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_hqq_config",false]],"get_default_mixed_precision_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_mixed_precision_config",false]],"get_default_mixed_precision_config_set() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_mixed_precision_config_set",false]],"get_default_mx_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_mx_config",false]],"get_default_qat_module_mappings() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_qat_module_mappings",false]],"get_default_rtn_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_rtn_config",false]],"get_default_sq_config() (in module neural_compressor.tensorflow.quantization.config)":[[34,"neural_compressor.tensorflow.quantization.config.get_default_sq_config",false]],"get_default_sq_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_sq_config",false]],"get_default_static_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_static_config",false]],"get_default_static_quant_config() (in module neural_compressor.tensorflow.keras.quantization.config)":[[30,"neural_compressor.tensorflow.keras.quantization.config.get_default_static_quant_config",false]],"get_default_static_quant_config() (in module neural_compressor.tensorflow.quantization.config)":[[34,"neural_compressor.tensorflow.quantization.config.get_default_static_quant_config",false]],"get_default_teq_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_default_teq_config",false]],"get_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.get_depth",false]],"get_dict_at_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.get_dict_at_depth",false]],"get_double_quant_config_dict() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_double_quant_config_dict",false]],"get_element_under_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.get_element_under_depth",false]],"get_enum_from_format() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_enum_from_format",false]],"get_filter_fn() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.get_filter_fn",false]],"get_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.get_graph_def",false]],"get_half_precision_node_set() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.get_half_precision_node_set",false]],"get_input_output_node_names() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.get_input_output_node_names",false]],"get_ipex_version() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.get_ipex_version",false]],"get_layer_names_in_block() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_layer_names_in_block",false]],"get_mllm_dataloader() (in module neural_compressor.torch.algorithms.autoround.autoround)":[[123,"neural_compressor.torch.algorithms.autoround.autoround.get_mllm_dataloader",false]],"get_model_device() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_model_device",false]],"get_model_info() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_model_info",false]],"get_model_input_shape() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.get_model_input_shape",false]],"get_model_type() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.get_model_type",false]],"get_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.get_module",false]],"get_module() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.get_module",false]],"get_module() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.get_module",false]],"get_module() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_module",false]],"get_module_input_output() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.get_module_input_output",false]],"get_multimodal_block_names() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_multimodal_block_names",false]],"get_named_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.get_named_children",false]],"get_non_persistent_buffers() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_non_persistent_buffers",false]],"get_parent() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.get_parent",false]],"get_parent() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.get_parent",false]],"get_processor_type_from_user_config() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_processor_type_from_user_config",false]],"get_quant_config() (in module neural_compressor.torch.algorithms.qat.quant_utils)":[[144,"neural_compressor.torch.algorithms.qat.quant_utils.get_quant_config",false]],"get_quant_config_with_scheme() (in module neural_compressor.torch.algorithms.qat.quant_utils)":[[144,"neural_compressor.torch.algorithms.qat.quant_utils.get_quant_config_with_scheme",false]],"get_quantizable_ops_from_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_from_cfgs",false]],"get_quantizable_ops_recursively() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.get_quantizable_ops_recursively",false]],"get_quantizable_ops_recursively() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_recursively",false]],"get_quantization_format() (in module neural_compressor.torch.algorithms.qat.quant_utils)":[[144,"neural_compressor.torch.algorithms.qat.quant_utils.get_quantization_format",false]],"get_quantizer() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.get_quantizer",false]],"get_rtn_double_quant_config_set() (in module neural_compressor.torch.quantization.autotune)":[[174,"neural_compressor.torch.quantization.autotune.get_rtn_double_quant_config_set",false]],"get_super_module_by_name() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.get_super_module_by_name",false]],"get_tensor_by_name() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.get_tensor_by_name",false]],"get_tensor_histogram() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.get_tensor_histogram",false]],"get_tf_model_type() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.get_tf_model_type",false]],"get_torch_version() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.get_torch_version",false]],"get_unquantized_node_set() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.get_unquantized_node_set",false]],"get_used_cpu_mem_mb() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.get_used_cpu_mem_MB",false]],"get_used_hpu_mem_mb() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.get_used_hpu_mem_MB",false]],"get_woq_tuning_config() (in module neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.get_woq_tuning_config",false]],"get_workspace() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.get_workspace",false]],"gptq (class in neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.GPTQ",false]],"gptq_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.gptq_entry",false]],"gptqconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.GPTQConfig",false]],"gptquantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.GPTQuantizer",false]],"graph_def_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.graph_def_session",false]],"graph_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.graph_session",false]],"graphanalyzer (class in neural_compressor.tensorflow.quantization.utils.graph_util)":[[91,"neural_compressor.tensorflow.quantization.utils.graph_util.GraphAnalyzer",false]],"graphconverter (class in neural_compressor.tensorflow.quantization.utils.graph_converter)":[[37,"neural_compressor.tensorflow.quantization.utils.graph_converter.GraphConverter",false]],"graphcseoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer)":[[62,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer.GraphCseOptimizer",false]],"graphfoldconstantoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant)":[[51,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant.GraphFoldConstantOptimizer",false]],"graphrewriterbase (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base)":[[74,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base.GraphRewriterBase",false]],"graphrewriterhelper (class in neural_compressor.tensorflow.quantization.utils.graph_util)":[[91,"neural_compressor.tensorflow.quantization.utils.graph_util.GraphRewriterHelper",false]],"graphtrace (class in neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.GraphTrace",false]],"graphtrace (class in neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.GraphTrace",false]],"graphtransformbase (class in neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base)":[[112,"neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base.GraphTransformBase",false]],"grappleroptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass)":[[63,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass.GrapplerOptimizer",false]],"group_size (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)":[[161,"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.group_size",false]],"halfprecisionconverter (class in neural_compressor.torch.algorithms.mixed_precision.half_precision_convert)":[[131,"neural_compressor.torch.algorithms.mixed_precision.half_precision_convert.HalfPrecisionConverter",false]],"halfprecisionmodulewrapper (class in neural_compressor.torch.algorithms.mixed_precision.module_wrappers)":[[133,"neural_compressor.torch.algorithms.mixed_precision.module_wrappers.HalfPrecisionModuleWrapper",false]],"hpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.HPU_Accelerator",false]],"hpuweightonlylinear (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.HPUWeightOnlyLinear",false]],"hqq_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.hqq_entry",false]],"hqqconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.HQQConfig",false]],"hqqlinear (class in neural_compressor.torch.algorithms.weight_only.hqq.core)":[[158,"neural_compressor.torch.algorithms.weight_only.hqq.core.HQQLinear",false]],"hqqmoduleconfig (class in neural_compressor.torch.algorithms.weight_only.hqq.config)":[[157,"neural_compressor.torch.algorithms.weight_only.hqq.config.HQQModuleConfig",false]],"hqqtensorhandle (class in neural_compressor.torch.algorithms.weight_only.hqq.core)":[[158,"neural_compressor.torch.algorithms.weight_only.hqq.core.HQQTensorHandle",false]],"hqquantizer (class in neural_compressor.torch.algorithms.weight_only.hqq.quantizer)":[[162,"neural_compressor.torch.algorithms.weight_only.hqq.quantizer.HQQuantizer",false]],"hybrid_gptq_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.hybrid_gptq_entry",false]],"hybridgptqconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.HybridGPTQConfig",false]],"incacceleratortype (class in neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.INCAcceleratorType",false]],"incweightonlylinear (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.INCWeightOnlyLinear",false]],"indexfetcher (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.IndexFetcher",false]],"init_tuning() (in module neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.init_tuning",false]],"initialize_int8_avgpool() (in module neural_compressor.tensorflow.keras.layers.pool2d)":[[28,"neural_compressor.tensorflow.keras.layers.pool2d.initialize_int8_avgpool",false]],"initialize_int8_conv2d() (in module neural_compressor.tensorflow.keras.layers.conv2d)":[[23,"neural_compressor.tensorflow.keras.layers.conv2d.initialize_int8_conv2d",false]],"initialize_int8_dense() (in module neural_compressor.tensorflow.keras.layers.dense)":[[24,"neural_compressor.tensorflow.keras.layers.dense.initialize_int8_dense",false]],"initialize_int8_depthwise_conv2d() (in module neural_compressor.tensorflow.keras.layers.depthwise_conv2d)":[[25,"neural_compressor.tensorflow.keras.layers.depthwise_conv2d.initialize_int8_depthwise_conv2d",false]],"initialize_int8_maxpool() (in module neural_compressor.tensorflow.keras.layers.pool2d)":[[28,"neural_compressor.tensorflow.keras.layers.pool2d.initialize_int8_maxpool",false]],"initialize_int8_separable_conv2d() (in module neural_compressor.tensorflow.keras.layers.separable_conv2d)":[[29,"neural_compressor.tensorflow.keras.layers.separable_conv2d.initialize_int8_separable_conv2d",false]],"injectdummybiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd)":[[47,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd.InjectDummyBiasAddOptimizer",false]],"insertlogging (class in neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging)":[[114,"neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging.InsertLogging",false]],"insertprintminmaxnode (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node)":[[65,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node.InsertPrintMinMaxNode",false]],"int8staticquantconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.INT8StaticQuantConfig",false]],"is_ckpt_format() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.is_ckpt_format",false]],"is_hpex_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_hpex_available",false]],"is_hpex_support_g_idx() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_hpex_support_g_idx",false]],"is_hpu_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_hpu_available",false]],"is_ipex_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_ipex_available",false]],"is_ipex_imported() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_ipex_imported",false]],"is_leaf() (in module neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.is_leaf",false]],"is_numba_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_numba_available",false]],"is_optimum_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_optimum_available",false]],"is_optimum_habana_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_optimum_habana_available",false]],"is_package_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_package_available",false]],"is_quantlinear() (in module neural_compressor.torch.algorithms.qat.quant_utils)":[[144,"neural_compressor.torch.algorithms.qat.quant_utils.is_quantlinear",false]],"is_saved_model_format() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.is_saved_model_format",false]],"is_tbb_available() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_tbb_available",false]],"is_transformers_imported() (in module neural_compressor.torch.utils.environ)":[[183,"neural_compressor.torch.utils.environ.is_transformers_imported",false]],"iterablefetcher (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.IterableFetcher",false]],"iterablesampler (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.IterableSampler",false]],"iterator_sess_run() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.iterator_sess_run",false]],"itex_installed() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.itex_installed",false]],"keras_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.keras_session",false]],"kerasadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.keras)":[[19,"neural_compressor.tensorflow.algorithms.static_quant.keras.KerasAdaptor",false]],"kerasconfigconverter (class in neural_compressor.tensorflow.algorithms.static_quant.keras)":[[19,"neural_compressor.tensorflow.algorithms.static_quant.keras.KerasConfigConverter",false]],"kerasmodel (class in neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.KerasModel",false]],"kerasquery (class in neural_compressor.tensorflow.algorithms.static_quant.keras)":[[19,"neural_compressor.tensorflow.algorithms.static_quant.keras.KerasQuery",false]],"kerassurgery (class in neural_compressor.tensorflow.algorithms.static_quant.keras)":[[19,"neural_compressor.tensorflow.algorithms.static_quant.keras.KerasSurgery",false]],"lazyimport (class in neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.LazyImport",false]],"load() (in module neural_compressor.torch.algorithms.layer_wise.load)":[[128,"neural_compressor.torch.algorithms.layer_wise.load.load",false]],"load() (in module neural_compressor.torch.algorithms.pt2e_quant.save_load)":[[140,"neural_compressor.torch.algorithms.pt2e_quant.save_load.load",false]],"load() (in module neural_compressor.torch.algorithms.static_quant.save_load)":[[151,"neural_compressor.torch.algorithms.static_quant.save_load.load",false]],"load() (in module neural_compressor.torch.algorithms.weight_only.save_load)":[[166,"neural_compressor.torch.algorithms.weight_only.save_load.load",false]],"load() (in module neural_compressor.torch.quantization.save_load_entry)":[[178,"neural_compressor.torch.quantization.save_load_entry.load",false]],"load_config_mapping() (in module neural_compressor.common.utils.save_load)":[[7,"neural_compressor.common.utils.save_load.load_config_mapping",false]],"load_empty_model() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.load_empty_model",false]],"load_first_layer_only() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_first_layer_only",false]],"load_layer_wise_quantized_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_layer_wise_quantized_model",false]],"load_model_from_shards_with_safetensors() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_model_from_shards_with_safetensors",false]],"load_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_module",false]],"load_non_persistent_buffers() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.load_non_persistent_buffers",false]],"load_saved_model() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.load_saved_model",false]],"load_tensor() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_tensor",false]],"load_tensor_from_safetensors() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_safetensors",false]],"load_tensor_from_safetensors_shard() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_safetensors_shard",false]],"load_tensor_from_shard() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_shard",false]],"load_value() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.load_value",false]],"log_process() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.log_process",false]],"log_quantizable_layers_per_transformer() (in module neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.log_quantizable_layers_per_transformer",false]],"logger (class in neural_compressor.common.utils.logger)":[[6,"neural_compressor.common.utils.logger.Logger",false]],"matmul (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.Matmul",false]],"mergeduplicatedqdqoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq)":[[89,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq.MergeDuplicatedQDQOptimizer",false]],"metainfochangingmemopoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer)":[[83,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer.MetaInfoChangingMemOpOptimizer",false]],"mixed_precision_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.mixed_precision_entry",false]],"mixedprecisionconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.MixedPrecisionConfig",false]],"mode (class in neural_compressor.common.utils.constants)":[[4,"neural_compressor.common.utils.constants.Mode",false]],"model (class in neural_compressor.tensorflow.utils.model)":[[120,"neural_compressor.tensorflow.utils.model.Model",false]],"model_forward() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.model_forward",false]],"model_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.model_forward",false]],"model_forward_per_sample() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.model_forward_per_sample",false]],"model_level (neural_compressor.common.tuning_param.paramlevel attribute)":[[3,"neural_compressor.common.tuning_param.ParamLevel.MODEL_LEVEL",false]],"module":[[0,"module-neural_compressor.common.base_config",false],[1,"module-neural_compressor.common.base_tuning",false],[2,"module-neural_compressor.common",false],[3,"module-neural_compressor.common.tuning_param",false],[4,"module-neural_compressor.common.utils.constants",false],[5,"module-neural_compressor.common.utils",false],[6,"module-neural_compressor.common.utils.logger",false],[7,"module-neural_compressor.common.utils.save_load",false],[8,"module-neural_compressor.common.utils.utility",false],[9,"module-neural_compressor.common.version",false],[10,"module-neural_compressor",false],[11,"module-neural_compressor.jax.algorithms",false],[12,"module-neural_compressor.jax",false],[13,"module-neural_compressor.tensorflow.algorithms",false],[14,"module-neural_compressor.tensorflow.algorithms.smoother.calibration",false],[15,"module-neural_compressor.tensorflow.algorithms.smoother.core",false],[16,"module-neural_compressor.tensorflow.algorithms.smoother",false],[17,"module-neural_compressor.tensorflow.algorithms.smoother.scaler",false],[18,"module-neural_compressor.tensorflow.algorithms.static_quant",false],[19,"module-neural_compressor.tensorflow.algorithms.static_quant.keras",false],[20,"module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow",false],[21,"module-neural_compressor.tensorflow",false],[22,"module-neural_compressor.tensorflow.keras",false],[23,"module-neural_compressor.tensorflow.keras.layers.conv2d",false],[24,"module-neural_compressor.tensorflow.keras.layers.dense",false],[25,"module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d",false],[26,"module-neural_compressor.tensorflow.keras.layers",false],[27,"module-neural_compressor.tensorflow.keras.layers.layer_initializer",false],[28,"module-neural_compressor.tensorflow.keras.layers.pool2d",false],[29,"module-neural_compressor.tensorflow.keras.layers.separable_conv2d",false],[30,"module-neural_compressor.tensorflow.keras.quantization.config",false],[31,"module-neural_compressor.tensorflow.keras.quantization",false],[32,"module-neural_compressor.tensorflow.quantization.algorithm_entry",false],[33,"module-neural_compressor.tensorflow.quantization.autotune",false],[34,"module-neural_compressor.tensorflow.quantization.config",false],[35,"module-neural_compressor.tensorflow.quantization",false],[36,"module-neural_compressor.tensorflow.quantization.quantize",false],[37,"module-neural_compressor.tensorflow.quantization.utils.graph_converter",false],[38,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert",false],[39,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer",false],[40,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16",false],[41,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd",false],[42,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout",false],[43,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu",false],[44,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random",false],[45,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const",false],[46,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction",false],[47,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd",false],[48,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer",false],[49,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape",false],[50,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm",false],[51,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant",false],[52,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add",false],[53,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul",false],[54,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math",false],[55,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn",false],[56,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in",false],[57,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu",false],[58,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm",false],[59,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv",false],[60,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv",false],[61,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose",false],[62,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer",false],[63,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass",false],[64,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic",false],[65,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node",false],[66,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu",false],[67,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize",false],[68,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes",false],[69,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm",false],[70,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input",false],[71,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes",false],[72,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes",false],[73,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer",false],[74,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base",false],[75,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter",false],[76,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant",false],[77,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value",false],[78,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize",false],[79,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize",false],[80,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize",false],[81,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize",false],[82,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8",false],[83,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer",false],[84,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter",false],[85,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse",false],[86,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation",false],[87,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq",false],[88,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern",false],[89,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq",false],[90,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern",false],[91,"module-neural_compressor.tensorflow.quantization.utils.graph_util",false],[92,"module-neural_compressor.tensorflow.quantization.utils",false],[93,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph",false],[94,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn",false],[95,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2",false],[96,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv",false],[97,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv",false],[98,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in",false],[99,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul",false],[100,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling",false],[101,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq",false],[102,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq",false],[103,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base",false],[104,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn",false],[105,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2",false],[106,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv",false],[107,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu",false],[108,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul",false],[109,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling",false],[110,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common",false],[111,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction",false],[112,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base",false],[113,"module-neural_compressor.tensorflow.quantization.utils.transform_graph",false],[114,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging",false],[115,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat",false],[116,"module-neural_compressor.tensorflow.quantization.utils.utility",false],[117,"module-neural_compressor.tensorflow.utils.constants",false],[118,"module-neural_compressor.tensorflow.utils.data",false],[119,"module-neural_compressor.tensorflow.utils",false],[120,"module-neural_compressor.tensorflow.utils.model",false],[121,"module-neural_compressor.tensorflow.utils.model_wrappers",false],[122,"module-neural_compressor.tensorflow.utils.utility",false],[123,"module-neural_compressor.torch.algorithms.autoround.autoround",false],[124,"module-neural_compressor.torch.algorithms.autoround",false],[125,"module-neural_compressor.torch.algorithms.base_algorithm",false],[126,"module-neural_compressor.torch.algorithms",false],[127,"module-neural_compressor.torch.algorithms.layer_wise",false],[128,"module-neural_compressor.torch.algorithms.layer_wise.load",false],[129,"module-neural_compressor.torch.algorithms.layer_wise.modified_pickle",false],[130,"module-neural_compressor.torch.algorithms.layer_wise.utils",false],[131,"module-neural_compressor.torch.algorithms.mixed_precision.half_precision_convert",false],[132,"module-neural_compressor.torch.algorithms.mixed_precision",false],[133,"module-neural_compressor.torch.algorithms.mixed_precision.module_wrappers",false],[134,"module-neural_compressor.torch.algorithms.mx_quant",false],[135,"module-neural_compressor.torch.algorithms.mx_quant.mx",false],[136,"module-neural_compressor.torch.algorithms.mx_quant.utils",false],[137,"module-neural_compressor.torch.algorithms.pt2e_quant.core",false],[138,"module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter",false],[139,"module-neural_compressor.torch.algorithms.pt2e_quant",false],[140,"module-neural_compressor.torch.algorithms.pt2e_quant.save_load",false],[141,"module-neural_compressor.torch.algorithms.pt2e_quant.utility",false],[142,"module-neural_compressor.torch.algorithms.qat",false],[143,"module-neural_compressor.torch.algorithms.qat.quant_linear",false],[144,"module-neural_compressor.torch.algorithms.qat.quant_utils",false],[145,"module-neural_compressor.torch.algorithms.qat.tensor_quantizer",false],[146,"module-neural_compressor.torch.algorithms.smooth_quant",false],[147,"module-neural_compressor.torch.algorithms.smooth_quant.save_load",false],[148,"module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant",false],[149,"module-neural_compressor.torch.algorithms.smooth_quant.utility",false],[150,"module-neural_compressor.torch.algorithms.static_quant",false],[151,"module-neural_compressor.torch.algorithms.static_quant.save_load",false],[152,"module-neural_compressor.torch.algorithms.static_quant.static_quant",false],[153,"module-neural_compressor.torch.algorithms.static_quant.utility",false],[154,"module-neural_compressor.torch.algorithms.weight_only.awq",false],[155,"module-neural_compressor.torch.algorithms.weight_only.gptq",false],[156,"module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack",false],[157,"module-neural_compressor.torch.algorithms.weight_only.hqq.config",false],[158,"module-neural_compressor.torch.algorithms.weight_only.hqq.core",false],[159,"module-neural_compressor.torch.algorithms.weight_only.hqq",false],[160,"module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer",false],[161,"module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor",false],[162,"module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer",false],[163,"module-neural_compressor.torch.algorithms.weight_only",false],[164,"module-neural_compressor.torch.algorithms.weight_only.modules",false],[165,"module-neural_compressor.torch.algorithms.weight_only.rtn",false],[166,"module-neural_compressor.torch.algorithms.weight_only.save_load",false],[167,"module-neural_compressor.torch.algorithms.weight_only.teq",false],[168,"module-neural_compressor.torch.algorithms.weight_only.utility",false],[169,"module-neural_compressor.torch.export.export_hf",false],[170,"module-neural_compressor.torch.export",false],[171,"module-neural_compressor.torch.export.pt2e_export",false],[172,"module-neural_compressor.torch",false],[173,"module-neural_compressor.torch.quantization.algorithm_entry",false],[174,"module-neural_compressor.torch.quantization.autotune",false],[175,"module-neural_compressor.torch.quantization.config",false],[176,"module-neural_compressor.torch.quantization",false],[177,"module-neural_compressor.torch.quantization.quantize",false],[178,"module-neural_compressor.torch.quantization.save_load_entry",false],[179,"module-neural_compressor.torch.utils.auto_accelerator",false],[180,"module-neural_compressor.torch.utils.bit_packer",false],[181,"module-neural_compressor.torch.utils.block_wise",false],[182,"module-neural_compressor.torch.utils.constants",false],[183,"module-neural_compressor.torch.utils.environ",false],[184,"module-neural_compressor.torch.utils",false],[185,"module-neural_compressor.torch.utils.utility",false],[186,"module-neural_compressor.version",false]],"move_input_device() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.move_input_device",false]],"move_input_to_device() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.move_input_to_device",false]],"move_input_to_device() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.move_input_to_device",false]],"movesqueezeafterreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu)":[[66,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu.MoveSqueezeAfterReluOptimizer",false]],"mullinear (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.MulLinear",false]],"mx_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.mx_quant_entry",false]],"mxlinear (class in neural_compressor.torch.algorithms.mx_quant.mx)":[[135,"neural_compressor.torch.algorithms.mx_quant.mx.MXLinear",false]],"mxquantconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.MXQuantConfig",false]],"mxquantizer (class in neural_compressor.torch.algorithms.mx_quant.mx)":[[135,"neural_compressor.torch.algorithms.mx_quant.mx.MXQuantizer",false]],"name (neural_compressor.common.base_config.baseconfig attribute)":[[0,"neural_compressor.common.base_config.BaseConfig.name",false]],"nbits (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)":[[161,"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.nbits",false]],"need_apply() (in module neural_compressor.tensorflow.quantization.quantize)":[[36,"neural_compressor.tensorflow.quantization.quantize.need_apply",false]],"need_apply() (in module neural_compressor.torch.quantization.quantize)":[[177,"neural_compressor.torch.quantization.quantize.need_apply",false]],"neural_compressor":[[10,"module-neural_compressor",false]],"neural_compressor.common":[[2,"module-neural_compressor.common",false]],"neural_compressor.common.base_config":[[0,"module-neural_compressor.common.base_config",false]],"neural_compressor.common.base_tuning":[[1,"module-neural_compressor.common.base_tuning",false]],"neural_compressor.common.tuning_param":[[3,"module-neural_compressor.common.tuning_param",false]],"neural_compressor.common.utils":[[5,"module-neural_compressor.common.utils",false]],"neural_compressor.common.utils.constants":[[4,"module-neural_compressor.common.utils.constants",false]],"neural_compressor.common.utils.logger":[[6,"module-neural_compressor.common.utils.logger",false]],"neural_compressor.common.utils.save_load":[[7,"module-neural_compressor.common.utils.save_load",false]],"neural_compressor.common.utils.utility":[[8,"module-neural_compressor.common.utils.utility",false]],"neural_compressor.common.version":[[9,"module-neural_compressor.common.version",false]],"neural_compressor.jax":[[12,"module-neural_compressor.jax",false]],"neural_compressor.jax.algorithms":[[11,"module-neural_compressor.jax.algorithms",false]],"neural_compressor.tensorflow":[[21,"module-neural_compressor.tensorflow",false]],"neural_compressor.tensorflow.algorithms":[[13,"module-neural_compressor.tensorflow.algorithms",false]],"neural_compressor.tensorflow.algorithms.smoother":[[16,"module-neural_compressor.tensorflow.algorithms.smoother",false]],"neural_compressor.tensorflow.algorithms.smoother.calibration":[[14,"module-neural_compressor.tensorflow.algorithms.smoother.calibration",false]],"neural_compressor.tensorflow.algorithms.smoother.core":[[15,"module-neural_compressor.tensorflow.algorithms.smoother.core",false]],"neural_compressor.tensorflow.algorithms.smoother.scaler":[[17,"module-neural_compressor.tensorflow.algorithms.smoother.scaler",false]],"neural_compressor.tensorflow.algorithms.static_quant":[[18,"module-neural_compressor.tensorflow.algorithms.static_quant",false]],"neural_compressor.tensorflow.algorithms.static_quant.keras":[[19,"module-neural_compressor.tensorflow.algorithms.static_quant.keras",false]],"neural_compressor.tensorflow.algorithms.static_quant.tensorflow":[[20,"module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow",false]],"neural_compressor.tensorflow.keras":[[22,"module-neural_compressor.tensorflow.keras",false]],"neural_compressor.tensorflow.keras.layers":[[26,"module-neural_compressor.tensorflow.keras.layers",false]],"neural_compressor.tensorflow.keras.layers.conv2d":[[23,"module-neural_compressor.tensorflow.keras.layers.conv2d",false]],"neural_compressor.tensorflow.keras.layers.dense":[[24,"module-neural_compressor.tensorflow.keras.layers.dense",false]],"neural_compressor.tensorflow.keras.layers.depthwise_conv2d":[[25,"module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d",false]],"neural_compressor.tensorflow.keras.layers.layer_initializer":[[27,"module-neural_compressor.tensorflow.keras.layers.layer_initializer",false]],"neural_compressor.tensorflow.keras.layers.pool2d":[[28,"module-neural_compressor.tensorflow.keras.layers.pool2d",false]],"neural_compressor.tensorflow.keras.layers.separable_conv2d":[[29,"module-neural_compressor.tensorflow.keras.layers.separable_conv2d",false]],"neural_compressor.tensorflow.keras.quantization":[[31,"module-neural_compressor.tensorflow.keras.quantization",false]],"neural_compressor.tensorflow.keras.quantization.config":[[30,"module-neural_compressor.tensorflow.keras.quantization.config",false]],"neural_compressor.tensorflow.quantization":[[35,"module-neural_compressor.tensorflow.quantization",false]],"neural_compressor.tensorflow.quantization.algorithm_entry":[[32,"module-neural_compressor.tensorflow.quantization.algorithm_entry",false]],"neural_compressor.tensorflow.quantization.autotune":[[33,"module-neural_compressor.tensorflow.quantization.autotune",false]],"neural_compressor.tensorflow.quantization.config":[[34,"module-neural_compressor.tensorflow.quantization.config",false]],"neural_compressor.tensorflow.quantization.quantize":[[36,"module-neural_compressor.tensorflow.quantization.quantize",false]],"neural_compressor.tensorflow.quantization.utils":[[92,"module-neural_compressor.tensorflow.quantization.utils",false]],"neural_compressor.tensorflow.quantization.utils.graph_converter":[[37,"module-neural_compressor.tensorflow.quantization.utils.graph_converter",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter":[[75,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16":[[40,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert":[[38,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer":[[39,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic":[[64,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd":[[41,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout":[[42,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu":[[43,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random":[[44,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const":[[45,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction":[[46,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd":[[47,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer":[[48,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape":[[49,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm":[[50,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant":[[51,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add":[[52,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul":[[53,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math":[[54,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn":[[55,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in":[[56,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu":[[57,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm":[[58,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv":[[59,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv":[[60,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose":[[61,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer":[[62,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass":[[63,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node":[[65,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu":[[66,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize":[[67,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes":[[68,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm":[[69,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input":[[70,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes":[[71,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes":[[72,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer":[[73,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base":[[74,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8":[[82,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant":[[76,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value":[[77,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize":[[78,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize":[[79,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize":[[80,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize":[[81,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer":[[83,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter":[[84,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse":[[85,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation":[[86,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq":[[87,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern":[[88,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq":[[89,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq",false]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern":[[90,"module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern",false]],"neural_compressor.tensorflow.quantization.utils.graph_util":[[91,"module-neural_compressor.tensorflow.quantization.utils.graph_util",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph":[[93,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq":[[101,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn":[[94,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2":[[95,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv":[[96,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv":[[97,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in":[[98,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul":[[99,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling":[[100,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq":[[102,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base":[[103,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn":[[104,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2":[[105,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv":[[106,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu":[[107,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul":[[108,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling":[[109,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling",false]],"neural_compressor.tensorflow.quantization.utils.quantize_graph_common":[[110,"module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common",false]],"neural_compressor.tensorflow.quantization.utils.transform_graph":[[113,"module-neural_compressor.tensorflow.quantization.utils.transform_graph",false]],"neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction":[[111,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction",false]],"neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base":[[112,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base",false]],"neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging":[[114,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging",false]],"neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat":[[115,"module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat",false]],"neural_compressor.tensorflow.quantization.utils.utility":[[116,"module-neural_compressor.tensorflow.quantization.utils.utility",false]],"neural_compressor.tensorflow.utils":[[119,"module-neural_compressor.tensorflow.utils",false]],"neural_compressor.tensorflow.utils.constants":[[117,"module-neural_compressor.tensorflow.utils.constants",false]],"neural_compressor.tensorflow.utils.data":[[118,"module-neural_compressor.tensorflow.utils.data",false]],"neural_compressor.tensorflow.utils.model":[[120,"module-neural_compressor.tensorflow.utils.model",false]],"neural_compressor.tensorflow.utils.model_wrappers":[[121,"module-neural_compressor.tensorflow.utils.model_wrappers",false]],"neural_compressor.tensorflow.utils.utility":[[122,"module-neural_compressor.tensorflow.utils.utility",false]],"neural_compressor.torch":[[172,"module-neural_compressor.torch",false]],"neural_compressor.torch.algorithms":[[126,"module-neural_compressor.torch.algorithms",false]],"neural_compressor.torch.algorithms.autoround":[[124,"module-neural_compressor.torch.algorithms.autoround",false]],"neural_compressor.torch.algorithms.autoround.autoround":[[123,"module-neural_compressor.torch.algorithms.autoround.autoround",false]],"neural_compressor.torch.algorithms.base_algorithm":[[125,"module-neural_compressor.torch.algorithms.base_algorithm",false]],"neural_compressor.torch.algorithms.layer_wise":[[127,"module-neural_compressor.torch.algorithms.layer_wise",false]],"neural_compressor.torch.algorithms.layer_wise.load":[[128,"module-neural_compressor.torch.algorithms.layer_wise.load",false]],"neural_compressor.torch.algorithms.layer_wise.modified_pickle":[[129,"module-neural_compressor.torch.algorithms.layer_wise.modified_pickle",false]],"neural_compressor.torch.algorithms.layer_wise.utils":[[130,"module-neural_compressor.torch.algorithms.layer_wise.utils",false]],"neural_compressor.torch.algorithms.mixed_precision":[[132,"module-neural_compressor.torch.algorithms.mixed_precision",false]],"neural_compressor.torch.algorithms.mixed_precision.half_precision_convert":[[131,"module-neural_compressor.torch.algorithms.mixed_precision.half_precision_convert",false]],"neural_compressor.torch.algorithms.mixed_precision.module_wrappers":[[133,"module-neural_compressor.torch.algorithms.mixed_precision.module_wrappers",false]],"neural_compressor.torch.algorithms.mx_quant":[[134,"module-neural_compressor.torch.algorithms.mx_quant",false]],"neural_compressor.torch.algorithms.mx_quant.mx":[[135,"module-neural_compressor.torch.algorithms.mx_quant.mx",false]],"neural_compressor.torch.algorithms.mx_quant.utils":[[136,"module-neural_compressor.torch.algorithms.mx_quant.utils",false]],"neural_compressor.torch.algorithms.pt2e_quant":[[139,"module-neural_compressor.torch.algorithms.pt2e_quant",false]],"neural_compressor.torch.algorithms.pt2e_quant.core":[[137,"module-neural_compressor.torch.algorithms.pt2e_quant.core",false]],"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter":[[138,"module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter",false]],"neural_compressor.torch.algorithms.pt2e_quant.save_load":[[140,"module-neural_compressor.torch.algorithms.pt2e_quant.save_load",false]],"neural_compressor.torch.algorithms.pt2e_quant.utility":[[141,"module-neural_compressor.torch.algorithms.pt2e_quant.utility",false]],"neural_compressor.torch.algorithms.qat":[[142,"module-neural_compressor.torch.algorithms.qat",false]],"neural_compressor.torch.algorithms.qat.quant_linear":[[143,"module-neural_compressor.torch.algorithms.qat.quant_linear",false]],"neural_compressor.torch.algorithms.qat.quant_utils":[[144,"module-neural_compressor.torch.algorithms.qat.quant_utils",false]],"neural_compressor.torch.algorithms.qat.tensor_quantizer":[[145,"module-neural_compressor.torch.algorithms.qat.tensor_quantizer",false]],"neural_compressor.torch.algorithms.smooth_quant":[[146,"module-neural_compressor.torch.algorithms.smooth_quant",false]],"neural_compressor.torch.algorithms.smooth_quant.save_load":[[147,"module-neural_compressor.torch.algorithms.smooth_quant.save_load",false]],"neural_compressor.torch.algorithms.smooth_quant.smooth_quant":[[148,"module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant",false]],"neural_compressor.torch.algorithms.smooth_quant.utility":[[149,"module-neural_compressor.torch.algorithms.smooth_quant.utility",false]],"neural_compressor.torch.algorithms.static_quant":[[150,"module-neural_compressor.torch.algorithms.static_quant",false]],"neural_compressor.torch.algorithms.static_quant.save_load":[[151,"module-neural_compressor.torch.algorithms.static_quant.save_load",false]],"neural_compressor.torch.algorithms.static_quant.static_quant":[[152,"module-neural_compressor.torch.algorithms.static_quant.static_quant",false]],"neural_compressor.torch.algorithms.static_quant.utility":[[153,"module-neural_compressor.torch.algorithms.static_quant.utility",false]],"neural_compressor.torch.algorithms.weight_only":[[163,"module-neural_compressor.torch.algorithms.weight_only",false]],"neural_compressor.torch.algorithms.weight_only.awq":[[154,"module-neural_compressor.torch.algorithms.weight_only.awq",false]],"neural_compressor.torch.algorithms.weight_only.gptq":[[155,"module-neural_compressor.torch.algorithms.weight_only.gptq",false]],"neural_compressor.torch.algorithms.weight_only.hqq":[[159,"module-neural_compressor.torch.algorithms.weight_only.hqq",false]],"neural_compressor.torch.algorithms.weight_only.hqq.bitpack":[[156,"module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack",false]],"neural_compressor.torch.algorithms.weight_only.hqq.config":[[157,"module-neural_compressor.torch.algorithms.weight_only.hqq.config",false]],"neural_compressor.torch.algorithms.weight_only.hqq.core":[[158,"module-neural_compressor.torch.algorithms.weight_only.hqq.core",false]],"neural_compressor.torch.algorithms.weight_only.hqq.optimizer":[[160,"module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer",false]],"neural_compressor.torch.algorithms.weight_only.hqq.qtensor":[[161,"module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor",false]],"neural_compressor.torch.algorithms.weight_only.hqq.quantizer":[[162,"module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer",false]],"neural_compressor.torch.algorithms.weight_only.modules":[[164,"module-neural_compressor.torch.algorithms.weight_only.modules",false]],"neural_compressor.torch.algorithms.weight_only.rtn":[[165,"module-neural_compressor.torch.algorithms.weight_only.rtn",false]],"neural_compressor.torch.algorithms.weight_only.save_load":[[166,"module-neural_compressor.torch.algorithms.weight_only.save_load",false]],"neural_compressor.torch.algorithms.weight_only.teq":[[167,"module-neural_compressor.torch.algorithms.weight_only.teq",false]],"neural_compressor.torch.algorithms.weight_only.utility":[[168,"module-neural_compressor.torch.algorithms.weight_only.utility",false]],"neural_compressor.torch.export":[[170,"module-neural_compressor.torch.export",false]],"neural_compressor.torch.export.export_hf":[[169,"module-neural_compressor.torch.export.export_hf",false]],"neural_compressor.torch.export.pt2e_export":[[171,"module-neural_compressor.torch.export.pt2e_export",false]],"neural_compressor.torch.quantization":[[176,"module-neural_compressor.torch.quantization",false]],"neural_compressor.torch.quantization.algorithm_entry":[[173,"module-neural_compressor.torch.quantization.algorithm_entry",false]],"neural_compressor.torch.quantization.autotune":[[174,"module-neural_compressor.torch.quantization.autotune",false]],"neural_compressor.torch.quantization.config":[[175,"module-neural_compressor.torch.quantization.config",false]],"neural_compressor.torch.quantization.quantize":[[177,"module-neural_compressor.torch.quantization.quantize",false]],"neural_compressor.torch.quantization.save_load_entry":[[178,"module-neural_compressor.torch.quantization.save_load_entry",false]],"neural_compressor.torch.utils":[[184,"module-neural_compressor.torch.utils",false]],"neural_compressor.torch.utils.auto_accelerator":[[179,"module-neural_compressor.torch.utils.auto_accelerator",false]],"neural_compressor.torch.utils.bit_packer":[[180,"module-neural_compressor.torch.utils.bit_packer",false]],"neural_compressor.torch.utils.block_wise":[[181,"module-neural_compressor.torch.utils.block_wise",false]],"neural_compressor.torch.utils.constants":[[182,"module-neural_compressor.torch.utils.constants",false]],"neural_compressor.torch.utils.environ":[[183,"module-neural_compressor.torch.utils.environ",false]],"neural_compressor.torch.utils.utility":[[185,"module-neural_compressor.torch.utils.utility",false]],"neural_compressor.version":[[186,"module-neural_compressor.version",false]],"node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)":[[55,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_from_map",false]],"node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)":[[56,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_from_map",false]],"node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)":[[58,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_from_map",false]],"node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)":[[55,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_name_from_input",false]],"node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)":[[56,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_name_from_input",false]],"node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)":[[58,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_name_from_input",false]],"op_level (neural_compressor.common.tuning_param.paramlevel attribute)":[[3,"neural_compressor.common.tuning_param.ParamLevel.OP_LEVEL",false]],"op_type_level (neural_compressor.common.tuning_param.paramlevel attribute)":[[3,"neural_compressor.common.tuning_param.ParamLevel.OP_TYPE_LEVEL",false]],"operatorconfig (class in neural_compressor.tensorflow.keras.quantization.config)":[[30,"neural_compressor.tensorflow.keras.quantization.config.OperatorConfig",false]],"operatorconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.OperatorConfig",false]],"optimize_weights_proximal_legacy() (in module neural_compressor.torch.algorithms.weight_only.hqq.optimizer)":[[160,"neural_compressor.torch.algorithms.weight_only.hqq.optimizer.optimize_weights_proximal_legacy",false]],"optimizeqdqgraph (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq)":[[102,"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq.OptimizeQDQGraph",false]],"pack_array_with_numba_b2_c16() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b2_c16",false]],"pack_array_with_numba_b2_c32() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b2_c32",false]],"pack_array_with_numba_b2_c64() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b2_c64",false]],"pack_array_with_numba_b2_c8() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b2_c8",false]],"pack_array_with_numba_b4_c16() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b4_c16",false]],"pack_array_with_numba_b4_c32() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b4_c32",false]],"pack_array_with_numba_b4_c64() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b4_c64",false]],"pack_array_with_numba_b4_c8() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b4_c8",false]],"pack_array_with_numba_b8_c16() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b8_c16",false]],"pack_array_with_numba_b8_c32() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b8_c32",false]],"pack_array_with_numba_b8_c64() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b8_c64",false]],"pack_array_with_numba_b8_c8() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.pack_array_with_numba_b8_c8",false]],"packer (class in neural_compressor.torch.algorithms.weight_only.hqq.bitpack)":[[156,"neural_compressor.torch.algorithms.weight_only.hqq.bitpack.Packer",false]],"packing (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)":[[161,"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.packing",false]],"paramlevel (class in neural_compressor.common.tuning_param)":[[3,"neural_compressor.common.tuning_param.ParamLevel",false]],"params_list (neural_compressor.common.base_config.baseconfig attribute)":[[0,"neural_compressor.common.base_config.BaseConfig.params_list",false]],"parse_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.parse_cfgs",false]],"parse_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.parse_saved_model",false]],"patch_hqq_moduile() (in module neural_compressor.torch.algorithms.weight_only.hqq.quantizer)":[[162,"neural_compressor.torch.algorithms.weight_only.hqq.quantizer.patch_hqq_moduile",false]],"pattern_factory() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.pattern_factory",false]],"patternpair (class in neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair",false]],"pickleerror":[[129,"neural_compressor.torch.algorithms.layer_wise.modified_pickle.PickleError",false]],"picklingerror":[[129,"neural_compressor.torch.algorithms.layer_wise.modified_pickle.PicklingError",false]],"postcseoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse)":[[85,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse.PostCseOptimizer",false]],"posthostconstconverter (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter)":[[84,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter.PostHostConstConverter",false]],"postprocess_model() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.postprocess_model",false]],"preoptimization (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize)":[[67,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize.PreOptimization",false]],"prepare() (in module neural_compressor.torch.quantization.quantize)":[[177,"neural_compressor.torch.quantization.quantize.prepare",false]],"prepare_qat() (in module neural_compressor.torch.quantization.quantize)":[[177,"neural_compressor.torch.quantization.quantize.prepare_qat",false]],"preprocess_quant_config() (in module neural_compressor.torch.quantization.quantize)":[[177,"neural_compressor.torch.quantization.quantize.preprocess_quant_config",false]],"processortype (class in neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.ProcessorType",false]],"pt2e_dynamic_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.pt2e_dynamic_quant_entry",false]],"pt2e_static_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.pt2e_static_quant_entry",false]],"qavgpool2d (class in neural_compressor.tensorflow.keras.layers.pool2d)":[[28,"neural_compressor.tensorflow.keras.layers.pool2d.QAvgPool2D",false]],"qconv2d (class in neural_compressor.tensorflow.keras.layers.conv2d)":[[23,"neural_compressor.tensorflow.keras.layers.conv2d.QConv2D",false]],"qdense (class in neural_compressor.tensorflow.keras.layers.dense)":[[24,"neural_compressor.tensorflow.keras.layers.dense.QDense",false]],"qdepthwiseconv2d (class in neural_compressor.tensorflow.keras.layers.depthwise_conv2d)":[[25,"neural_compressor.tensorflow.keras.layers.depthwise_conv2d.QDepthwiseConv2D",false]],"qdq_quantize() (in module neural_compressor.torch.algorithms.smooth_quant.smooth_quant)":[[148,"neural_compressor.torch.algorithms.smooth_quant.smooth_quant.qdq_quantize",false]],"qdq_weight_actor() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_actor",false]],"qdq_weight_asym() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_asym",false]],"qdq_weight_sym() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_sym",false]],"qdqlayer (class in neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.QDQLayer",false]],"qdqlayer (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.QDQLayer",false]],"qmaxpool2d (class in neural_compressor.tensorflow.keras.layers.pool2d)":[[28,"neural_compressor.tensorflow.keras.layers.pool2d.QMaxPool2D",false]],"qseparableconv2d (class in neural_compressor.tensorflow.keras.layers.separable_conv2d)":[[29,"neural_compressor.tensorflow.keras.layers.separable_conv2d.QSeparableConv2D",false]],"qtensor (class in neural_compressor.torch.algorithms.weight_only.hqq.qtensor)":[[161,"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensor",false]],"qtensorconfig (class in neural_compressor.torch.algorithms.weight_only.hqq.config)":[[157,"neural_compressor.torch.algorithms.weight_only.hqq.config.QTensorConfig",false]],"qtensormetainfo (class in neural_compressor.torch.algorithms.weight_only.hqq.qtensor)":[[161,"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo",false]],"quant_dequant_w_v1() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.quant_dequant_w_v1",false]],"quant_dequant_x_v1() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.quant_dequant_x_v1",false]],"quant_tensor() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.quant_tensor",false]],"quant_weight_w_scale() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.quant_weight_w_scale",false]],"quantize() (in module neural_compressor.torch.quantization.quantize)":[[177,"neural_compressor.torch.quantization.quantize.quantize",false]],"quantize_4bit() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.quantize_4bit",false]],"quantize_elemwise_op() (in module neural_compressor.torch.algorithms.mx_quant.utils)":[[136,"neural_compressor.torch.algorithms.mx_quant.utils.quantize_elemwise_op",false]],"quantize_model() (in module neural_compressor.tensorflow.quantization.quantize)":[[36,"neural_compressor.tensorflow.quantization.quantize.quantize_model",false]],"quantize_model_with_single_config() (in module neural_compressor.tensorflow.quantization.quantize)":[[36,"neural_compressor.tensorflow.quantization.quantize.quantize_model_with_single_config",false]],"quantize_mx_op() (in module neural_compressor.torch.algorithms.mx_quant.utils)":[[136,"neural_compressor.torch.algorithms.mx_quant.utils.quantize_mx_op",false]],"quantizegraphbase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base)":[[103,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base.QuantizeGraphBase",false]],"quantizegraphforintel (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu)":[[107,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu.QuantizeGraphForIntel",false]],"quantizegraphhelper (class in neural_compressor.tensorflow.quantization.utils.quantize_graph_common)":[[110,"neural_compressor.tensorflow.quantization.utils.quantize_graph_common.QuantizeGraphHelper",false]],"quantizenodebase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base)":[[103,"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base.QuantizeNodeBase",false]],"quantizer (class in neural_compressor.torch.algorithms.base_algorithm)":[[125,"neural_compressor.torch.algorithms.base_algorithm.Quantizer",false]],"quantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.Quantizer",false]],"quantlinear (class in neural_compressor.torch.algorithms.qat.quant_linear)":[[143,"neural_compressor.torch.algorithms.qat.quant_linear.QuantLinear",false]],"rawgptquantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.RAWGPTQuantizer",false]],"read_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.read_graph",false]],"read_json_file() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.read_json_file",false]],"reconstruct_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.reconstruct_saved_model",false]],"recover_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.recover_forward",false]],"recover_forward() (in module neural_compressor.torch.utils.block_wise)":[[181,"neural_compressor.torch.utils.block_wise.recover_forward",false]],"recover_model_from_json() (in module neural_compressor.torch.algorithms.smooth_quant.save_load)":[[147,"neural_compressor.torch.algorithms.smooth_quant.save_load.recover_model_from_json",false]],"register_accelerator() (in module neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.register_accelerator",false]],"register_algo() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.register_algo",false]],"register_algo() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.register_algo",false]],"register_autotune() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.register_autotune",false]],"register_config() (in module neural_compressor.common.base_config)":[[0,"neural_compressor.common.base_config.register_config",false]],"register_pack_func() (in module neural_compressor.torch.utils.bit_packer)":[[180,"neural_compressor.torch.utils.bit_packer.register_pack_func",false]],"register_supported_configs_for_fwk() (in module neural_compressor.common.base_config)":[[0,"neural_compressor.common.base_config.register_supported_configs_for_fwk",false]],"register_weight_hooks() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.register_weight_hooks",false]],"removetrainingnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes)":[[68,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes.RemoveTrainingNodesOptimizer",false]],"renamebatchnormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm)":[[69,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm.RenameBatchNormOptimizer",false]],"replace_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.replace_forward",false]],"replace_forward() (in module neural_compressor.torch.utils.block_wise)":[[181,"neural_compressor.torch.utils.block_wise.replace_forward",false]],"replace_pattern (neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.patternpair attribute)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair.replace_pattern",false]],"replace_with_quant_linear() (in module neural_compressor.torch.algorithms.qat.quant_utils)":[[144,"neural_compressor.torch.algorithms.qat.quant_utils.replace_with_quant_linear",false]],"replacement_fn() (in module neural_compressor.torch.algorithms.weight_only.hqq.quantizer)":[[162,"neural_compressor.torch.algorithms.weight_only.hqq.quantizer.replacement_fn",false]],"rerangequantizedconcat (class in neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat)":[[115,"neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat.RerangeQuantizedConcat",false]],"reshape_in_channel_to_last() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.reshape_in_channel_to_last",false]],"reshape_scale_as_input() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.reshape_scale_as_input",false]],"reshape_scale_as_weight() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.reshape_scale_as_weight",false]],"roundingmode (class in neural_compressor.torch.algorithms.mx_quant.utils)":[[136,"neural_compressor.torch.algorithms.mx_quant.utils.RoundingMode",false]],"rtn_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.rtn_entry",false]],"rtnconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.RTNConfig",false]],"rtnquantizer (class in neural_compressor.torch.algorithms.weight_only.rtn)":[[165,"neural_compressor.torch.algorithms.weight_only.rtn.RTNQuantizer",false]],"sampler (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.Sampler",false]],"save() (in module neural_compressor.torch.algorithms.pt2e_quant.save_load)":[[140,"neural_compressor.torch.algorithms.pt2e_quant.save_load.save",false]],"save() (in module neural_compressor.torch.algorithms.static_quant.save_load)":[[151,"neural_compressor.torch.algorithms.static_quant.save_load.save",false]],"save() (in module neural_compressor.torch.algorithms.weight_only.save_load)":[[166,"neural_compressor.torch.algorithms.weight_only.save_load.save",false]],"save() (in module neural_compressor.torch.quantization.save_load_entry)":[[178,"neural_compressor.torch.quantization.save_load_entry.save",false]],"save_config_mapping() (in module neural_compressor.common.utils.save_load)":[[7,"neural_compressor.common.utils.save_load.save_config_mapping",false]],"save_layers_in_shards_iteratively() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.save_layers_in_shards_iteratively",false]],"saved_model_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.saved_model_session",false]],"saveloadformat (class in neural_compressor.torch.utils.constants)":[[182,"neural_compressor.torch.utils.constants.SaveLoadFormat",false]],"scalepropagationtransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation)":[[86,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation.ScaleProPagationTransformer",false]],"search_clip() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.search_clip",false]],"search_pattern (neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.patternpair attribute)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair.search_pattern",false]],"sequentialsampler (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.SequentialSampler",false]],"sequentialsampler (class in neural_compressor.tensorflow.utils.data)":[[118,"neural_compressor.tensorflow.utils.data.SequentialSampler",false]],"set_module() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.set_module",false]],"set_module() (in module neural_compressor.torch.algorithms.weight_only.utility)":[[168,"neural_compressor.torch.algorithms.weight_only.utility.set_module",false]],"set_module() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.set_module",false]],"set_random_seed() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.set_random_seed",false]],"set_resume_from() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.set_resume_from",false]],"set_tensorboard() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.set_tensorboard",false]],"set_workspace() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.set_workspace",false]],"shape (neural_compressor.torch.algorithms.weight_only.hqq.qtensor.qtensormetainfo attribute)":[[161,"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo.shape",false]],"shareqdqforitexypatternoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern)":[[90,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern.ShareQDQForItexYPatternOptimizer",false]],"simple_inference() (in module neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.simple_inference",false]],"singleton() (in module neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.singleton",false]],"singleton() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.singleton",false]],"slim_session() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.slim_session",false]],"smooth_quant_entry() (in module neural_compressor.tensorflow.quantization.algorithm_entry)":[[32,"neural_compressor.tensorflow.quantization.algorithm_entry.smooth_quant_entry",false]],"smooth_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.smooth_quant_entry",false]],"smoothquant (class in neural_compressor.tensorflow.algorithms.smoother.core)":[[15,"neural_compressor.tensorflow.algorithms.smoother.core.SmoothQuant",false]],"smoothquantcalibration (class in neural_compressor.tensorflow.algorithms.smoother.calibration)":[[14,"neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibration",false]],"smoothquantcalibrationllm (class in neural_compressor.tensorflow.algorithms.smoother.calibration)":[[14,"neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibrationLLM",false]],"smoothquantconfig (class in neural_compressor.tensorflow.quantization.config)":[[34,"neural_compressor.tensorflow.quantization.config.SmoothQuantConfig",false]],"smoothquantconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.SmoothQuantConfig",false]],"smoothquantquantizer (class in neural_compressor.torch.algorithms.smooth_quant.smooth_quant)":[[148,"neural_compressor.torch.algorithms.smooth_quant.smooth_quant.SmoothQuantQuantizer",false]],"smoothquantscaler (class in neural_compressor.tensorflow.algorithms.smoother.scaler)":[[17,"neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScaler",false]],"smoothquantscalerllm (class in neural_compressor.tensorflow.algorithms.smoother.scaler)":[[17,"neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScalerLLM",false]],"splitsharedinputoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input)":[[70,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input.SplitSharedInputOptimizer",false]],"sqlinearwrapper (class in neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.SQLinearWrapper",false]],"static_quant_entry() (in module neural_compressor.tensorflow.quantization.algorithm_entry)":[[32,"neural_compressor.tensorflow.quantization.algorithm_entry.static_quant_entry",false]],"static_quant_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.static_quant_entry",false]],"staticquantconfig (class in neural_compressor.tensorflow.keras.quantization.config)":[[30,"neural_compressor.tensorflow.keras.quantization.config.StaticQuantConfig",false]],"staticquantconfig (class in neural_compressor.tensorflow.quantization.config)":[[34,"neural_compressor.tensorflow.quantization.config.StaticQuantConfig",false]],"staticquantconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.StaticQuantConfig",false]],"staticquantquantizer (class in neural_compressor.torch.algorithms.static_quant.static_quant)":[[152,"neural_compressor.torch.algorithms.static_quant.static_quant.StaticQuantQuantizer",false]],"statistics (class in neural_compressor.common.utils.utility)":[[8,"neural_compressor.common.utils.utility.Statistics",false]],"strip_equivalent_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.strip_equivalent_nodes",false]],"strip_unused_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.strip_unused_nodes",false]],"stripequivalentnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes)":[[71,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes.StripEquivalentNodesOptimizer",false]],"stripunusednodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes)":[[72,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes.StripUnusedNodesOptimizer",false]],"switchoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer)":[[73,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer.SwitchOptimizer",false]],"tensorflow_itexadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)":[[20,"neural_compressor.tensorflow.algorithms.static_quant.tensorflow.Tensorflow_ITEXAdaptor",false]],"tensorflowadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)":[[20,"neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorFlowAdaptor",false]],"tensorflowbasemodel (class in neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.TensorflowBaseModel",false]],"tensorflowcheckpointmodel (class in neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.TensorflowCheckpointModel",false]],"tensorflowconfig (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)":[[20,"neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorFlowConfig",false]],"tensorflowconfigconverter (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)":[[20,"neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorflowConfigConverter",false]],"tensorflowglobalconfig (class in neural_compressor.tensorflow.utils.model)":[[120,"neural_compressor.tensorflow.utils.model.TensorflowGlobalConfig",false]],"tensorflowllmmodel (class in neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.TensorflowLLMModel",false]],"tensorflowmodel (class in neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.TensorflowModel",false]],"tensorflowquery (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)":[[20,"neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorflowQuery",false]],"tensorflowsavedmodelmodel (class in neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.TensorflowSavedModelModel",false]],"tensorquantizer (class in neural_compressor.torch.algorithms.qat.tensor_quantizer)":[[145,"neural_compressor.torch.algorithms.qat.tensor_quantizer.TensorQuantizer",false]],"teq_quantize_entry() (in module neural_compressor.torch.quantization.algorithm_entry)":[[173,"neural_compressor.torch.quantization.algorithm_entry.teq_quantize_entry",false]],"teqconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.TEQConfig",false]],"teqlinearfakequant (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.TEQLinearFakeQuant",false]],"tequantizer (class in neural_compressor.torch.algorithms.weight_only.teq)":[[167,"neural_compressor.torch.algorithms.weight_only.teq.TEQuantizer",false]],"tfslimnetsfactory (class in neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.TFSlimNetsFactory",false]],"to_device() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.to_device",false]],"to_dtype() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.to_dtype",false]],"torchbaseconfig (class in neural_compressor.torch.quantization.config)":[[175,"neural_compressor.torch.quantization.config.TorchBaseConfig",false]],"torchsmoothquant (class in neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.TorchSmoothQuant",false]],"trace_gptq_target_blocks() (in module neural_compressor.torch.algorithms.weight_only.gptq)":[[155,"neural_compressor.torch.algorithms.weight_only.gptq.trace_gptq_target_blocks",false]],"trainableequivalenttransformation (class in neural_compressor.torch.algorithms.weight_only.teq)":[[167,"neural_compressor.torch.algorithms.weight_only.teq.TrainableEquivalentTransformation",false]],"transformation() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)":[[138,"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.transformation",false]],"transformerbasedmodelblockpatterndetector (class in neural_compressor.torch.algorithms.static_quant.utility)":[[153,"neural_compressor.torch.algorithms.static_quant.utility.TransformerBasedModelBlockPatternDetector",false]],"try_loading_keras() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.try_loading_keras",false]],"tuningconfig (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.TuningConfig",false]],"tuninglogger (class in neural_compressor.common.utils.logger)":[[6,"neural_compressor.common.utils.logger.TuningLogger",false]],"tuningmonitor (class in neural_compressor.common.base_tuning)":[[1,"neural_compressor.common.base_tuning.TuningMonitor",false]],"tuningparam (class in neural_compressor.common.tuning_param)":[[3,"neural_compressor.common.tuning_param.TuningParam",false]],"unpackedweightonlylinearparams (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.UnpackedWeightOnlyLinearParams",false]],"unpicklingerror":[[129,"neural_compressor.torch.algorithms.layer_wise.modified_pickle.UnpicklingError",false]],"update_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)":[[130,"neural_compressor.torch.algorithms.layer_wise.utils.update_module",false]],"update_sq_scale() (in module neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.update_sq_scale",false]],"valid_keras_format() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.valid_keras_format",false]],"valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)":[[55,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.valid_reshape_inputs",false]],"valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)":[[56,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.valid_reshape_inputs",false]],"validate_and_inference_input_output() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.validate_and_inference_input_output",false]],"validate_graph_node() (in module neural_compressor.tensorflow.utils.model_wrappers)":[[121,"neural_compressor.tensorflow.utils.model_wrappers.validate_graph_node",false]],"validate_modules() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.validate_modules",false]],"values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)":[[55,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.values_from_const",false]],"values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)":[[56,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.values_from_const",false]],"values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)":[[58,"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.values_from_const",false]],"version1_eq_version2() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.version1_eq_version2",false]],"version1_gt_version2() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.version1_gt_version2",false]],"version1_gte_version2() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.version1_gte_version2",false]],"version1_lt_version2() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.version1_lt_version2",false]],"version1_lte_version2() (in module neural_compressor.tensorflow.utils.utility)":[[122,"neural_compressor.tensorflow.utils.utility.version1_lte_version2",false]],"w8a8pt2equantizer (class in neural_compressor.torch.algorithms.pt2e_quant.core)":[[137,"neural_compressor.torch.algorithms.pt2e_quant.core.W8A8PT2EQuantizer",false]],"weightonlylinear (class in neural_compressor.torch.algorithms.weight_only.modules)":[[164,"neural_compressor.torch.algorithms.weight_only.modules.WeightOnlyLinear",false]],"white_list (neural_compressor.tensorflow.quantization.config.smoothquantconfig attribute)":[[34,"neural_compressor.tensorflow.quantization.config.SmoothQuantConfig.white_list",false]],"woqmodelloader (class in neural_compressor.torch.algorithms.weight_only.save_load)":[[166,"neural_compressor.torch.algorithms.weight_only.save_load.WOQModelLoader",false]],"wrapperlayer (class in neural_compressor.torch.algorithms.smooth_quant.utility)":[[149,"neural_compressor.torch.algorithms.smooth_quant.utility.WrapperLayer",false]],"write_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)":[[116,"neural_compressor.tensorflow.quantization.utils.utility.write_graph",false]],"write_json_file() (in module neural_compressor.torch.utils.utility)":[[185,"neural_compressor.torch.utils.utility.write_json_file",false]],"xpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)":[[179,"neural_compressor.torch.utils.auto_accelerator.XPU_Accelerator",false]]},"objects":{"":[[10,0,0,"-","neural_compressor"]],"neural_compressor":[[2,0,0,"-","common"],[12,0,0,"-","jax"],[21,0,0,"-","tensorflow"],[172,0,0,"-","torch"],[186,0,0,"-","version"]],"neural_compressor.common":[[0,0,0,"-","base_config"],[1,0,0,"-","base_tuning"],[3,0,0,"-","tuning_param"],[5,0,0,"-","utils"],[9,0,0,"-","version"]],"neural_compressor.common.base_config":[[0,1,1,"","BaseConfig"],[0,1,1,"","ComposableConfig"],[0,1,1,"","ConfigRegistry"],[0,3,1,"","get_all_config_set_from_config_registry"],[0,3,1,"","register_config"],[0,3,1,"","register_supported_configs_for_fwk"]],"neural_compressor.common.base_config.BaseConfig":[[0,2,1,"","name"],[0,2,1,"","params_list"]],"neural_compressor.common.base_config.ComposableConfig":[[0,2,1,"","config_list"]],"neural_compressor.common.base_tuning":[[1,1,1,"","ConfigLoader"],[1,1,1,"","ConfigSet"],[1,1,1,"","EvaluationFuncWrapper"],[1,1,1,"","Evaluator"],[1,1,1,"","Sampler"],[1,1,1,"","SequentialSampler"],[1,1,1,"","TuningConfig"],[1,1,1,"","TuningMonitor"],[1,3,1,"","init_tuning"]],"neural_compressor.common.base_tuning.ConfigSet":[[1,2,1,"","config_list"]],"neural_compressor.common.tuning_param":[[3,1,1,"","ParamLevel"],[3,1,1,"","TuningParam"]],"neural_compressor.common.tuning_param.ParamLevel":[[3,2,1,"","MODEL_LEVEL"],[3,2,1,"","OP_LEVEL"],[3,2,1,"","OP_TYPE_LEVEL"]],"neural_compressor.common.utils":[[4,0,0,"-","constants"],[6,0,0,"-","logger"],[7,0,0,"-","save_load"],[8,0,0,"-","utility"]],"neural_compressor.common.utils.constants":[[4,1,1,"","Mode"]],"neural_compressor.common.utils.logger":[[6,1,1,"","Logger"],[6,1,1,"","TuningLogger"]],"neural_compressor.common.utils.save_load":[[7,3,1,"","load_config_mapping"],[7,3,1,"","save_config_mapping"]],"neural_compressor.common.utils.utility":[[8,1,1,"","CpuInfo"],[8,1,1,"","LazyImport"],[8,1,1,"","ProcessorType"],[8,1,1,"","Statistics"],[8,3,1,"","call_counter"],[8,3,1,"","detect_processor_type_based_on_hw"],[8,3,1,"","dump_elapsed_time"],[8,3,1,"","get_workspace"],[8,3,1,"","log_process"],[8,3,1,"","set_random_seed"],[8,3,1,"","set_resume_from"],[8,3,1,"","set_tensorboard"],[8,3,1,"","set_workspace"],[8,3,1,"","singleton"]],"neural_compressor.jax":[[11,0,0,"-","algorithms"]],"neural_compressor.tensorflow":[[13,0,0,"-","algorithms"],[22,0,0,"-","keras"],[35,0,0,"-","quantization"],[119,0,0,"-","utils"]],"neural_compressor.tensorflow.algorithms":[[16,0,0,"-","smoother"],[18,0,0,"-","static_quant"]],"neural_compressor.tensorflow.algorithms.smoother":[[14,0,0,"-","calibration"],[15,0,0,"-","core"],[17,0,0,"-","scaler"]],"neural_compressor.tensorflow.algorithms.smoother.calibration":[[14,1,1,"","SmoothQuantCalibration"],[14,1,1,"","SmoothQuantCalibrationLLM"]],"neural_compressor.tensorflow.algorithms.smoother.core":[[15,1,1,"","SmoothQuant"]],"neural_compressor.tensorflow.algorithms.smoother.scaler":[[17,1,1,"","SmoothQuantScaler"],[17,1,1,"","SmoothQuantScalerLLM"]],"neural_compressor.tensorflow.algorithms.static_quant":[[19,0,0,"-","keras"],[20,0,0,"-","tensorflow"]],"neural_compressor.tensorflow.algorithms.static_quant.keras":[[19,1,1,"","KerasAdaptor"],[19,1,1,"","KerasConfigConverter"],[19,1,1,"","KerasQuery"],[19,1,1,"","KerasSurgery"]],"neural_compressor.tensorflow.algorithms.static_quant.tensorflow":[[20,1,1,"","TensorFlowAdaptor"],[20,1,1,"","TensorFlowConfig"],[20,1,1,"","TensorflowConfigConverter"],[20,1,1,"","TensorflowQuery"],[20,1,1,"","Tensorflow_ITEXAdaptor"]],"neural_compressor.tensorflow.keras":[[26,0,0,"-","layers"],[31,0,0,"-","quantization"]],"neural_compressor.tensorflow.keras.layers":[[23,0,0,"-","conv2d"],[24,0,0,"-","dense"],[25,0,0,"-","depthwise_conv2d"],[27,0,0,"-","layer_initializer"],[28,0,0,"-","pool2d"],[29,0,0,"-","separable_conv2d"]],"neural_compressor.tensorflow.keras.layers.conv2d":[[23,1,1,"","QConv2D"],[23,3,1,"","initialize_int8_conv2d"]],"neural_compressor.tensorflow.keras.layers.dense":[[24,1,1,"","QDense"],[24,3,1,"","initialize_int8_dense"]],"neural_compressor.tensorflow.keras.layers.depthwise_conv2d":[[25,1,1,"","QDepthwiseConv2D"],[25,3,1,"","initialize_int8_depthwise_conv2d"]],"neural_compressor.tensorflow.keras.layers.pool2d":[[28,1,1,"","QAvgPool2D"],[28,1,1,"","QMaxPool2D"],[28,3,1,"","initialize_int8_avgpool"],[28,3,1,"","initialize_int8_maxpool"]],"neural_compressor.tensorflow.keras.layers.separable_conv2d":[[29,1,1,"","QSeparableConv2D"],[29,3,1,"","initialize_int8_separable_conv2d"]],"neural_compressor.tensorflow.keras.quantization":[[30,0,0,"-","config"]],"neural_compressor.tensorflow.keras.quantization.config":[[30,1,1,"","OperatorConfig"],[30,1,1,"","StaticQuantConfig"],[30,3,1,"","get_all_registered_configs"],[30,3,1,"","get_default_static_quant_config"]],"neural_compressor.tensorflow.quantization":[[32,0,0,"-","algorithm_entry"],[33,0,0,"-","autotune"],[34,0,0,"-","config"],[36,0,0,"-","quantize"],[92,0,0,"-","utils"]],"neural_compressor.tensorflow.quantization.algorithm_entry":[[32,3,1,"","smooth_quant_entry"],[32,3,1,"","static_quant_entry"]],"neural_compressor.tensorflow.quantization.autotune":[[33,3,1,"","autotune"],[33,3,1,"","get_all_config_set"]],"neural_compressor.tensorflow.quantization.config":[[34,1,1,"","SmoothQuantConfig"],[34,1,1,"","StaticQuantConfig"],[34,3,1,"","get_default_sq_config"],[34,3,1,"","get_default_static_quant_config"]],"neural_compressor.tensorflow.quantization.config.SmoothQuantConfig":[[34,2,1,"","white_list"]],"neural_compressor.tensorflow.quantization.quantize":[[36,3,1,"","need_apply"],[36,3,1,"","quantize_model"],[36,3,1,"","quantize_model_with_single_config"]],"neural_compressor.tensorflow.quantization.utils":[[37,0,0,"-","graph_converter"],[75,0,0,"-","graph_rewriter"],[91,0,0,"-","graph_util"],[93,0,0,"-","quantize_graph"],[110,0,0,"-","quantize_graph_common"],[113,0,0,"-","transform_graph"],[116,0,0,"-","utility"]],"neural_compressor.tensorflow.quantization.utils.graph_converter":[[37,1,1,"","GraphConverter"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter":[[40,0,0,"-","bf16"],[64,0,0,"-","generic"],[74,0,0,"-","graph_base"],[82,0,0,"-","int8"],[87,0,0,"-","qdq"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16":[[38,0,0,"-","bf16_convert"],[39,0,0,"-","dequantize_cast_optimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert":[[38,1,1,"","BF16Convert"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer":[[39,1,1,"","DequantizeCastOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic":[[41,0,0,"-","convert_add_to_biasadd"],[42,0,0,"-","convert_layout"],[43,0,0,"-","convert_leakyrelu"],[44,0,0,"-","convert_nan_to_random"],[45,0,0,"-","convert_placeholder_to_const"],[46,0,0,"-","dilated_contraction"],[47,0,0,"-","dummy_biasadd"],[48,0,0,"-","expanddims_optimizer"],[49,0,0,"-","fetch_weight_from_reshape"],[50,0,0,"-","fold_batch_norm"],[51,0,0,"-","fold_constant"],[52,0,0,"-","fuse_biasadd_add"],[53,0,0,"-","fuse_column_wise_mul"],[54,0,0,"-","fuse_conv_with_math"],[55,0,0,"-","fuse_decomposed_bn"],[56,0,0,"-","fuse_decomposed_in"],[57,0,0,"-","fuse_gelu"],[58,0,0,"-","fuse_layer_norm"],[59,0,0,"-","fuse_pad_with_conv"],[60,0,0,"-","fuse_pad_with_fp32_conv"],[61,0,0,"-","fuse_reshape_transpose"],[62,0,0,"-","graph_cse_optimizer"],[63,0,0,"-","grappler_pass"],[65,0,0,"-","insert_print_node"],[66,0,0,"-","move_squeeze_after_relu"],[67,0,0,"-","pre_optimize"],[68,0,0,"-","remove_training_nodes"],[69,0,0,"-","rename_batch_norm"],[70,0,0,"-","split_shared_input"],[71,0,0,"-","strip_equivalent_nodes"],[72,0,0,"-","strip_unused_nodes"],[73,0,0,"-","switch_optimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd":[[41,1,1,"","ConvertAddToBiasAddOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout":[[42,1,1,"","ConvertLayoutOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu":[[43,1,1,"","ConvertLeakyReluOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random":[[44,1,1,"","ConvertNanToRandom"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const":[[45,1,1,"","ConvertPlaceholderToConst"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction":[[46,1,1,"","DilatedContraction"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd":[[47,1,1,"","InjectDummyBiasAddOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer":[[48,1,1,"","ExpandDimsOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape":[[49,1,1,"","FetchWeightFromReshapeOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm":[[50,1,1,"","FoldBatchNormNodesOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant":[[51,1,1,"","GraphFoldConstantOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add":[[52,1,1,"","FuseBiasAddAndAddOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul":[[53,1,1,"","FuseColumnWiseMulOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math":[[54,1,1,"","FuseConvWithMathOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn":[[55,1,1,"","FuseDecomposedBNOptimizer"],[55,3,1,"","bypass_reshape"],[55,3,1,"","get_const_dim_count"],[55,3,1,"","node_from_map"],[55,3,1,"","node_name_from_input"],[55,3,1,"","valid_reshape_inputs"],[55,3,1,"","values_from_const"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in":[[56,1,1,"","FuseDecomposedINOptimizer"],[56,3,1,"","bypass_reshape"],[56,3,1,"","get_const_dim_count"],[56,3,1,"","node_from_map"],[56,3,1,"","node_name_from_input"],[56,3,1,"","valid_reshape_inputs"],[56,3,1,"","values_from_const"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu":[[57,1,1,"","FuseGeluOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm":[[58,1,1,"","FuseLayerNormOptimizer"],[58,3,1,"","node_from_map"],[58,3,1,"","node_name_from_input"],[58,3,1,"","values_from_const"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv":[[59,1,1,"","FusePadWithConv2DOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv":[[60,1,1,"","FusePadWithFP32Conv2DOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose":[[61,1,1,"","FuseTransposeReshapeOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer":[[62,1,1,"","GraphCseOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass":[[63,1,1,"","GrapplerOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node":[[65,1,1,"","InsertPrintMinMaxNode"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu":[[66,1,1,"","MoveSqueezeAfterReluOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize":[[67,1,1,"","PreOptimization"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes":[[68,1,1,"","RemoveTrainingNodesOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm":[[69,1,1,"","RenameBatchNormOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input":[[70,1,1,"","SplitSharedInputOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes":[[71,1,1,"","StripEquivalentNodesOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes":[[72,1,1,"","StripUnusedNodesOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer":[[73,1,1,"","SwitchOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base":[[74,1,1,"","GraphRewriterBase"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8":[[76,0,0,"-","freeze_fake_quant"],[77,0,0,"-","freeze_value"],[78,0,0,"-","fuse_conv_redundant_dequantize"],[79,0,0,"-","fuse_conv_requantize"],[80,0,0,"-","fuse_matmul_redundant_dequantize"],[81,0,0,"-","fuse_matmul_requantize"],[83,0,0,"-","meta_op_optimizer"],[84,0,0,"-","post_hostconst_converter"],[85,0,0,"-","post_quantized_op_cse"],[86,0,0,"-","scale_propagation"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant":[[76,1,1,"","FreezeFakeQuantOpOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value":[[77,1,1,"","FreezeValueTransformer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize":[[78,1,1,"","FuseConvRedundantDequantizeTransformer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize":[[79,1,1,"","FuseConvRequantizeTransformer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize":[[80,1,1,"","FuseMatMulRedundantDequantizeTransformer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize":[[81,1,1,"","FuseMatMulRequantizeDequantizeNewAPITransformer"],[81,1,1,"","FuseMatMulRequantizeDequantizeTransformer"],[81,1,1,"","FuseMatMulRequantizeNewAPITransformer"],[81,1,1,"","FuseMatMulRequantizeTransformer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer":[[83,1,1,"","MetaInfoChangingMemOpOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter":[[84,1,1,"","PostHostConstConverter"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse":[[85,1,1,"","PostCseOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation":[[86,1,1,"","ScaleProPagationTransformer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq":[[88,0,0,"-","insert_qdq_pattern"],[89,0,0,"-","merge_duplicated_qdq"],[90,0,0,"-","share_qdq_y_pattern"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern":[[88,1,1,"","GenerateGraphWithQDQPattern"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq":[[89,1,1,"","MergeDuplicatedQDQOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern":[[90,1,1,"","ShareQDQForItexYPatternOptimizer"]],"neural_compressor.tensorflow.quantization.utils.graph_util":[[91,1,1,"","GraphAnalyzer"],[91,1,1,"","GraphRewriterHelper"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph":[[101,0,0,"-","qdq"],[103,0,0,"-","quantize_graph_base"],[104,0,0,"-","quantize_graph_bn"],[105,0,0,"-","quantize_graph_concatv2"],[106,0,0,"-","quantize_graph_conv"],[107,0,0,"-","quantize_graph_for_intel_cpu"],[108,0,0,"-","quantize_graph_matmul"],[109,0,0,"-","quantize_graph_pooling"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq":[[94,0,0,"-","fuse_qdq_bn"],[95,0,0,"-","fuse_qdq_concatv2"],[96,0,0,"-","fuse_qdq_conv"],[97,0,0,"-","fuse_qdq_deconv"],[98,0,0,"-","fuse_qdq_in"],[99,0,0,"-","fuse_qdq_matmul"],[100,0,0,"-","fuse_qdq_pooling"],[102,0,0,"-","optimize_qdq"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn":[[94,1,1,"","FuseNodeStartWithFusedBatchNormV3"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2":[[95,1,1,"","FuseNodeStartWithConcatV2"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv":[[96,1,1,"","FuseNodeStartWithConv2d"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv":[[97,1,1,"","FuseNodeStartWithDeconv2d"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in":[[98,1,1,"","FuseNodeStartWithFusedInstanceNorm"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul":[[99,1,1,"","FuseNodeStartWithMatmul"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling":[[100,1,1,"","FuseNodeStartWithPooling"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq":[[102,1,1,"","OptimizeQDQGraph"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base":[[103,1,1,"","QuantizeGraphBase"],[103,1,1,"","QuantizeNodeBase"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn":[[104,1,1,"","FuseNodeStartWithFusedBatchNormV3"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2":[[105,1,1,"","FuseNodeStartWithConcatV2"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv":[[106,1,1,"","FuseNodeStartWithConv2d"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu":[[107,1,1,"","QuantizeGraphForIntel"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul":[[108,1,1,"","FuseNodeStartWithMatmul"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling":[[109,1,1,"","FuseNodeStartWithPooling"]],"neural_compressor.tensorflow.quantization.utils.quantize_graph_common":[[110,1,1,"","QuantizeGraphHelper"]],"neural_compressor.tensorflow.quantization.utils.transform_graph":[[111,0,0,"-","bias_correction"],[112,0,0,"-","graph_transform_base"],[114,0,0,"-","insert_logging"],[115,0,0,"-","rerange_quantized_concat"]],"neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction":[[111,1,1,"","BiasCorrection"]],"neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base":[[112,1,1,"","GraphTransformBase"]],"neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging":[[114,1,1,"","InsertLogging"]],"neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat":[[115,1,1,"","RerangeQuantizedConcat"]],"neural_compressor.tensorflow.quantization.utils.utility":[[116,3,1,"","apply_inlining"],[116,3,1,"","collate_tf_preds"],[116,3,1,"","construct_function_from_graph_def"],[116,3,1,"","fix_ref_type_of_graph_def"],[116,3,1,"","generate_feed_dict"],[116,3,1,"","get_graph_def"],[116,3,1,"","get_input_output_node_names"],[116,3,1,"","get_model_input_shape"],[116,3,1,"","get_tensor_by_name"],[116,3,1,"","is_ckpt_format"],[116,3,1,"","is_saved_model_format"],[116,3,1,"","iterator_sess_run"],[116,3,1,"","parse_saved_model"],[116,3,1,"","read_graph"],[116,3,1,"","reconstruct_saved_model"],[116,3,1,"","strip_equivalent_nodes"],[116,3,1,"","strip_unused_nodes"],[116,3,1,"","write_graph"]],"neural_compressor.tensorflow.utils":[[117,0,0,"-","constants"],[118,0,0,"-","data"],[120,0,0,"-","model"],[121,0,0,"-","model_wrappers"],[122,0,0,"-","utility"]],"neural_compressor.tensorflow.utils.data":[[118,1,1,"","BaseDataLoader"],[118,1,1,"","BatchSampler"],[118,1,1,"","DummyDataset"],[118,1,1,"","DummyDatasetV2"],[118,1,1,"","IndexFetcher"],[118,1,1,"","IterableFetcher"],[118,1,1,"","IterableSampler"],[118,1,1,"","SequentialSampler"],[118,3,1,"","default_collate"]],"neural_compressor.tensorflow.utils.model":[[120,1,1,"","Model"],[120,1,1,"","TensorflowGlobalConfig"]],"neural_compressor.tensorflow.utils.model_wrappers":[[121,1,1,"","BaseModel"],[121,1,1,"","KerasModel"],[121,1,1,"","TensorflowBaseModel"],[121,1,1,"","TensorflowCheckpointModel"],[121,1,1,"","TensorflowLLMModel"],[121,1,1,"","TensorflowModel"],[121,1,1,"","TensorflowSavedModelModel"],[121,3,1,"","checkpoint_session"],[121,3,1,"","estimator_session"],[121,3,1,"","frozen_pb_session"],[121,3,1,"","get_model_type"],[121,3,1,"","get_tf_model_type"],[121,3,1,"","graph_def_session"],[121,3,1,"","graph_session"],[121,3,1,"","keras_session"],[121,3,1,"","load_saved_model"],[121,3,1,"","saved_model_session"],[121,3,1,"","slim_session"],[121,3,1,"","try_loading_keras"],[121,3,1,"","validate_and_inference_input_output"],[121,3,1,"","validate_graph_node"]],"neural_compressor.tensorflow.utils.utility":[[122,1,1,"","CaptureOutputToFile"],[122,1,1,"","CpuInfo"],[122,1,1,"","TFSlimNetsFactory"],[122,3,1,"","combine_histogram"],[122,3,1,"","deep_get"],[122,3,1,"","disable_random"],[122,3,1,"","dump_elapsed_time"],[122,3,1,"","get_all_fp32_data"],[122,3,1,"","get_tensor_histogram"],[122,3,1,"","itex_installed"],[122,3,1,"","register_algo"],[122,3,1,"","singleton"],[122,3,1,"","valid_keras_format"],[122,3,1,"","version1_eq_version2"],[122,3,1,"","version1_gt_version2"],[122,3,1,"","version1_gte_version2"],[122,3,1,"","version1_lt_version2"],[122,3,1,"","version1_lte_version2"]],"neural_compressor.torch":[[126,0,0,"-","algorithms"],[170,0,0,"-","export"],[176,0,0,"-","quantization"],[184,0,0,"-","utils"]],"neural_compressor.torch.algorithms":[[124,0,0,"-","autoround"],[125,0,0,"-","base_algorithm"],[127,0,0,"-","layer_wise"],[132,0,0,"-","mixed_precision"],[134,0,0,"-","mx_quant"],[139,0,0,"-","pt2e_quant"],[142,0,0,"-","qat"],[146,0,0,"-","smooth_quant"],[150,0,0,"-","static_quant"],[163,0,0,"-","weight_only"]],"neural_compressor.torch.algorithms.autoround":[[123,0,0,"-","autoround"]],"neural_compressor.torch.algorithms.autoround.autoround":[[123,1,1,"","AutoRoundQuantizer"],[123,3,1,"","dump_model_op_stats"],[123,3,1,"","get_dataloader"],[123,3,1,"","get_mllm_dataloader"]],"neural_compressor.torch.algorithms.base_algorithm":[[125,1,1,"","Quantizer"]],"neural_compressor.torch.algorithms.layer_wise":[[128,0,0,"-","load"],[129,0,0,"-","modified_pickle"],[130,0,0,"-","utils"]],"neural_compressor.torch.algorithms.layer_wise.load":[[128,3,1,"","load"]],"neural_compressor.torch.algorithms.layer_wise.modified_pickle":[[129,4,1,"","PickleError"],[129,4,1,"","PicklingError"],[129,4,1,"","UnpicklingError"]],"neural_compressor.torch.algorithms.layer_wise.utils":[[130,1,1,"","QDQLayer"],[130,3,1,"","clean_module_weight"],[130,3,1,"","get_children"],[130,3,1,"","get_module"],[130,3,1,"","get_named_children"],[130,3,1,"","get_super_module_by_name"],[130,3,1,"","load_first_layer_only"],[130,3,1,"","load_layer_wise_quantized_model"],[130,3,1,"","load_model_from_shards_with_safetensors"],[130,3,1,"","load_module"],[130,3,1,"","load_tensor"],[130,3,1,"","load_tensor_from_safetensors"],[130,3,1,"","load_tensor_from_safetensors_shard"],[130,3,1,"","load_tensor_from_shard"],[130,3,1,"","load_value"],[130,3,1,"","register_weight_hooks"],[130,3,1,"","save_layers_in_shards_iteratively"],[130,3,1,"","update_module"]],"neural_compressor.torch.algorithms.mixed_precision":[[131,0,0,"-","half_precision_convert"],[133,0,0,"-","module_wrappers"]],"neural_compressor.torch.algorithms.mixed_precision.half_precision_convert":[[131,1,1,"","HalfPrecisionConverter"]],"neural_compressor.torch.algorithms.mixed_precision.module_wrappers":[[133,1,1,"","HalfPrecisionModuleWrapper"]],"neural_compressor.torch.algorithms.mx_quant":[[135,0,0,"-","mx"],[136,0,0,"-","utils"]],"neural_compressor.torch.algorithms.mx_quant.mx":[[135,1,1,"","MXLinear"],[135,1,1,"","MXQuantizer"]],"neural_compressor.torch.algorithms.mx_quant.utils":[[136,1,1,"","ElemFormat"],[136,1,1,"","RoundingMode"],[136,3,1,"","quantize_elemwise_op"],[136,3,1,"","quantize_mx_op"]],"neural_compressor.torch.algorithms.pt2e_quant":[[137,0,0,"-","core"],[138,0,0,"-","half_precision_rewriter"],[140,0,0,"-","save_load"],[141,0,0,"-","utility"]],"neural_compressor.torch.algorithms.pt2e_quant.core":[[137,1,1,"","W8A8PT2EQuantizer"]],"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter":[[138,1,1,"","PatternPair"],[138,3,1,"","apply_single_pattern_pair"],[138,3,1,"","get_filter_fn"],[138,3,1,"","get_half_precision_node_set"],[138,3,1,"","get_unquantized_node_set"],[138,3,1,"","pattern_factory"],[138,3,1,"","transformation"]],"neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.PatternPair":[[138,2,1,"","fn"],[138,2,1,"","replace_pattern"],[138,2,1,"","search_pattern"]],"neural_compressor.torch.algorithms.pt2e_quant.save_load":[[140,3,1,"","load"],[140,3,1,"","save"]],"neural_compressor.torch.algorithms.pt2e_quant.utility":[[141,3,1,"","create_quant_spec_from_config"],[141,3,1,"","create_xiq_quantizer_from_pt2e_config"]],"neural_compressor.torch.algorithms.qat":[[143,0,0,"-","quant_linear"],[144,0,0,"-","quant_utils"],[145,0,0,"-","tensor_quantizer"]],"neural_compressor.torch.algorithms.qat.quant_linear":[[143,1,1,"","QuantLinear"]],"neural_compressor.torch.algorithms.qat.quant_utils":[[144,3,1,"","convert"],[144,3,1,"","convert_model_with_mapping"],[144,3,1,"","get_quant_config"],[144,3,1,"","get_quant_config_with_scheme"],[144,3,1,"","get_quantization_format"],[144,3,1,"","is_quantlinear"],[144,3,1,"","replace_with_quant_linear"]],"neural_compressor.torch.algorithms.qat.tensor_quantizer":[[145,1,1,"","TensorQuantizer"]],"neural_compressor.torch.algorithms.smooth_quant":[[147,0,0,"-","save_load"],[148,0,0,"-","smooth_quant"],[149,0,0,"-","utility"]],"neural_compressor.torch.algorithms.smooth_quant.save_load":[[147,3,1,"","recover_model_from_json"]],"neural_compressor.torch.algorithms.smooth_quant.smooth_quant":[[148,1,1,"","SmoothQuantQuantizer"],[148,3,1,"","qdq_quantize"]],"neural_compressor.torch.algorithms.smooth_quant.utility":[[149,1,1,"","AutoAlpha"],[149,1,1,"","Calibration"],[149,1,1,"","GraphTrace"],[149,1,1,"","SQLinearWrapper"],[149,1,1,"","TorchSmoothQuant"],[149,1,1,"","WrapperLayer"],[149,3,1,"","build_captured_dataloader"],[149,3,1,"","cal_scale"],[149,3,1,"","cfg_to_qconfig"],[149,3,1,"","check_cfg_and_qconfig"],[149,3,1,"","dump_model_op_stats"],[149,3,1,"","enough_memo_store_scale"],[149,3,1,"","forward_wrapper"],[149,3,1,"","get_module"],[149,3,1,"","get_parent"],[149,3,1,"","get_quantizable_ops_recursively"],[149,3,1,"","model_forward"],[149,3,1,"","model_forward_per_sample"],[149,3,1,"","move_input_to_device"],[149,3,1,"","quant_dequant_w_v1"],[149,3,1,"","quant_dequant_x_v1"],[149,3,1,"","register_autotune"],[149,3,1,"","reshape_in_channel_to_last"],[149,3,1,"","reshape_scale_as_input"],[149,3,1,"","reshape_scale_as_weight"],[149,3,1,"","set_module"],[149,3,1,"","update_sq_scale"]],"neural_compressor.torch.algorithms.static_quant":[[151,0,0,"-","save_load"],[152,0,0,"-","static_quant"],[153,0,0,"-","utility"]],"neural_compressor.torch.algorithms.static_quant.save_load":[[151,3,1,"","load"],[151,3,1,"","save"]],"neural_compressor.torch.algorithms.static_quant.static_quant":[[152,1,1,"","StaticQuantQuantizer"]],"neural_compressor.torch.algorithms.static_quant.utility":[[153,1,1,"","TransformerBasedModelBlockPatternDetector"],[153,3,1,"","cfg_to_qconfig"],[153,3,1,"","check_cfg_and_qconfig"],[153,3,1,"","dump_model_op_stats"],[153,3,1,"","generate_activation_observer"],[153,3,1,"","generate_xpu_qconfig"],[153,3,1,"","get_depth"],[153,3,1,"","get_dict_at_depth"],[153,3,1,"","get_element_under_depth"],[153,3,1,"","get_quantizable_ops_from_cfgs"],[153,3,1,"","get_quantizable_ops_recursively"],[153,3,1,"","parse_cfgs"],[153,3,1,"","simple_inference"]],"neural_compressor.torch.algorithms.weight_only":[[154,0,0,"-","awq"],[155,0,0,"-","gptq"],[159,0,0,"-","hqq"],[164,0,0,"-","modules"],[165,0,0,"-","rtn"],[166,0,0,"-","save_load"],[167,0,0,"-","teq"],[168,0,0,"-","utility"]],"neural_compressor.torch.algorithms.weight_only.awq":[[154,1,1,"","AWQQuantizer"]],"neural_compressor.torch.algorithms.weight_only.gptq":[[155,1,1,"","GPTQ"],[155,1,1,"","GPTQuantizer"],[155,1,1,"","Quantizer"],[155,1,1,"","RAWGPTQuantizer"],[155,3,1,"","find_all_layers"],[155,3,1,"","find_layers"],[155,3,1,"","find_layers_name"],[155,3,1,"","is_leaf"],[155,3,1,"","log_quantizable_layers_per_transformer"],[155,3,1,"","trace_gptq_target_blocks"]],"neural_compressor.torch.algorithms.weight_only.hqq":[[156,0,0,"-","bitpack"],[157,0,0,"-","config"],[158,0,0,"-","core"],[160,0,0,"-","optimizer"],[161,0,0,"-","qtensor"],[162,0,0,"-","quantizer"]],"neural_compressor.torch.algorithms.weight_only.hqq.bitpack":[[156,1,1,"","Packer"]],"neural_compressor.torch.algorithms.weight_only.hqq.config":[[157,1,1,"","HQQModuleConfig"],[157,1,1,"","QTensorConfig"]],"neural_compressor.torch.algorithms.weight_only.hqq.core":[[158,1,1,"","HQQLinear"],[158,1,1,"","HQQTensorHandle"]],"neural_compressor.torch.algorithms.weight_only.hqq.optimizer":[[160,3,1,"","optimize_weights_proximal_legacy"]],"neural_compressor.torch.algorithms.weight_only.hqq.qtensor":[[161,1,1,"","QTensor"],[161,1,1,"","QTensorMetaInfo"]],"neural_compressor.torch.algorithms.weight_only.hqq.qtensor.QTensorMetaInfo":[[161,2,1,"","axis"],[161,2,1,"","group_size"],[161,2,1,"","nbits"],[161,2,1,"","packing"],[161,2,1,"","shape"]],"neural_compressor.torch.algorithms.weight_only.hqq.quantizer":[[162,1,1,"","HQQuantizer"],[162,3,1,"","filter_fn"],[162,3,1,"","patch_hqq_moduile"],[162,3,1,"","replacement_fn"]],"neural_compressor.torch.algorithms.weight_only.modules":[[164,1,1,"","FakeAffineTensorQuantFunction"],[164,1,1,"","HPUWeightOnlyLinear"],[164,1,1,"","INCWeightOnlyLinear"],[164,1,1,"","Matmul"],[164,1,1,"","MulLinear"],[164,1,1,"","QDQLayer"],[164,1,1,"","TEQLinearFakeQuant"],[164,1,1,"","UnpackedWeightOnlyLinearParams"],[164,1,1,"","WeightOnlyLinear"]],"neural_compressor.torch.algorithms.weight_only.rtn":[[165,1,1,"","RTNQuantizer"]],"neural_compressor.torch.algorithms.weight_only.save_load":[[166,1,1,"","WOQModelLoader"],[166,3,1,"","change_config_to_hf_format"],[166,3,1,"","load"],[166,3,1,"","save"]],"neural_compressor.torch.algorithms.weight_only.teq":[[167,1,1,"","TEQuantizer"],[167,1,1,"","TrainableEquivalentTransformation"]],"neural_compressor.torch.algorithms.weight_only.utility":[[168,1,1,"","GraphTrace"],[168,3,1,"","fetch_module"],[168,3,1,"","forward_wrapper"],[168,3,1,"","get_absorb_layers"],[168,3,1,"","get_block_prefix"],[168,3,1,"","get_module"],[168,3,1,"","get_module_input_output"],[168,3,1,"","get_parent"],[168,3,1,"","model_forward"],[168,3,1,"","move_input_to_device"],[168,3,1,"","qdq_weight_actor"],[168,3,1,"","qdq_weight_asym"],[168,3,1,"","qdq_weight_sym"],[168,3,1,"","quant_tensor"],[168,3,1,"","quant_weight_w_scale"],[168,3,1,"","quantize_4bit"],[168,3,1,"","recover_forward"],[168,3,1,"","replace_forward"],[168,3,1,"","search_clip"],[168,3,1,"","set_module"]],"neural_compressor.torch.export":[[169,0,0,"-","export_hf"],[171,0,0,"-","pt2e_export"]],"neural_compressor.torch.export.export_hf":[[169,3,1,"","export_hf2compressored_model"]],"neural_compressor.torch.export.pt2e_export":[[171,3,1,"","export"],[171,3,1,"","export_model_for_pt2e_quant"]],"neural_compressor.torch.quantization":[[173,0,0,"-","algorithm_entry"],[174,0,0,"-","autotune"],[175,0,0,"-","config"],[177,0,0,"-","quantize"],[178,0,0,"-","save_load_entry"]],"neural_compressor.torch.quantization.algorithm_entry":[[173,3,1,"","autoround_quantize_entry"],[173,3,1,"","awq_quantize_entry"],[173,3,1,"","fp8_entry"],[173,3,1,"","gptq_entry"],[173,3,1,"","hqq_entry"],[173,3,1,"","hybrid_gptq_entry"],[173,3,1,"","mixed_precision_entry"],[173,3,1,"","mx_quant_entry"],[173,3,1,"","pt2e_dynamic_quant_entry"],[173,3,1,"","pt2e_static_quant_entry"],[173,3,1,"","rtn_entry"],[173,3,1,"","smooth_quant_entry"],[173,3,1,"","static_quant_entry"],[173,3,1,"","teq_quantize_entry"]],"neural_compressor.torch.quantization.autotune":[[174,3,1,"","autotune"],[174,3,1,"","get_all_config_set"],[174,3,1,"","get_rtn_double_quant_config_set"]],"neural_compressor.torch.quantization.config":[[175,1,1,"","AWQConfig"],[175,1,1,"","AutoRoundConfig"],[175,1,1,"","DynamicQuantConfig"],[175,1,1,"","FP8Config"],[175,1,1,"","GPTQConfig"],[175,1,1,"","HQQConfig"],[175,1,1,"","HybridGPTQConfig"],[175,1,1,"","INT8StaticQuantConfig"],[175,1,1,"","MXQuantConfig"],[175,1,1,"","MixedPrecisionConfig"],[175,1,1,"","OperatorConfig"],[175,1,1,"","RTNConfig"],[175,1,1,"","SmoothQuantConfig"],[175,1,1,"","StaticQuantConfig"],[175,1,1,"","TEQConfig"],[175,1,1,"","TorchBaseConfig"],[175,3,1,"","get_all_registered_configs"],[175,3,1,"","get_default_AutoRound_config"],[175,3,1,"","get_default_awq_config"],[175,3,1,"","get_default_double_quant_config"],[175,3,1,"","get_default_dynamic_config"],[175,3,1,"","get_default_fp8_config"],[175,3,1,"","get_default_fp8_config_set"],[175,3,1,"","get_default_gptq_config"],[175,3,1,"","get_default_hqq_config"],[175,3,1,"","get_default_mixed_precision_config"],[175,3,1,"","get_default_mixed_precision_config_set"],[175,3,1,"","get_default_mx_config"],[175,3,1,"","get_default_qat_module_mappings"],[175,3,1,"","get_default_rtn_config"],[175,3,1,"","get_default_sq_config"],[175,3,1,"","get_default_static_config"],[175,3,1,"","get_default_teq_config"],[175,3,1,"","get_woq_tuning_config"]],"neural_compressor.torch.quantization.quantize":[[177,3,1,"","convert"],[177,3,1,"","finalize_calibration"],[177,3,1,"","need_apply"],[177,3,1,"","prepare"],[177,3,1,"","prepare_qat"],[177,3,1,"","preprocess_quant_config"],[177,3,1,"","quantize"]],"neural_compressor.torch.quantization.save_load_entry":[[178,3,1,"","load"],[178,3,1,"","save"]],"neural_compressor.torch.utils":[[179,0,0,"-","auto_accelerator"],[180,0,0,"-","bit_packer"],[181,0,0,"-","block_wise"],[182,0,0,"-","constants"],[183,0,0,"-","environ"],[185,0,0,"-","utility"]],"neural_compressor.torch.utils.auto_accelerator":[[179,1,1,"","AcceleratorRegistry"],[179,1,1,"","Auto_Accelerator"],[179,1,1,"","CPU_Accelerator"],[179,1,1,"","CUDA_Accelerator"],[179,1,1,"","HPU_Accelerator"],[179,1,1,"","INCAcceleratorType"],[179,1,1,"","XPU_Accelerator"],[179,3,1,"","auto_detect_accelerator"],[179,3,1,"","register_accelerator"]],"neural_compressor.torch.utils.bit_packer":[[180,3,1,"","pack_array_with_numba_b2_c16"],[180,3,1,"","pack_array_with_numba_b2_c32"],[180,3,1,"","pack_array_with_numba_b2_c64"],[180,3,1,"","pack_array_with_numba_b2_c8"],[180,3,1,"","pack_array_with_numba_b4_c16"],[180,3,1,"","pack_array_with_numba_b4_c32"],[180,3,1,"","pack_array_with_numba_b4_c64"],[180,3,1,"","pack_array_with_numba_b4_c8"],[180,3,1,"","pack_array_with_numba_b8_c16"],[180,3,1,"","pack_array_with_numba_b8_c32"],[180,3,1,"","pack_array_with_numba_b8_c64"],[180,3,1,"","pack_array_with_numba_b8_c8"],[180,3,1,"","register_pack_func"]],"neural_compressor.torch.utils.block_wise":[[181,3,1,"","block_wise_calibration"],[181,3,1,"","get_block_prefix"],[181,3,1,"","recover_forward"],[181,3,1,"","replace_forward"]],"neural_compressor.torch.utils.constants":[[182,1,1,"","SaveLoadFormat"]],"neural_compressor.torch.utils.environ":[[183,3,1,"","can_pack_with_numba"],[183,3,1,"","device_synchronize"],[183,3,1,"","get_accelerator"],[183,3,1,"","get_ipex_version"],[183,3,1,"","get_torch_version"],[183,3,1,"","get_used_cpu_mem_MB"],[183,3,1,"","get_used_hpu_mem_MB"],[183,3,1,"","is_hpex_available"],[183,3,1,"","is_hpex_support_g_idx"],[183,3,1,"","is_hpu_available"],[183,3,1,"","is_ipex_available"],[183,3,1,"","is_ipex_imported"],[183,3,1,"","is_numba_available"],[183,3,1,"","is_optimum_available"],[183,3,1,"","is_optimum_habana_available"],[183,3,1,"","is_package_available"],[183,3,1,"","is_tbb_available"],[183,3,1,"","is_transformers_imported"]],"neural_compressor.torch.utils.utility":[[185,3,1,"","detect_device"],[185,3,1,"","dowload_hf_model"],[185,3,1,"","dump_model_op_stats"],[185,3,1,"","fetch_module"],[185,3,1,"","find_matching_blocks"],[185,3,1,"","forward_wrapper"],[185,3,1,"","get_block_names"],[185,3,1,"","get_double_quant_config_dict"],[185,3,1,"","get_enum_from_format"],[185,3,1,"","get_layer_names_in_block"],[185,3,1,"","get_model_device"],[185,3,1,"","get_model_info"],[185,3,1,"","get_module"],[185,3,1,"","get_multimodal_block_names"],[185,3,1,"","get_non_persistent_buffers"],[185,3,1,"","get_processor_type_from_user_config"],[185,3,1,"","get_quantizer"],[185,3,1,"","load_empty_model"],[185,3,1,"","load_non_persistent_buffers"],[185,3,1,"","move_input_device"],[185,3,1,"","postprocess_model"],[185,3,1,"","read_json_file"],[185,3,1,"","register_algo"],[185,3,1,"","set_module"],[185,3,1,"","to_device"],[185,3,1,"","to_dtype"],[185,3,1,"","validate_modules"],[185,3,1,"","write_json_file"]]},"objnames":{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","attribute","Python attribute"],"3":["py","function","Python function"],"4":["py","exception","Python exception"]},"objtypes":{"0":"py:module","1":"py:class","2":"py:attribute","3":"py:function","4":"py:exception"},"terms":{"":[0,111,116,122,128,149,166,168,178,185,188,189,191,192,194,196,197,198,199,202,204,215,219,229,231,232,233,243,245,246,248,249,250,251,252,253,256,257,259,260,261,262,263,264,265,266,267,269,273,274,275],"0":[0,1,34,42,116,118,128,149,153,160,168,175,179,192,193,194,195,196,197,199,203,205,213,215,219,220,221,224,225,227,230,232,234,235,237,238,240,241,242,243,246,250,251,252,257,259,260,261,262,265,267,268,270,271,272,274,275,276],"00":[219,272],"00000293":[249,250,251,252,253,254,255],"00000543":[249,250,251,252,253,254,255],"0003":272,"0005":272,"0006":272,"00063651":219,"0008":272,"00083269":219,"001":[274,275],"00125558":219,"0013797":220,"0016":272,"00163109":219,"00189279":220,"00193569":219,"00209263":219,"0021":272,"00223214":[219,220],"0025":272,"0029":[274,275],"00296431384049356":[274,275],"00305243":220,"00350214":220,"0036":[274,275],"00370309":220,"0040":272,"00415615":220,"0043":272,"0046":272,"0051":272,"00568582":220,"00583878":220,"0059755356051027775":[274,275],"0061":272,"006533813662827015":[274,275],"00718404":220,"00732226":220,"0086":[274,275],"0097":272,"00978":[175,199,274],"01":[1,160,175,193,199,219,220,272],"01193694":220,"0142":272,"01522314":220,"0201":272,"02323515":220,"03":[196,205,220,235,272],"0352":272,"03631029":219,"04":[205,221,270],"05":[149,205,227,272],"0500":[274,275],"05516":[175,199,274],"0559":272,"0698":[274,275],"07":[274,275],"0737":[274,275],"08":[225,230,272],"0806":[274,275],"09":[205,272],"0924":220,"0__euler__20__8":227,"0__fp32":227,"0up2":[250,251,252],"0x":128,"1":[1,15,23,25,29,43,62,77,90,114,116,118,122,123,128,149,153,155,160,164,168,175,178,179,188,192,193,194,195,197,198,199,202,203,204,205,213,217,218,221,225,227,228,231,233,242,266,268,270,272,274,275],"10":[130,160,193,195,205,213,218,228,229,243,263,270],"100":[0,1,32,33,36,179,192,204,219,265,274,276],"1000":[196,235,250,251,252],"10004":[192,194,199,200,242,276],"10005":192,"1001":[250,251,252],"10016":[274,275],"100g":230,"100x":[199,274],"101":[274,275],"1024":[114,256],"102400":246,"1024_a":256,"10271":193,"10281":193,"10438":[199,274,275],"10537":193,"10g":225,"10k":[123,237,238,239,242],"11":[194,246,270,274,275],"119":[274,275],"12":[205,220,243,270,272],"120":[274,275],"125m":[193,195,232,242,258,269],"127":[118,193,274,275],"128":[118,123,155,175,192,193,199,213,241,242,243,267,274],"129":267,"12b":272,"13":[267,270,274,275],"133":267,"13325":[199,274,275],"1381":[274,275],"139":[274,275],"13b":272,"14":[192,270],"14314":[199,274],"15":[116,270,272],"1510":[274,275],"156":219,"15646777":219,"1583":[274,275],"16":[180,192,194,195,250,251,252,256,270],"1601":[274,275],"162":[274,275],"16599":[274,275],"169":220,"16e":[193,217,230],"17":[219,221,268,272],"1710":228,"172":[219,274,275],"17323":[155,175,199,274],"1742":[274,275],"1749":[274,275],"17509":[274,275],"1751":[274,275],"17b":[193,217,230],"18":[192,268,272,273],"185":220,"1890":[274,275],"19":[234,243,268],"192":[274,275],"192795":215,"195":267,"196":267,"1970":[219,220],"1983354538679123":[274,275],"1_405b_fp8":234,"1b7":272,"1e":[149,196,235,274,275],"1e1":160,"1x2":[274,275],"2":[1,28,42,62,90,128,149,168,178,179,180,191,192,193,197,198,199,202,203,204,205,213,214,221,227,228,232,237,238,239,242,268,270,271,272,273,274,275,276],"20":[160,222,227,268],"200":[175,193,195,199,227,241],"2017":228,"2019_05_30":256,"2020":193,"2022":[199,274,275],"2023":[193,199,274,275],"2025":[195,205],"2026":271,"20262058":219,"2048":[122,155,175,193,196,199,242],"207":[274,275],"20b":272,"21":[205,268,272,273,274,275],"21020":[274,275],"22":[268,272],"2209":[199,274,275],"22098215":219,"2210":[155,175,199,274],"2211":[199,274,275],"2220":[274,275],"2238":220,"224":[205,220],"22444":[274,275],"23":[205,246,268,272],"2305":[199,274],"2306":[175,199,274],"2309":[175,199,274],"2310":193,"235b":[217,233],"24":[256,270],"2407":192,"2420":[274,275],"24_h":256,"25":[193,225,230,232],"2524":192,"255":[274,275],"256":[175,230,231,233,241],"2563":192,"2570":[274,275],"2572":192,"26":272,"2606":192,"26609924":219,"27":[228,267,272],"270m":219,"29":272,"2970":[274,275],"2991":[274,275],"2_11_0":253,"2_12_0":248,"2d":[58,274,275],"2e5m2":192,"2gb":121,"2x2":[274,275],"3":[1,116,128,149,178,179,192,193,194,198,199,202,204,205,213,215,217,221,225,227,230,240,243,268,269,270,273,274,275,276],"30":221,"3000":[196,235],"30b":[233,272],"31":[227,272],"3138":228,"32":[145,149,164,168,175,180,190,193,194,195,196,204,213,219,220,227,232,241,249,250,251,252,253,254,255],"3207":234,"3253":[274,275],"32768":[196,235],"32x16d":229,"33":[193,272],"34":[220,272],"35":272,"37":272,"370g":246,"3740":[274,275],"38":240,"3815":[274,275],"384":243,"3845":[274,275],"3850":[274,275],"385297635664756e":[274,275],"3852e":[274,275],"39":220,"3911":[274,275],"3924":[274,275],"3961":220,"3b":[192,272],"3d":[58,273,274,275],"3dgan":273,"3dunet":[217,265],"3dunet_dynamic_ndhwc":265,"3dunet_dynamic_ndhwc_int8":265,"3dunetcnn":265,"3f":259,"3rd":[194,273,274],"3x":267,"4":[42,123,164,168,175,180,188,191,193,195,198,199,200,205,217,227,230,232,233,235,237,240,241,242,243,245,265,268,270,274,275,276],"40":272,"4055":[274,275],"4096":[196,235],"40b":272,"42":[123,175,199,228],"43":[241,272],"44":227,"45":272,"46":[220,272],"4632":192,"4639":192,"47":272,"4734":[274,275],"4741":[274,275],"4743":[274,275],"48":[237,274,275],"49":272,"4928":192,"4958":192,"4_224":250,"4bit":175,"4f":[215,220],"4k":[192,276],"4th":[194,237,238,239,272,273,274],"4x":274,"5":[1,34,149,153,175,192,193,196,197,199,203,218,223,235,237,238,268,270,274,275],"50":[251,274,275],"500":[222,264,265],"5000":227,"50256":257,"5040":[274,275],"51":272,"512":[194,199,231,233],"5203":220,"52705":257,"53":[196,272],"5444":[274,275],"55":272,"5555":[274,275],"5599":192,"56":240,"57":[272,274,275],"5731":192,"58":272,"5826":[274,275],"5833":192,"5866":192,"5892":192,"59":[272,274,275],"5902":192,"5911":192,"5919":192,"5972":[274,275],"5f":[248,257,260,261,262],"5gb":166,"5k":227,"5th":241,"5x":273,"6":[192,193,199,203,224,232,243,248,261,262,268,270,274],"6038":[274,275],"61":272,"61645776":219,"62":272,"6273":192,"63":272,"6314":192,"6325":192,"637690492221736e":[274,275],"6376e":[274,275],"6393":192,"64":[175,180,194,213,220,250,251,252,256,272,274,275],"6409":192,"6420":192,"6425":192,"6481":[274,275],"6506":[274,275],"65421":215,"6552":192,"6556":192,"6599":192,"6609":192,"6684":192,"67":272,"6733":192,"6764":192,"6769":192,"6781":192,"68":272,"6821":[274,275],"6829":192,"6835":[274,275],"6836":[274,275],"6837":[274,275],"6839":[274,275],"6840":192,"6848":[274,275],"6883":[274,275],"6914":220,"6b":[192,240,242,272],"7":[149,160,168,193,196,199,203,224,225,230,268,270,274,275],"70":272,"7026":192,"7031":192,"7035":192,"7055":192,"70b":[193,217,272],"71":272,"7126":192,"7158":220,"7165":192,"7174":[274,275],"72":[272,274,275],"7242":192,"7253":192,"7299":192,"73":272,"7301":192,"7324":192,"7348":192,"7359":192,"7372":192,"7388":192,"74":272,"7419":192,"7440":[274,275],"7451":[274,275],"7474":192,"7482":192,"75":272,"754":194,"7541":192,"7557":192,"7568":192,"7589":[274,275],"7596":192,"76":272,"7608":[274,275],"7672":192,"7680":192,"77":[227,272],"7772":[274,275],"7778":192,"7805":192,"79":272,"7965":192,"7998":192,"7b":[192,205,214,242,272,276],"7b1":192,"8":[123,128,136,145,149,168,175,180,190,191,192,193,195,196,199,200,215,220,222,224,227,231,234,235,237,238,242,264,270,273,274,275,276],"80":[245,267,272],"8014":192,"8025":192,"8041":192,"8080":192,"8085":192,"8150":192,"82":272,"8207":[274,275],"8246":[274,275],"8298":[274,275],"83":[274,275],"8324":192,"8351":192,"84":[274,275],"85":[274,275],"86":272,"8618":228,"8630":228,"87":272,"8763":[274,275],"8768":[274,275],"88":267,"89":[272,274,275],"8b":[178,192,193,196,217,235,276],"8x7b":192,"9":[190,192,196,205,224,225,227,230,232,240,249,250,251,252,260,276],"90":272,"90gb":246,"91":[274,275],"92":272,"93":[274,275],"9301":[274,275],"9308":[274,275],"96":272,"97":272,"9860":[274,275],"9867":272,"99":[1,34],"9907":272,"9911":272,"9915":272,"9928":272,"9930":272,"9933":272,"9945":272,"9955":272,"9957":272,"9972":272,"9975":272,"9976":272,"9983":220,"9984":272,"9986":272,"9987":272,"9988":272,"9989":272,"999":34,"9990":272,"9991":[220,272],"9992":272,"9994":272,"9995":272,"9997":272,"A":[0,1,6,8,14,17,43,62,63,116,120,121,122,129,136,138,141,148,149,151,160,162,168,179,185,189,190,196,199,200,215,227,256,272,273,274,275],"And":[58,189,204,215,266,274,275],"As":[192,195,199,219,235,266,274],"At":[189,193,195],"Being":188,"By":[128,199,214,234,245,273],"For":[1,3,7,149,166,168,175,188,192,193,195,196,197,199,200,201,202,203,214,219,220,232,233,235,240,242,248,249,250,251,252,253,256,259,260,263,264,265,266,267,269,274,275],"IT":273,"If":[1,3,55,56,58,62,128,149,166,168,171,178,185,189,192,193,196,200,204,215,219,220,232,240,243,245,249,250,251,252,253,254,255,267,270,271,274,276],"In":[185,188,195,196,199,200,204,219,220,227,232,234,235,245,259,265,266,274,275,276],"It":[6,42,128,168,177,192,198,199,200,202,204,213,219,220,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,267,269,274,276],"No":[149,189,193,215,267,273],"Not":[122,192,215],"On":274,"One":[200,215,273],"Or":[227,258],"TO":[249,250,251,252,253,254,255],"The":[0,1,2,3,5,7,8,14,15,19,23,24,25,28,29,30,32,33,34,36,42,62,75,92,116,117,118,119,120,121,122,123,124,125,128,130,137,138,139,140,141,144,146,148,149,150,152,153,157,158,160,161,162,166,168,169,171,173,174,175,177,178,179,185,188,190,191,192,193,194,195,196,198,199,200,203,204,213,215,219,220,222,229,232,234,237,238,240,241,242,243,246,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266,267,269,270,272,274,275,276],"Then":[196,218,221,223,227,274,275],"There":[191,193,195,198,203,205,215,266,274,275],"These":234,"To":[125,183,189,190,192,193,194,195,197,198,199,203,205,215,219,220,221,223,227,228,231,232,234,249,250,251,252,253,254,255,257,260,261,262,263,274,275],"Will":[111,178],"With":[83,204,227,234,273,274,275],"_":[190,192,193,194,196,199,200,204,205,218,219,220,222,224,225,226,227,229,232,234,235,237,238,239,240,241,242,246,247,248,249,250,251,252,253,254,255,256,257,259,260,261,262,264,265,266,267,270,274,275,276],"__all__":215,"__getitem__":259,"__init__":[166,178,196,215,218,257,259],"__iter__":257,"__len__":[257,259],"__version__":[129,215,229,243],"_configset":1,"_description_":[174,200],"_disabl":196,"_fake_quant":196,"_generate_dataload":118,"_if_quant":196,"_inductor":[191,198],"_input_dtyp":196,"_lossandgradi":215,"_original_dtyp":196,"_quantizedconv":78,"_quantizeddeconv":78,"_quantizedfusedbatchnorm":94,"_quantizedmatmul":[80,81],"_real_quant":196,"_saved_model":116,"_setup":196,"_update_config_json_dtyp":196,"a22b":[217,233],"a3b":233,"a_qdq":220,"a_scal":[219,220],"ab":[155,168,175,204,274,275],"abil":[193,275],"abl":[204,245,274],"abound":273,"about":[188,192,215,242],"abov":[42,192,197,198,199,202,227,240,256,274,275],"absolut":[149,190,193,274],"absorb":[149,168,199],"absorb_layer_dict":[154,175],"absorb_to_lay":[149,167,168,175],"absorbed_1":168,"absorpt":168,"abstract":74,"abus":188,"acc":[194,202,259,272],"acc_result":[248,257],"accaraci":[221,223],"acceler":[175,179,183,192,194,195,196,197,199,200,203,205,221,227,235,240,242,270,273,274,275,276],"accelerate_config":[196,235],"acceleratorregistri":179,"accept":[188,193,213,215,232,245,276],"access":[55,56,58,179],"accompani":271,"accord":[125,177,185,190,192,204,213,219,225,229,243,274,275],"accordingli":[232,275],"account":[188,249,250,251,252,253,254,255],"accumul":[193,195,199],"accur":[149,155,175,195,198,199,240,274,275],"accuraci":[1,189,193,195,198,199,204,213,214,222,223,224,225,226,227,228,229,230,232,234,235,236,237,238,242,246,247,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,266,269,273,275],"achiev":[193,196,197,198,199,200,202,214,219,220,232,240,272,273,274,276],"across":[125,193,205,213,269,275],"act":[118,188,196],"act_algo":[149,175,198],"act_algorithm":34,"act_bit":[175,196],"act_data_typ":196,"act_dtyp":[30,34,175,197,198,202,257],"act_dynam":175,"act_granular":[30,34,175,202],"act_group_s":[175,196],"act_max_valu":[23,24,25,28,29],"act_maxabs_hw_weights_pcs_maxabs_pow2":192,"act_maxabs_pow2_weights_pcs_opt_pow2":192,"act_min_valu":[23,24,25,28,29],"act_ord":[175,199],"act_sym":[30,34,175,196,198,202,204,213],"action":[188,244],"activ":[17,23,24,25,29,149,153,175,190,191,192,195,196,197,198,199,203,204,235,245,274,275],"activation_dtyp":[219,220],"activity_regular":[23,24,25,29],"actord":199,"actual":[198,267],"ad":[179,191,194,199,230,232,237,238,245],"adam":235,"adapt":[188,196,235,273],"adaptor":[19,20],"add":[41,52,90,116,189,190,192,196,205,221,231,239,240,245,250,251,252,257,259,266],"addit":[166,195,196,199],"addition":199,"address":[188,194,195,199,215,273],"addv2":[41,57],"adher":[189,244],"adjust":[232,274,275],"adopt":[189,244,273,274,275],"advanc":[188,193,194,199,202,204,205,234,272,274],"advantag":[190,194],"adventur":[193,195],"affect":[274,275],"affin":164,"after":[66,116,138,149,183,191,192,193,196,198,199,203,205,219,220,226,227,232,235,247,248,256,257,259,260,261,262,266,274,275],"afterward":190,"ag":188,"again":228,"against":138,"aggress":[193,196],"agnost":[4,200],"agre":[189,245],"ahmadki":227,"ai":[192,193,194,200,205,217,221,242,270,273],"aim":[205,213,269,272,275],"al":[193,199,205,270,273,274,275],"alemb":267,"algo":[3,19,20,141,177],"algo_nam":[0,36,177,215],"algorithm":[0,3,12,21,30,32,36,122,172,173,175,177,178,181,185,192,193,196,199,200,204,213,214,215,240,269,272,274],"algorithm_entri":[35,176,215],"algorithm_nam":240,"algos_map":[122,185],"alias":215,"alibaba":273,"align":[188,192],"aliv":219,"all":[0,4,13,30,33,51,84,118,120,121,122,125,128,130,149,153,155,164,174,175,178,185,188,189,192,193,196,200,204,205,213,214,215,221,222,225,227,229,230,232,240,273,274,275,276],"all_block":185,"all_par":[149,168],"allevi":275,"allow":[0,168,190,193,194,196,198,199,213,232,235],"allowlist":[175,192],"along":[160,161,166,199,227],"alpha":[17,34,149,153,164,175,215,227,237,238,257,274],"alpha_max":[149,175],"alpha_min":[149,175],"alpha_step":[149,175],"alreadi":[128,194,200,232,245,267],"also":[129,189,192,194,196,199,200,202,203,219,227,228,229,230,232,234,243,249,250,251,252,253,254,255,266,269,273,274,275,276],"alsologtostderr":[250,251,252],"altern":128,"although":[190,196],"alwai":[1,192,195,213],"amax":[145,168,193,196],"amd":205,"among":[193,196,274,275],"amount":[149,183,203],"amp":175,"amx":[190,194,273],"an":[9,10,17,55,56,58,111,116,128,129,141,153,168,185,186,188,190,192,193,194,195,196,197,198,199,200,203,204,205,213,219,220,221,229,231,232,233,237,238,239,242,243,249,250,251,252,253,254,255,272,273,274,275],"analysi":193,"analyt":273,"analyz":[91,121,144],"ani":[3,33,125,128,144,157,171,175,177,179,188,190,200,204,205,215,245,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"annot":226,"annotations_trainval2017":226,"answer":[188,219],"anteat":[196,235],"ao":141,"apach":271,"api":[12,21,33,34,35,36,58,63,91,120,122,125,155,172,174,175,176,177,182,192,197,199,205,213,219,232,240,245,267,269,270,274,277],"api_serv":192,"appear":[128,188],"append":246,"appli":[32,36,97,98,99,102,104,108,116,123,125,138,149,164,173,177,185,188,190,193,195,196,198,199,203,204,213,232,235,248,257,260,261,262,266,274,275],"applianc":273,"applic":[166,192,199,202,220,254,255,273,274,275],"apply_inlin":116,"apply_single_pattern_pair":138,"apply_templ":123,"appoint":188,"approach":[190,193,195,198,199,235,273,274],"appropri":[179,188,198,213,214,240,249,250,251,252,253,254,255,274,275,276],"approv":189,"approx":[199,274],"approxim":199,"appu":199,"apr":273,"apt":[225,267],"ar":[55,56,125,128,138,141,149,153,183,185,188,189,190,191,192,193,194,195,196,198,199,200,203,204,214,215,219,220,222,227,228,229,231,232,233,235,237,238,240,264,265,266,271,272,273,274,275,276],"arbitrari":[128,200],"arbitrary_style_transf":266,"arc":[270,276],"architectur":[193,194,196,199,205,214,219,221,223,240,269,273,274,276],"arctic":270,"area":193,"arg":[3,4,8,42,131,136,155,168,173,179,181,182,185,190,192,196,200,218,246,248,259,260,261,262,275],"argu":215,"argument":[128,138,149,166,174,177,178,200,204,213,230,232,262,266],"arithmet":235,"arm":205,"arr":122,"arrai":[128,180],"art":219,"arxiv":[155,175,193,199,205,273,274,275],"ascii":128,"ask":[205,270],"asplo":273,"assert":[196,259],"assertionerror":[171,185],"assign":[177,193],"assist":6,"associ":[128,138,249,250,251,252,253,254,255],"asym":[149,164,168,241,242],"asymmetr":[149,204],"atmospher":219,"atom":271,"ats":240,"attach":[274,275],"attack":188,"attent":[153,181,188,192,193,219,230,231,233],"attention_mask":257,"attention_output":[219,220],"attention_softmax_qdq":219,"attn":[192,231,233],"attr":116,"attribut":[71,177,179,185,192],"attributeerror":129,"audio":123,"aug":273,"authent":219,"author":271,"auto":[0,1,33,149,174,175,179,183,185,192,193,195,196,197,200,205,216,224,225,230,231,232,233,235,269],"auto_acceler":184,"auto_alpha_arg":[34,175],"auto_detect_acceler":179,"auto_input_output":116,"auto_round":[175,193,196,230,232,235],"auto_scheme_batch_s":175,"auto_scheme_device_map":175,"auto_scheme_method":175,"autoalpha":149,"autogptq":267,"autom":[193,232,273],"automat":[179,185,192,193,196,200,204,214,225,230,232,246,257,275],"automodelforcausallm":[193,195,269,276],"autoround":[126,173,175,193,195,200,205,232,240,241,272,274,276],"autoround_arg":199,"autoround_it":241,"autoround_quantize_entri":173,"autoround_seq_len":242,"autoroundconfig":[173,175,193,195,199,276],"autoroundquant":123,"autotoken":[193,195,276],"autotrack":[14,116,257],"autotun":[35,176,202,203,204,206,215,232,246,257,274],"avail":[149,183,185,193,194,195,199,200,214,215,232,267,269],"averag":[193,199,232,267],"averagepooling2d":28,"avgpool":[28,100,109],"avoid":[128,149,168,181,185,215],"avx":194,"avx512":[194,274],"avx512_bf16":194,"avx512_core_amx_fp16":194,"avx512_fp16":194,"aw":273,"awar":[142,175,177,199,200,205,273],"awq":[163,168,173,175,181,200,240,242,274,276],"awq_arg":199,"awq_quantize_entri":173,"awqconfig":[173,175,199,276],"awqquant":154,"ax":136,"axi":[160,161,220,257],"azur":[189,273],"b":[62,123,189,192,199,221,231,232,233,270,274,275],"b1":62,"b16":39,"back":[128,185,195,196],"backend":[175,192,194,199,200,222,229,243,246],"backward":274,"badri":199,"baichuan":272,"baichuan2":272,"balanc":[149,193,195,197,199,204,234,274,275],"ban":188,"bandit":189,"bandwidth":[194,199,274],"bar":273,"bare":[267,270],"base":[0,1,8,20,36,74,103,112,118,121,125,129,141,149,153,164,175,177,179,183,185,191,192,193,194,199,200,205,206,214,215,218,227,234,237,240,241,249,250,251,252,253,254,255,273,274,276],"base16":253,"base_algorithm":126,"base_config":[1,2,30,32,33,34,36,174,175,177],"base_tun":[2,33,174,202,204],"baseconfig":[0,1,3,30,32,33,36,174,175,177,190,200,204,215],"basedataload":[118,248,257,259],"basedatalod":118,"baselin":[193,213,235],"baseline_model":[204,213],"basemodel":[32,33,36,121,204],"bash":[221,222,224,225,226,227,228,229,230,231,232,233,240,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,276],"basic":164,"batch":[118,123,196,199,232,248,257,259,260,261,262],"batch_decod":276,"batch_sampl":118,"batch_siz":[118,123,175,196,199,222,230,231,232,233,235,240,242,248,249,250,251,252,253,254,255,256,257,259,260,261,262,264,265,266],"batchmatmul":99,"batchmatmulv2":99,"batchnorm":[50,55],"batchsampl":118,"batchtospacend":46,"battlemag":270,"beam":240,"becaus":[128,203,248,260,261,262,266,267,274,275],"becom":[199,274],"been":[122,128,136,148,149,153,175,194,199,204,215,265,274,275],"befor":[19,88,90,155,166,178,183,189,192,199,220,224,225,230,233,235,240,242,265,267,274,276],"begin":[198,215],"behavior":[128,188,196],"below":[43,54,62,189,190,192,193,195,199,200,204,205,213,222,227,228,229,232,240,242,246,248,249,250,251,252,253,254,255,256,257,259,260,261,262,269,274,275,276],"benchmark":[218,228,240,269,276],"benchmark_serv":192,"benefit":269,"berlin":219,"bert":[243,256],"bert_large_squad_model_zoo":[217,256],"bert_model":256,"bert_squad_int8":256,"besid":[199,240,274],"best":[168,188,199,200,202,203,215,228,234,248,257,260,261,262],"best_acc_test":246,"best_auc_test":246,"best_clip_ratio":168,"best_model":[194,202,203,204,213],"beta":160,"better":[83,193,194,196,199,215,237,238,242,257,273,274],"between":[111,138,149,192,193,199,200,204,205,232,274,275],"bf16":[75,131,133,138,175,192,199,204,228,231,234,235],"bf16_convert":40,"bf16_op":[37,38,88],"bf16_result":225,"bf16_video":225,"bf16convert":38,"bfloat16":[164,175,181,192,194,205,234],"bfloat16fp16":192,"bia":[111,135,158,164,196],"bias_constraint":[23,24,25,29],"bias_correct":113,"bias_initi":[23,24,25,29],"bias_regular":[23,24,25,29],"biasadd":[41,47,52,54,90],"biascorrect":111,"bibtex":271,"big":199,"bigcod":192,"bigscienc":[192,272],"bilibili":273,"bilinear":220,"bin":[122,128,130,196,225,230,267],"bin_index_fil":130,"binari":[116,219,220,267],"bind":[214,240,276],"bit":[145,149,156,161,164,168,175,180,190,191,194,195,196,199,200,219,220,232,241,267,273,274,275,276],"bit_pack":184,"bita":193,"bitnami":273,"bitpack":159,"bitwidth":191,"black":224,"blend":219,"bleu":259,"blob":259,"block":[153,168,181,185,192,193,195,196,199,234,275],"block_list":[168,181],"block_nam":185,"block_num":[168,181],"block_pattern":153,"block_prefix":[168,181],"block_scal":195,"block_siz":[136,145,175,196,199],"block_wis":184,"block_wise_calibr":181,"blocklist":[175,192],"blocksiz":[175,193],"blockwis":275,"blog":[175,195,205,273],"bloom":[192,237,238,272,274,275],"blue":[179,199],"bmm":[192,199,274],"bnb":199,"bnb_nf4":[175,185],"bodi":188,"bool":[1,8,17,30,34,116,128,130,138,141,144,148,149,155,158,160,161,162,166,168,175,177,183,185,190,199,200],"boolean":141,"boost":[194,273],"both":[116,179,183,188,198,199,202,214,219,232,240,261,262,274,275,276],"bottleneck":[199,274],"bound":[62,149,267],"bounti":245,"branch":[116,189,231,232,233,245,257],"brand":271,"brandenburg":219,"break":90,"breakthrough":193,"bridg":235,"briefli":[274,275],"bring":[274,275],"brought":274,"brown":227,"buffer":[128,185],"buffer_nam":185,"buffer_tensor":185,"bug":[189,205,245],"build":[121,149,196,204,229,243,257,265,270,273,276],"build_captured_dataload":149,"build_torch_model":194,"build_with_cpu":240,"built":[32,36,63,204],"builtin":128,"busi":273,"bustl":219,"button":189,"bypass_reshap":[55,56],"byte":[128,149],"byte_arrai":128,"bytesio":128,"c":[62,199,229,240,243,267,274],"c1":62,"c1c2":62,"c2":62,"c_":199,"c_out":199,"cach":[199,205,230,231,232,233,267,274],"cache_dir":185,"cal":265,"cal_scal":149,"calcul":[1,48,118,149,160,190,192,197,199,204,219,220,274,275],"calib":[23,24,25,28,29,226,247,248,257,264],"calib_dataload":[15,32,33,36,202,203,204,213,248,259,260,261,262,266],"calib_fn":246,"calib_func":[15,32,33,36,37,168,204],"calib_funct":[190,219,220],"calib_it":223,"calib_iter":[15,19,32,33,36,204],"calib_num":149,"calib_numb":246,"calibr":[16,32,36,77,123,148,149,174,177,181,190,193,195,198,199,200,204,205,218,219,220,226,228,234,237,238,242,246,247,248,257,259,260,261,262,266,267,274],"calibrate_model":192,"calibration_data":88,"calibrationcsv":264,"call":[8,128,149,183,204,214,274,275,276],"call_count":8,"callabl":[1,15,32,33,36,128,148,173,174,175,177,179,185,190,200,204,215],"can":[111,128,149,177,179,190,192,193,194,195,196,197,198,199,200,202,203,204,205,213,214,215,219,220,221,222,227,228,229,230,232,233,234,235,239,240,243,244,247,248,249,250,251,252,253,254,255,256,258,259,260,261,262,263,264,265,266,267,272,274,275,276],"can_pack_with_numba":183,"candid":138,"cannot":[199,215,237,267],"cap":[205,221],"capabl":[20,192,194,199,274,276],"capac":[199,274],"capit":192,"caption":[224,227],"captions_5k":227,"captions_sourc":224,"captur":[122,149,198,199],"captureddataload":149,"captureoutputtofil":122,"card":[199,229,234,243],"carri":[148,149,177],"case":[58,62,128,178,179,193,199,200,204,215,223,232,245,259,266,273,274],"cast":[39,220],"caus":[199,274],"causal":[166,178,237,238,239],"ccl_root":240,"cclroot":[229,243],"cd":[192,222,225,226,227,230,231,232,233,234,240,241,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,266,270],"cdot":[274,275],"ceil":257,"center":[201,205,270,273],"cento":270,"cern":273,"certain":[128,190],"certif":189,"cfg":[59,60,148,149,153],"cfg_to_qconfig":[149,153],"challeng":[193,195,199],"chang":[83,111,149,166,177,189,190,192,196,200,227,245,248,260,261,262,267],"change_config_to_hf_format":166,"channel":[111,149,168,192,193,197,199,220],"charact":[245,267],"characterist":188,"charm":219,"charmap":267,"chart":274,"chat":[123,214,242,272,276],"chatbot":[193,273],"chatglm2":272,"chatglm3":272,"check":[55,56,116,122,138,149,153,162,177,183,204,205,229,243,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,267,270],"check_cfg_and_qconfig":[149,153],"checknumer":68,"checkout":[189,192,234],"checkpoint":[121,128,166,169,178,196,247,250,251,252],"checkpoint_dir":[130,166,178],"checkpoint_sess":121,"chees":215,"cheeseshopaddress":215,"chen":271,"cheng":[199,274],"child":[62,130,155,196],"children":[130,144],"chines":273,"choic":[196,199,204,274,275],"choleski":267,"choos":[168,196,200,205,219,220,256,263,273,274,275],"chosen":192,"ci":189,"circumst":188,"citi":219,"ckpt":[116,121,250,251,252,266],"cl":[8,122,185,215],"claim":271,"clamp":193,"clamp_":[274,275],"clarifi":188,"class":[16,18,22,36,129,132,185,196,199,200,202,204,213,215,218,220,257,259],"class_nam":220,"classic":200,"classif":273,"classifi":220,"clean":130,"clean_module_weight":130,"clean_weight":130,"clear":245,"cli":226,"click":[270,273],"client":8,"clip":[149,168,199,274,275],"clip_scor":227,"clm":[237,238,239],"clone":[189,192,225,227,230,231,232,233,234,240,250,251,252,263,270],"close":111,"cloud":[189,193,273],"cnn_dailymail":196,"co":[178,228],"coarsest":[274,275],"coco":[228,260,261,262,263],"coco2014":[224,227],"coco2017":[228,263],"coco_v":[260,261,262],"cocodataset":226,"code":[128,175,190,194,199,202,205,218,240,271,273,276],"codec":[128,267],"codenam":[194,237,238,239,241,272],"coder":273,"coeffici":43,"collabor":[189,205],"collat":116,"collate_fn":[118,248,259],"collate_funct":248,"collate_tf_pr":116,"collect":[1,122,135,148,149,152,154,156,165,179,190,204,274],"color":[179,199],"column":[199,274,275],"columnwis":53,"colva_beach_sq":220,"com":[175,178,188,192,195,215,219,224,225,227,229,230,231,232,233,234,240,245,247,248,249,250,251,252,253,256,259,260,261,262,264,266,270,271],"combin":[122,153,193,199,203,205,273],"combine_histogram":122,"come":[128,192,193,250,251,252,272],"comma":[123,185],"command":[214,228,229,232,237,238,239,240,242,246,249,250,251,252,253,263],"commandlin":192,"comment":[129,188,199],"commit":[188,189,200,204],"common":[10,30,32,33,34,36,110,128,129,173,174,175,177,185,188,192,197,202,203,204,215,269,275],"commun":[188,219],"compar":[193,195,196,198,199,213,232,274],"comparison":193,"compat":[116,121,169,189,196,205,227,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"compatible_format":129,"competit":193,"compil":[191,192,198,229,242,276],"compile_inductor":228,"complaint":188,"complement":194,"complet":[185,192,235,245,267],"complex":[3,194,215],"complex_attr":3,"complextfmap":215,"compon":[15,213,215,271],"compos":0,"composableconfig":[0,215],"comprehens":[200,204],"compress":[9,10,155,175,186,192,193,195,196,197,199,200,203,205,213,217,232,240,269,273,274,275,276],"compress_bit":180,"compression_dim":164,"compression_dtyp":164,"compressor":[9,10,11,12,21,33,34,35,36,120,125,126,172,173,174,175,176,177,178,182,183,184,185,186,189,190,192,193,194,195,196,197,198,199,200,202,204,213,215,216,217,219,220,222,224,225,226,229,230,231,232,233,241,243,247,249,250,251,252,253,254,255,256,258,264,265,267,269,271,272,273,274,276],"comput":[149,153,160,190,192,193,194,195,198,199,227,273,274,275],"concat":[115,257],"concaten":149,"concatv2":[95,105,115],"concept":196,"concret":[116,121],"conda":[219,220,267],"conda_prefix":240,"condit":[1,73,213,271],"conduct":[219,220],"confer":[274,275],"confidenti":188,"config":[0,1,3,7,8,15,19,20,31,32,33,35,36,120,138,141,144,148,149,153,159,162,166,174,176,177,185,191,192,193,194,196,198,199,200,202,206,215,218,219,220,235],"config1":1,"config2":1,"config_list":[0,1],"config_map":[7,162,166],"config_name_map":7,"config_set":[1,193,194,202,203,204,213,246,257],"config_sourc":1,"configload":1,"configmappingtyp":162,"configregistri":[0,7],"configs_map":[36,131,173,177],"configset":1,"configur":[0,1,8,32,36,138,140,141,144,147,149,153,157,162,173,175,177,183,185,190,195,199,200,213,214,219,228,232,240,275,276],"confirm":[229,243],"conflict":[215,267],"consid":[116,188,215],"consider":203,"consist":[44,51,189,193,196,199,215,245,275],"const":[44,45,51,52,55,56,58,70,85],"constant":[5,119,184,215],"constrain":[235,248,260,261,262],"constraint":[235,257],"construct":[118,120,121,128,188,213],"construct_function_from_graph_def":116,"consum":[169,213,223],"consumpt":[193,199,274,275],"contact":188,"contain":[55,56,58,62,110,116,128,130,138,141,144,148,149,153,160,164,185,196,199,204,205,221,229,243,265,267],"content":[192,266,276],"content_imag":266,"content_images_path":266,"context":[199,274],"contigu":196,"continu":[196,199,272],"contract":46,"contribut":[188,205],"control":196,"conv":[46,50,54,59,60,61,79,90],"conv1":202,"conv1d":200,"conv2d":[25,26,29,34,41,47,48,49,53,54,59,96,106,111,149,192,220],"conv2d_config":202,"conv2dbackpropinput":97,"conv3d":[59,96],"conv3dbackpropinputv2":97,"conveni":[200,232],"convent":[189,193],"convers":[42,43,138,189,194,197,274,275,276],"convert":[14,19,20,37,38,41,42,43,44,45,54,62,74,86,102,107,125,131,138,144,173,177,185,191,192,193,194,195,196,197,198,199,200,203,204,205,214,218,249,250,251,252,253,254,255,260,261,262,269,274,275],"convert_add_to_biasadd":64,"convert_from_int4":183,"convert_from_uint4":205,"convert_layout":64,"convert_leakyrelu":64,"convert_model_with_map":144,"convert_nan_to_random":64,"convert_placeholder_to_const":64,"convert_to_tensor":257,"convertaddtobiasaddoptim":41,"convertlayoutoptim":42,"convertleakyreluoptim":43,"convertnantorandom":44,"convertplaceholdertoconst":45,"convolut":273,"cooper":[194,273],"copi":[177,265],"copyreg":129,"copyright":[189,271],"core":[16,139,159,189,199,205,214,218,240,270,271,276],"corner":189,"coronaviru":192,"corpor":271,"correct":[111,188,196,229,243],"correctli":183,"correspond":[148,149,153,162,192,200,274],"cost":[192,193,199,219,220,274],"could":[128,149,188,194,198,199,202,204,219,220,267,274,275],"count":[199,274],"cover":[189,273],"coverag":189,"cowork":166,"cp35":[250,251,252],"cp35m":[250,251,252],"cp36":[250,251,252],"cp36m":[250,251,252],"cp37":[250,251,252],"cp37m":[250,251,252],"cpu":[8,78,79,80,81,122,128,130,133,149,155,164,166,168,178,179,183,185,192,194,198,200,204,205,227,241,254,255,273],"cpu_acceler":179,"cpufreq":215,"cpuinfo":[8,122],"craft":193,"crbug":215,"creat":[3,118,129,138,141,179,188,192,196,245,249,250,251,252,253,254,255,274],"create_quant_spec_from_config":141,"create_tf_record":256,"create_xiq_quantizer_from_pt2e_config":141,"criteo":[246,264],"criteria":275,"criterion":275,"critic":[155,188,192,193,204,235],"crucial":198,"cse":[62,85],"csv":264,"cuda":[128,149,160,179,185,200,224,225,232],"cuda_acceler":179,"cuda_visible_devic":[224,225,230,232,235],"cuisin":219,"cultur":219,"cur_input":257,"cur_len":257,"curl":[192,226],"current":[58,149,168,175,177,178,183,185,196,198,199,200,213,215,232,233,239,242,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,275],"custom":[23,24,25,26,28,29,129,168,193,200,205,213,231,232,233,248,257,260,261,262,266,273,274],"custom_tune_config":[194,202,203,204,213],"customdataset":248,"customized_msg":[8,122],"cv":[198,200,204,249,250,251,252,253,254,255],"cvf":[274,275],"d":[62,153,192,225,230,248,257,260,261,262,264],"d1":62,"d20241121":192,"dai":246,"dampen":267,"dare":[196,235],"darvish":193,"data":[8,14,32,36,44,116,119,122,123,128,135,136,141,149,168,181,185,190,191,192,194,195,198,199,200,204,205,219,220,225,232,246,249,250,251,252,253,254,255,256,257,259,264,265,270,273,274,275],"data_format":[23,25,28,29],"data_load":37,"data_parallel_s":[196,232,235],"data_path":[226,247],"data_typ":[145,196,199],"dataargu":196,"databrick":272,"dataclass":196,"datafil":264,"dataload":[14,17,118,123,149,155,168,181,204,248,257,259,260,261,262,266],"dataloader_drop_last":[196,235],"datalod":149,"dataset":[14,17,118,123,190,192,196,199,202,203,204,219,220,221,223,227,235,237,238,239,242,274],"dataset_dir":[226,228],"dataset_loc":[221,222,225,229,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,266],"dataset_nam":[123,243],"dataset_path":228,"date":199,"dco":189,"dec":273,"decid":204,"decis":215,"declar":215,"decod":[128,192,193,195],"decode_jpeg":220,"decode_predict":220,"decoder_block_0":219,"decompos":[55,56],"decor":[0,8,55,56,58,122,149,183,185],"decreas":[85,193],"dedic":[260,261,262],"deem":188,"deep":[122,193,194,195,200,205,264,273,274],"deep_get":122,"deepen":273,"deepseek":[205,217,231],"deepspe":192,"def":[1,55,56,58,122,185,190,193,194,196,197,200,202,204,213,215,218,219,220,246,257,259,266,274,275],"default":[0,3,8,30,34,84,116,121,122,123,128,130,140,141,148,149,160,166,168,171,173,174,175,177,178,185,192,193,194,195,196,197,199,200,204,205,213,214,215,219,220,232,234,240,254,255,262,266,275,276],"default_col":118,"default_sampl":[1,213],"default_sq_alpha_arg":34,"default_v":3,"default_white_list":[0,30,34,175],"defin":[3,74,188,192,193,196,199,202,204,205,213,257,274,275],"definit":[116,164,267],"defult":166,"degrad":[196,235],"delici":219,"delight":219,"deliv":[194,195,199,273],"demand":[199,274],"demo":[192,200],"democrat":273,"demonstr":[193,199,205,213,214,234],"denot":[274,275],"dens":26,"dense_1":220,"dense_2":220,"depend":[185,189,205,229,243,246,267,270],"deploi":[189,196,199,205,213,235,274],"deploy":[195,200,273,275],"deprec":[1,215],"depth":153,"depth_multipli":[25,29],"depthwis":[25,149],"depthwise_constraint":[25,29],"depthwise_conv2d":26,"depthwise_initi":[25,29],"depthwise_regular":[25,29],"depthwiseconv2d":25,"depthwiseconv2dn":[53,59,96,106],"dequant":[39,76,78,79,80,81,83,130,149,158,164,168,192,195,199,274,275],"dequantize_cast_optim":40,"dequantize_per_channel":[274,275],"dequantizecastoptim":39,"dequantized_valu":195,"derogatori":188,"desc_act":[241,267],"descent":[175,199,273,274],"describ":[196,215,219,220,222,226,227,229,237,238,239,241,243,247,263],"descript":[103,192,197,245],"deseri":128,"design":[198,200,204,235,276],"desir":[141,221,223],"despit":213,"destabil":196,"destin":116,"detach":[274,275],"detail":[0,149,175,179,188,192,194,197,199,200,202,203,204,205,215,221,249,250,251,252,253,256,263,264,265,267,272,274,276],"detect":[8,153,179,185,189,192,200,217,229,232,243,248,260,261,262],"detect_devic":185,"detect_processor_type_based_on_hw":8,"detection_box":[260,261,262],"detection_class":[260,261,262],"detection_scor":[260,261,262],"determin":[162,188,191,196,198,213,214,275],"dettmer":[199,274],"dev":[217,224,256,267],"dev1122":192,"develop":[3,189,190,192,193,194,195,215,273],"devic":[67,77,78,79,80,81,84,88,102,107,115,128,130,133,145,149,153,155,158,160,164,166,168,175,178,181,183,185,192,193,194,195,196,199,200,205,214,224,225,227,232,234,267,274],"device_count":[229,243],"device_id":128,"device_map":[175,193,195,232,276],"device_nam":[179,183],"device_synchron":183,"devop":189,"diagnosi":273,"diagon":[199,267],"diagram":199,"dict":[7,20,30,34,36,116,121,122,123,128,131,136,138,144,147,148,149,153,154,155,160,162,168,171,173,174,175,177,185,196,199,200,202,214,215,276],"dictionari":[55,56,58,122,128,136,144,149,153,166,178,185],"differ":[0,3,4,111,121,123,182,188,192,193,199,200,204,214,219,220,225,232,257,269,274,275],"difficult":[197,203,213,274,275],"difficulti":[197,203,274,275],"diffus":[192,225,226,227,273],"diffusion_model":225,"digit":273,"dilat":46,"dilated_contract":64,"dilatedcontract":46,"dilation_r":[23,25,29],"dim":[274,275],"dimens":[55,56,118,149,199,267],"dimension_list":225,"dir":[222,224,226,227,229,230,267],"direct":[86,200],"directli":[202,219,220,235,276],"directori":[121,130,140,166,178,193,195,196,205,227,228,245,249,250,251,252,253,254,255,262,265,266,267],"disabl":[122,188,192,196],"disable_random":122,"disclosur":245,"discuss":200,"disk":234,"displai":122,"distil":217,"distilbert":273,"distinct":193,"distribut":[111,118,190,192,196,199,204,225,273,274,275],"distutil":267,"div_":[274,275],"divers":[205,219],"divid":[195,274,275],"divis":149,"dl":[194,273],"dlrm":[246,247],"do":[147,188,192,200,205,215,218,226,232,240,245,247,275],"do_blockwis":[149,175],"do_ev":[196,235,243],"do_sampl":276,"do_train":[196,235],"doc":[122,179,205,219,270],"doc_strid":243,"docker":[205,221,225,229,230,243,267],"docstyl":189,"document":[179,194,196,197,202,203,219,220,222,226,227,229,237,238,239,241,243,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,272,274,276],"doe":[32,36,198,199,204,215,219,220,267],"doesn":[128,194,204],"dog":227,"dolli":272,"domain":217,"don":[111,192,197,198,266],"done":[226,247,248,257,259,260,261,262,266,274],"dot":[122,194,274],"doubl":[174,175,199,229,242,243,273],"double_qu":185,"double_quant_bit":[175,199],"double_quant_dtyp":[175,199],"double_quant_group_s":[175,199],"double_quant_typ":185,"double_quant_use_sym":[175,199],"dowload_hf_model":185,"download":[185,221,222,223,224,225,226,228,229,230,241,246,247,248,249,250,251,252,253,254,255,257,266,270],"download_dataset":228,"downstream":196,"dozen":190,"dpcpp":276,"dpcpproot":[229,243],"dpq_arg":199,"dq":[88,90,102,191,198,200,274,275],"driven":[196,269],"driver":[248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"drop":[123,189,193,194,196,199,274],"drop_last":118,"dropout":[219,220],"ds_mxfp4":231,"ds_mxfp8":231,"ds_nvfp4":231,"dtype":[118,133,138,141,149,158,164,168,175,185,192,194,196,199,200,230,232,234,235,257,274,275,276],"due":[193,232,234,240,259,274,275],"dummi":[47,118,204,205],"dummy_biasadd":64,"dummy_v2":118,"dummydataset":[118,204],"dummydatasetv2":118,"dump":[123,129,149,153,185,189,204,274],"dump_elapsed_tim":[8,122],"dump_fp32":114,"dump_model_op_stat":[123,149,153,185],"dump_stats_path":[175,192],"duplic":[85,89],"dure":[128,129,149,175,177,185,190,192,193,195,196,198,200,204,232,234,235,248,260,261,262,274],"dynam":[118,128,141,171,173,175,199,200,205,269,273],"dynamic_max_gap":[175,199],"dynamic_shap":171,"dynamicquantconfig":[175,191],"dynamo":[198,200],"e":[128,188,189,192,193,196,199,205,214,221,223,232,234,235,240,259,274,275,276],"e2m1":[193,195,199],"e2m3":193,"e3m2":193,"e4m3":[175,192,193,195,205],"e5m2":[192,193],"e8m0":[193,196],"each":[17,118,128,130,148,149,153,166,168,185,189,193,195,199,203,215,274,275],"eager":[171,191,198,199,200],"earli":274,"eas":[200,204,273],"easi":[196,198,200,204,245,273],"easier":273,"easili":[195,213,274,275],"ecosystem":273,"edit":[188,231,233],"edouard":[274,275],"edu":248,"educ":188,"effect":[198,199,235,273],"effici":[149,192,193,195,196,198,214,235,273,274,275],"effort":193,"eg":168,"either":[1,128,198,204,213,214,232,256,274],"elaps":[8,122],"electron":188,"elem_format":136,"element":[1,118,136,168,185,193,195,199,274,275],"elemformat":136,"eleutherai":[192,237,238,240,242,269,272],"elia":[199,274],"elif":[248,257],"elimin":54,"ellipsi":[138,175,179],"els":[116,168,196,257,260,261,262,276],"email":205,"emb":199,"embed":[155,220],"emerald":[241,270],"emerg":[193,275],"emit":192,"emnlp":273,"empathi":188,"empir":[111,232],"emploi":195,"empow":193,"empti":[185,192,199,200],"emul":[200,232,274],"en":270,"enabl":[90,141,190,192,193,194,195,196,198,199,204,219,220,230,231,232,234,237,242,254,255,273,275],"enable_adam":175,"enable_block_wise_calibr":234,"enable_experimental_flag":242,"enable_full_rang":[168,175,199],"enable_minmax_tun":[175,199],"enable_norm_bias_tun":175,"enable_quanted_input":[175,199],"enable_torch_compil":[175,193,232,235],"encapsul":[91,196,248,257,260,261,262,266],"encod":[128,267],"encount":267,"end":[116,192,196,231,233,276],"energi":193,"enforce_eag":235,"engin":[194,196],"enhanc":[214,273],"enjoi":219,"enough":[3,149,204,232,240,274,276],"enough_memo_store_scal":149,"ensur":[193,196,198,202,240,245,246],"entir":[195,197,199,203,275],"entranc":67,"entri":[32,33,36,55,56,58,173,174,177,178,200,215,271],"entrypoint":192,"enum":[179,185],"enumer":[3,4,179,193,220,257],"env":[229,243,267],"environ":[179,184,188,190,194,200,205,214,221,228,242,276],"eoferror":129,"epoch":196,"equal":[111,122,185,193,240,243],"equat":[274,275],"equival":[71,167,193,197,199,203,273,274,275],"erf":57,"error":[128,149,192,196,199,267,274,275],"especi":[196,269],"essenti":267,"establish":235,"estim":121,"estimator_sess":121,"et":[193,199,274,275],"etc":[125,196,205,240],"ethnic":188,"eval":[192,196,215,218,234,237,238,239,242,248,256,257,260,261,262,264,266],"eval_acc":1,"eval_acc_fn":[194,202,204],"eval_accumulation_step":[196,235],"eval_arg":[1,33,174,194,200,202,204],"eval_batch_s":232,"eval_fn":[1,33,174,193,194,200,202,203,204,213,246,257],"eval_fn_wrapp":203,"eval_func":[14,246,259,266],"eval_perf":1,"eval_result":215,"eval_result_of_q_model":1,"eval_s":196,"eval_step":[196,235],"eval_strategi":[196,235],"evalu":[1,174,192,193,200,203,204,213,215,225,232,234,240,246,248,254,255,260,261,262,264,272,274],"evaluationfuncwrapp":1,"even":[219,220,234,235,274,275],"event":188,"everi":[55,56,58,199],"everyon":188,"exact":[123,196],"exampl":[0,1,3,7,122,128,140,147,161,166,168,171,179,185,188,197,204,205,213,214,219,220,222,224,225,229,230,231,232,233,234,235,237,238,239,240,241,242,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,266,269],"example_algo":[122,185],"example_input":[140,147,148,149,153,167,168,171,174,177,191,197,198,199,200],"examplealgorithm":0,"examplealgorithmconfig":0,"exceed":121,"excel":274,"except":[128,149,196,199,215,259],"exclud":192,"excluded_op_nam":[59,60],"excluded_precis":175,"exec":[225,230],"execut":[42,125,128,148,155,185,198,199,227,256,274,276],"exens":240,"exhaust":149,"exist":[42,121,122,183,194,200,276],"exit":[213,262,266],"exp":193,"expand_and_reshap":136,"expand_dim":[220,257],"expanddim":48,"expanddims_optim":64,"expanddimsoptim":48,"expans":242,"expect":[188,189,190,199,202,244,267,272,274],"experi":[188,196,204,219,220,275,276],"experiment":[205,233,242,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,276],"explain":[3,274,275],"explicit":188,"explicitli":[3,192,196,198,214,240,276],"explor":[193,219,256],"explos":193,"expon":[193,196],"export":[172,190,191,193,194,195,196,198,200,219,220,223,225,228,231,232,233,239,240,250,251,252,263,265,267,276],"export_dir":169,"export_format":[175,193,195,232,235],"export_hf":170,"export_hf2compressored_model":169,"export_inference_graph":[250,251,252],"export_model_for_pt2e_qu":171,"export_path":[232,235],"exported_model":[191,198],"express":[188,195],"extend":[196,200,269,276],"extend_engin":91,"extens":[122,128,129,190,192,194,198,200,205,206,215,237,238,240,254,255,267,269,270,272,273,274,276],"extra":[123,128,199],"extra_data_dir":[123,175],"extract":[55,56,58,221,223],"extran":215,"extrem":235,"f":[128,196,199,215,220,229,243,274,275],"face":[185,188,192,196,273,276],"facebook":[193,195,232,237,238,239,242,244,245,258,272],"facil":128,"facilit":215,"fact":274,"factor":[17,149,160,191,192,193,195,197,199,204,235,267,274,275],"factori":122,"fail":[128,193,259,267],"failur":189,"fair":188,"faith":188,"fake":[3,149,164,168,190,196,199,219,220,232,266,274,275],"fake_qu":[37,76,88,102,107,175,196],"fakeaffinetensorquantfunct":164,"fakealgoconfig":3,"fakequ":[19,76],"falcon":[192,237,238,272],"fall":[128,185],"fallback":[194,197,198],"fals":[20,23,24,25,28,29,34,37,59,60,77,79,102,107,111,114,115,116,118,123,128,135,136,138,141,145,149,153,155,160,162,164,168,175,177,185,190,196,197,199,202,204,213,219,220,229,242,267,275,276],"famou":[199,274],"faq":[188,205],"far":200,"fast":[193,195,199,204,273],"faster":[205,260,273],"faster_rcnn_resnet50":[217,248],"faster_rcnn_resnet50_fp32_coco_pretrained_model":260,"father":130,"fault":189,"fbgemm":194,"fc1":[168,198,218,232],"fc2":[168,218,232],"fc8":252,"featur":[149,189,190,194,202,205,219,220,232,234,273,274],"feb":273,"fed":149,"feed":116,"feed_dict":116,"feng":271,"fengd":192,"fetch":[49,118],"fetch_modul":[168,185],"fetch_weight_from_reshap":64,"fetchweightfromreshapeoptim":49,"few":273,"fewer":196,"ffn":153,"field":[193,195,196,266],"field_nam":8,"fig":192,"figur":199,"file":[7,116,122,128,129,130,147,149,153,185,189,192,196,199,218,219,220,224,227,235,245,246,249,250,251,252,253,254,255,256,264,265,266,267,271],"file_lik":128,"file_path":185,"filepath":[128,215],"filter":[23,29,118,138,162],"filter_fn":162,"final":[128,196,198,250,251,252,263,274],"finalize_calibr":[177,199,218],"find":[55,56,58,116,185,193,213,219,272,275],"find_all_lay":155,"find_lay":155,"find_layers_nam":155,"find_matching_block":185,"fine":[193,195,200,215,235,273],"finer":[274,275],"finest":[274,275],"finetun":[196,199,235,243,274],"finish":[196,214],"first":[0,111,122,128,130,144,149,168,181,193,194,196,199,205,218,240,248,260,261,262,266,270,274,275,276],"first_n":114,"firstli":257,"fit":[248,257,260,261,262],"fix":[116,130,195,199,275],"fix_ref_type_of_graph_def":116,"flag":[190,219,220,242,250,251,252,259,266],"flash_attn":[231,233],"flex":[205,270],"flexibl":[193,194,196,199,204],"float":[0,14,17,34,125,149,168,175,177,179,190,191,192,193,194,195,196,197,198,199,202,203,213,215,219,220,232,239,274,275],"float16":[133,138,192,199,276],"float32":[118,164,185,192,199,274,275],"float_model":[199,214],"floor":193,"flop":[199,274],"flow":[199,274],"flux":[205,217,224,225],"flux_mxfp8":224,"fn":138,"fn_arg":138,"focu":276,"focus":[188,193,196,199,204,269],"fold":[34,50,51,149,167,168,175,197,199,265,275],"fold_batch_norm":64,"fold_const":64,"foldbatchnormnodesoptim":50,"folder":[116,199,200,222,227,229,240,256,259,263,266,276],"follow":[1,76,91,125,155,188,189,190,193,194,195,196,197,203,205,214,215,221,223,227,234,235,237,238,239,240,242,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,270,271,274,275,276],"food":219,"footprint":195,"forc":[179,240],"forest":224,"forg":[219,220,267],"fork":[189,192,199,231,232,233,245],"format":[19,20,42,116,120,121,136,166,169,178,182,185,190,192,193,194,195,198,200,204,205,215,219,220,232,249,250,251,252,253,254,255,257,259,263,273,274],"format_vers":129,"formula":[195,274,275],"forpytorch":270,"forti":265,"forward":[149,168,181,185,192,196,199,218,274,275],"forward_wrapp":[149,168,185],"foster":188,"found":[138,149,190,194,205,215,219,220,221,272,275],"foundat":273,"four":[191,198,213],"fp1":[274,275],"fp16":[131,133,138,175,195,240,274],"fp2":[274,275],"fp32":[32,36,67,102,107,111,122,138,147,148,151,166,168,173,189,190,192,193,194,195,196,197,198,199,200,202,204,227,240,248,257,259,260,261,262,266,272,274,275],"fp32_baselin":1,"fp32_bert_squad":256,"fp32_graph":111,"fp32_graphdef":259,"fp32_layer":[23,24,25,28,29],"fp32_model":[166,178,193,195,197,198,203,204],"fp32_model_path":257,"fp32_op":[37,38,88],"fp4":[168,193,195,199],"fp6":193,"fp8":[173,175,178,190,193,195,199,200,205,217,219,220,224,226,230,231,232,233,234,247,273],"fp8_awar":[168,175,199],"fp8_config":[175,192,205],"fp8_e4m3":[190,219,220],"fp8_e5m2":190,"fp8_entri":173,"fp8_inc":192,"fp8_sampl":199,"fp8_white_list":192,"fp8config":[173,175,192,205,218],"frac":[193,274,275],"framepack":[205,217,225],"framework":[0,4,19,30,120,192,194,198,204,213,215,228,269,273,274],"framework_nam":[0,215],"framework_specific_info":[19,20],"franc":192,"francisco":192,"frantar":[199,274],"free":[149,188,193,197,203,274,275],"freez":[76,77,116,191,198,250,251,252],"freeze_fake_qu":82,"freeze_graph":[250,251,252],"freeze_valu":82,"freezefakequantopoptim":76,"freezevaluetransform":77,"frequent":270,"fresh":270,"friendli":[193,196,273,274,275],"frisbe":227,"from":[0,1,7,19,49,55,56,58,116,118,121,125,128,130,138,140,147,148,149,151,153,166,168,173,175,178,185,188,189,190,191,192,193,194,195,197,198,199,202,203,204,213,214,215,218,219,220,221,223,227,232,234,240,245,246,248,250,251,252,256,257,259,260,261,262,263,264,265,266,267,269,272,273,274,275,276],"from_dict":202,"from_json_fil":[199,218],"from_preset":[219,220],"from_pretrain":[193,195,269,276],"frontend":276,"frozen":[121,235,248,253],"frozen_func":116,"frozen_inference_graph":[260,261,262],"frozen_mobilenet_v2":250,"frozen_pb_sess":121,"frozen_resnet_v2_50":251,"frozen_vgg16":252,"fsdp":196,"fsdp1":[196,235],"fsdp2":196,"fsdp_activation_checkpoint":196,"fsdp_cpu_ram_efficient_load":196,"fsdp_transformer_layer_cls_to_wrap":235,"fuel":193,"full":[185,190,192,196,199,205,227,244,267,271],"full_rang":168,"fulli":[202,232],"func":[8,116,248,257,260,261,262,266],"function":[6,14,27,110,129,156,189,190,193,194,196,198,199,200,204,205,219,220,248,257,260,261,262,272,274,275,276],"fundament":[197,202,203],"further":[58,188,194,195,205,274],"furthermor":[260,261,262],"fuse":[46,52,53,54,55,56,57,58,59,60,61,78,79,80,81,83,102,107,153,192,231,232,233],"fuse_biasadd_add":64,"fuse_column_wise_mul":64,"fuse_conv_redundant_dequant":82,"fuse_conv_requant":82,"fuse_conv_with_math":64,"fuse_decomposed_bn":64,"fuse_decomposed_in":64,"fuse_gelu":64,"fuse_layer_norm":64,"fuse_matmul_redundant_dequant":82,"fuse_matmul_requant":82,"fuse_pad_with_conv":64,"fuse_pad_with_fp32_conv":64,"fuse_qdq_bn":101,"fuse_qdq_concatv2":101,"fuse_qdq_conv":101,"fuse_qdq_deconv":101,"fuse_qdq_in":101,"fuse_qdq_matmul":101,"fuse_qdq_pool":101,"fuse_reshape_transpos":64,"fusebiasaddandaddoptim":52,"fusecolumnwisemuloptim":53,"fuseconvredundantdequantizetransform":78,"fuseconvrequantizetransform":79,"fuseconvwithmathoptim":54,"fusedbatchnorm":69,"fusedbatchnormv2":69,"fusedbatchnormv3":[94,104],"fusedbatcnormv3":58,"fusedecomposedbnoptim":55,"fusedecomposedinoptim":56,"fusedinstancenorm":98,"fusedmo":205,"fusegeluoptim":57,"fuselayernormoptim":58,"fusematmulredundantdequantizetransform":80,"fusematmulrequantizedequantizenewapitransform":81,"fusematmulrequantizedequantizetransform":81,"fusematmulrequantizenewapitransform":81,"fusematmulrequantizetransform":81,"fusenodestartwithconcatv2":[95,105],"fusenodestartwithconv2d":[96,106],"fusenodestartwithdeconv2d":97,"fusenodestartwithfusedbatchnormv3":[94,104],"fusenodestartwithfusedinstancenorm":98,"fusenodestartwithmatmul":[99,108],"fusenodestartwithpool":[100,109],"fusepadwithconv2doptim":59,"fusepadwithfp32conv2doptim":60,"fusetransposereshapeoptim":61,"fusion":[47,49,58,66,90,97,98,99,102,103,104,108,203],"futur":[1,192,200,239,242,272],"fwk_name":[0,215],"fx":[138,171,178,191,194,198,222,246,273],"g":[128,189,193,196,199,214,235,274,275],"g2f43ebf5":192,"g_idx":[164,267],"gain":273,"gan":273,"gap":[196,199,235],"gar":199,"gate":219,"gate_proj":[193,232],"gaudi":[192,200,205,221,242,270,273],"gaudi118":192,"gaudi2":[192,205,221,234,270],"gaudi3":270,"gaudillamadecoderlay":192,"gaudillamaforcausallm":192,"gaudillamamodel":192,"gb":214,"gcc9":229,"gcp":273,"gelu":57,"gemma":219,"gemma3":[190,219],"gemma3_backbon":219,"gemma3_instruct_270m":219,"gemma3backbon":219,"gemma3causallm":219,"gemma3decoderblock":219,"gemma_lm":219,"gen":[194,237,238,239,241,272,273,274],"gen_id":276,"gen_text":276,"gender":188,"gener":[1,30,34,37,75,116,118,123,144,149,153,155,174,175,177,189,192,193,194,195,199,200,202,205,214,219,232,237,241,245,257,259,263,264,266,273,274,275,276],"generate_activation_observ":153,"generate_data":257,"generate_feed_dict":116,"generate_kwarg":276,"generate_xpu_qconfig":153,"generategraphwithqdqpattern":88,"gestalt":273,"get":[8,30,33,34,55,56,58,116,118,121,122,130,144,149,153,155,168,175,181,183,185,196,197,200,223,229,234,237,238,243,250,251,252,257,263,266,267,270,272,273,274,275,277],"get_absorb_lay":168,"get_acceler":183,"get_all_config":7,"get_all_config_set":[33,174],"get_all_config_set_from_config_registri":[0,215],"get_all_fp32_data":122,"get_all_registered_config":[30,175],"get_block_nam":185,"get_block_prefix":[168,181],"get_children":130,"get_config_set_for_tun":246,"get_const_dim_count":[55,56],"get_dataload":123,"get_default_autoround_config":175,"get_default_awq_config":175,"get_default_double_quant_config":175,"get_default_dynamic_config":175,"get_default_fp8_config":175,"get_default_fp8_config_set":175,"get_default_gptq_config":175,"get_default_hqq_config":175,"get_default_mixed_precision_config":175,"get_default_mixed_precision_config_set":175,"get_default_mx_config":175,"get_default_qat_module_map":175,"get_default_rtn_config":[175,214],"get_default_sq_config":[34,175],"get_default_static_config":175,"get_default_static_quant_config":[30,34],"get_default_teq_config":175,"get_depth":153,"get_device_properti":[229,243],"get_dict_at_depth":153,"get_double_quant_config_dict":185,"get_element_under_depth":153,"get_enum_from_format":185,"get_filter_fn":138,"get_graph_def":116,"get_half_precision_node_set":138,"get_input_output_node_nam":116,"get_ipex_vers":183,"get_layer_names_in_block":185,"get_metrics_with_perplex":196,"get_mllm_dataload":123,"get_model_devic":185,"get_model_info":185,"get_model_input_shap":116,"get_model_typ":121,"get_modul":[130,149,168,185],"get_module_input_output":168,"get_multimodal_block_nam":185,"get_named_children":130,"get_non_persistent_buff":185,"get_par":[149,168],"get_processor_type_from_user_config":185,"get_quant":185,"get_quant_config":144,"get_quant_config_with_schem":144,"get_quant_func":196,"get_quantizable_ops_from_cfg":153,"get_quantizable_ops_recurs":[149,153],"get_quantization_format":[144,196],"get_rtn_double_quant_config_set":174,"get_super_module_by_nam":130,"get_tensor_by_nam":116,"get_tensor_histogram":122,"get_tf_model_typ":121,"get_torch_vers":183,"get_unquantized_node_set":138,"get_used_cpu_mem_mb":183,"get_used_hpu_mem_mb":183,"get_white_list":175,"get_woq_tuning_config":[175,213],"get_workspac":8,"getattr":196,"getenv":215,"getitem":259,"gettempdir":169,"gigant":[197,203,275],"girl":[193,195,276],"git":[189,192,224,225,227,230,231,232,233,234,240,250,251,252,260,261,262,267,270],"github":[175,178,189,192,199,205,224,225,227,229,230,231,232,233,234,240,245,247,250,251,252,256,259,260,261,262,264,270,271],"give":3,"given":[0,55,56,58,125,130,138,141,149,162,168,177,185,190,200,213,219,220,275],"global":[120,195,199,200,202],"global_scal":195,"glorot_uniform":[23,24,25,29],"glx":267,"gm":138,"gnr":257,"go":[234,245],"goal":[213,274],"good":[188,196,202],"googl":[194,215,273],"googleapi":[248,249,250,251,252,253,256,259,260,264,266],"got":[116,232,267],"gpt":[192,240,242,269,272],"gpt2":258,"gpt_j":217,"gptj":[237,238,240],"gptq":[125,163,166,173,175,178,200,205,214,215,240,241,242,267,272,274,276],"gptq_actord":242,"gptq_arg":199,"gptq_entri":173,"gptq_max_seq_length":242,"gptq_related_block":155,"gptq_use_max_length":242,"gptqconfig":[173,175,199,213,276],"gptquantiz":155,"gpu":[77,84,128,149,179,185,192,199,200,204,205,224,225,230,232,254,255,267],"gpu_memory_util":[196,232,235],"gracefulli":188,"gradient":[175,196,199,273,274],"gradient_accumulate_step":[123,175,199],"gradient_accumulation_step":[196,235],"gradient_checkpoint":196,"gradient_checkpointing_kwarg":196,"grain":[193,195,200,273],"granit":270,"granular":[23,24,25,28,29,141,193,274,275],"graph":[37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,93,101,103,107,110,111,113,114,115,116,121,138,178,191,198,217,248,250,251,252,257,259,266,274],"graph_bas":75,"graph_convert":92,"graph_cse_optim":64,"graph_def":[14,17,42,116,121],"graph_def_sess":121,"graph_modul":171,"graph_network":248,"graph_rewrit":92,"graph_sess":121,"graph_transform_bas":113,"graph_util":92,"graphanalyz":91,"graphconvert":37,"graphcseoptim":62,"graphdef":[62,116,121],"graphfoldconstantoptim":51,"graphic":270,"graphmodel":138,"graphmodul":[138,171],"graphrewriterbas":74,"graphrewriterhelp":91,"graphsag":217,"graphsage_frozen_model":248,"graphtrac":[149,168],"graphtransform":112,"graphtransformbas":112,"grappler":63,"grappler_pass":64,"grappleroptim":63,"grass":227,"greater":[122,190,204],"greatli":199,"green":179,"grei":199,"grep":192,"ground":227,"group":[23,161,168,193,199,274],"group_dim":[175,199],"group_index":183,"group_siz":[161,164,168,175,196,199,213,241],"grow":[195,199,274],"growth":[193,194],"gsm8k":[196,231,233,235],"gsm8k_llama":232,"gt":[192,197,199,275],"guangxuan":[199,274,275],"guid":[194,204,205,215,221,229,240,243,259,264,265,270],"guidanc":227,"guidelin":[201,205],"gz":[246,251,252,259,260,261,262,266],"h":[192,256,262,266],"h5":[254,255],"ha":[55,56,58,62,122,128,136,155,179,189,194,195,202,204,244,245,250,251,252,274,275],"habana":[183,185,205,221,234,270],"habana_framework":218,"habana_visible_devic":[205,221],"habanaai":[192,234],"habanalab":[205,221],"haihao":271,"half":[131,133,138,175,194,199],"half_away_from_zero":[23,24,25,28,29],"half_precision_convert":132,"half_precision_rewrit":139,"halfprecisionconvert":131,"halfprecisionmodulewrapp":133,"hand":[200,204],"handl":[6,49,116,149,158,192,196,201,215,232],"handler":130,"har":[192,240,241],"harass":188,"harder":196,"hardwar":[8,185,192,193,195,196,198,205,214,229,235,243,273],"harm":188,"hasattr":276,"have":[17,62,71,116,128,148,149,153,175,179,185,188,189,192,193,194,195,199,213,215,219,220,227,228,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,266,271,274,275,276],"haven":245,"hbm":270,"head":[199,224,232],"header":[8,267],"heavi":199,"hellaswag":[192,231,232,233,237,238,239,240],"hello":192,"help":[168,195,196,213,215,232,262,266,272,274],"helper":[91,116,121,153,192],"henc":[248,260,261,262],"herd":273,"here":[192,193,195,197,198,199,203,204,214,219,220,232,234,237,238,239,240,245,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,272,274,276],"herebi":275,"herlper":110,"hessian":[199,267],"heterogen":273,"hf":[166,169,178,185,196,214,224,230,237,238,242,253,272,276],"hf_home":225,"hi":192,"hicham":199,"hierarch":195,"high":[118,175,192,193,204,234,235,240,273],"higher":[0,179,192,193,195,196,199,214,222,227,240,243,246,248,249,250,251,252,260,261,262,263,274],"highli":[196,199,273],"hint":267,"histogram":122,"histor":219,"histori":219,"home":192,"hood":196,"hook":[130,259,275],"host":[205,221,234],"hostconst":84,"how":[128,168,179,185,189,190,193,194,196,198,199,200,201,202,203,204,219,220,237,238,239,240,246,248,257,259,260,261,262,266,273,274,275,276],"howev":[128,199,205,214,274,275],"howpublish":271,"hp_dtype":[175,192],"hpex":183,"hpu":[164,178,179,181,183,185,192,200,205,218,232,234],"hpu_acceler":179,"hpu_initi":218,"hpuattentionimpl":192,"hpuweightonlylinear":164,"hqq":[163,175,200],"hqq_arg":199,"hqq_blog":[175,199],"hqq_entri":173,"hqqconfig":[173,175,199],"hqqlinear":[158,162],"hqqmodul":157,"hqqmoduleconfig":157,"hqqtensorhandl":158,"hqquantiz":162,"hqt":192,"hqt_output":[175,192],"htcore":218,"html":[192,199,242,248,270],"http":[155,175,178,192,195,199,219,221,223,224,225,226,227,228,229,230,231,232,233,234,240,241,245,247,248,249,250,251,252,253,256,259,260,261,262,264,266,270,271],"huang":271,"hub":[166,178,185,190,220,229],"hug":[185,196,273,276],"hugginfac":[166,178],"huggingfac":[166,178,192,205,226,228,240,241,243],"hw":192,"hw_aligned_single_scal":192,"hybrid":[175,214,240,276],"hybrid_act_ord":199,"hybrid_gptq_entri":173,"hybrid_ord":175,"hybridgptqconfig":[175,199],"hyper":199,"hyperparamet":[274,275],"i":[1,3,8,37,39,42,43,48,52,58,70,73,103,111,116,118,122,128,129,138,140,141,144,149,153,155,161,162,166,168,171,175,177,178,179,181,183,185,188,189,190,191,192,193,194,195,196,197,198,199,200,203,204,205,213,214,215,218,219,220,221,222,223,226,227,228,229,232,234,235,237,238,239,240,242,243,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,271,273,274,275,276],"i2v_background":225,"ic":273,"icon":219,"id":227,"idea":[205,274,275],"ideal":194,"ident":[62,68,188],"identifi":[55,56,58,121,128,193],"ieee":[194,274,275],"if_quant":[145,196],"ignor":[199,274,275],"ignore_scale_zp_bit":175,"illustr":199,"ilsvrc2012":[249,250,251,252,253,254,255],"imag":[123,194,205,217,220,221,222,223,226,229,249,250,251,252,253,254,255,265,266,274,275],"image_processor":[123,175],"image_recognit":222,"image_tensor":[260,261,262],"imagenet":[202,222,229,249,250,251,252,253,254,255],"imagenet_prepar":[254,255],"imagenet_util":220,"imagenetdatapath":223,"imageri":188,"img":[220,249,250,251,252,253,254,255],"img224":253,"img_raw":[249,250,251,252,253,254,255],"iml":273,"implement":[91,111,115,125,128,193,196,199,221,223,248,260,261,262,266,276],"implicitli":[3,128],"import":[1,8,116,166,178,183,190,191,192,193,194,195,196,197,198,199,200,202,203,204,205,213,214,218,219,220,229,243,246,248,257,259,260,261,262,266,269,274,275,276],"importerror":[129,267],"impract":199,"improv":[189,190,193,194,195,198,199,215,219,220,232,273,274,276],"in_featur":[135,158,164],"in_graph":116,"in_graph_is_binari":116,"inappropri":188,"inc":[32,36,164,166,178,188,192,196,204,213,257,272,273],"inc_jax_onli":270,"inc_pt_onli":[224,225,230,270],"inc_target_devic":[179,200,240,276],"inc_tf_onli":270,"incacceleratortyp":179,"incept":[249,254,261],"inception_v3":[217,249,254],"inception_v3_kera":254,"inceptionv3_fp32_pretrained_model":249,"incid":188,"includ":[123,125,129,166,173,178,185,188,192,196,199,200,204,205,213,214,217,222,227,229,240,263,271,272,276],"inclus":188,"incompat":267,"incorpor":199,"incorrect":128,"increas":[193,195,196,199,232,267],"incur":193,"incweightonlylinear":164,"indent":245,"index":[55,56,58,118,130,185,240,241,259,267,270,274,275],"indexerror":129,"indexfetch":118,"indic":[0,118,128,141,161,179,204,232,267],"indicated_lay":130,"individu":[17,177,188,274,275],"industri":273,"infer":[14,32,36,121,153,168,181,190,193,194,195,196,197,198,199,203,204,205,224,227,235,240,242,246,247,250,251,252,259,269,273,274,275,276],"inferenc":193,"inference_dtyp":181,"info":[8,122,148,149,153,177,185,192,196,205,215,259],"inform":[120,161,188,189,192,193,197,199,201,204,205,214,215,229,242,243,277],"ingredi":[260,261,262],"inherit":125,"init":240,"init_alpha":[149,175],"init_tun":1,"initi":[1,13,16,18,22,23,24,25,26,27,28,29,31,116,128,132,141,185,192,196,200,204,259,274,275],"initialize_int8_avgpool":28,"initialize_int8_conv2d":23,"initialize_int8_dens":24,"initialize_int8_depthwise_conv2d":25,"initialize_int8_maxpool":28,"initialize_int8_separable_conv2d":29,"inject":47,"injectdummybiasaddoptim":47,"inlin":116,"inner":[185,257],"innov":273,"inp":218,"inplac":[148,149,177,190,200,276],"input":[17,42,48,52,55,56,58,59,60,62,70,71,73,74,90,91,116,118,121,122,130,140,147,149,153,160,164,168,171,177,181,185,191,192,193,195,196,198,199,200,237,242,250,251,252,257,259,266,267,274,275],"input_binari":[250,251,252],"input_checkpoint":[250,251,252],"input_fn":121,"input_func":168,"input_graph":[102,107,111,248,250,251,252,260,261,262],"input_graph_def":[55,56,58],"input_id":[257,276],"input_ids_pad":257,"input_max":149,"input_max_ab":149,"input_min":149,"input_minmax":149,"input_model":[221,222,224,229,230,232,246,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266],"input_nam":[55,56,121],"input_node_map":[55,56],"input_node_nam":[72,102,107,116],"input_output_nam":63,"input_pb":[112,114,115],"input_quant":196,"input_scal":[130,149,164],"input_shap":118,"input_tensor":[116,121,259],"input_tensor_ids_op_nam":153,"input_tensor_nam":[116,121,259,260,261,262],"input_valu":168,"inputcapturemodul":149,"inputcsv":264,"inputlay":[219,220],"inputs_fil":259,"inputs_qdq":219,"insecur":128,"insensit":179,"insert":[19,65,88,90,114,149,168,177,192,196,198,199,200,203,274],"insert_log":113,"insert_print_nod":64,"insert_qdq_pattern":87,"insertlog":114,"insertprintminmaxnod":65,"insid":[196,199,235,267],"insight":273,"inspect":196,"inspir":199,"instal":[122,196,204,221,222,223,224,225,226,227,230,231,232,233,235,237,238,239,240,241,242,243,246,247,258,267,269,276,277],"instanc":[141,188,189,196,199,269],"instancenorm":56,"instead":[198,199],"instruct":[178,192,193,194,217,219,222,226,227,229,230,232,237,238,239,240,243,245,247,249,250,251,252,253,254,255,260,261,262,273,274,276],"insult":188,"int":[0,3,8,14,15,19,32,33,36,116,123,136,149,153,158,160,161,164,168,175,180,181,185,196,199,204,215],"int32":[164,199,257],"int4":[175,199,272,274],"int8":[23,24,25,28,29,30,34,75,94,95,96,102,104,105,106,107,111,141,168,175,178,189,192,193,195,199,200,202,204,227,228,246,257,272,273,274,275],"int8_graphdef":259,"int8_model":228,"int8_model_path":257,"int8_sequ":37,"int8staticquantconfig":175,"integ":[185,197,199,203,274,275],"integr":[116,193,194,196,200,204,205,274],"intel":[9,10,11,12,21,33,34,35,36,122,125,126,172,173,174,175,176,177,178,182,183,184,185,186,188,189,190,192,194,196,197,198,199,200,201,202,204,213,216,217,219,220,221,222,224,225,226,230,237,238,239,240,241,242,247,254,255,258,267,269,271,272,273,274],"intel_extension_for_pytorch":[183,198,229,243,276],"intelai":264,"intelcaff":273,"intellig":273,"intelon":273,"intend":[189,219],"interact":[205,221],"interest":[188,205,219,220],"interfac":[32,74,121,125,192,194,198,200,204,246,274],"intermedi":[199,274],"intern":[118,192,219,220],"intersect":138,"introduc":[62,195,199,235,274,275],"intuit":[199,274,275],"invalid":[149,190,219,220],"invent":274,"invers":199,"inverse_freq_qdq":219,"investig":[188,215],"involv":198,"io":[128,175,199,220,225,230,256,270],"ipc":[205,221],"ipex":[147,148,149,153,173,178,183,194,197,217,227,237,238,240,243,246,272,275,276],"ipex_config":149,"ipex_config_path":[149,153],"is_ckpt_format":116,"is_dynam":141,"is_hpex_avail":183,"is_hpex_support_g_idx":183,"is_hpu_avail":183,"is_in_train":196,"is_ipex_avail":183,"is_ipex_import":183,"is_leaf":155,"is_numba_avail":183,"is_optimum_avail":183,"is_optimum_habana_avail":183,"is_package_avail":183,"is_quant":246,"is_quantlinear":144,"is_saved_model_format":116,"is_tbb_avail":183,"is_transformers_import":183,"isa":194,"isinst":196,"isn":[55,56,58],"issu":[149,188,189,195,201,205,232,234,270,274],"item":[122,274,275],"iter":[14,32,36,116,118,130,144,149,153,160,168,175,179,193,195,199,204,213,222,227,232,235,265,275],"iter_op":116,"iterablefetch":118,"iterablesampl":118,"iterator_sess_run":116,"itex":[20,90,204],"itex_instal":122,"itex_mod":[20,37,77,88,102,107],"itex_qdq_mod":[59,60],"itrex":240,"its":[48,83,130,138,140,144,185,188,192,194,195,199,213,219,235,259,271,274],"itself":[235,248,257,260,261,262,266],"j":[192,240,242,272,274,275],"jan":[205,273],"jason":275,"jax":[10,205,219,220,270],"ji":[199,274],"jit":[198,237],"job":192,"john":122,"joint":273,"journei":273,"jpeg":[249,250,251,252,253,254,255],"jpg":220,"json":[7,130,147,149,153,185,192,196,199,218,227,256],"json_file_path":147,"judg":155,"juli":273,"jun":[195,273],"june":273,"just":[84,118,149,190,198,204,219,220,227,240,248,260,261,262,266,267,274,275,276],"k":[192,220],"k_proj":[193,232],"k_qdq":[219,220],"kaggl":[219,264],"kappa":160,"keep":[8,128,215,232],"keepdim":[274,275],"kei":[121,122,128,130,149,168,185,199,219,220,237,273,274],"kelli":192,"kept":185,"kera":[18,21,33,36,58,121,122,190,202,204,219,220,254,255],"keras_hub":[219,220],"keras_sess":121,"kerasadaptor":19,"kerasconfigconvert":19,"kerasmodel":121,"kerasquantizedmodelwrapp":219,"kerasqueri":19,"kerassurgeri":19,"kernel":[192,196,199,257],"kernel_constraint":[23,24],"kernel_initi":[23,24],"kernel_qdq":219,"kernel_regular":[23,24],"kernel_s":[23,25,29],"key_norm":219,"keynot":273,"keyword":[128,149,166,178],"kind":185,"kit\u4e3aai\u5e94\u7528\u5e26\u6765\u9ad8\u6548\u5f02\u6784\u52a0\u901f\u670d\u52a1":273,"kl":[141,149,175],"know":[179,192,215],"knowledg":[197,203,217],"known":[128,192,193,219,228,234,267],"kv":[230,231,232,233],"kvcach":192,"kwarg":[23,24,25,28,29,94,95,96,97,98,99,100,103,104,106,108,121,123,131,155,164,166,168,173,175,177,178,181,185,196],"kwd":[3,4,8,136,179,182],"l":[192,199,222,229,256],"lab":224,"label":[118,149,204,220,221,223,249,250,251,252,253,254,255,257,259],"label_shap":118,"labels_offset":[250,251,252],"lack":267,"lake":[194,270,273],"lakesid":220,"lambada":192,"lambada_openai":[192,232,236,237,238,239,240,242,272],"lambda":128,"land":273,"landmark":219,"landscap":[205,273],"languag":[149,166,178,188,193,195,196,197,199,200,203,204,205,217,237,238,239,240,241,242,257,258,273,274,275,276],"laplacian":199,"larg":[149,193,195,196,197,199,200,203,204,205,223,237,238,239,240,241,242,243,256,264,273,274,275,276],"large_vers":264,"larger":[0,179,199,233,274,275],"last":[149,192,194,196,199,237,238,239,241],"last_batch":118,"latent":227,"later":[128,149,179,191,196,215,219,220,264],"latest":[194,200,205,221,224,225,230,259,264,265,270,273],"latin1":128,"latter":[248,260,261,262,266],"launch":[196,235,265],"layer":[19,20,22,122,127,130,144,149,155,164,185,192,193,196,197,198,200,232,234,250,251,252,267,274,275],"layer1":199,"layer2":199,"layer_config":[123,199],"layer_initi":26,"layer_nam":149,"layer_wis":126,"layernorm":[58,220,274,275],"layers_per_shard":130,"layout":42,"lazi":8,"lazyimport":8,"lcm_dreamshaper_v7":228,"ld_library_path":[240,267],"lead":[194,199,204,215,274,275],"leadership":188,"leakyrelu":43,"learn":[193,194,195,196,199,200,205,235,273,274,275],"learn_expon":[145,196],"learning_r":[196,235],"least":189,"left":[227,274,275],"legal":[205,277],"len":[179,192,257,259],"length":[123,185,196,199,245,257,273,274],"less":[43,122,168,193,232,234],"let":257,"level":[3,188,192,193,195,274,275],"leverag":[63,191,198,202,213,274,276],"lib":[240,267],"libgl":267,"libgl1":267,"libglib2":267,"librari":[9,10,186,192,194,196,204,205,240,273],"licens":189,"lightweight":214,"like":[3,62,83,85,116,118,121,128,178,185,189,192,193,194,195,199,204,205,219,220,240,246,248,260,261,262,267,274],"limit":[129,193,199,200,204,205,240,272],"lin":[199,274],"linalg":267,"linalgerror":267,"line":[190,215,219,220,245,266],"linear":[135,143,144,149,158,162,164,168,192,196,197,198,199,205,218,235,274,275,276],"link":[192,200,217,250,251,252,276],"linkedin":273,"lint":245,"linux":[214,240,267,276],"list":[0,1,3,14,30,33,34,36,42,116,121,130,138,149,153,155,168,174,175,179,185,192,193,200,203,204,205,219,227,228,240,246,248,249,250,251,252,253,256,257,258,259,260,261,262,264,265,266,272,275],"littl":276,"llama":[178,192,193,196,205,214,217,230,235,237,238,240,242,272,273,276],"llama2_70b_fp8":234,"llama2_7b":217,"llama3":[193,196,234,235],"llama4":230,"llama4_mxfp4":230,"llamadecoderlay":235,"llm":[14,17,155,175,178,181,193,195,196,197,198,199,203,205,234,237,238,239,242,269,273,274,275,276],"llm_acc_test":240,"llm_compressor":[195,232,235],"llm_qat":196,"llm_saved_model":257,"llm_weight_minmax":88,"lm":[192,196,199,232,234,237,238,239,240,241,242],"lm_eval":[196,232,235],"lm_head":[196,199],"lm_head_config":199,"ln":267,"ln_1":220,"ln_2":220,"lnl":276,"load":[7,116,121,127,129,130,140,147,148,149,151,153,166,178,182,185,190,192,193,195,196,204,205,227,234,240,242,257,263,266,267,276],"load_best_model_at_end":[196,235],"load_config_map":7,"load_empty_model":[185,199,214],"load_first_layer_onli":130,"load_imag":220,"load_in_4bit":240,"load_in_8bit":240,"load_layer_wise_quantized_model":130,"load_model":220,"load_model_from_shards_with_safetensor":130,"load_modul":130,"load_non_persistent_buff":185,"load_saved_model":121,"load_state_dict":128,"load_tensor":130,"load_tensor_from_safetensor":130,"load_tensor_from_safetensors_shard":130,"load_tensor_from_shard":130,"load_valu":130,"loaded_model":[199,276],"loader":[14,32,36,166,220],"loc":128,"local":[166,178,195,199,202,205,224,226,230,267,270],"local_config_fil":[19,20],"localhost":192,"locat":[128,149,198,204,246,256,259,260,261,262,266],"log":[6,8,114,149,192],"log2":193,"log_process":8,"log_quantizable_layers_per_transform":155,"logger":[5,8,196],"logging_step":[196,235],"logic":[156,160,179,193,196,200],"loglevel":[219,220],"logo":271,"long":[199,215,222,229,267],"long_str":215,"longer":[123,214],"look":[203,219,220],"lookup":179,"loss":[1,193,194,195,198,199,204,223,232,263,272,273,274,275],"lossi":274,"lost":196,"lot":[234,274,275],"low":[118,192,194,195,196,199,205,213,234,235,267,273,274,275,276],"low_gpu_mem_usag":[175,193,199,232,235],"lower":[149,191,192,193,195,196,198,233,273,274,275],"lp_norm":160,"lpot":273,"lr":[175,199],"lr_schedul":[175,199],"lr_scheduler_typ":[196,235],"ls_i_test":246,"ls_o_test":246,"lunar":270,"lwq":199,"m":[149,168,189,192,218,219,220,229,231,233,240,270],"m150":240,"machin":[199,204,214,273,275],"maco":270,"made":[227,274],"magenta":266,"magnitud":149,"mai":[116,128,129,188,189,192,194,196,199,200,203,205,215,267,271,273,274,276],"mail":188,"main":[32,33,36,155,173,174,177,179,199,200,202,204,214,221,223,224,225,226,227,228,229,230,235,247,248,258,260,261,262,266,274],"mainli":[205,269,274],"mainstream":205,"maintain":[188,189,193,195,198,199,204,205,215,227,245,274],"major":[274,275],"make":[111,185,188,194,195,197,199,203,205,215,219,220,235,245,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,274,275],"make_supervised_data_modul":196,"makeiter":116,"malici":128,"manag":0,"mandatori":[254,255],"mani":[168,179,199,204,215,219,220,274],"manual":[193,219],"manylinux2010":[250,251,252],"map":[7,128,144,162,175,177,185,196,199,205,215,234,257,267,274],"map_loc":128,"mar":[205,273],"marketplac":273,"mask":[243,261],"mask_rcnn_inception_v2":217,"mask_rcnn_inception_v2_coco_2018_01_28":261,"master":[224,225,230,245,247,259,264],"match":[66,128,138,185,196,198,204,205,257],"math":[54,257,274],"mathemat":[197,203,274,275],"matmul":[34,41,47,53,61,81,90,99,108,164,192],"matric":[274,275],"matrix":[203,274],"max":[111,149,168,175,193,199,204,205,270,274,275],"max_length":219,"max_min_data":77,"max_model_len":[196,235],"max_new_token":[193,195,276],"max_seq_length":[155,243],"max_shard_s":166,"max_step":[196,235],"max_token":192,"max_trial":[1,194,213,257],"max_x":149,"maxab":[175,192,218],"maxabs_hw":[175,192],"maxabs_hw_opt_weight":192,"maxabs_measur":218,"maxabs_pow2":192,"maxabs_qu":218,"maxabs_quant_g2":192,"maxexp":193,"maximum":[1,43,121,149,160,166,190,192,193,196,199,274,275],"maxpool":[28,100,109],"maxpooling2d":28,"mean":[149,160,166,178,192,193,195,199,202,274,275],"measur":[116,175,192,199,204,218,234,239,266,269,274],"measure_exclud":[175,192],"measure_on_hpu":175,"mebibyt":183,"mechan":129,"media":[188,273],"median":14,"medium":[258,273],"meet":[199,202,204,213,273,274],"member":[179,188],"memori":[62,149,168,181,183,192,193,194,195,197,199,200,203,233,234,240,246,274,275,276],"mention":[199,274],"merg":[89,118],"merge_duplicated_qdq":87,"mergeduplicatedqdqoptim":89,"mesa":267,"messag":[114,189,262,266],"met":[1,213,274],"meta":[83,161,178,192,193,196,214,230,232,235,237,238,242,272,273,276],"meta_info":161,"meta_op_optim":82,"metadata":[128,196],"metagraphdef":121,"metainfochangingmemopoptim":83,"metal":[267,270],"metaop":83,"meteor":270,"method":[17,111,125,128,129,153,166,178,179,192,193,195,199,200,202,204,205,215,217,220,232,240,274,275],"meticul":193,"metric":[1,196,203,248,257,260,261,262,266],"mha":220,"mib":183,"microsc":[196,200],"microsoft":[192,193,234,273,276],"middl":[274,275],"might":[194,215],"migrat":[197,203,274,275],"million":264,"mimic":[196,274],"min":[111,168,193,199,204,274,275],"min_max":160,"min_x":149,"mini":[192,276],"miniforg":[219,220],"minilm":273,"minim":[111,190,192,195,198,199,204,248,260,261,262,274],"minimum":[149,160,193,275],"minmax":[34,141,149,175,198],"minmax_lr":[175,199],"misc":[129,271],"miss":274,"mistral":[192,240,272],"mistralai":[192,272],"mitig":199,"mix":[132,173,175,196,200,205,217,219,269],"mixed_precis":[126,222],"mixed_precision_entri":173,"mixedprecisionconfig":[173,175,194],"mixprecisionconfig":173,"mixtral":192,"mixtur":228,"mkdir":226,"mklroot":[229,243],"ml":273,"mlcommon":[224,247],"mleffici":273,"mllm":123,"mlp":[200,220],"mlperf":[217,227,246,265,273],"mlperf_sd_infer":227,"mme":242,"mmlu":[192,231,233],"mmlu_llama":232,"mobilenet":[250,262],"mobilenet_v2":250,"mobilenet_v2_1":250,"mobilenet_v2_inf_graph":250,"mobilenetv2":[217,250],"mobiusml":[175,199],"mod":162,"mod_dict":175,"mode":[4,8,91,121,128,136,149,173,175,177,185,190,192,199,200,219,220,222,227,229,246,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265],"model":[1,3,9,10,14,17,19,32,33,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,57,59,60,61,62,63,65,66,67,68,69,70,71,72,73,74,76,77,78,79,80,81,83,84,85,86,88,89,90,116,119,121,122,123,125,128,130,138,140,144,147,148,149,151,153,155,166,167,168,169,171,173,174,177,178,181,185,186,189,190,191,192,193,194,195,196,197,199,200,202,203,204,205,214,215,217,221,222,223,225,227,229,232,234,235,237,238,239,240,243,258,267,269,273,274,275,276],"model_arg":[196,232,235],"model_attr":3,"model_forward":[149,168],"model_forward_per_sampl":149,"model_info":175,"model_kwarg":257,"model_level":3,"model_max_length":[196,235],"model_nam":[130,205,219,250,251,252,258,262],"model_name_or_id":236,"model_name_or_path":[166,178,196,205,227,228,232,234,235,240,243,258,276],"model_path":[14,116,155,175,199,226,231,232,233,247,257,262,266],"model_state_dict_path":[199,214],"model_weight":247,"model_wrapp":119,"modelargu":196,"modeling_auto":267,"modeltyp":257,"moder":193,"modern":[199,219,274],"modif":[189,227],"modifi":[177,190,192,227],"modified_pickl":127,"modul":[2,5,124,127,139,146,150,159,163,170,184,192,194,199,200,205,213,215,218,269,276],"modular":196,"module_hook_config":168,"module_nam":[8,130,185],"module_name_list":168,"module_typ":155,"module_wrapp":132,"moduleinfo":192,"modulelist":155,"moe":[231,232,233],"mold":1,"monitor":[1,177,196,200],"more":[3,116,149,175,192,193,194,197,199,200,201,204,205,215,221,237,238,239,240,242,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,267,272,274,275,276],"moscow":219,"most":[192,194,196,199,204,205,219,274,275],"mostli":215,"motiv":276,"move":[66,128,149,168,185,199,221,223,233,249,250,251,252,253,254,255,274],"move_input_devic":185,"move_input_to_devic":[149,168],"move_squeeze_after_relu":64,"movesqueezeafterreluoptim":66,"mp":204,"mpiroot":[229,243],"mse":[199,274],"mseloss":[274,275],"msfp":193,"msft":273,"mtl":276,"much":[196,274,275],"mul":[43,53,54,57,199],"mullinear":164,"multimod":[185,193,195,217,230],"multipl":[0,204,217,232,269,275],"multipli":[191,193,195,199],"museum":219,"music":219,"must":[189,190,249,250,251,252,253,254,255,257,270],"mutat":177,"mv":227,"mx":[134,136,175,196,200,205,232,269],"mx_fp4":196,"mx_fp8":[145,196],"mx_quant":126,"mx_quant_entri":173,"mx_spec":[135,136],"mxfp4":[175,205,217,231,233,235],"mxfp4_mix":232,"mxfp6":193,"mxfp8":[175,196,205,217,224,231,233,235],"mxfp8_model":224,"mxfp8_result":225,"mxfp8_video":225,"mxint8":193,"mxlinear":135,"mxquantconfig":[173,175],"mxquantiz":135,"my":[189,192],"mydata":257,"mydataload":[202,204,213,257],"n":[215,219,240,272,274,275],"n01440764":[249,250,251,252,253,254,255],"n_bit":[274,275],"n_block":199,"n_pack":180,"n_sampl":[149,199,241],"na":204,"name":[0,1,3,7,14,23,24,28,34,42,55,56,58,91,116,121,122,123,128,130,135,148,149,153,155,162,168,169,175,177,179,181,183,185,189,192,193,195,196,198,199,200,202,215,219,222,225,229,230,241,250,251,252,257,259,264,266,271],"named_children":196,"namespac":215,"nan":44,"narrow":[193,196],"nation":188,"natur":[195,199,217],"nbit":161,"nblock":175,"nc_graphsage_int8_model":248,"nc_inception_v3":249,"nc_mobilenet_v2":250,"nc_resnet_v2_50":251,"nc_vgg16":252,"nchw":42,"ndarrai":[55,56,58,180,267],"nearest":[175,199,200,232,274],"necessari":[188,205,248,260,261,262],"necessarili":129,"need":[3,90,118,136,147,149,166,178,192,196,199,203,213,214,215,222,240,245,246,248,250,251,252,260,261,262,263,266,267,274,275,276],"need_appli":[36,177],"need_spac":149,"neelnanda":[123,237,238,239,242],"nemo":192,"neo":269,"neox":272,"nest":[122,153],"net":[122,205,221,223,249,250,251,252,253,254,255],"netflix":273,"netron":[250,251,252],"network":[175,185,193,194,195,217,273,274,275],"neural":[9,10,11,12,21,33,34,35,36,120,125,126,172,173,174,175,176,177,178,182,183,184,185,186,189,190,192,193,194,195,196,197,198,199,200,202,204,213,215,216,217,219,220,222,224,225,226,229,230,231,232,233,241,243,247,249,250,251,252,253,254,255,256,258,264,265,267,269,271,272,273,274,276],"neural_compressor":[190,191,193,194,195,196,197,198,199,200,202,203,204,205,213,214,215,218,219,220,246,248,257,259,260,261,262,266,269,276],"neural_compressor_jax":190,"neuralmag":178,"neuralspe":240,"neurip":273,"never":128,"nevertheless":193,"new":[116,118,125,149,168,179,189,194,197,198,199,273,274],"new_api":[37,59,60,65,67,79,102,107,111],"new_func":116,"new_graph_def":116,"new_in_featur":180,"new_modul":[130,149,168,185],"newapi":81,"next":[48,118,199,205,240,274],"nextplatform":273,"nf4":[168,199],"nhwc":42,"ni":192,"nightli":227,"nightlif":219,"nlp":[194,200,204,256,259,274],"nn":[130,140,143,144,148,149,153,155,162,164,166,168,169,171,173,174,177,178,181,185,192,196,199,200,218,274,275],"nnunet_preprocess":265,"nnunet_raw_data_bas":265,"no_absorb_lay":168,"no_cuda":243,"no_grad":[218,246],"node":[14,38,42,43,44,45,48,50,52,55,56,58,62,65,68,70,71,72,85,91,103,116,121,138,149,168,179,240,257],"node_candidate_list":138,"node_def":[55,56,58],"node_from_map":[55,56,58],"node_list":138,"node_map":[55,56,58],"node_nam":[55,56,58,121],"node_name_from_input":[55,56,58],"node_name_list":114,"node_set_from_user_config":138,"nodedef":[55,56,58],"nois":196,"non":[144,185,192,194,199],"non_persistent_buff":185,"none":[0,1,3,8,15,19,20,23,24,25,28,29,30,32,33,34,36,37,51,77,91,116,118,122,123,125,128,130,135,136,137,144,145,149,153,155,158,161,164,166,167,168,169,171,174,175,177,178,181,185,190,192,193,196,199,200,204,205,218,221,232,257,276],"noproxi":192,"norm":199,"normal":[195,199,274,275],"normalfloat":199,"not_use_best_ms":[175,199],"note":[1,43,125,129,191,192,193,194,195,197,198,199,203,205,215,222,223,227,229,230,232,234,237,238,240,242,243,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,266,270,272,274,275,276],"notic":[111,194,199,219,220,240,271],"notimplementederror":185,"noutput":[219,220],"nov":273,"now":[196,237,238,240,261,262,267,276],"nsampl":[123,155,175,193,267],"nuanc":199,"num":[168,192,240,276],"num_beam":[240,276],"num_bit":[149,164,196,274,275],"num_detect":[260,261,262],"num_gpu":234,"num_scheduler_step":192,"num_train_epoch":[196,235],"num_work":118,"numactl":[240,267],"numba":[180,183],"number":[0,1,8,14,55,56,118,123,130,149,161,168,179,181,191,193,195,196,199,213,224,232,246,267,274,275],"numer":[193,194,195,199,273],"numpi":[55,56,58,180,267],"nvcr":[225,230],"nvfp4":[205,217,231],"nvfp4_model_path":232,"nvidia":[195,205,225,230],"o":[128,192,215,226,270],"obj":181,"object":[1,7,62,74,103,116,118,121,122,128,129,131,138,141,147,149,153,168,185,198,200,204,215,217,248,259,260,261,262,267],"object_detect":[260,261,262,263],"oblig":188,"observ":[153,175,177,191,192,198,199,200,235],"obstacl":193,"obtain":[196,232,274,275],"occupi":[193,234],"occur":198,"ocl_icd_vendor":240,"ocp":193,"oct":273,"off":[55,56,58,189,193,199,232,240,274],"offens":188,"offer":[192,193,195,196,199,204],"offici":[116,188,229,243,259,260,261,262],"offlin":[188,190,197,203,204,274,275],"offline_infer":192,"often":[196,199,235],"old":[122,197],"old_hist":122,"oliv":273,"omit":192,"omp":[240,276],"omp_num_thread":[214,240],"ompi_mca_btl_vader_single_copy_mechan":[205,221],"onboard":[229,243],"onc":[116,128,196,204,219,220,235,245,257,273,276],"one":[90,91,128,144,149,153,168,181,190,193,194,199,200,204,213,219,220,234,248,256,260,261,262,266,274,275],"oneapi":[194,240,273,276],"oneccl_bind_pt":240,"onednn":[194,204],"onednn_max_cpu_isa":194,"ones":[128,257],"onli":[42,51,58,74,90,111,128,130,149,163,164,166,167,168,175,177,178,192,194,196,200,205,213,215,217,226,233,240,245,247,250,251,252,259,266,267,269,272,273,275,276],"onlin":[188,195,199],"onnx":273,"onnxcommunitymeetup2023":273,"onto":128,"oom":[193,196,232],"op":[17,39,41,53,54,55,56,57,58,59,60,62,66,69,73,76,78,79,80,81,83,88,90,94,95,96,102,104,105,106,107,111,114,116,123,148,149,153,168,173,185,194,197,200,274,275,276],"op_infos_from_cfg":[148,149,153],"op_level":3,"op_nam":[149,153,168,185,198],"op_name_dict":198,"op_name_or_module_typ":[0,30,34,175],"op_typ":[14,17,34,149,153,197,198],"op_type_dict":198,"op_type_level":3,"op_wise_config":[88,102,107],"op_wise_sequ":[102,107],"open":[9,10,128,186,188,205,245,267,273],"openai":192,"opencl":240,"opencv":267,"oper":[0,3,14,30,34,91,116,138,149,190,191,192,193,194,195,196,197,198,199,200,202,203,204,274,275,276],"operator_name_or_list":200,"operatorconfig":[30,175],"ops_lst":153,"ops_nam":153,"opt":[193,195,232,240,242,258,272,274,275,276],"opt_125m":217,"opt_cfg":63,"opt_model":[191,198],"opt_param":160,"optdecoderlay":275,"optim":[42,62,63,67,68,116,159,175,192,193,195,198,199,203,204,205,214,215,222,227,229,232,235,239,240,246,248,249,250,251,252,253,256,259,260,264,272,273,274,275,276],"optimize_qdq":101,"optimize_transform":276,"optimize_weights_proximal_legaci":160,"optimizeqdqgraph":102,"optimum":[183,234],"option":[3,8,122,123,125,128,130,140,141,149,151,160,166,168,171,173,174,175,177,178,185,192,193,196,199,200,204,215,232,274,275],"orchestr":217,"order":[1,199,213,227,245,274,275,276],"ordereddict":[135,148,152,154,165,215],"ordereddicttyp":177,"org":[155,175,221,223,226,241,249,250,251,252,253,254,255,261,262,266,270],"orient":188,"orig_bit":180,"orig_lay":164,"orig_model":199,"orig_sav":200,"origin":[14,116,130,149,162,166,168,169,177,178,185,189,190,196,199,200,202,204,219,220,232,235,242,246,248,260,261,262,274],"original_model":[166,178,199],"other":[55,56,58,121,129,149,188,190,193,195,196,200,204,205,215,231,232,233,237,238,239,240,269,271,274],"otherwis":[128,138,149,162,185,188,199],"our":[111,149,193,205,219,220,248,259,260,261,262,276],"out":[148,149,177,189,193,196,199,202,204,205,267,274],"out_dir":196,"out_dtyp":175,"out_featur":[135,158,164],"out_graph_def":116,"out_graph_fil":116,"outer":118,"outlier":[14,197,199,203,274,275],"outlin":245,"outofcheeseerror":215,"outperform":199,"output":[39,42,47,62,85,91,116,121,122,140,149,151,153,160,166,168,175,177,185,192,196,199,200,202,205,218,219,220,227,250,251,252,253,259,266,274,275,276],"output_dir":[130,140,151,166,175,193,195,196,200,227,231,233,235,237,238,239,240,241,242,243,249,250,251,252,253,254,255,256,266],"output_fil":[250,251,252,256],"output_func":168,"output_graph":[248,250,251,252],"output_graph_def":203,"output_handl":8,"output_llama3":192,"output_model":[224,232,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266],"output_nam":121,"output_node_nam":[71,72,102,103,107,116,250,251,252],"output_quant":196,"output_tensor":[116,121],"output_tensor_id_op_nam":[148,149,153],"output_tensor_ids_op_nam":[149,153],"output_tensor_nam":[116,121,259,260,261,262],"output_valu":168,"output_video_path":225,"outputfil":264,"over":[128,179,192,275],"overal":[193,199],"overflow":[199,274],"overhead":[193,199],"overli":215,"overrid":[200,215,240,276],"overview":[205,269],"own":[62,128,179,192,195,266,274],"p":[199,214,219,220,240,256,274,276],"pack":[49,156,161,169,180,183,196],"pack_array_with_numba_b2_c16":180,"pack_array_with_numba_b2_c32":180,"pack_array_with_numba_b2_c64":180,"pack_array_with_numba_b2_c8":180,"pack_array_with_numba_b4_c16":180,"pack_array_with_numba_b4_c32":180,"pack_array_with_numba_b4_c64":180,"pack_array_with_numba_b4_c8":180,"pack_array_with_numba_b8_c16":180,"pack_array_with_numba_b8_c32":180,"pack_array_with_numba_b8_c64":180,"pack_array_with_numba_b8_c8":180,"packag":[183,205,215,240,257,267,273],"package_nam":183,"packed_arrai":180,"packer":156,"pad":[23,25,28,29,59,60],"pad_token_id":257,"padding_mask":219,"page":[188,189,190,245],"pager":215,"pain":274,"pair":[88,138,179,192,194,198],"palpabl":219,"pandem":192,"paper":[199,274],"parallel":[192,232],"param":[3,118,192],"param_nam":130,"paramet":[0,1,3,7,8,14,17,32,36,55,56,58,74,103,116,121,122,123,128,130,136,138,140,141,144,147,148,149,151,153,155,157,160,162,166,168,171,173,174,175,177,178,179,181,183,185,197,198,199,203,204,219,220,242,274,275],"paramlevel":3,"params_list":[0,3],"parent":[149,168,196],"pars":[116,121,148,149,153],"parse_cfg":153,"parse_saved_model":116,"part":[168,181,194,219,220,274,275],"parti":[189,192,271,274],"partial":204,"particip":[188,244],"particular":276,"particularli":[204,235],"partner":273,"pass":[8,65,116,122,128,129,147,149,166,178,189,193,196,199,222,229,232,245,265,274],"passthrough":196,"past":[199,237,274],"past_key_valu":257,"pat":273,"patch":162,"patch_embed":220,"patch_hqq_moduil":162,"patchedkvcach":192,"patchedmodulefusedsdpa":192,"patchedvllmkvcach":192,"path":[7,14,116,121,123,130,137,148,149,151,152,153,166,169,177,185,192,198,199,200,214,218,220,221,222,223,225,226,227,229,231,233,246,247,249,250,251,252,253,254,255,256,257,260,261,262,263,264,265],"path_to_measure_json":199,"path_to_quant_json":199,"path_to_quantized_model":199,"path_to_store_your_quantized_model":219,"path_to_the_model":219,"path_to_your_gemma_model":219,"pathlib":169,"pathlik":128,"pattern":[46,47,49,66,83,88,89,90,102,107,138,191,193,198,203,215],"pattern_factori":138,"pattern_lst":153,"pattern_pair":138,"patternpair":138,"pb":[121,204,248,249,250,251,252,253,256,259,260,263,265,266],"pc":[189,246],"pend":267,"pentium":271,"peopl":[219,274],"pep":215,"per":[130,149,168,173,192,193,197,199],"per_channel":[141,175,260,261,262],"per_device_eval_batch_s":[196,235],"per_device_train_batch_s":[196,235],"per_tensor":[23,24,25,28,29,30,34,141,175,202],"percdamp":[175,199,267],"percent":267,"percentag":199,"percentil":[14,34,168],"perform":[14,15,83,149,190,191,192,193,194,195,198,199,200,202,204,214,219,220,222,229,234,235,242,248,249,250,251,252,254,255,256,259,260,261,262,263,264,269,273,274,275,276],"performance_onli":[20,37,88,102,107,115],"perman":188,"permiss":188,"perplex":196,"persist":185,"person":[122,188,273],"perturb":196,"phase":[185,204,274],"phi":[192,271,273,276],"philosophi":[198,204,248,260,261,262],"physic":[188,234,240],"pickl":[128,129],"pickle_load_arg":128,"pickle_modul":128,"pickleerror":129,"pickler":129,"pickletool":129,"picklingerror":129,"piec":[199,274],"pile":[123,237,238,239,242],"pin_memori":118,"pip":[192,196,205,219,220,221,222,223,224,225,226,227,229,230,231,232,233,234,235,237,238,239,240,241,242,243,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,269,270],"pipe":215,"pipelin":[1,189,196,235],"piqa":[192,230,231,232,233,237,238,239,240],"pkl":192,"place":[148,149,168,177,190,200,219],"placehold":[45,118,141,215],"plai":[121,199,273,274,275],"plan":200,"platform":[190,205,273,274],"pleas":[149,155,192,194,196,197,198,199,200,201,202,203,205,221,227,229,231,232,234,240,242,243,244,245,246,248,249,250,251,252,253,256,257,259,260,261,262,263,264,265,266,267,270,272,274,275,276],"plug":273,"point":[160,168,190,191,192,193,194,195,196,197,198,199,203,219,220,274,275],"pointwise_constraint":29,"pointwise_initi":29,"pointwise_regular":29,"polici":[188,205,213,277],"polit":188,"pollut":215,"pont":270,"pool2d":26,"pool_siz":28,"poor":[193,195,196,200],"popen":215,"popular":[9,10,186,200,205,213,221,223,272,274],"port":[55,56,58,192],"portabl":129,"pose":193,"posit":[177,188,195,267],"position_embed":220,"positions_qdq":219,"possibl":[128,138,192,196,245],"post":[84,85,149,155,175,188,193,195,196,197,198,199,200,203,213,217,235,273,274,275],"post_attention_norm":219,"post_hostconst_convert":82,"post_node_nam":65,"post_quantized_op_cs":82,"postcseoptim":85,"postfix":77,"posthostconstconvert":84,"postprocess_model":185,"potenti":190,"power":[192,193,204,273],"ppi":248,"pr":189,"pre":[67,130,175,190,192,196,198,199,213,215,262,273,274],"pre_attention_norm":219,"pre_node_nam":65,"pre_optim":64,"preced":[274,275],"precis":[20,131,132,133,138,173,175,192,195,196,198,199,200,205,213,217,227,228,232,234,235,269,273,274,275],"pred":[116,220],"predefin":213,"predict":[116,199,220,237,238,239,241,250,251,274,275],"predict_fil":256,"preemptiv":177,"prefer":[199,274],"prefix":[116,128,130,168,181,192],"preoptim":67,"prepar":[125,148,151,166,173,177,181,185,190,191,192,193,195,196,197,198,199,200,204,205,214,218,219,220,269,274],"prepare_attention_mask_for_gener":257,"prepare_dataset":[249,250,251,252,253,254,255,256,260,261,262,263],"prepare_dataset_model":259,"prepare_model":[254,255,257,262,263,266],"prepare_qat":[177,235],"prepare_stat":[219,220],"prepared_model":[191,197,198,199,214,269],"preprint":[193,199,274,275],"preprocess":[168,177,247,249,250,251,252,253,254,255,264],"preprocess_csv_tfrecord":264,"preprocess_quant_config":177,"preprocessed_data":265,"present":[55,56,58,273,274,275],"preserv":[193,195,199,235],"preset":[190,199,220],"preset_name_to_schem":196,"presid":192,"pretrain":[155,196,221,223,229,232,235,263,264],"pretrained_model_name_or_path":[130,185],"preval":[199,274],"prevent":199,"previou":[200,218,274,275],"primari":213,"primarili":190,"primit":128,"print":[65,155,160,193,195,205,218,219,220,229,243,248,257,259,260,261,262,274,275,276],"print_predict":220,"printer":8,"prior":76,"prioriti":[0,179,183,192,215],"privat":188,"probabl":[199,220,274],"problem":[129,194],"procedur":[248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"proceed":[274,275],"process":[1,6,8,14,123,144,148,149,183,185,190,191,192,193,195,198,199,203,204,213,214,217,235,240,242,245,249,250,251,252,253,254,255,274,275,276],"processed_data":264,"processor":[8,123,175,185,190,194,205,214,219,220,237,238,239,240,241,242,272,273,274,276],"processor_typ":[175,214],"processortyp":[8,175,185],"produc":196,"product":[193,194,273,274],"profession":188,"profileract":192,"program":[198,205,245,263,271],"progress":240,"project":[178,187,188,189,193,244,245,273,277],"promis":192,"promontori":220,"promot":[193,199],"prompt":[192,219,276],"propag":[86,196],"proper":196,"properti":271,"propos":[194,199,274,275],"protect":199,"protected_nod":68,"protective_rang":199,"protobuf":[121,260,261,262],"prove":[199,274,275],"provid":[91,141,149,185,190,192,193,194,195,196,198,199,200,202,203,204,205,213,214,216,231,232,233,237,238,239,240,241,242,249,250,251,252,253,254,255,257,259,269,272,274,276],"prune":[217,273],"pseudo":199,"pt":[128,193,195,196,199,205,224,225,227,230,231,232,233,242,246,263,269,270,273,276],"pt2e":[137,139,141,171,173,178,217],"pt2e_dynamic_quant_entri":173,"pt2e_export":170,"pt2e_quant":126,"pt2e_static_quant_entri":173,"pt_enable_int64_support":242,"pt_hpu_enable_lazy_collect":192,"pt_hpu_lazy_mod":[205,242],"pt_hpu_weight_shar":192,"ptq":[196,197,198,203,204,235,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,266,275],"public":[188,232,245],"publish":[188,194,272,275],"pull":[55,56,58],"pure":[196,232],"purif":273,"purpos":[194,197,198,199,202],"push":[189,193,199,274,275],"put":[128,262,266],"pvc":[240,276],"pwd":226,"py":[116,179,192,202,214,215,218,219,220,221,223,226,227,228,229,230,232,234,235,236,237,238,239,240,241,242,243,246,247,248,250,251,252,254,255,256,258,259,260,261,262,263,264,266,267,276],"py3":[225,230],"pycocotool":267,"pylanc":215,"pyobject":267,"pypi":270,"pytest":189,"python":[8,9,10,63,116,128,129,179,186,192,205,214,215,218,219,220,221,223,226,227,228,229,232,234,235,236,237,238,239,240,241,242,243,247,248,249,250,251,252,254,255,256,258,260,261,262,263,264,266,267,270,273,276],"python3":[192,267],"pythonioencod":267,"pytorch":[125,126,144,171,172,173,174,175,176,177,178,182,183,184,185,189,200,205,206,215,221,222,225,228,230,237,238,239,240,241,242,243,246,247,263,269,270,272,273,275,276],"pytorch_model":196,"pytorchdynamo":200,"q":[88,90,102,191,196,198,200,219,220,223,248,257,259,260,261,262,266,274,275],"q_config":[23,24,25,28,29],"q_func":149,"q_max":[274,275],"q_min":[274,275],"q_model":[32,36,153,191,197,198,203,213,248,257,259,260,261,262,266,276],"q_proj":[193,232],"q_qdq":[219,220],"q_tensor":168,"q_weight":158,"q_x":[274,275],"qat":126,"qavgpool2d":28,"qconfig":[153,177,199,205,227],"qconfig_file_path":7,"qconv2d":23,"qd":198,"qdens":24,"qdepthwiseconv2d":25,"qdq":[19,75,93,168,192,203],"qdq_enabl":37,"qdq_quantiz":148,"qdq_weight_actor":168,"qdq_weight_asym":168,"qdq_weight_sym":168,"qdqlayer":[130,164,219,220],"qi":196,"qlora":[199,274],"qmaxpool2d":28,"qmodel":[202,204,231,233],"qmodel_save_path":239,"qseparableconv2d":29,"qstaticcachedgemma3attent":219,"qstaticdens":220,"qstaticeinsumdens":[219,220],"qstaticmultiheadattent":220,"qstaticreversibleembed":219,"qstaticrotaryembed":219,"qt_config":37,"qtensor":[158,159],"qtensorconfig":157,"qtensormetainfo":161,"quadrat":[175,199],"quala":273,"qualiti":[215,227],"quant":[16,18,19,20,30,34,144,149,152,168,174,175,192,196,197,199,215,218,221,223,226,228,237,240,247,272,274,276],"quant_arg":196,"quant_axi":[23,24,25,28,29],"quant_cfg":[144,196],"quant_config":[19,20,32,36,122,123,125,135,137,148,152,154,155,162,165,167,177,185,190,191,192,193,195,197,198,199,200,202,203,204,214,218,248,257,259,260,261,262,266,269],"quant_dequant_w_v1":149,"quant_dequant_x_v1":149,"quant_func":196,"quant_linear":[142,196],"quant_lm_head":[155,175,199,232],"quant_mod":[20,23,24,25,28,29],"quant_modul":144,"quant_narrow_rang":[23,24,25,28,29],"quant_nontext_modul":[123,175],"quant_round_mod":[23,24,25,28,29],"quant_scal":[175,199],"quant_schem":[196,235],"quant_statu":[23,24,25,28,29],"quant_t":[23,24,25,28,29],"quant_tensor":168,"quant_util":[142,196],"quant_vis":185,"quant_weight_w_scal":168,"quant_zero":[175,199],"quanti":240,"quantif":[197,199,203,275],"quantil":168,"quantit":199,"quantiz":[1,4,6,8,14,15,17,19,20,21,22,23,24,25,26,28,29,123,125,127,130,134,135,136,137,140,141,142,143,144,145,147,148,149,151,152,153,154,155,157,158,159,160,161,164,165,166,167,168,169,170,171,172,185,194,203,205,206,213,215,216,225,226,227,234,236,246,247,267,269,273,276],"quantizable_op":[149,153],"quantizaiton_config":276,"quantization_config":276,"quantizationargu":196,"quantizationspec":141,"quantize_4bit":168,"quantize_elemwise_op":136,"quantize_graph":92,"quantize_graph_bas":93,"quantize_graph_bn":93,"quantize_graph_common":92,"quantize_graph_concatv2":93,"quantize_graph_conv":93,"quantize_graph_for_intel_cpu":93,"quantize_graph_matmul":93,"quantize_graph_pool":93,"quantize_model":[36,190,202,203,204,219,220,248,259,260,261,262,266,274],"quantize_model_with_single_config":36,"quantize_mx_op":136,"quantize_per_channel":[274,275],"quantize_per_tensor_absmax":[274,275],"quantized_model":[199,214,224,227,269],"quantized_model_path":228,"quantized_nod":88,"quantized_valu":195,"quantizedconcatv2":[95,105],"quantizedconv":[78,79],"quantizeddeconv":78,"quantizedmatmul":[80,81],"quantizedmatmulwithbiasanddequant":81,"quantizegraph":103,"quantizegraphbas":103,"quantizegraphforintel":107,"quantizegraphhelp":110,"quantizenodebas":103,"quantizer_cl":185,"quantizev2":85,"quantiztaion":153,"quantlinear":143,"queri":[19,20,153,185,219,220,274],"query_norm":219,"question":[188,189,205,270,274,275],"quick":214,"quicker":233,"quickli":[213,223,272],"quiet":[231,232,233],"quint8":149,"qw":196,"qwen":[192,205,217,233,240,276],"qwen2":[192,273],"qwen3":[217,233,273],"qwen_mxfp4":233,"qwen_mxfp8":233,"r":[111,192,196,197,198,199,202,204,219,220,221,222,223,224,226,227,229,231,232,233,235,237,238,239,240,241,242,243,246,247,248,249,250,251,252,253,254,255,257,258,260,261,262,263,264,265,266,274],"r1":[116,205,217,231],"race":188,"rais":[55,56,58,128,129,149,168,171,181,185,205,215,273],"rajpurkar":256,"ram":[128,199,214],"rand":[175,199,274,275],"randn":[205,218],"random":[8,44,122,123,199],"randomli":[265,274,275],"rang":[118,168,191,193,194,199,200,204,205,229,232,243,274,275],"rapid":[237,238,239,241,270,272],"rate":[192,196,199,235,274],"rather":[199,245,250,251,252],"ratio":[111,193,232,272],"raw":[148,151,166,173,222,224,229,246,249,250,251,252,253,254,255],"raw_arrai":180,"raw_data":265,"raw_dir":[249,250,251,252,253,254,255],"raw_func":183,"rawgptquant":155,"rb":128,"rcnn":[260,261],"re":227,"reach":[1,189],"read":[116,128,185,244],"read_fil":220,"read_graph":116,"read_json_fil":185,"readabl":215,"readi":199,"readlin":128,"readm":[192,199,246],"readvariableop":257,"real":[118,273,274],"realdiv":[54,57],"realist":196,"rearrang":199,"reason":[188,199,219,274],"rebuild":116,"recent":194,"recip":[37,193,195,205,213,257,269],"recogn":185,"recognit":[194,217],"recommend":[183,192,194,205,214,217,221,227,229,234,240,243,246,247,248,249,250,251,252,260,261,262,263,264,276],"reconstruct":[116,130,273],"reconstruct_saved_model":116,"record":[168,190,192,213,249,250,251,252,253,254,255,260,261,262],"record_max_info":[34,149],"recov":[147,149,168,181,196],"recover_forward":[168,181],"recover_model_from_json":147,"rectangl":199,"recurs":[144,196,240],"recursivescriptmodul":151,"red":179,"reduc":[175,181,192,193,194,195,196,197,198,199,203,204,232,234,235,273,274,275,276],"reduct":195,"redund":[78,80,185],"ref":[116,224],"ref_lin":259,"refer":[149,155,175,192,194,197,198,200,202,203,204,205,218,221,227,229,240,242,243,246,257,259,264,265,267,276],"reference_fil":259,"refin":[179,196,204],"regard":188,"regardless":188,"regist":[0,30,122,128,129,130,149,175,179,180,185,215,219,275],"register_acceler":179,"register_algo":[122,185,215],"register_autotun":149,"register_config":[0,215],"register_pack_func":180,"register_packag":128,"register_supported_configs_for_fwk":0,"register_weight_hook":130,"registri":[0,179],"regress":189,"reichstag":219,"reinstal":267,"reject":188,"rel":[232,263],"relat":[124,139,146,150,159,184,249,250,251,252,253,254,255,259,269],"relative_loss":1,"releas":[190,191,198,224,225,230,234,240,242,257],"relev":215,"reli":200,"religion":188,"reload":[7,232],"relu":[62,66,90],"relu6":62,"remain":[166,178,195],"remap":[58,128],"remind":195,"remov":[14,39,45,48,62,68,71,72,73,83,85,185,188,232,242],"remove_training_nod":64,"removetrainingnodesoptim":68,"renam":[69,200],"rename_batch_norm":64,"renamebatchnormoptim":69,"reorder":199,"repercuss":188,"replac":[130,138,144,149,162,168,177,181,185,191,192,193,198,215,257,276],"replace_forward":[168,181],"replace_pattern":138,"replace_with_quant_linear":[144,196],"replacement_fn":162,"repo":[187,189,227,228,245,246,249,250,251,252,253,254,255,277],"repo_id":185,"repo_typ":185,"report":[188,189,205],"report_to":[196,235],"repositori":[189,196,263],"repres":[0,1,3,4,138,161,188,190,192,198,199,204,219,220,274],"represent":[129,188,193,195,199,219,220,274],"reproduc":[123,222,229,243,245,246,248,249,250,251,252,253,256,257,258,259,260,261,262,263,264,265,266],"requant":[79,81],"request":[192,198,205,240],"requir":[121,168,177,183,190,192,193,194,195,196,198,199,204,219,220,222,224,226,227,229,234,235,237,238,239,240,241,242,243,246,247,248,249,250,251,252,253,257,258,260,261,262,263,264,266,267,274,276],"requirements_cpu_woq":240,"requirements_gpu":240,"requirements_lm_ev":192,"requirements_pt":267,"rerang":115,"rerange_quant":115,"rerange_quantized_concat":113,"rerangequantizedconcat":115,"rerewrit":39,"rerun":[240,276],"research":[200,205,250,251,252,271,275],"reshap":[49,55,56,61,149,274,275],"reshape_1":[250,251],"reshape_in0_ndef":[55,56],"reshape_in1_ndef":[55,56],"reshape_in_channel_to_last":149,"reshape_scale_as_input":149,"reshape_scale_as_weight":149,"resid":[128,249,250,251,252,253,254,255],"resiz":220,"resizemethod":220,"resnet":[221,223,250,251,252],"resnet18":[205,217,222,223],"resnet50":[202,221,260],"resnet_v2_50":251,"resnet_v2_50_2017_04_14":251,"resnet_v2_50_inf_graph":251,"resnetv2_50":[217,255],"resnetv2_50_kera":255,"resnext101":229,"resnext101_32x16d_wsl":229,"resolv":201,"resourc":[195,235],"respect":[188,227,274,275],"respons":202,"rest":[168,181,245],"restor":199,"restrict":[58,128],"result":[116,138,140,153,188,191,192,199,203,213,222,228,229,235,243,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,266,273,274,275],"result_path":225,"results_fold":265,"resume_from":8,"retrain":198,"retri":149,"retriev":[0,6,118,138,149,185,196],"return":[0,7,8,30,32,34,36,42,55,56,58,62,116,121,122,123,128,130,136,138,140,141,144,147,148,149,151,153,155,160,162,166,168,171,173,174,175,177,178,181,183,185,190,193,194,196,200,202,213,218,220,229,241,243,246,248,257,259,260,261,262,266,274,275],"return_int":168,"return_tensor":[193,195,276],"reus":[200,219,220],"reuse_cach":192,"review":[188,189,273],"revis":[166,178,185],"revolution":195,"rewrit":[38,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,138,196],"rf":227,"rich":219,"right":[128,188,189,196,227,274,275],"rm":227,"rmax":[204,274],"rmin":[193,204,274],"rmsnormal":219,"ro":[249,250,251,252,253,254,255],"robust":196,"role":[121,199,274,275],"rollov":118,"root":245,"rotary_embed":219,"roughli":[199,274],"rouhani":193,"round":[111,136,175,190,191,192,193,196,199,200,219,220,224,225,230,231,232,233,235,273,274,275],"round_":[274,275],"round_method":175,"roundingmod":136,"row":[274,275],"rtn":[34,125,163,173,174,175,193,195,200,214,215,232,235,240,241,242,274,276],"rtn_algo_entri":215,"rtn_arg":199,"rtn_entri":173,"rtnconfig":[173,174,175,185,199,200,213,269,276],"rtnquantiz":165,"rule":204,"run":[14,116,128,149,175,190,194,196,199,200,204,205,214,218,219,220,221,223,228,232,243,267,273,274],"run_arg":[174,177,200,257],"run_autotun":222,"run_benchmark":[222,224,225,227,229,230,232,246,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266],"run_clm_no_train":[236,237,238,239,242],"run_evalu":[231,233],"run_fn":[148,149,174,177,197,198,199,200,246],"run_gener":[192,231,233,240],"run_generation_cpu_woq":[240,241],"run_generation_gpu_woq":[240,276],"run_qa":243,"run_quant":[221,224,227,229,230,231,232,233,246,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266],"runtim":[191,192,196,205,221,256,274],"s8":[23,24,25,28,29],"sacrif":[193,273],"safe":[166,189,245],"safe_seri":166,"safetensor":[130,196,205],"sail":227,"salient":199,"same":[1,17,71,116,149,192,193,195,196,199,213,219,232,256,274,275],"sampl":[1,65,118,123,149,190,196,199,204,213,218,220,227,232,264,267,274,275],"sample_one_step":218,"sample_pr":220,"sample_two_step":218,"sampler":[1,118,175,199,213],"san":192,"sandbar":220,"saniti":[229,243],"sapphir":[237,238,239,270,272],"satisfi":270,"save":[7,116,121,128,130,140,147,151,166,177,178,185,190,192,193,195,196,200,202,205,225,227,228,232,234,235,240,246,248,254,255,257,259,260,261,262,266,267,274,275,276],"save_config_map":7,"save_dir":276,"save_layers_in_shards_it":130,"save_load":[5,139,146,150,163],"save_load_entri":176,"save_model":[196,220],"save_path":234,"save_pretrain":276,"save_q_input":149,"save_step":[196,235],"save_strategi":[196,235],"save_total_limit":[196,235],"saved_dir":[240,276],"saved_inc":[193,195],"saved_model":[116,204,266],"saved_model_sess":121,"saved_model_tag":121,"saved_path":130,"saved_result":[140,151,166,178,199,200,227,230,237,238,240,241,242,246],"savedmodel":[121,254,255],"savedresult":243,"saveloadformat":[166,182],"scalabl":[194,204,205,237,238,239,241,242,270,272,273,274],"scalar":175,"scale":[17,23,24,25,28,29,86,111,149,157,160,161,164,168,190,191,192,193,196,197,198,199,204,232,235,274,275],"scale_bf16_to_fp8":[164,168],"scale_bit":136,"scale_c":111,"scale_dtyp":[164,175,199],"scale_format":175,"scale_method":[175,192],"scale_param":175,"scale_propag":82,"scale_quant_group_s":[175,199],"scale_shap":[145,196],"scale_shar":[149,175],"scalepropagationtransform":86,"scaler":16,"scales_per_op":[17,34],"scan":189,"scenario":[199,200,274],"scene":219,"schedul":199,"schema":[168,183],"scheme":[144,149,153,164,168,169,175,193,195,199,241],"scope":[116,189,200],"score":[193,220,227,228,259],"scout":[193,217,230],"script":[189,192,205,218,219,220,221,223,227,228,237,238,239,240,241,249,250,251,252,253,254,255,256,257,259,260,261,262,263,265,266,273,276],"sd":227,"sdxl_smooth_quant":227,"seamless":276,"seamlessli":193,"search":[138,155,168,199,200,203,215,240,273],"search_clip":168,"search_pattern":138,"seashor":220,"second":[52,128,199,214,240,274,275,276],"section":[196,215],"secur":[129,205,245,273,277],"see":[129,179,188,189,190,192,196,199,201,215,219,220,271,274,275],"seed":[8,122,123,175,199],"seek":128,"seem":215,"segment":[189,217],"select":[168,173,179,185,192,193,199,232,265,274],"self":[51,168,192,196,200,218,257,259],"semant":217,"send":189,"sens":219,"sensit":[193,196],"sentenc":215,"sep":273,"separ":[29,123,185,188,215,219,220,265,271],"separable_conv2d":26,"separableconv2d":29,"seqlen":[123,175,193,199],"sequenc":[51,123,196,199,274],"sequenti":[1,118,122,155,213],"sequentialsampl":[1,118],"seri":[193,205,239,270,273],"serial":[128,129,166],"serv":[121,274],"server":[8,214],"servic":273,"sess":[116,121],"session":[116,121],"set":[0,1,8,19,33,39,83,116,118,120,121,128,138,141,149,166,168,174,175,178,185,188,190,192,193,194,196,197,199,200,202,203,205,213,214,219,220,227,230,232,235,240,242,249,250,251,252,253,254,255,257,259,263,266,267,274,275,276],"set_loc":[191,197,198,199,200,202],"set_modul":[149,168,185],"set_random_se":8,"set_resume_from":8,"set_tensorboard":8,"set_workspac":8,"setattr":196,"settings_recommend":215,"setup":[192,205,219,221,225,226,230,240,247],"setvar":240,"sever":[110,190,193,194,214,225,232,274,275],"sex":188,"sexual":188,"sf":267,"sh":[192,221,222,224,225,226,227,228,229,230,231,232,233,240,243,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266],"shaji":199,"shape":[116,118,155,161,171,192,199,204,205,274,275],"shard":[130,166,196],"shard_dir":130,"share":[17,70,85,90,168,193,196,199,232,234,242,267,274,275],"share_qdq_y_pattern":87,"shared_criterion":[149,175],"shared_lay":[175,193,232],"shareqdqforitexypatternoptim":90,"sharp":192,"shell":[205,221,223],"shen":271,"shift":111,"shm":[225,230],"shop":215,"shorter":233,"shot":[199,204,273],"should":[32,36,43,128,149,162,166,177,178,183,190,192,193,198,200,202,203,204,219,227,229,232,240,243,245,249,250,251,252,253,254,255,256,266,274,276],"should_sav":196,"show":[188,193,240,262,266,274,275],"show_nam":114,"show_op":114,"shown":[192,193,195,274,275],"shuffl":118,"sign":[175,189,195,199,273,274],"signatur":121,"signific":[204,273,274,275],"significantli":[193,194,195,196,199,235],"signround":199,"sigopt":273,"silicon":193,"simianluo":228,"similar":[195,219,220,274,275],"similarli":[274,275],"simpl":[3,190,204,229,243,274,275],"simple_attr":3,"simple_infer":153,"simpli":219,"simplic":[274,275],"simplifi":[193,273],"simul":[196,200,235],"sinc":[192,199,205,232,274],"singl":[36,118,138,149,193,195,199,231,232,233,270,275],"singleton":[8,91,122],"situat":200,"sixteen":194,"size":[1,85,118,121,123,161,166,168,188,192,193,195,198,199,225,230,232,248,257,260,261,262,267,274,275],"skip":[128,232,240,276],"skip_special_token":276,"skip_verified_config":1,"slicer":242,"slightli":[196,220],"slim":[121,122,250,251,252],"slim_sess":121,"slow":[193,196],"slower":199,"small":[55,56,57,58,196,199,235,274],"smaller":[58,193,233],"smooth":[14,15,16,17,32,34,148,149,173,175,200,205,215,227,237,269],"smooth_quant":[126,153,215],"smooth_quant_config":32,"smooth_quant_en":153,"smooth_quant_entri":[32,173,215],"smoother":13,"smoothquant":[15,146,148,149,175,197,199,200,203,205,272,273,274],"smoothquant_scale_info":149,"smoothquantcalibr":14,"smoothquantcalibrationllm":14,"smoothquantconfig":[15,32,34,173,175,197,203,204,246,257],"smoothquantquant":148,"smoothquantscal":17,"smoothquantscalerllm":17,"snap":248,"snippet":215,"so":[1,177,192,193,199,200,204,205,219,220,244,250,251,252,266,267,274,275,276],"social":[188,273],"socialist":192,"socioeconom":188,"softmax":[192,219,220],"softwar":[205,221,229,243,271,273],"solut":[111,197,199,203,267,273,274,275],"solv":[189,274],"some":[196,199,200,215,222,227,229,234,240,269,270,274,275],"someon":192,"sometim":274,"sonnet":192,"soon":[234,272],"sort":199,"sota":273,"sound":270,"sourc":[0,1,3,4,6,7,8,9,10,14,15,17,19,20,23,24,25,28,29,30,32,33,34,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,68,69,70,71,72,73,74,76,77,78,79,80,81,83,84,85,86,88,89,90,91,94,95,96,97,98,99,100,102,103,104,105,106,107,108,109,110,111,112,114,115,116,118,120,121,122,123,125,128,129,130,131,133,135,136,137,138,140,141,143,144,145,147,148,149,151,152,153,154,155,156,157,158,160,161,162,164,165,166,167,168,169,171,173,174,175,177,178,179,180,181,182,183,185,186,192,205,229,240,243,245,257,259,271,273],"space":[188,189,200,213,215,240,245,274],"spacetobatchnd":46,"spars":273,"sparsiti":199,"speak":[199,274],"special":[128,195,200],"specif":[0,118,120,141,149,166,185,188,193,194,198,199,200,204,214,215,266,270,272],"specifi":[3,91,123,128,136,140,149,153,175,178,185,190,196,200,214,219,228,240,246,248,257,260,261,262,266,274,276],"speed":[192,224,225,273,274],"speedup":[273,274],"spellcheck":189,"spevif":168,"spf":192,"spiq":[149,274,275],"split":[70,123,196,224,234,274,275],"split_shared_input":64,"splitsharedinputoptim":70,"spr":[20,257],"sq":[15,148,204,237,258,272],"sq_config":203,"sqlalchemi":267,"sqlinearwrapp":149,"sqrt":57,"squad":[243,256],"squar":[192,199],"squeez":[66,252],"squeezebit":[205,273],"sram":242,"sram_slicer_shared_mme_input_expansion_en":242,"ssd":262,"ssd_mobilenet_v1":217,"ssd_mobilenet_v1_coco_2018_01_28":262,"ssd_resnet50_v1":262,"stabil":199,"stabilityai":[226,227,228],"stabl":[226,227,229,240,273],"stack":[155,196,205,221,229,243],"stage":[0,8,196],"stai":[197,199,267,276],"stand_norm":118,"standard":[190,196,215],"stanford":248,"star":189,"starcoder2":192,"start":[223,233,270,273,277],"stat":[123,185],"state":[192,196,199,214],"state_dict":[130,199],"statefulpartitionedcal":257,"statement":215,"static":[18,19,20,30,32,34,149,152,153,173,175,177,195,200,205,217,219,220,228,230,232,238,269,275],"static_attention_dtyp":230,"static_config":203,"static_group":[175,199],"static_kv_dtyp":[230,232],"static_qu":[13,126,202,215],"static_quant_entri":[32,173],"staticmethod":110,"staticqu":[150,152],"staticquantconfig":[19,20,30,34,122,173,175,198,202,203,204,213,219,220,248,257,259,260,261,262,266],"staticquantquant":152,"statist":[8,192,218],"statu":[188,200],"stderr":122,"step":[191,192,196,198,199,219,220,263,274,275,276],"still":[190,192,196,200,203,273,274],"stock":[20,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"stop":[1,213],"stopgradi":68,"storag":[128,196,199,248,249,250,251,252,253,256,259,260,264,266,274,275],"store":[14,140,149,195,219,220],"str":[0,3,7,8,14,30,33,34,36,122,123,128,130,131,136,138,140,141,144,149,151,153,160,162,166,168,169,171,173,175,177,178,179,181,183,185,196,199,200,204,215,259],"straightforward":[199,204,274,275],"strategi":[193,195,196,215,273,274],"stream":122,"streamlin":273,"street":219,"stretch":192,"stride":[23,25,28,29],"strided_slice_19":259,"string":[8,116,121,122,128,129,144,155,185,192,204],"strip":[55,56,58,71,72,116],"strip_equivalent_nod":[64,116],"strip_unused_lib":116,"strip_unused_nod":[64,116],"stripequivalentnodesoptim":71,"stripunusednodesoptim":72,"strong":[196,219,235],"structur":[155,200,249,250,251,252,253,254,255,273,274],"stun":219,"style":[215,219],"style_imag":266,"style_images_path":266,"style_transf":266,"styliz":266,"sub":[54,153,215,249,250,251,252,253,254,255],"sub_modul":215,"subclass":149,"subfold":[221,223],"subgraph":[43,54],"subject":271,"subject_consist":225,"submit":[189,245,273],"submodul":[177,240],"subprocess":215,"subsect":[274,275],"subset":[224,249,250,251,252,253,254,255],"subsidiari":271,"substitut":[32,36,204],"success":270,"successfulli":[205,273],"successor":[78,79,80,81],"sudo":267,"suffici":[190,245],"suffix":116,"suggest":[200,215,232],"suit":245,"suitabl":200,"summar":[114,195,215],"super":218,"super_bit":175,"super_group_s":175,"supplement":204,"support":[0,9,10,84,149,173,175,183,185,186,190,191,195,196,198,202,205,213,215,219,220,221,224,227,232,233,237,238,240,246,249,250,251,252,259,261,262,263,266,267,269,272,273,274],"supported_lay":[155,168,185],"supported_op_typ":51,"supported_typ":185,"suppos":[274,275],"suppress":[199,274,275],"sure":[185,205,245,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"surg":128,"suyu":271,"switch":[73,227],"switch_optim":64,"switchoptim":73,"sy":[122,215],"sym":[141,145,149,168,196,199,241],"symmetr":[141,149,204],"synchron":183,"synset":[249,250,251,252,253,254,255],"sys_nic":[205,221],"system":[128,193,194,214,225,229,240,243,276],"systemat":[197,203,275],"t":[55,56,58,111,128,192,194,197,198,204,215,221,229,231,233,245,246,266,267],"tab":245,"tabl":[193,195,205,269],"taco":273,"tag":[121,128,274,275],"tai":271,"tail":199,"tailor":[199,214],"take":[118,188,190,194,199,204,205,214,249,250,251,252,253,254,255,264],"tamper":128,"tar":[250,251,252,259,260,261,262,266],"target":[19,138,155,185,192,196,200,232],"target_bit":[175,193],"target_block":185,"target_depth":153,"target_dtyp":138,"task":[111,192,196,199,214,230,232,235,236,239,240,242,256,274,276],"task_nam":[231,233],"taskset":[214,240,276],"tb00_40m":246,"tbb":[183,267],"team":[6,188],"techniqu":[9,10,186,198,204,205,213,217,234,235,269,273,274],"technologi":[193,240,272],"tell":128,"temp_auto_round":[175,193,195],"temp_path":14,"temperatur":276,"tempfil":169,"templat":[123,175],"temporari":[14,149,188],"temporarili":188,"ten":214,"tencent":273,"tensor":[14,58,116,121,122,128,130,136,138,140,145,147,148,149,153,157,158,160,161,168,174,177,183,185,190,191,192,193,195,196,200,204,215,218,219,220,232,259,266],"tensor2tensor":259,"tensor_data":[77,122],"tensor_nam":[116,128,130],"tensor_parallel_s":[196,231,232,233,235],"tensor_quant":[142,196],"tensorboard":[8,196,235],"tensordot":257,"tensorflow":[10,203,205,206,215,220,254,255,258,269,273,275],"tensorflow_itexadaptor":20,"tensorflowadaptor":20,"tensorflowbasemodel":121,"tensorflowcheckpointmodel":121,"tensorflowconfig":20,"tensorflowconfigconvert":20,"tensorflowglobalconfig":120,"tensorflowllmmodel":121,"tensorflowmodel":121,"tensorflowqueri":20,"tensorflowsavedmodelmodel":121,"tensorquant":145,"teq":[163,173,175,200,240,242,273,276],"teq_arg":199,"teq_quantize_entri":173,"teqconfig":[173,175,199,276],"teqlinearfakequ":164,"tequant":167,"terabyt":246,"term":[189,200,204,271],"test":[185,189,205,229,243,245,260,261,262,266],"test_ld":246,"text":[192,193,195,199,217,237,240,241,244,246,271,273,274],"text_to_imag":224,"tf":[17,34,36,92,116,118,120,121,122,202,204,205,215,220,249,250,251,252,253,254,255,257,260,261,262,263,270,273],"tf_record":256,"tfgptj_for_causal_lm":257,"tfrecord":264,"tfslimnetsfactori":122,"tgz":250,"th":77,"than":[43,122,123,179,190,193,199,232,240,243,245,250,251,252,260,261,262,274],"theater":219,"theblok":205,"thei":[128,179,188,194,215,222,229,265],"them":[128,179,199,200,231,233,246,260,261,262,274],"themselv":199,"theoret":[199,274],"therefor":[205,274,275],"thi":[0,1,74,91,103,110,111,115,118,128,129,149,153,177,181,185,188,189,190,192,194,195,196,197,198,199,202,203,204,205,213,215,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,237,238,239,240,241,243,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,271,272,274,275,276],"think":199,"third":[189,271],"those":[62,128,198,204,245,274],"though":[220,274,275],"thread":[240,267,276],"threaten":188,"three":[62,194,200,213,274,275],"threshold":232,"thrive":219,"through":[144,196,198,199,200,205,232,245,274,275],"thu":274,"thudm":272,"tian":271,"tiiuae":[192,272],"tile":215,"till":8,"tim":[199,274],"time":[8,116,122,128,198,199,200,203,205,213,214,219,220,223,233,234,257,267,273,274,276],"timeout":[248,260,261,262],"tip":[214,233,242],"titl":271,"tmp":[250,251,252],"tmp_file_path":122,"to_devic":185,"to_dtyp":185,"to_quant_block_nam":[175,185],"todo":[3,118,155,179],"togeth":[0,273],"token":[123,166,193,195,196,199,274,276],"token_embed":219,"token_id":219,"toler":[1,193,204,244],"tolerable_loss":[1,193,213],"too":[193,196],"tool":[116,192,250,251,252,273,274],"toolchain":[267,273],"toolkit":273,"top":[189,220],"topologi":[224,225,230,232],"torch":[1,7,10,191,192,193,194,195,196,197,198,199,205,213,214,218,227,229,234,237,241,242,243,246,267,269,274,275,276],"torch_dtyp":[193,195,196,205],"torch_util":175,"torchbaseconfig":175,"torchdynamo":200,"torchfunctyp":138,"torchimport":200,"torchinductor_freez":[226,247],"torchscript":178,"torchsmoothqu":[148,149],"torchvis":[205,222,229],"torchvision_model":222,"total":[123,199],"total_valu":168,"toward":188,"tp":[231,233],"tp_size":230,"trace":[140,148,149,153,174,177,192,198,200,246],"trace_gptq_target_block":155,"traced_model":149,"track":[8,245],"trackabl":116,"trade":[193,199,232,274],"tradit":[193,195,204,219],"train":[45,68,149,155,175,177,192,193,194,195,197,198,199,200,203,205,213,217,221,222,223,228,229,253,254,255,260,261,262,264,273,275],"train_fn":199,"train_ld":246,"train_siz":196,"trainabl":[167,199,273],"trainableequivalenttransform":167,"trainingargu":196,"trane":200,"tranformer_block_1":220,"tranformer_block_2":220,"transact":275,"transfer":[274,275],"transform":[38,111,113,114,115,118,138,148,149,153,155,167,175,177,181,183,185,192,193,195,196,197,198,199,203,205,237,240,241,243,253,267,269,272,273,274,275],"transform_graph":92,"transformer_block":155,"transformer_lt":[217,259],"transformer_lt_official_fp32_pretrained_model":259,"transformerbasedmodelblockpatterndetector":153,"transformers_nam":155,"transformers_pr":155,"transit":196,"translat":193,"transpar":245,"transpos":61,"travers":213,"treat":[128,185],"tree":[245,247,264],"tri":[0,215],"trial":[1,213],"troll":188,"true":[1,23,24,25,29,30,34,73,114,116,118,128,130,138,145,148,149,155,158,162,164,166,167,168,175,177,185,190,191,192,193,195,196,197,198,199,200,202,204,213,219,220,222,227,229,235,246,250,251,252,253,258,274,275,276],"true_sequenti":[175,199],"truncat":[123,175],"trust":128,"trust_remote_cod":[166,178,193,195,276],"try":[121,193,204,205,221,259,267,274],"try_cnt":116,"try_loading_kera":121,"tsv":[224,227],"tunabl":[0,3],"tunable_typ":3,"tune":[0,1,3,6,33,142,149,174,175,193,194,197,198,199,200,205,213,215,216,223,229,232,235,243,248,249,250,251,252,253,256,260,261,262,263,264,265,266,267,269,273,276],"tune_cfg":[148,149,153,185],"tune_config":[1,33,174,194,200,202,203,204,213,246,257],"tune_limit":232,"tune_task":232,"tuning_config":[1,193],"tuning_param":2,"tuningconfig":[1,33,174,193,194,200,202,203,204,213,246,257],"tuninglogg":[1,6],"tuningmonitor":1,"tuningparam":3,"tupl":[1,33,36,131,138,140,147,148,149,153,160,161,171,173,174,175,177,185,200,204,215],"tutori":[229,243,246,248,257,259,260,261,262,266,273],"twitter":273,"two":[128,189,192,193,194,195,198,199,203,213,215,216,248,260,261,262,264,266,274,275],"txt":[192,196,219,220,221,222,223,224,226,227,229,231,232,233,235,237,238,239,240,241,242,243,246,247,248,249,250,251,252,253,254,255,256,257,260,261,262,263,264,265,266,267],"type":[0,1,3,7,8,14,32,34,36,62,83,103,116,121,122,123,128,130,135,136,138,140,141,147,149,153,155,160,161,162,166,168,171,173,174,175,177,181,185,192,194,195,196,197,198,199,200,202,204,205,214,232,240],"typealia":215,"types_to_splic":68,"typic":[190,196,234,242],"u":[111,240],"u2191":267,"ubuntu":270,"ubuntu22":221,"ubuntu24":205,"ue4m3":195,"uint4":242,"uint8":[141,168,175,204,220,274],"ultim":274,"ultra":[205,270],"ultralyt":263,"unaccept":188,"uncas":[243,256],"uncom":[219,220],"undefin":128,"under":[91,122,185,189,196,205,245,257,271,273],"underli":[55,56,58,128],"understand":[244,274],"unet":227,"unicodedecodeerror":128,"unicodeencodeerror":267,"unifi":[6,125,171],"uniform":199,"uniformli":199,"uninstal":[231,233],"union":[0,171,174,175,177,185,200,204],"uniqu":[219,249,250,251,252,253,254,255,274],"unit":[24,189,192],"unit_scal":192,"unless":128,"unlik":[204,235],"unpack":[156,164],"unpack_weight":164,"unpack_zp":164,"unpackedweightonlylinearparam":164,"unpickl":[128,129],"unpicklingerror":129,"unquant":138,"unquantized_node_set":138,"unsaf":128,"unseen":[204,274],"unsloth":231,"until":[149,192],"untrust":128,"unus":[72,116,185],"unvfp4":217,"unwelcom":188,"unzip":[226,246,247,248,256,265],"up":[86,153,192,224,225,267,273,274],"up_proj":[193,232],"updat":[62,130,149,153,192,199,224,225,230,240,245,267,272],"update_modul":130,"update_sq_scal":149,"upgrad":[248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"upload":264,"upon":276,"upstream":[166,178,234],"url":[155,189,240,241,270,271],"us":[0,8,17,19,20,32,36,37,58,118,122,123,128,130,136,137,138,140,141,148,149,152,153,160,161,162,166,168,174,177,178,179,183,185,188,189,190,192,193,194,195,196,197,198,199,200,202,204,205,213,214,215,219,220,221,224,225,227,228,230,231,232,233,234,235,237,238,239,240,242,245,246,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,264,265,266,267,271,273,274,275,276],"usag":[0,1,3,122,168,179,181,182,185,192,195,200,214,231,232,233,234,240,242,256,260,261,262,266,274],"use_aot_devlist":240,"use_auto_clip":[175,199],"use_auto_scal":[175,199],"use_bf16":37,"use_bia":[23,24,25,29],"use_block_wis":[155,175],"use_double_qu":[175,199],"use_full_rang":[175,199],"use_hpu_graph":234,"use_kv_cach":192,"use_layer_wis":[155,175,199],"use_max_length":155,"use_mse_search":[175,199,241],"use_optimum_format":164,"use_qdq":175,"use_sym":[175,199,213],"useless":223,"user":[123,128,138,149,153,175,185,190,192,193,194,195,197,198,199,200,202,203,204,213,214,215,218,239,240,249,250,251,252,253,254,255,263,272,273,274,275,276],"user_cfg":[149,153],"user_eval_fns1":1,"user_eval_fns2":1,"user_eval_fns3":1,"user_eval_fns4":1,"user_model":[130,269],"user_processor_typ":185,"userfloatmodel":[191,198],"usr":267,"usual":[196,204,274,275],"utf":[128,267],"util":[0,1,2,21,32,33,35,36,127,134,139,144,146,150,163,172,173,175,192,196,204,214,215,219,220,248,257,259],"v":[192,225,230],"v0":[190,192,224,225,230,272],"v1":[116,121,192,250,251,252,256,262,267,268],"v1_6":[249,264],"v2":[247,250,251,261,267,272],"v2_2_0":259,"v2_7_0":256,"v3":[205,224,225,230,249,254,268],"v5":263,"v_proj":[193,232],"v_qdq":[219,220],"val":[161,222,227,229,249,250,251,252,253,254,255],"val2017":226,"val_dataload":202,"val_dataset":202,"valid":[6,23,25,28,29,43,55,56,121,141,185,192,217,221,222,223,224,225,227,228,230,237,238,239,240,242,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,276],"valid_keras_format":122,"valid_reshape_input":[55,56],"validate_and_inference_input_output":121,"validate_graph_nod":121,"validate_modul":185,"valu":[44,55,56,58,77,111,118,128,130,149,153,160,164,179,190,191,192,193,194,195,197,199,203,204,219,220,232,237,274,275],"valueerror":[55,56,58,168,181,267],"values_from_const":[55,56,58],"var":[229,243],"vari":275,"variabl":[129,179,190,194,200,214,219,220,228,240,242,257,265,276],"varianc":111,"variant":233,"variat":195,"varieti":[200,213,219],"variou":[125,193,198,200,204],"vault":[205,221],"vbench":225,"vcvtne2ps2bf16":194,"vcvtneps2bf16":194,"vdpbf16p":194,"ve":245,"vecchio":270,"vector":194,"vendor":240,"ventura":270,"venu":219,"verbos":160,"veri":[199,219,274],"verif":232,"verifi":[196,229,232,234,272],"version":[2,10,42,143,164,177,183,188,190,192,196,197,205,215,222,227,229,240,243,246,248,249,250,251,252,253,254,255,256,259,260,261,262,263,264,265,266,270,271,273,275],"version1":122,"version1_eq_version2":122,"version1_gt_version2":122,"version1_gte_version2":122,"version1_lt_version2":122,"version1_lte_version2":122,"version2":122,"vgg":[250,251,252],"vgg16":[217,252],"vgg_16":252,"vgg_16_2016_08_28":252,"vgg_16_inf_graph":252,"vi_t_backbon":220,"via":[175,188,193,196,199,249,250,251,252,253,273,274],"vibrant":219,"video":[123,217],"view":[189,205],"viewpoint":188,"violat":129,"virtual":273,"visibl":[190,224,225],"vision":[192,205,253,274,275],"vision_transform":253,"vit":[190,217,220,253],"vit_base_patch16_224_imagenet":220,"vit_encod":220,"vit_orig":220,"vit_patching_and_embed":220,"vit_quant":220,"vitbackbon":220,"vitencod":220,"vitencoderblock":220,"vitimageclassifi":220,"vitpatchingandembed":220,"vllm":[169,178,196,231,232,233,235],"vllm_contiguous_pa":192,"vllm_serv":192,"vllm_skip_warmup":192,"vllm_use_precompil":[231,232,233],"vllmkvcach":192,"vlm":205,"vmware":273,"vnni":274,"vocab":256,"vocab_fil":[256,259],"vscode":215,"vtune":271,"vvv":[231,233],"w":[155,192,228,231,274,275],"w4a16":[175,199],"w4a8":[173,199],"w8a16":199,"w8a8":[137,191,198,199,274],"w8a8pt2equant":137,"w_algo":175,"w_dq":[274,275],"w_dtype":[175,197,198,236],"w_fp32":111,"w_granular":175,"w_int8":111,"w_q":[274,275],"w_scale":[219,220,274,275],"w_sym":175,"wa":[128,190,193,197,264,273],"wai":[121,199,203,256,274,275],"walk":196,"wall":219,"want":[55,56,58,245],"warm":153,"warmup":192,"warmup_ratio":[196,235],"warn":[149,215],"wasn":128,"we":[1,55,56,58,62,74,111,128,149,188,191,193,197,198,199,200,203,204,205,213,214,215,219,220,227,228,229,232,234,237,238,239,240,242,244,245,246,248,249,250,251,252,253,254,255,257,259,260,261,262,265,266,272,274,275,276],"websit":[219,260,261,262],"wechat":273,"wei":[199,274,275],"weight":[1,14,17,48,49,111,130,149,157,163,164,166,167,168,175,178,190,191,192,195,196,197,198,200,202,203,204,205,213,217,235,240,246,247,263,269,272,273,275,276],"weight_algorithm":34,"weight_clip":[34,149],"weight_config":[155,167],"weight_decai":[196,235],"weight_dtyp":[30,34,202,219,220,241,257],"weight_empir":111,"weight_granular":[30,34,202,260,261,262],"weight_max_lb":149,"weight_max_valu":[23,24,25,28,29],"weight_min_valu":[23,24,25,28,29],"weight_name_map":[14,257],"weight_onli":[126,175,215],"weight_pack":196,"weight_quant":196,"weight_sym":[30,34,202,204,213],"weightonlylinear":[164,199],"weightonlyqu":[199,240,242],"weights_onli":128,"welcom":[187,188,189,205,245,277],"well":[190,193,215,229,230,240,243,274,275],"wenhua":[199,274],"were":128,"wget":[224,248,249,250,251,252,253,256,259,260,261,262,264,266,267],"what":[153,188,192,204,244,273],"when":[1,32,36,42,52,58,116,128,129,138,166,177,180,188,190,192,196,198,199,204,213,214,215,219,220,228,230,265,274],"where":[128,140,185,190,193,199,219,228,249,250,251,252,253,254,255,274,275],"whether":[36,116,122,123,128,141,144,148,149,155,160,161,166,168,177,183,196,199],"which":[0,44,71,91,122,128,149,155,160,161,166,175,177,185,188,192,193,194,195,196,198,199,200,202,204,213,219,220,221,234,235,242,248,257,260,261,262,266,267,274,275],"while":[193,194,195,196,198,199,204,205,227,274,275],"white":[34,227],"white_list":[0,30,34,175],"white_module_list":185,"whl":[229,240,241,250,251,252,270],"who":[188,193,195],"whole":[191,195,218,243,274],"whose":[121,149,185],"why":[274,275],"wide":[194,199,205,219,264,274],"wide_deep_fp32_pretrained_model":264,"wide_deep_large_d":[217,264],"width":[193,232,274],"wiki":188,"window":[214,267,270],"winogrand":[192,237,238,239],"winter":[274,275],"wip":[199,272],"wise":[111,127,130,136,181,195,196,234,275,276],"within":[0,1,121,185,188,194,199,232,273,275,276],"without":[116,183,188,190,193,219,220,237,266,273,274],"wnd_int8_opt":264,"woq":[166,175,178,240,241,272,276],"woq_algo":[240,241,242],"woq_bit":242,"woq_config":276,"woq_group_s":242,"woq_model":276,"woq_model_save_path":240,"woq_schem":242,"woqmodelload":166,"word":[199,215,237,238,239,241,243,274],"work":[32,36,178,200,201,204,214,215,219,220,240,245,260,261,262,274,275],"workflow":[193,205,231,233,269],"workload":[194,195,273],"workshop":273,"workspac":8,"worth":[215,219,220],"would":[189,198,257,274,275],"wrap":[36,120],"wrapper":[1,14,63,120,121,133,164,168,204],"wrapperlay":149,"write":[116,185],"write_graph":116,"write_json_fil":185,"written":196,"ww42":257,"wwm":256,"wwm_uncased_l":256,"www":[219,221,223],"x":[43,62,149,185,196,215,260,261,262,269,274,275],"x1":[218,274,275],"x2":[218,274,275],"x86":[194,250,251,252],"x86_inductor_quant":141,"x86inductorquant":[141,191],"x_q":[274,275],"x_scale":[274,275],"x_test":246,"x_tmp":[274,275],"xdoctest":128,"xeon":[190,194,205,219,220,237,238,239,241,242,270,271,272,273,274],"xiao":[199,274,275],"xiui":[199,274,275],"xl":227,"xla":[190,219,220],"xla_backend_extra_opt":[190,219,220],"xla_cpu_disable_new_fusion_emitt":[190,219,220],"xla_cpu_experimental_onednn_custom_cal":[190,219,220],"xla_cpu_experimental_ynn_fusion_typ":[190,219,220],"xla_cpu_use_onednn":[190,219,220],"xla_cpu_use_xnnpack":[190,219,220],"xla_flag":[190,219,220],"xpu":[153,179,204,229,240,243,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,276],"xpu_acceler":179,"xvf":[250,251,252,260],"xvzf":[261,262,266],"xx":168,"xx_func":215,"y":[90,215,267,274,275],"y_dq":[274,275],"y_q":[274,275],"yaml":[19,196,235,266],"year":271,"yet":190,"yield":[1,118,242,257,274],"yiliu30":[231,232,233],"yolo":263,"yolo_v5":[217,263],"yolov5":263,"yolov5s_int8":263,"you":[128,149,189,192,193,196,215,219,220,227,228,229,230,232,233,234,243,244,245,247,248,249,250,251,252,253,254,255,256,258,259,260,261,262,263,264,265,266,267,270,271,276],"your":[189,192,193,196,198,205,215,219,220,225,226,229,235,240,243,245,246,250,251,252,256,266,267,271,273,276],"your_data_path":226,"yourmodel":199,"yourself":219,"youtub":273,"yum":267,"yvinec":[274,275],"z":[215,274,275],"zero":[23,24,25,29,149,157,160,161,168,193,198,199,274,275],"zeropoint":[204,274],"zip":[149,225,226,248,256],"zone":273,"zoo":[246,256,259,264,265,266],"zp":[164,168,274,275],"zxvf":259,"\u817e\u8baf\u4e91taco":273,"\u96c6\u6210\u82f1\u7279\u5c14":273},"titles":["neural_compressor.common.base_config","neural_compressor.common.base_tuning","neural_compressor.common","neural_compressor.common.tuning_param","neural_compressor.common.utils.constants","neural_compressor.common.utils","neural_compressor.common.utils.logger","neural_compressor.common.utils.save_load","neural_compressor.common.utils.utility","neural_compressor.common.version","neural_compressor","neural_compressor.jax.algorithms","neural_compressor.jax","neural_compressor.tensorflow.algorithms","neural_compressor.tensorflow.algorithms.smoother.calibration","neural_compressor.tensorflow.algorithms.smoother.core","neural_compressor.tensorflow.algorithms.smoother","neural_compressor.tensorflow.algorithms.smoother.scaler","neural_compressor.tensorflow.algorithms.static_quant","neural_compressor.tensorflow.algorithms.static_quant.keras","neural_compressor.tensorflow.algorithms.static_quant.tensorflow","neural_compressor.tensorflow","neural_compressor.tensorflow.keras","neural_compressor.tensorflow.keras.layers.conv2d","neural_compressor.tensorflow.keras.layers.dense","neural_compressor.tensorflow.keras.layers.depthwise_conv2d","neural_compressor.tensorflow.keras.layers","neural_compressor.tensorflow.keras.layers.layer_initializer","neural_compressor.tensorflow.keras.layers.pool2d","neural_compressor.tensorflow.keras.layers.separable_conv2d","neural_compressor.tensorflow.keras.quantization.config","neural_compressor.tensorflow.keras.quantization","neural_compressor.tensorflow.quantization.algorithm_entry","neural_compressor.tensorflow.quantization.autotune","neural_compressor.tensorflow.quantization.config","neural_compressor.tensorflow.quantization","neural_compressor.tensorflow.quantization.quantize","neural_compressor.tensorflow.quantization.utils.graph_converter","neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert","neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer","neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes","neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer","neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base","neural_compressor.tensorflow.quantization.utils.graph_rewriter","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse","neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation","neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq","neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern","neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq","neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern","neural_compressor.tensorflow.quantization.utils.graph_util","neural_compressor.tensorflow.quantization.utils","neural_compressor.tensorflow.quantization.utils.quantize_graph","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq","neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq","neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base","neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn","neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2","neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv","neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu","neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul","neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling","neural_compressor.tensorflow.quantization.utils.quantize_graph_common","neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction","neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base","neural_compressor.tensorflow.quantization.utils.transform_graph","neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging","neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat","neural_compressor.tensorflow.quantization.utils.utility","neural_compressor.tensorflow.utils.constants","neural_compressor.tensorflow.utils.data","neural_compressor.tensorflow.utils","neural_compressor.tensorflow.utils.model","neural_compressor.tensorflow.utils.model_wrappers","neural_compressor.tensorflow.utils.utility","neural_compressor.torch.algorithms.autoround.autoround","neural_compressor.torch.algorithms.autoround","neural_compressor.torch.algorithms.base_algorithm","neural_compressor.torch.algorithms","neural_compressor.torch.algorithms.layer_wise","neural_compressor.torch.algorithms.layer_wise.load","neural_compressor.torch.algorithms.layer_wise.modified_pickle","neural_compressor.torch.algorithms.layer_wise.utils","neural_compressor.torch.algorithms.mixed_precision.half_precision_convert","neural_compressor.torch.algorithms.mixed_precision","neural_compressor.torch.algorithms.mixed_precision.module_wrappers","neural_compressor.torch.algorithms.mx_quant","neural_compressor.torch.algorithms.mx_quant.mx","neural_compressor.torch.algorithms.mx_quant.utils","neural_compressor.torch.algorithms.pt2e_quant.core","neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter","neural_compressor.torch.algorithms.pt2e_quant","neural_compressor.torch.algorithms.pt2e_quant.save_load","neural_compressor.torch.algorithms.pt2e_quant.utility","neural_compressor.torch.algorithms.qat","neural_compressor.torch.algorithms.qat.quant_linear","neural_compressor.torch.algorithms.qat.quant_utils","neural_compressor.torch.algorithms.qat.tensor_quantizer","neural_compressor.torch.algorithms.smooth_quant","neural_compressor.torch.algorithms.smooth_quant.save_load","neural_compressor.torch.algorithms.smooth_quant.smooth_quant","neural_compressor.torch.algorithms.smooth_quant.utility","neural_compressor.torch.algorithms.static_quant","neural_compressor.torch.algorithms.static_quant.save_load","neural_compressor.torch.algorithms.static_quant.static_quant","neural_compressor.torch.algorithms.static_quant.utility","neural_compressor.torch.algorithms.weight_only.awq","neural_compressor.torch.algorithms.weight_only.gptq","neural_compressor.torch.algorithms.weight_only.hqq.bitpack","neural_compressor.torch.algorithms.weight_only.hqq.config","neural_compressor.torch.algorithms.weight_only.hqq.core","neural_compressor.torch.algorithms.weight_only.hqq","neural_compressor.torch.algorithms.weight_only.hqq.optimizer","neural_compressor.torch.algorithms.weight_only.hqq.qtensor","neural_compressor.torch.algorithms.weight_only.hqq.quantizer","neural_compressor.torch.algorithms.weight_only","neural_compressor.torch.algorithms.weight_only.modules","neural_compressor.torch.algorithms.weight_only.rtn","neural_compressor.torch.algorithms.weight_only.save_load","neural_compressor.torch.algorithms.weight_only.teq","neural_compressor.torch.algorithms.weight_only.utility","neural_compressor.torch.export.export_hf","neural_compressor.torch.export","neural_compressor.torch.export.pt2e_export","neural_compressor.torch","neural_compressor.torch.quantization.algorithm_entry","neural_compressor.torch.quantization.autotune","neural_compressor.torch.quantization.config","neural_compressor.torch.quantization","neural_compressor.torch.quantization.quantize","neural_compressor.torch.quantization.save_load_entry","neural_compressor.torch.utils.auto_accelerator","neural_compressor.torch.utils.bit_packer","neural_compressor.torch.utils.block_wise","neural_compressor.torch.utils.constants","neural_compressor.torch.utils.environ","neural_compressor.torch.utils","neural_compressor.torch.utils.utility","neural_compressor.version","Intel\u00ae Neural Compressor Documentation","Contributor Covenant Code of Conduct","Contribution Guidelines","JAX","Dynamic Quantization","FP8 Quantization","Microscaling Quantization","PyTorch Mixed Precision","NVFP4 Quantization","PyTorch Quantization-Aware Training (QAT)","PyTorch Smooth Quantization","PyTorch Static Quantization","PyTorch Weight Only Quantization","Torch","Security Policy","TensorFlow Quantization","Smooth Quant","TensorFlow","Intel\u00ae Neural Compressor","API","Tensorflow Quantization AutoTune","Tensorflow Quantization Base API","Tensorflow Quantization Config","Pytorch Quantization AutoTune","Pytorch Quantization Base API","Pytorch Quantization Config","AutoTune","Quantization on Client","INC Coding Conventions","Design","Examples","Usage demo:","1. Create Environment","1. Create Environment","ImageNet FP8 Quantization","Step-by-Step","ImageNet Quantization","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Stable Diffusion","Step-by-Step","Step-by-Step","Requirement","Step-by-step","Requirement","Step-by-step","Quantization Aware Training (QAT)","Run","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step recipes for LLM quantization","Weight-only quantization","Step-by-Step","Code of Conduct","Contributing to DLRM","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Step-by-Step","Prerequisite","Step-by-Step","Step-by-Step","Step-by-Step","Frequently Asked Questions","Version mapping between Intel Neural Compressor to Gaudi Software Stack","Getting Started","Installation","Legal Information","LLMs Quantization Recipes","Full Publications/Events (91)","Quantization","Smooth Quant","Transformers-like API","Intel\u00ae Neural Compressor Documentation"],"titleterms":{"":[205,270],"1":[196,219,220,222,224,226,229,230,232,234,235,237,238,239,240,241,243,246,247,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,267],"11":257,"125m":[237,238,239],"128k":241,"13b":[237,238,241],"15":[250,251,252,273],"2":[196,219,220,222,224,226,229,230,234,235,240,241,243,246,247,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266,267],"2018":273,"2019":265,"2020":273,"2021":273,"2022":273,"2023":273,"2024":273,"2025":273,"25":273,"3":[196,219,220,224,226,229,232,234,235,241,246,247,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266,267],"30b":241,"35":273,"4":[196,219,220,257,259,264,267,273],"405b":234,"40b":241,"5":[219,220,232,267,273],"6":[219,220,267],"64":270,"6b":[237,238,241,257],"7":[232,267,273],"70b":[232,234,237,238],"7b":[237,238,241],"8":[232,267],"8b":[232,241],"91":273,"For":[261,262,276],"With":[202,229],"accept":189,"accuraci":[192,194,196,202,239,240,241,257,272,274],"adapt":[257,259,266],"addit":[205,264,266],"advantag":193,"agreement":245,"algorithm":[11,13,14,15,16,17,18,19,20,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,275,276],"algorithm_entri":[32,173],"alpha":[197,203,275],"analysi":[248,257,260,261,262,266],"annot":215,"api":[190,193,194,195,200,204,206,208,211,276],"approach":[204,256,262,266],"architectur":[216,270],"argument":[196,199],"ask":267,"asymmetr":274,"attribut":188,"auto":[203,275],"auto_acceler":179,"autom":[262,266],"automat":[256,259,260,261,262,263],"autoround":[123,124,196,199,242],"autotun":[33,174,193,194,200,207,210,213],"awar":[196,202,235,274],"awq":[154,199],"backend":[190,198,204],"background":215,"baichuan":241,"baichuan2":241,"base":[208,211,270],"base_algorithm":125,"base_config":0,"base_tun":1,"baselin":196,"basic":[193,258],"benchmark":[192,222,230,232,246,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266],"benefit":[193,196],"best":[193,196],"between":268,"bf16":[38,39,40,194,196,225],"bf16_convert":38,"bias_correct":111,"binari":270,"bit":193,"bit_pack":180,"bitpack":156,"block_wis":181,"brat":265,"buffer":[260,261,262],"build":267,"built":270,"cach":192,"calib_dataload":257,"calibr":[14,192,265],"channel":[274,275],"chat":241,"chatglm2":241,"chatglm3":241,"check":[189,192],"checklist":189,"choos":193,"citat":271,"ckpt":[261,262],"cla":245,"class":[0,1,3,4,6,8,14,15,17,19,20,23,24,25,28,29,30,34,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,68,69,70,71,72,73,74,76,77,78,79,80,81,83,84,85,86,88,89,90,91,94,95,96,97,98,99,100,102,103,104,105,106,107,108,109,110,111,112,114,115,118,120,121,122,123,125,130,131,133,135,136,137,138,143,145,148,149,152,153,154,155,156,157,158,161,162,164,165,166,167,168,175,179,182],"client":[192,199,214],"clip":227,"code":[188,189,192,215,244,245,246,248,257,259,260,261,262,266],"command":[196,243,254,255,256,259,262,264,265,266],"comment":215,"common":[0,1,2,3,4,5,6,7,8,9,193,199,200,267],"commun":205,"compat":270,"compil":[260,261,262],"compon":196,"compressor":[187,205,246,248,257,259,260,261,262,263,266,268,270,277],"comput":270,"conduct":[188,189,244],"config":[30,34,157,175,209,212,266],"configur":[193,196],"constant":[4,117,182],"content":[0,1,3,4,6,7,8,14,15,17,19,20,23,24,25,28,29,30,32,33,34,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,68,69,70,71,72,73,74,76,77,78,79,80,81,83,84,85,86,88,89,90,91,94,95,96,97,98,99,100,102,103,104,105,106,107,108,109,110,111,112,114,115,116,118,120,121,122,123,125,128,129,130,131,133,135,136,137,138,140,141,143,144,145,147,148,149,151,152,153,154,155,156,157,158,160,161,162,164,165,166,167,168,169,171,173,174,175,177,178,179,180,181,182,183,185,196,205],"contribut":[189,245],"contributor":[188,189,245],"conv2d":23,"convent":215,"convert":256,"convert_add_to_biasadd":41,"convert_layout":42,"convert_leakyrelu":43,"convert_nan_to_random":44,"convert_placeholder_to_const":45,"core":[15,137,158,196],"coven":[188,189],"cpu":[226,229,240,242,243,247,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,270,276],"creat":[189,219,220,237,238,239,240],"criteria":189,"data":[118,193,223],"dataset":[222,224,226,228,229,246,247,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266],"debug":[219,220],"deepspe":234,"demo":[218,232],"dens":24,"depend":[240,248,253,260,261,262,263,264,266,276],"deploy":196,"depthwise_conv2d":25,"dequantize_cast_optim":39,"design":216,"detail":[248,257,259,260,261,262,266],"detect":196,"determin":203,"dev202242":257,"devic":[190,204,240,276],"diffus":228,"dilated_contract":46,"dlrm":245,"docker":270,"document":[187,205,277],"download":[219,220,256,259,260,261,262,263,264,265],"dpq":199,"driven":194,"dummi":223,"dummy_biasadd":47,"dynam":[191,274],"effici":199,"eleutherai":241,"enabl":[246,248,257,259,260,261,262,266],"enforc":188,"engin":270,"enhanc":275,"environ":[183,196,219,220,222,224,226,227,229,230,237,238,239,240,243,246,247,248,249,250,251,252,253,254,255,256,257,260,261,262,263,264,265,270],"evalu":[196,224,227,228,231,233,235,241,242,257,259,266],"event":[205,273],"exampl":[190,191,192,193,194,196,198,199,202,203,217,246,274,275,276],"except":129,"expanddims_optim":48,"export":[169,170,171],"export_hf":169,"extens":[229,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"face":235,"facebook":241,"falcon":241,"faster_rcnn_resnet50":260,"featur":269,"fetch_weight_from_reshap":49,"fid":228,"fine":196,"fix":[197,203],"fold_batch_norm":50,"fold_const":51,"folder":215,"format":[196,256,261,262],"fp16":194,"fp32":[253,258],"fp4":236,"fp8":[192,221,225],"framework":[197,205,270,275],"freeze_fake_qu":76,"freeze_valu":77,"frequent":267,"from":[196,205,270],"frozen":264,"full":273,"function":[0,1,7,8,23,24,25,28,29,30,32,33,34,36,55,56,58,116,118,121,122,123,128,130,136,138,140,141,144,147,148,149,151,153,155,160,162,166,168,169,171,173,174,175,177,178,179,180,181,183,185],"fundament":[274,275],"fuse_biasadd_add":52,"fuse_column_wise_mul":53,"fuse_conv_redundant_dequant":78,"fuse_conv_requant":79,"fuse_conv_with_math":54,"fuse_decomposed_bn":55,"fuse_decomposed_in":56,"fuse_gelu":57,"fuse_layer_norm":58,"fuse_matmul_redundant_dequant":80,"fuse_matmul_requant":81,"fuse_pad_with_conv":59,"fuse_pad_with_fp32_conv":60,"fuse_qdq_bn":94,"fuse_qdq_concatv2":95,"fuse_qdq_conv":96,"fuse_qdq_deconv":97,"fuse_qdq_in":98,"fuse_qdq_matmul":99,"fuse_qdq_pool":100,"fuse_reshape_transpos":61,"gaudi":268,"gener":[41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,227],"get":[191,192,193,194,195,198,199,202,205,214,218,235,258,269],"gpt":[237,238,241,257],"gptq":[155,199],"gpu":[229,240,243,248,249,250,251,252,253,256,259,260,261,262,263,264,265,266,270,276],"graph_bas":74,"graph_convert":37,"graph_cse_optim":62,"graph_rewrit":[38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90],"graph_transform_bas":112,"graph_util":91,"graphsag":248,"grappler_pass":63,"guidelin":189,"habana":192,"half_precision_convert":131,"half_precision_rewrit":138,"hardwar":[194,270],"heterogen":270,"hf":[234,241],"high":196,"how":213,"hpu":[242,270],"hqq":[156,157,158,159,160,161,162,199],"hug":235,"imag":[227,270],"imagenet":[221,223],"import":215,"inc":[215,241,246],"infer":[228,232],"inform":[228,271],"insert_log":114,"insert_print_nod":65,"insert_qdq_pattern":88,"instal":[192,205,219,220,229,234,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266,270],"instruct":[234,241],"int4":241,"int8":[76,77,78,79,80,81,82,83,84,85,86,241,253,258],"intel":[187,205,229,243,246,248,249,250,251,252,253,256,257,259,260,261,262,263,264,265,266,268,270,276,277],"intel_extension_for_pytorch":270,"interfac":215,"intern":215,"introduct":[190,191,192,193,194,195,197,198,199,200,202,203,204,214,274,275,276],"ipex":[198,229,274],"issu":[193,196,245,267],"itex":[248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"j":[237,238,241,257],"jax":[11,12,190],"json":215,"kei":[193,196],"kera":[19,22,23,24,25,26,27,28,29,30,31],"kv":192,"languag":272,"larg":272,"layer":[23,24,25,26,27,28,29,199],"layer_initi":27,"layer_wis":[127,128,129,130],"legal":271,"level":196,"licens":[245,271],"like":[200,276],"limit":[274,275],"line":196,"llama":[232,234,241],"llama2":[237,238],"llama3":232,"llm":[192,241,272],"load":[128,199,200,219,220],"logger":[6,215],"lt":259,"main":196,"mandatori":[248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"manual":[256,260,261,262,263,266],"map":268,"mask_rcnn_inception_v2":261,"matmul":[274,275],"matrix":[192,194,197,199,200,204,269,275],"mechan":195,"medium":241,"memori":196,"merge_duplicated_qdq":89,"meta":[234,241],"meta_op_optim":83,"microsc":193,"microsoft":241,"mini":241,"mistral":241,"mistralai":241,"mix":[193,194,204,232],"mixed_precis":[131,132,133],"mixedprecis":222,"mme":270,"model":[120,198,213,218,219,220,224,226,228,230,231,233,236,241,242,246,247,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266,272],"model_wrapp":121,"modified_pickl":129,"modul":[0,1,3,4,6,7,8,14,15,17,19,20,23,24,25,28,29,30,32,33,34,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,68,69,70,71,72,73,74,76,77,78,79,80,81,83,84,85,86,88,89,90,91,94,95,96,97,98,99,100,102,103,104,105,106,107,108,109,110,111,112,114,115,116,118,120,121,122,123,125,128,129,130,131,133,135,136,137,138,140,141,143,144,145,147,148,149,151,152,153,154,155,156,157,158,160,161,162,164,165,166,167,168,169,171,173,174,175,177,178,179,180,181,182,183,185,196,219,220],"module_wrapp":133,"move_squeeze_after_relu":66,"multipl":193,"mx":[135,193,236],"mx_quant":[134,135,136],"mxfp":232,"mxfp4":[193,196,232],"mxfp8":[193,225,232],"neural":[187,205,246,248,257,259,260,261,262,263,266,268,270,277],"neural_compressor":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,192],"new":205,"nvfp4":[195,232],"one":218,"onli":[199,241,242,274],"opt":[237,238,239,241],"optim":160,"optimize_qdq":102,"optimum":192,"option":[248,249,250,251,252,253,256,259,260,261,262,263,264,265,266],"other":[264,270],"our":[188,275],"overview":[189,192,196,213],"packag":[248,253,260,261,262,263,264,266,276],"paramet":[192,193,196],"part":[257,259,266],"pb":[261,262,264],"per":[274,275],"perform":[196,239,240,257,258],"phi":241,"platform":270,"pledg":188,"polici":201,"pool2d":28,"post":[190,204],"post_hostconst_convert":84,"post_quantized_op_cs":85,"practic":[193,196],"pre":[228,235,249,250,251,252,265],"pre_optim":67,"precis":[193,194,204],"prepar":[222,224,226,229,230,246,247,248,249,250,251,252,253,254,255,256,257,259,260,261,262,263,264,265,266,276],"prepare_qat":196,"prerequisit":[222,224,225,226,227,229,230,232,237,238,239,240,241,242,243,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,270],"pretrain":[226,246,247,253,254,255,256,257,259,266],"problem":200,"process":264,"processor":270,"profil":192,"prompt":[231,233],"protocol":[260,261,262],"pt2e":198,"pt2e_export":171,"pt2e_quant":[137,138,139,140,141],"public":[205,215,273],"pull":[189,245],"py":196,"pypi":205,"pytorch":[193,194,196,197,198,199,210,211,212,213,217,229,274],"q_dataload":259,"qat":[142,143,144,145,196,235],"qattrain":196,"qdq":[87,88,89,90,94,95,96,97,98,99,100,101,102],"qtensor":161,"quant":[203,258,275],"quant_linear":143,"quant_util":144,"quantiz":[30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,162,173,174,175,176,177,178,190,191,192,193,195,196,197,198,199,200,202,204,207,208,209,210,211,212,214,217,218,219,220,221,223,224,228,230,231,232,233,235,237,238,239,240,241,242,243,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,272,274,275],"quantizaiton":[221,223],"quantize_graph":[93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109],"quantize_graph_bas":103,"quantize_graph_bn":104,"quantize_graph_common":110,"quantize_graph_concatv2":105,"quantize_graph_conv":106,"quantize_graph_for_intel_cpu":107,"quantize_graph_matmul":108,"quantize_graph_pool":109,"quantlinear":196,"question":267,"quick":[196,269],"qwen":241,"qwen2":241,"recip":[232,241,272],"recommend":[196,215],"record":256,"refer":[193,195,196,199,215,274,275],"remove_training_nod":68,"rename_batch_norm":69,"replac":196,"report":201,"request":[189,194,245],"requir":[221,223,231,232,233,254,255,265,270],"requisit":[228,235],"rerange_quantized_concat":115,"resnet18":229,"resnet50":229,"resnext101_32x16d":229,"respons":188,"result":227,"right":193,"rtn":[165,199],"rule":[197,198,199,202,215],"run":[192,222,224,225,226,227,229,230,234,236,237,238,239,240,241,242,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266],"sampl":[198,269],"save":[199,219,220],"save_load":[7,140,147,151,166],"save_load_entri":178,"scale":195,"scale_propag":86,"scaler":17,"scheme":[196,204,274],"scope":188,"script":232,"section":[187,277],"secur":201,"select":205,"separable_conv2d":29,"server":192,"set":[215,243,265],"setup":196,"share_qdq_y_pattern":90,"side":199,"smooth":[197,203,204,257,258,274,275],"smooth_quant":[146,147,148,149],"smoother":[14,15,16,17],"smoothquant":275,"softwar":[194,268,270],"solut":193,"some":[219,220],"sourc":270,"specif":196,"specifi":[197,198,199,202],"split_shared_input":70,"ssd_mobilenet_v1":262,"stabl":228,"stack":268,"standard":188,"start":[191,192,193,194,195,196,198,199,202,205,214,235,269],"static":[190,198,204,274],"static_qu":[18,19,20,150,151,152,153],"statu":[189,242],"step":[189,218,222,224,225,226,227,229,230,232,234,235,237,238,239,240,241,243,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,264,265,266],"string":215,"strip_equivalent_nod":71,"strip_unused_nod":72,"structur":215,"style":[245,266],"submodul":[2,5,10,12,13,16,18,21,22,26,31,35,40,64,75,82,87,92,93,101,113,119,124,126,127,132,134,139,142,146,150,159,163,170,172,176,184],"support":[189,192,194,197,199,200,204,242,270,275,276],"switch_optim":73,"symmetr":274,"system":270,"target":193,"target_bit":232,"templat":189,"tensor":[274,275],"tensor_quant":145,"tensorflow":[13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,202,204,207,208,209,213,217,248,249,250,251,252,253,256,257,259,260,261,262,263,264,265,266,270,274],"tensorquant":196,"teq":[167,199],"test":[192,231,233],"tf":256,"through":203,"thudm":241,"tiiuae":241,"tip":193,"todo":215,"torch":[123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,200,270],"tpc":270,"trademark":271,"train":[190,196,204,235,249,250,251,252,265,274],"trainer":196,"transfer":266,"transform":[259,276],"transform_graph":[111,112,113,114,115],"troubleshoot":196,"tune":[196,202,203,246,257,259,274,275],"tuning_param":3,"two":[218,270],"type":[193,215],"understand":195,"unvfp4":232,"up2":[250,251,252],"updat":[246,248,257,259,260,261,262,266],"us":[203,223,270],"usag":[193,197,198,199,203,218,276],"user":[248,257,260,261,262,266],"util":[4,5,6,7,8,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,130,136,141,149,153,168,179,180,181,182,183,184,185],"v":215,"v0":241,"valid":[241,270],"version":[9,186,268],"vllm":192,"vulner":201,"weight":[199,241,242,274],"weight_onli":[154,155,156,157,158,159,160,161,162,163,164,165,166,167,168],"what":205,"why":196,"wise":199,"without":202,"woq":236,"work":213,"workflow":[196,216],"xe":270}})