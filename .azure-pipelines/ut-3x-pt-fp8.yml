trigger: none

pr:
  autoCancel: true
  drafts: false
  branches:
    include:
      - master
  paths:
    include:
      - .azure-pipelines/scripts/ut/run_3x_pt_fp8.sh
      - .azure-pipelines/scripts/install_nc.sh
      - .azure-pipelines/ut-3x-pt-fp8.yml
      - .azure-pipelines/template/docker-template.yml
      - .azure-pipelines/scripts/ut/coverage.3x_pt_fp8
      - neural_compressor/common
      - neural_compressor/torch
      - neural_compressor/transformers
      - test/torch/algorithms/fp8_quant
      - test/torch/quantization/fp8_quant
      - test/torch/quantization/weight_only/test_rtn.py
      - test/torch/quantization/weight_only/test_load.py
      - setup.py
      - requirements_pt.txt

pool: GAUDI

variables:
  IMAGE_NAME: "neural-compressor"
  IMAGE_TAG: "py310"
  UPLOAD_PATH: $(Build.SourcesDirectory)/log_dir
  DOWNLOAD_PATH: $(Build.SourcesDirectory)/log_dir
  ARTIFACT_NAME: "UT_coverage_report_3x_pt_fp8"
  REPO: $(Build.Repository.Uri)

stages:
  - stage: Torch_habana
    displayName: Torch 3x Habana FP8
    dependsOn: []
    jobs:
      - job:
        displayName: Torch 3x Habana FP8
        timeoutInMinutes: 120
        steps:
          - template: template/ut-template.yml
            parameters:
              imageSource: "pull"
              dockerConfigName: "commonDockerConfig"
              utScriptFileName: "run_3x_pt_fp8"
              uploadPath: $(UPLOAD_PATH)
              utArtifact: "ut_3x"

  - stage: Torch_habana_baseline
    displayName: Torch 3x Habana FP8 baseline
    dependsOn: []
    jobs:
      - job:
        displayName: Torch 3x Habana FP8 baseline
        timeoutInMinutes: 120
        steps:
          - template: template/ut-template.yml
            parameters:
              imageSource: "pull"
              dockerConfigName: "gitCloneDockerConfig"
              utScriptFileName: "run_3x_pt_fp8"
              uploadPath: $(UPLOAD_PATH)
              utArtifact: "ut_3x_baseline"

  - stage: Coverage
    displayName: "Coverage Compare"
    pool:
      vmImage: "ubuntu-latest"
    dependsOn: [Torch_habana, Torch_habana_baseline]
    jobs:
      - job: CollectDatafiles
        steps:
          - task: DownloadPipelineArtifact@2
            inputs:
              artifact:
              patterns: '*_coverage/.coverage'
              path: $(DOWNLOAD_PATH)

          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.12'
            displayName: 'Use Python 3.12'

          - script: |
              cd ${BUILD_SOURCESDIRECTORY}
              pip install -U pip setuptools
              python setup.py install pt
              cd ${BUILD_SOURCESDIRECTORY}/.azure-pipelines/scripts
              bash ut/collect_log_3x.sh 3x_pt_fp8
            displayName: "Collect UT Coverage"

          - task: PublishCodeCoverageResults@2
            inputs:
              summaryFileLocation: $(Build.SourcesDirectory)/log_dir/coverage_PR/coverage.xml

          - task: PublishPipelineArtifact@1
            condition: succeededOrFailed()
            inputs:
              targetPath: $(UPLOAD_PATH)
              artifact: $(ARTIFACT_NAME)
              publishLocation: "pipeline"
