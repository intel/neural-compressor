neural_compressor.torch.utils.utility
=====================================

.. py:module:: neural_compressor.torch.utils.utility

.. autoapi-nested-parse::

   Intel Neural Compressor PyTorch utilities.



Functions
---------

.. autoapisummary::

   neural_compressor.torch.utils.utility.register_algo
   neural_compressor.torch.utils.utility.fetch_module
   neural_compressor.torch.utils.utility.set_module
   neural_compressor.torch.utils.utility.get_model_info
   neural_compressor.torch.utils.utility.get_double_quant_config_dict
   neural_compressor.torch.utils.utility.get_quantizer
   neural_compressor.torch.utils.utility.postprocess_model
   neural_compressor.torch.utils.utility.dump_model_op_stats
   neural_compressor.torch.utils.utility.get_model_device
   neural_compressor.torch.utils.utility.get_processor_type_from_user_config
   neural_compressor.torch.utils.utility.dowload_hf_model
   neural_compressor.torch.utils.utility.load_empty_model
   neural_compressor.torch.utils.utility.get_module
   neural_compressor.torch.utils.utility.get_layer_names_in_block
   neural_compressor.torch.utils.utility.to_dtype
   neural_compressor.torch.utils.utility.to_device
   neural_compressor.torch.utils.utility.get_block_names
   neural_compressor.torch.utils.utility.validate_modules
   neural_compressor.torch.utils.utility.get_multimodal_block_names
   neural_compressor.torch.utils.utility.detect_device
   neural_compressor.torch.utils.utility.find_matching_blocks
   neural_compressor.torch.utils.utility.get_non_persistent_buffers
   neural_compressor.torch.utils.utility.load_non_persistent_buffers
   neural_compressor.torch.utils.utility.move_input_device
   neural_compressor.torch.utils.utility.forward_wrapper


Module Contents
---------------

.. py:function:: register_algo(name)

   Decorator function to register algorithms in the algos_mapping dictionary.

   Usage example:
       @register_algo(name=example_algo)
       def example_algo(model: torch.nn.Module, quant_config: RTNConfig) -> torch.nn.Module:
           ...

   :param name: The name under which the algorithm function will be registered.
   :type name: str

   :returns: The decorator function to be used with algorithm functions.
   :rtype: decorator


.. py:function:: fetch_module(model, op_name)

   Get module with a given op name.

   :param model: the input model.
   :type model: object
   :param op_name: name of op.
   :type op_name: str

   :returns: module (object).


.. py:function:: set_module(model, op_name, new_module)

   Set module with a given op name.

   :param model: the input model.
   :type model: object
   :param op_name: name of op.
   :type op_name: str
   :param new_module: the input model.
   :type new_module: object

   :returns: module (object).


.. py:function:: get_model_info(model: torch.nn.Module, white_module_list: List[Callable]) -> List[Tuple[str, str]]

   Get model info according to white_module_list.


.. py:function:: get_double_quant_config_dict(double_quant_type='BNB_NF4')

   Query config dict of double_quant according to double_quant_type.

   :param double_quant_type: double_quant type. Defaults to "BNB_NF4".
   :type double_quant_type: str, optional


.. py:function:: get_quantizer(model, quantizer_cls, quant_config=None, *args, **kwargs)

   Get the quantizer.

   Initialize a quantizer or get `quantizer` attribute from model.

   :param model: pytorch model.
   :type model: torch.nn.Module
   :param quantizer_cls: quantizer class of a specific algorithm.
   :type quantizer_cls: Quantizer
   :param quant_config: Specifies how to apply the algorithm on the given model.
                        Defaults to None.
   :type quant_config: dict, optional

   :returns: quantizer object.


.. py:function:: postprocess_model(model, mode, quantizer)

   Process `quantizer` attribute of model according to current phase.

   In `prepare` phase, the `quantizer` is set as an attribute of the model
   to avoid redundant initialization during `convert` phase.

   In 'convert' or 'quantize' phase, the unused `quantizer` attribute is removed.

   :param model: pytorch model.
   :type model: torch.nn.Module
   :param mode: The mode of current phase, including 'prepare', 'convert' and 'quantize'.
   :type mode: Mode
   :param quantizer: quantizer object.
   :type quantizer: Quantizer


.. py:function:: dump_model_op_stats(mode, tune_cfg)

   Dump quantizable ops stats of model to user.

   :param mode: quantization mode.
   :type mode: object
   :param tune_cfg: quantization config
   :type tune_cfg: dict


.. py:function:: get_model_device(model: torch.nn.Module)

   Get the device.

   :param model: the input model.
   :type model: torch.nn.Module

   :returns: a string.
   :rtype: device (str)


.. py:function:: get_processor_type_from_user_config(user_processor_type: Optional[Union[str, neural_compressor.common.utils.ProcessorType]] = None)

   Get the processor type.

   Get the processor type based on the user configuration or automatically detect it based on the hardware.

   :param user_processor_type: The user-specified processor type. Defaults to None.
   :type user_processor_type: Optional[Union[str, ProcessorType]]

   :returns: The detected or user-specified processor type.
   :rtype: ProcessorType

   :raises AssertionError: If the user-specified processor type is not supported.
   :raises NotImplementedError: If the processor type is not recognized.


.. py:function:: dowload_hf_model(repo_id, cache_dir=None, repo_type=None, revision=None)

   Download hugging face model from hf hub.


.. py:function:: load_empty_model(pretrained_model_name_or_path, cls=None, **kwargs)

   Load a empty model.


.. py:function:: get_module(module, key)

   Get module from model by key name.

   :param module: original model
   :type module: torch.nn.Module
   :param key: module name to be replaced
   :type key: str


.. py:function:: get_layer_names_in_block(model, supported_types=SUPPORTED_LAYERS, to_quant_block_names=None)

   Retrieves the names of layers within each block of the model.

   :returns:

             A list of strings, where each string is the name of a layer
                   within a block of the model.
   :rtype: list


.. py:function:: to_dtype(input, dtype=torch.float32)

   Moves input data to the specified data type.

   Args:
   input: The input data to be moved.
   dtype: The target data type.

   Returns:
   The input data on the specified data type.


.. py:function:: to_device(input, device=torch.device('cpu'))

   Moves input data to the specified device.

   Args:
   input: The input data to be moved.
   device: The target device.

   Returns:
   The input data on the specified device.


.. py:function:: get_block_names(model)

   Get the block names for transformers-like networks.

   Args:
   model: The model.

   Returns:
   block_names: A list whose elements are list of block's layer names


.. py:function:: validate_modules(module_names)

   Test a list of modules' validity.

   Args:
   modules (list of str): List of strings to be validated.

   Returns:
   bool: True if all modules have equal length or not dependent, otherwise False.


.. py:function:: get_multimodal_block_names(model, quant_vision=False)

   Get the multimodal model block names for transformers-like networks.

   Args:
   model: The model.

   Returns:
   block_names: A list whose elements are list of block's layer names


.. py:function:: detect_device(device=None)

   Detects the device to use for model execution (GPU, HPU, or CPU).

   :param device:
                  - If a string ('cuda', 'cpu', or 'hpu') or torch.device is provided, that device is selected.
                  - If an integer is provided, it treats it as a GPU device index.
                  - If None or 'auto', it automatically selects 'cuda' if available, 'hpu' if Habana is available,
                    or falls back to 'cpu'.
   :type device: str, int, torch.device, optional

   :returns: The selected device in string format ('cuda:X', 'hpu', or 'cpu').
   :rtype: str


.. py:function:: find_matching_blocks(model, all_blocks, to_quant_block_names=None)

   Find and return matching blocks in the model based on to_quant_block_names.

   :param model: The model (not used in this specific function but kept for completeness).
   :param all_blocks: List of lists, where each inner list contains full block names in the model.
   :param to_quant_block_names: Comma-separated string of target block names to match.

   :returns: List of lists containing full paths of matching blocks in the model.
   :rtype: target_blocks


.. py:function:: get_non_persistent_buffers(model)

   Get all non-persistent buffers in the model.

   :param model: PyTorch model
   :type model: torch.nn.Module

   :returns: A dictionary containing all non-persistent buffers, {buffer_names: buffer_tensors}
   :rtype: dict


.. py:function:: load_non_persistent_buffers(model, non_persistent_buffers)

   Load all non-persistent buffers into the model.

   :param model: PyTorch model
   :type model: torch.nn.Module
   :param non_persistent_buffers: A dictionary containing all non-persistent buffers, {buffer_names: buffer_tensors}
   :type non_persistent_buffers: dict


.. py:function:: move_input_device(input, device='cpu')

   Auto mapping input to device for all kinds of format.

   :param input: input data
   :type input: torch.tensor
   :param device: target device. Defaults to "cpu".
   :type device: str, optional

   :returns: input data on target device
   :rtype: input (torch.tensor)


.. py:function:: forward_wrapper(model, input)

   Model forward with device auto mapping.

   :param model: input model
   :type model: torch.nn.Module
   :param input: input data
   :type input: torch.tensor

   :returns: output data
   :rtype: output


