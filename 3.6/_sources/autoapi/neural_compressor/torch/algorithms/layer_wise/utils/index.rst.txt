neural_compressor.torch.algorithms.layer_wise.utils
===================================================

.. py:module:: neural_compressor.torch.algorithms.layer_wise.utils

.. autoapi-nested-parse::

   Utils for layer wise quantization.



Classes
-------

.. autoapisummary::

   neural_compressor.torch.algorithms.layer_wise.utils.QDQLayer


Functions
---------

.. autoapisummary::

   neural_compressor.torch.algorithms.layer_wise.utils.get_module
   neural_compressor.torch.algorithms.layer_wise.utils.get_children
   neural_compressor.torch.algorithms.layer_wise.utils.get_named_children
   neural_compressor.torch.algorithms.layer_wise.utils.get_super_module_by_name
   neural_compressor.torch.algorithms.layer_wise.utils.update_module
   neural_compressor.torch.algorithms.layer_wise.utils.load_layer_wise_quantized_model
   neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_shard
   neural_compressor.torch.algorithms.layer_wise.utils.load_tensor
   neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_safetensors
   neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_safetensors_shard
   neural_compressor.torch.algorithms.layer_wise.utils.load_value
   neural_compressor.torch.algorithms.layer_wise.utils.load_module
   neural_compressor.torch.algorithms.layer_wise.utils.load_first_layer_only
   neural_compressor.torch.algorithms.layer_wise.utils.register_weight_hooks
   neural_compressor.torch.algorithms.layer_wise.utils.clean_module_weight
   neural_compressor.torch.algorithms.layer_wise.utils.save_layers_in_shards_iteratively
   neural_compressor.torch.algorithms.layer_wise.utils.load_model_from_shards_with_safetensors


Module Contents
---------------

.. py:class:: QDQLayer(module, input_scale=None)



   Quantized and Dequantized Layer.


.. py:function:: get_module(model, key)

   Get module from model by key name.

   :param model: original model
   :type model: torch.nn.Module
   :param key: module name to be replaced
   :type key: str


.. py:function:: get_children(model)

   Get all the children of given model.


.. py:function:: get_named_children(model, pre=[])

   Get all the name and children of given model.


.. py:function:: get_super_module_by_name(model, module_name)

   Get the father module with given name of child module.


.. py:function:: update_module(model, module_name, new_module)

   Update module.


.. py:function:: load_layer_wise_quantized_model(path)

   Load layer wise quantized model.


.. py:function:: load_tensor_from_shard(pretrained_model_name_or_path, tensor_name, prefix=None)

   Load tensor from shard.


.. py:function:: load_tensor(path, tensor_name=None, prefix=None)

   Load a tensor from bin file with given tensor name.


.. py:function:: load_tensor_from_safetensors(path, tensor_name=None, prefix=None, device='cpu')

   Load a tensor from safetensors file with given tensor name.


.. py:function:: load_tensor_from_safetensors_shard(pretrained_model_name_or_path, tensor_name, prefix=None, device='cpu')

   Load tensor from shard.


.. py:function:: load_value(model, param_name, path, device='cpu')

   Load the module value.

   :param model: torch model.
   :type model: torch.nn.module
   :param param_name: module name.
   :type param_name: str
   :param path: path to load state_dict per layer.
   :type path: str
   :param device: module device. Defaults to "cpu".
   :type device: str, optional

   :returns: the module value.
   :rtype: tensor


.. py:function:: load_module(model, module_name, path, device='cpu')

   Load all named parameters of module.

   :param model: torch model.
   :type model: torch.nn.module
   :param module_name: module name.
   :type module_name: str
   :param path: path to load state_dict per layer.
   :type path: str
   :param device: module device. Defaults to "cpu".
   :type device: str, optional


.. py:function:: load_first_layer_only(user_model, model_name)

   Load first layer only.

   :param user_model: input model
   :type user_model: torch.nn.Module
   :param model_name: model name or path
   :type model_name: str


.. py:function:: register_weight_hooks(model, path, device='cpu', clean_weight=True, saved_path=None, indicated_layers=None)

   Register weight hooks for model.

   :param model: torch model.
   :type model: torch.nn.module
   :param path: path to load state_dict per layer.
   :type path: str
   :param device: module device. Defaults to "cpu".
   :type device: str, optional
   :param clean_weight: to clean model weight. Defaults to True.
   :type clean_weight: bool, optional
   :param saved_path: path to save module weight. Defaults to None.
   :type saved_path: str, optional

   :returns: handlers.
   :rtype: list


.. py:function:: clean_module_weight(module)

   Clean module weight.


.. py:function:: save_layers_in_shards_iteratively(checkpoint_dir, output_dir, layers_per_shard=10)

   Save model layers iteratively in shards, each shard containing a fixed number of layers using safetensors.


.. py:function:: load_model_from_shards_with_safetensors(shard_dir, bin_index_file)

   Load the model from its shards and the bin index using safetensors.

   :param shard_dir: Directory containing the model shard files.
   :type shard_dir: str
   :param bin_index_file: Path to the bin index JSON file.
   :type bin_index_file: str

   :returns: The reconstructed model with the layers.
   :rtype: torch.nn.Module


