#
# Copyright (c) 2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

version: 1.0                                         # optional. reserved for future use. if not specified, a supported version would be written back to user yaml.

model:                                               # mandatory. used to specify model specific information.
  name: ssd_mobilenet_v1
  framework: tensorflow                              # mandatory. supported values are tensorflow, pytorch, pytorch_fx, pytorch_ipex, onnxrt_integer, onnxrt_qlinear or mxnet; allow new framework backend extension.
  inputs: image_tensor                               # optional. inputs and outputs fields are only required in tensorflow.
  outputs: num_detections,detection_boxes,detection_scores,detection_classes

device: cpu                                          # optional. default value is cpu. other value is gpu.

graph_optimization:                                  # optional. tuning constraints on model-wise for advance user to reduce tuning space.
  precisions: fp32, bf16

  op_wise: {                                         # optional. tuning constraints on op-wise for advance user to reduce tuning space.
         'conv1': {
           'activation':  {'dtype': ['bf16']}
         },
         'pool1': {
           'activation': {'dtype': ['bf16']},
         },
         'conv2': {
           'activation':  {'dtype': ['fp32']},
         }
        }


evaluation:                                          # optional. used to config evaluation process.
  accuracy:                                          # optional. required if user doesn't provide eval_func in neural_compressor.Quantization.
    metric:                                          # optional. used to evaluate accuracy of passing model.
      topk: 1                                        # built-in metrics are topk, map, f1, allow user to register new metric.
    configs:                                         # optional. if not specified, use all cores in 1 socket.
      cores_per_instance: 28
      num_of_instance: 1
      inter_num_of_threads: 4
      intra_num_of_threads: 28
      kmp_blocktime: 1
    dataloader:                                      # optional. if not specified, user need construct a q_dataloader in code for neural_compressor.Quantization.
      batch_size: 256
      dataset:
        TFRecordDataset:
          root: /path/to/tf_record
      transform:
        Resize:
          size: 256
        CenterCrop:
          size: 224
  performance:                                       # optional. used to benchmark performance of passing model.
    warmup: 10
    iteration: 100
    configs:
      cores_per_instance: 4
      num_of_instance: 7
      inter_num_of_threads: 1
      intra_num_of_threads: 4
      kmp_blocktime: 1
    dataloader:
      dataset:
        dummy:
          shape: [[128, 3, 224, 224], [128, 1, 1, 1]]

tuning:
  strategy:
    name: basic                                      # optional. default value is basic. other values are bayesian, mse.
  accuracy_criterion:
    relative:  0.01                                  # optional. default value is relative, other value is absolute. this example allows relative accuracy loss: 1%.
  objective: performance                             # optional. objective with accuracy constraint guaranteed. default value is performance. other values are modelsize and footprint.

  exit_policy:
    timeout: 0                                       # optional. tuning timeout (seconds). default value is 0 which means early stop. combine with max_trials field to decide when to exit.
    max_trials: 100                                  # optional. max tune times. default value is 100. combine with timeout field to decide when to exit.
    performance_only: False                          # optional. max tune times. default value is False which means only generate fully quantized model.
  random_seed: 9527                                  # optional. random seed for deterministic tuning.
  tensorboard: True                                  # optional. dump tensor distribution in evaluation phase for debug purpose. default value is False.

  workspace:
    path: /path/to/saving/directory                  # optional. default workspace is ./nc_workspace/current_time_stamp, saving tuning history and deploy yaml.
    resume: /path/to/a/specified/snapshot/file       # optional. if specified, resume from tuning history.
