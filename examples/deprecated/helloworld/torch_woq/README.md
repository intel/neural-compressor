Applying Weight-Only Quantization to LLMs
=====================
This example demonstrates how to apply weight-only quantization on [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-v0.1).


### Setting up the environment 
```shell
pip install -r requirements.txt
```

### Running the Quantization Script

```shell
python quant_mistral.py
``` 
