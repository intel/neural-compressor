diff --git a/maskrcnn_benchmark/__init__.py b/maskrcnn_benchmark/__init__.py
index 5c7f19c..dcf712f 100644
--- a/maskrcnn_benchmark/__init__.py
+++ b/maskrcnn_benchmark/__init__.py
@@ -1 +1,14 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
diff --git a/maskrcnn_benchmark/config/__init__.py b/maskrcnn_benchmark/config/__init__.py
index 22a1502..340d155 100644
--- a/maskrcnn_benchmark/config/__init__.py
+++ b/maskrcnn_benchmark/config/__init__.py
@@ -1,2 +1,15 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .defaults import _C as cfg
diff --git a/maskrcnn_benchmark/config/defaults.py b/maskrcnn_benchmark/config/defaults.py
index 367337f..cdded58 100644
--- a/maskrcnn_benchmark/config/defaults.py
+++ b/maskrcnn_benchmark/config/defaults.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import os
 
@@ -10,9 +23,9 @@ from yacs.config import CfgNode as CN
 # Whenever an argument can be either used for training or for testing, the
 # corresponding name will be post-fixed by a _TRAIN for a training parameter,
 # or _TEST for a test-specific parameter.
-# For example, the maximum image side during training will be
-# INPUT.MAX_SIZE_TRAIN, while for testing it will be
-# INPUT.MAX_SIZE_TEST
+# For example, the number of images during training will be
+# IMAGES_PER_BATCH_TRAIN, while the number of images for testing will be
+# IMAGES_PER_BATCH_TEST
 
 # -----------------------------------------------------------------------------
 # Config definition
@@ -54,15 +67,6 @@ _C.INPUT.PIXEL_STD = [1., 1., 1.]
 # Convert image to BGR format (for Caffe2 models), in range 0-255
 _C.INPUT.TO_BGR255 = True
 
-# Image ColorJitter
-_C.INPUT.BRIGHTNESS = 0.0
-_C.INPUT.CONTRAST = 0.0
-_C.INPUT.SATURATION = 0.0
-_C.INPUT.HUE = 0.0
-
-# Flips
-_C.INPUT.HORIZONTAL_FLIP_PROB_TRAIN = 0.5
-_C.INPUT.VERTICAL_FLIP_PROB_TRAIN = 0.0
 
 # -----------------------------------------------------------------------------
 # Dataset
@@ -101,6 +105,9 @@ _C.MODEL.BACKBONE.CONV_BODY = "R-50-C4"
 
 # Add StopGrad at a specified stage so the bottom layers are frozen
 _C.MODEL.BACKBONE.FREEZE_CONV_BODY_AT = 2
+_C.MODEL.BACKBONE.OUT_CHANNELS = 256 * 4
+# GN for backbone
+_C.MODEL.BACKBONE.USE_GN = False
 
 
 # ---------------------------------------------------------------------------- #
@@ -166,9 +173,6 @@ _C.MODEL.RPN.MIN_SIZE = 0
 # all FPN levels
 _C.MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN = 2000
 _C.MODEL.RPN.FPN_POST_NMS_TOP_N_TEST = 2000
-# Apply the post NMS per batch (default) or per image during training
-# (default is True to be consistent with Detectron, see Issue #672)
-_C.MODEL.RPN.FPN_POST_NMS_PER_BATCH = True
 # Custom rpn head, empty to use default conv or separable conv
 _C.MODEL.RPN.RPN_HEAD = "SingleConvRPNHead"
 
@@ -280,14 +284,9 @@ _C.MODEL.RESNETS.STEM_FUNC = "StemWithFixedBatchNorm"
 # Apply dilation in stage "res5"
 _C.MODEL.RESNETS.RES5_DILATION = 1
 
-_C.MODEL.RESNETS.BACKBONE_OUT_CHANNELS = 256 * 4
 _C.MODEL.RESNETS.RES2_OUT_CHANNELS = 256
 _C.MODEL.RESNETS.STEM_OUT_CHANNELS = 64
 
-_C.MODEL.RESNETS.STAGE_WITH_DCN = (False, False, False, False)
-_C.MODEL.RESNETS.WITH_MODULATED_DCN = False
-_C.MODEL.RESNETS.DEFORMABLE_GROUPS = 1
-
 
 # ---------------------------------------------------------------------------- #
 # RetinaNet Options (Follow the Detectron version)
@@ -349,44 +348,6 @@ _C.MODEL.RETINANET.INFERENCE_TH = 0.05
 # NMS threshold used in RetinaNet
 _C.MODEL.RETINANET.NMS_TH = 0.4
 
-
-# ---------------------------------------------------------------------------- #
-# FBNet options
-# ---------------------------------------------------------------------------- #
-_C.MODEL.FBNET = CN()
-_C.MODEL.FBNET.ARCH = "default"
-# custom arch
-_C.MODEL.FBNET.ARCH_DEF = ""
-_C.MODEL.FBNET.BN_TYPE = "bn"
-_C.MODEL.FBNET.SCALE_FACTOR = 1.0
-# the output channels will be divisible by WIDTH_DIVISOR
-_C.MODEL.FBNET.WIDTH_DIVISOR = 1
-_C.MODEL.FBNET.DW_CONV_SKIP_BN = True
-_C.MODEL.FBNET.DW_CONV_SKIP_RELU = True
-
-# > 0 scale, == 0 skip, < 0 same dimension
-_C.MODEL.FBNET.DET_HEAD_LAST_SCALE = 1.0
-_C.MODEL.FBNET.DET_HEAD_BLOCKS = []
-# overwrite the stride for the head, 0 to use original value
-_C.MODEL.FBNET.DET_HEAD_STRIDE = 0
-
-# > 0 scale, == 0 skip, < 0 same dimension
-_C.MODEL.FBNET.KPTS_HEAD_LAST_SCALE = 0.0
-_C.MODEL.FBNET.KPTS_HEAD_BLOCKS = []
-# overwrite the stride for the head, 0 to use original value
-_C.MODEL.FBNET.KPTS_HEAD_STRIDE = 0
-
-# > 0 scale, == 0 skip, < 0 same dimension
-_C.MODEL.FBNET.MASK_HEAD_LAST_SCALE = 0.0
-_C.MODEL.FBNET.MASK_HEAD_BLOCKS = []
-# overwrite the stride for the head, 0 to use original value
-_C.MODEL.FBNET.MASK_HEAD_STRIDE = 0
-
-# 0 to use all blocks defined in arch_def
-_C.MODEL.FBNET.RPN_HEAD_BLOCKS = 0
-_C.MODEL.FBNET.RPN_BN_TYPE = ""
-
-
 # ---------------------------------------------------------------------------- #
 # Solver
 # ---------------------------------------------------------------------------- #
@@ -409,7 +370,6 @@ _C.SOLVER.WARMUP_ITERS = 500
 _C.SOLVER.WARMUP_METHOD = "linear"
 
 _C.SOLVER.CHECKPOINT_PERIOD = 2500
-_C.SOLVER.TEST_PERIOD = 0
 
 # Number of images per batch
 # This is global, so if we have 8 GPUs and IMS_PER_BATCH = 16, each GPU will
@@ -429,27 +389,6 @@ _C.TEST.IMS_PER_BATCH = 8
 # Number of detections per image
 _C.TEST.DETECTIONS_PER_IMG = 100
 
-# ---------------------------------------------------------------------------- #
-# Test-time augmentations for bounding box detection
-# See configs/test_time_aug/e2e_mask_rcnn_R-50-FPN_1x.yaml for an example
-# ---------------------------------------------------------------------------- #
-_C.TEST.BBOX_AUG = CN()
-
-# Enable test-time augmentation for bounding box detection if True
-_C.TEST.BBOX_AUG.ENABLED = False
-
-# Horizontal flip at the original scale (id transform)
-_C.TEST.BBOX_AUG.H_FLIP = False
-
-# Each scale is the pixel size of an image's shortest side
-_C.TEST.BBOX_AUG.SCALES = ()
-
-# Max pixel size of the longer side
-_C.TEST.BBOX_AUG.MAX_SIZE = 4000
-
-# Horizontal flip at each scale
-_C.TEST.BBOX_AUG.SCALE_H_FLIP = False
-
 
 # ---------------------------------------------------------------------------- #
 # Misc options
@@ -457,13 +396,14 @@ _C.TEST.BBOX_AUG.SCALE_H_FLIP = False
 _C.OUTPUT_DIR = "."
 
 _C.PATHS_CATALOG = os.path.join(os.path.dirname(__file__), "paths_catalog.py")
+_C.SAVE_CHECKPOINTS = False
+_C.PER_EPOCH_EVAL = True
 
 # ---------------------------------------------------------------------------- #
-# Precision options
+# MLPerf-specific options
 # ---------------------------------------------------------------------------- #
+_C.MLPERF = CN()
 
-# Precision of input, allowable: (float32, float16)
-_C.DTYPE = "float32"
-
-# Enable verbosity in apex.amp
-_C.AMP_VERBOSE = False
+# Accuracy targets for early termination
+_C.MLPERF.MIN_BBOX_MAP = 0.377
+_C.MLPERF.MIN_SEGM_MAP = 0.339
diff --git a/maskrcnn_benchmark/config/paths_catalog.py b/maskrcnn_benchmark/config/paths_catalog.py
index 49c061c..e06d5d1 100644
--- a/maskrcnn_benchmark/config/paths_catalog.py
+++ b/maskrcnn_benchmark/config/paths_catalog.py
@@ -1,8 +1,21 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """Centralized catalog of paths."""
 
 import os
-from copy import deepcopy
+
 
 class DatasetCatalog(object):
     DATA_DIR = "datasets"
@@ -33,19 +46,19 @@ class DatasetCatalog(object):
         },
         "keypoints_coco_2014_train": {
             "img_dir": "coco/train2014",
-            "ann_file": "coco/annotations/person_keypoints_train2014.json",
+            "ann_file": "annotations/person_keypoints_train2014.json",
         },
         "keypoints_coco_2014_val": {
             "img_dir": "coco/val2014",
-            "ann_file": "coco/annotations/person_keypoints_val2014.json"
+            "ann_file": "coco/annotations/instances_val2014.json"
         },
         "keypoints_coco_2014_minival": {
             "img_dir": "coco/val2014",
-            "ann_file": "coco/annotations/person_keypoints_minival2014.json",
+            "ann_file": "annotations/person_keypoints_minival2014.json",
         },
         "keypoints_coco_2014_valminusminival": {
             "img_dir": "coco/val2014",
-            "ann_file": "coco/annotations/person_keypoints_valminusminival2014.json",
+            "ann_file": "annotations/person_keypoints_valminusminival2014.json",
         },
         "voc_2007_train": {
             "data_dir": "voc/VOC2007",
@@ -92,9 +105,6 @@ class DatasetCatalog(object):
             "split": "test"
             # PASCAL VOC2012 doesn't made the test annotations available, so there's no json annotation
         },
-
-        ##############################################
-        # These ones are deprecated, should be removed
         "cityscapes_fine_instanceonly_seg_train_cocostyle": {
             "img_dir": "cityscapes/images",
             "ann_file": "cityscapes/annotations/instancesonly_filtered_gtFine_train.json"
@@ -106,47 +116,7 @@ class DatasetCatalog(object):
         "cityscapes_fine_instanceonly_seg_test_cocostyle": {
             "img_dir": "cityscapes/images",
             "ann_file": "cityscapes/annotations/instancesonly_filtered_gtFine_test.json"
-        },
-        ##############################################
-
-        "cityscapes_poly_instance_train": {
-            "img_dir": "cityscapes/leftImg8bit/",
-            "ann_dir": "cityscapes/gtFine/",
-            "split": "train",
-            "mode": "poly",
-        },
-        "cityscapes_poly_instance_val": {
-            "img_dir": "cityscapes/leftImg8bit",
-            "ann_dir": "cityscapes/gtFine",
-            "split": "val",
-            "mode": "poly",
-        },
-        "cityscapes_poly_instance_minival": {
-            "img_dir": "cityscapes/leftImg8bit",
-            "ann_dir": "cityscapes/gtFine",
-            "split": "val",
-            "mode": "poly",
-            "mini": 10,
-        },
-        "cityscapes_mask_instance_train": {
-            "img_dir": "cityscapes/leftImg8bit/",
-            "ann_dir": "cityscapes/gtFine/",
-            "split": "train",
-            "mode": "mask",
-        },
-        "cityscapes_mask_instance_val": {
-            "img_dir": "cityscapes/leftImg8bit",
-            "ann_dir": "cityscapes/gtFine",
-            "split": "val",
-            "mode": "mask",
-        },
-        "cityscapes_mask_instance_minival": {
-            "img_dir": "cityscapes/leftImg8bit",
-            "ann_dir": "cityscapes/gtFine",
-            "split": "val",
-            "mode": "mask",
-            "mini": 10,
-        },
+        }
     }
 
     @staticmethod
@@ -173,12 +143,6 @@ class DatasetCatalog(object):
                 factory="PascalVOCDataset",
                 args=args,
             )
-        elif "cityscapes" in name:
-            data_dir = DatasetCatalog.DATA_DIR
-            attrs = deepcopy(DatasetCatalog.DATASETS[name])
-            attrs["img_dir"] = os.path.join(data_dir, attrs["img_dir"])
-            attrs["ann_dir"] = os.path.join(data_dir, attrs["ann_dir"])
-            return dict(factory="CityScapesDataset", args=attrs)
         raise RuntimeError("Dataset not available: {}".format(name))
 
 
diff --git a/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp b/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp
index d531da6..d35aedf 100644
--- a/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp
+++ b/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp
@@ -91,7 +91,7 @@ void pre_calc_for_bilinear_interpolate(
           T hy = 1. - ly, hx = 1. - lx;
           T w1 = hy * hx, w2 = hy * lx, w3 = ly * hx, w4 = ly * lx;
 
-          // save weights and indices
+          // save weights and indeces
           PreCalc<T> pc;
           pc.pos1 = y_low * width + x_low;
           pc.pos2 = y_low * width + x_high;
@@ -168,8 +168,8 @@ void ROIAlignForward_cpu_kernel(
     // We do average (integral) pooling inside a bin
     const T count = roi_bin_grid_h * roi_bin_grid_w; // e.g. = 4
 
-    // we want to precalculate indices and weights shared by all channels,
-    // this is the key point of optimization
+    // we want to precalculate indeces and weights shared by all chanels,
+    // this is the key point of optimiation
     std::vector<PreCalc<T>> pre_calc(
         roi_bin_grid_h * roi_bin_grid_w * pooled_width * pooled_height);
     pre_calc_for_bilinear_interpolate(
diff --git a/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu b/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu
index 456a5f2..7d40767 100644
--- a/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu
+++ b/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu
@@ -117,8 +117,7 @@ at::Tensor SigmoidFocalLoss_forward_cuda(
   auto losses_size = num_samples * logits.size(1);
   cudaStream_t stream = at::cuda::getCurrentCUDAStream();
 
-  dim3 grid(std::min(THCCeilDiv((long)losses_size, 512L), 4096L));
-  
+  dim3 grid(std::min(THCCeilDiv(losses_size, 512L), 4096L));
   dim3 block(512);
 
   if (losses.numel() == 0) {
@@ -162,7 +161,7 @@ at::Tensor SigmoidFocalLoss_backward_cuda(
   auto d_logits_size = num_samples * logits.size(1);
   cudaStream_t stream = at::cuda::getCurrentCUDAStream();
 
-  dim3 grid(std::min(THCCeilDiv((long)d_logits_size, 512L), 4096L));
+  dim3 grid(std::min(THCCeilDiv(d_logits_size, 512L), 4096L));
   dim3 block(512);
 
   if (d_logits.numel() == 0) {
diff --git a/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.cu b/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.cu
deleted file mode 100644
index 74f7d33..0000000
--- a/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.cu
+++ /dev/null
@@ -1,691 +0,0 @@
-// modify from
-// https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/blob/mmdetection/mmdet/ops/dcn/src/deform_conv_cuda.c
-
-#include <ATen/ATen.h>
-#include <ATen/cuda/CUDAContext.h>
-
-#include <THC/THC.h>
-#include <THC/THCDeviceUtils.cuh>
-
-#include <vector>
-#include <iostream>
-#include <cmath>
-
-
-void deformable_im2col(const at::Tensor data_im, const at::Tensor data_offset,
-                       const int channels, const int height, const int width,
-                       const int ksize_h, const int ksize_w, const int pad_h,
-                       const int pad_w, const int stride_h, const int stride_w,
-                       const int dilation_h, const int dilation_w,
-                       const int parallel_imgs, const int deformable_group,
-                       at::Tensor data_col);
-
-void deformable_col2im(const at::Tensor data_col, const at::Tensor data_offset,
-                       const int channels, const int height, const int width,
-                       const int ksize_h, const int ksize_w, const int pad_h,
-                       const int pad_w, const int stride_h, const int stride_w,
-                       const int dilation_h, const int dilation_w,
-                       const int parallel_imgs, const int deformable_group,
-                       at::Tensor grad_im);
-
-void deformable_col2im_coord(
-    const at::Tensor data_col, const at::Tensor data_im,
-    const at::Tensor data_offset, const int channels, const int height,
-    const int width, const int ksize_h, const int ksize_w, const int pad_h,
-    const int pad_w, const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w, const int parallel_imgs,
-    const int deformable_group, at::Tensor grad_offset);
-
-void modulated_deformable_im2col_cuda(
-    const at::Tensor data_im, const at::Tensor data_offset,
-    const at::Tensor data_mask, const int batch_size, const int channels,
-    const int height_im, const int width_im, const int height_col,
-    const int width_col, const int kernel_h, const int kenerl_w,
-    const int pad_h, const int pad_w, const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w, const int deformable_group,
-    at::Tensor data_col);
-
-void modulated_deformable_col2im_cuda(
-    const at::Tensor data_col, const at::Tensor data_offset,
-    const at::Tensor data_mask, const int batch_size, const int channels,
-    const int height_im, const int width_im, const int height_col,
-    const int width_col, const int kernel_h, const int kenerl_w,
-    const int pad_h, const int pad_w, const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w, const int deformable_group,
-    at::Tensor grad_im);
-
-void modulated_deformable_col2im_coord_cuda(
-    const at::Tensor data_col, const at::Tensor data_im,
-    const at::Tensor data_offset, const at::Tensor data_mask,
-    const int batch_size, const int channels, const int height_im,
-    const int width_im, const int height_col, const int width_col,
-    const int kernel_h, const int kenerl_w, const int pad_h, const int pad_w,
-    const int stride_h, const int stride_w, const int dilation_h,
-    const int dilation_w, const int deformable_group, at::Tensor grad_offset,
-    at::Tensor grad_mask);
-
-void shape_check(at::Tensor input, at::Tensor offset, at::Tensor *gradOutput,
-                 at::Tensor weight, int kH, int kW, int dH, int dW, int padH,
-                 int padW, int dilationH, int dilationW, int group,
-                 int deformable_group) 
-{
-  AT_CHECK(weight.ndimension() == 4,
-           "4D weight tensor (nOutputPlane,nInputPlane,kH,kW) expected, "
-           "but got: %s",
-           weight.ndimension());
-
-  AT_CHECK(weight.is_contiguous(), "weight tensor has to be contiguous");
-
-  AT_CHECK(kW > 0 && kH > 0,
-           "kernel size should be greater than zero, but got kH: %d kW: %d", kH,
-           kW);
-
-  AT_CHECK((weight.size(2) == kH && weight.size(3) == kW),
-           "kernel size should be consistent with weight, ",
-           "but got kH: %d kW: %d weight.size(2): %d, weight.size(3): %d", kH,
-           kW, weight.size(2), weight.size(3));
-
-  AT_CHECK(dW > 0 && dH > 0,
-           "stride should be greater than zero, but got dH: %d dW: %d", dH, dW);
-
-  AT_CHECK(
-      dilationW > 0 && dilationH > 0,
-      "dilation should be greater than 0, but got dilationH: %d dilationW: %d",
-      dilationH, dilationW);
-
-  int ndim = input.ndimension();
-  int dimf = 0;
-  int dimh = 1;
-  int dimw = 2;
-
-  if (ndim == 4) {
-    dimf++;
-    dimh++;
-    dimw++;
-  }
-
-  AT_CHECK(ndim == 3 || ndim == 4, "3D or 4D input tensor expected but got: %s",
-           ndim);
-
-  long nInputPlane = weight.size(1) * group;
-  long inputHeight = input.size(dimh);
-  long inputWidth = input.size(dimw);
-  long nOutputPlane = weight.size(0);
-  long outputHeight =
-      (inputHeight + 2 * padH - (dilationH * (kH - 1) + 1)) / dH + 1;
-  long outputWidth =
-      (inputWidth + 2 * padW - (dilationW * (kW - 1) + 1)) / dW + 1;
-
-  AT_CHECK(nInputPlane % deformable_group == 0,
-           "input channels must divide deformable group size");
-
-  if (outputWidth < 1 || outputHeight < 1)
-    AT_ERROR(
-        "Given input size: (%ld x %ld x %ld). "
-        "Calculated output size: (%ld x %ld x %ld). Output size is too small",
-        nInputPlane, inputHeight, inputWidth, nOutputPlane, outputHeight,
-        outputWidth);
-
-  AT_CHECK(input.size(1) == nInputPlane,
-           "invalid number of input planes, expected: %d, but got: %d",
-           nInputPlane, input.size(1));
-
-  AT_CHECK((inputHeight >= kH && inputWidth >= kW),
-           "input image is smaller than kernel");
-
-  AT_CHECK((offset.size(2) == outputHeight && offset.size(3) == outputWidth),
-           "invalid spatial size of offset, expected height: %d width: %d, but "
-           "got height: %d width: %d",
-           outputHeight, outputWidth, offset.size(2), offset.size(3));
-
-  AT_CHECK((offset.size(1) == deformable_group * 2 * kH * kW),
-           "invalid number of channels of offset");
-
-  if (gradOutput != NULL) {
-    AT_CHECK(gradOutput->size(dimf) == nOutputPlane,
-             "invalid number of gradOutput planes, expected: %d, but got: %d",
-             nOutputPlane, gradOutput->size(dimf));
-
-    AT_CHECK((gradOutput->size(dimh) == outputHeight &&
-              gradOutput->size(dimw) == outputWidth),
-             "invalid size of gradOutput, expected height: %d width: %d , but "
-             "got height: %d width: %d",
-             outputHeight, outputWidth, gradOutput->size(dimh),
-             gradOutput->size(dimw));
-  }
-}
-
-int deform_conv_forward_cuda(at::Tensor input, at::Tensor weight,
-                             at::Tensor offset, at::Tensor output,
-                             at::Tensor columns, at::Tensor ones, int kW,
-                             int kH, int dW, int dH, int padW, int padH,
-                             int dilationW, int dilationH, int group,
-                             int deformable_group, int im2col_step) 
-{
-  // todo: resize columns to include im2col: done
-  // todo: add im2col_step as input
-  // todo: add new output buffer and transpose it to output (or directly
-  // transpose output) todo: possibly change data indexing because of
-  // parallel_imgs
-
-  shape_check(input, offset, NULL, weight, kH, kW, dH, dW, padH, padW,
-              dilationH, dilationW, group, deformable_group);
-
-  input = input.contiguous();
-  offset = offset.contiguous();
-  weight = weight.contiguous();
-
-  int batch = 1;
-  if (input.ndimension() == 3) {
-    // Force batch
-    batch = 0;
-    input.unsqueeze_(0);
-    offset.unsqueeze_(0);
-  }
-
-  // todo: assert batchsize dividable by im2col_step
-
-  long batchSize = input.size(0);
-  long nInputPlane = input.size(1);
-  long inputHeight = input.size(2);
-  long inputWidth = input.size(3);
-
-  long nOutputPlane = weight.size(0);
-
-  long outputWidth =
-      (inputWidth + 2 * padW - (dilationW * (kW - 1) + 1)) / dW + 1;
-  long outputHeight =
-      (inputHeight + 2 * padH - (dilationH * (kH - 1) + 1)) / dH + 1;
-
-  AT_CHECK((offset.size(0) == batchSize), "invalid batch size of offset");
-
-  output = output.view({batchSize / im2col_step, im2col_step, nOutputPlane,
-                        outputHeight, outputWidth});
-  columns = at::zeros(
-      {nInputPlane * kW * kH, im2col_step * outputHeight * outputWidth},
-      input.options());
-
-  if (ones.ndimension() != 2 ||
-      ones.size(0) * ones.size(1) < outputHeight * outputWidth) {
-    ones = at::ones({outputHeight, outputWidth}, input.options());
-  }
-
-  input = input.view({batchSize / im2col_step, im2col_step, nInputPlane,
-                      inputHeight, inputWidth});
-  offset =
-      offset.view({batchSize / im2col_step, im2col_step,
-                   deformable_group * 2 * kH * kW, outputHeight, outputWidth});
-
-  at::Tensor output_buffer =
-      at::zeros({batchSize / im2col_step, nOutputPlane,
-                 im2col_step * outputHeight, outputWidth},
-                output.options());
-
-  output_buffer = output_buffer.view(
-      {output_buffer.size(0), group, output_buffer.size(1) / group,
-       output_buffer.size(2), output_buffer.size(3)});
-
-  for (int elt = 0; elt < batchSize / im2col_step; elt++) {
-    deformable_im2col(input[elt], offset[elt], nInputPlane, inputHeight,
-                      inputWidth, kH, kW, padH, padW, dH, dW, dilationH,
-                      dilationW, im2col_step, deformable_group, columns);
-
-    columns = columns.view({group, columns.size(0) / group, columns.size(1)});
-    weight = weight.view({group, weight.size(0) / group, weight.size(1),
-                          weight.size(2), weight.size(3)});
-
-    for (int g = 0; g < group; g++) {
-      output_buffer[elt][g] = output_buffer[elt][g]
-                                  .flatten(1)
-                                  .addmm_(weight[g].flatten(1), columns[g])
-                                  .view_as(output_buffer[elt][g]);
-    }
-  }
-
-  output_buffer = output_buffer.view(
-      {output_buffer.size(0), output_buffer.size(1) * output_buffer.size(2),
-       output_buffer.size(3), output_buffer.size(4)});
-
-  output_buffer = output_buffer.view({batchSize / im2col_step, nOutputPlane,
-                                      im2col_step, outputHeight, outputWidth});
-  output_buffer.transpose_(1, 2);
-  output.copy_(output_buffer);
-  output = output.view({batchSize, nOutputPlane, outputHeight, outputWidth});
-
-  input = input.view({batchSize, nInputPlane, inputHeight, inputWidth});
-  offset = offset.view(
-      {batchSize, deformable_group * 2 * kH * kW, outputHeight, outputWidth});
-
-  if (batch == 0) {
-    output = output.view({nOutputPlane, outputHeight, outputWidth});
-    input = input.view({nInputPlane, inputHeight, inputWidth});
-    offset = offset.view({offset.size(1), offset.size(2), offset.size(3)});
-  }
-
-  return 1;
-}
-
-int deform_conv_backward_input_cuda(at::Tensor input, at::Tensor offset,
-                                    at::Tensor gradOutput, at::Tensor gradInput,
-                                    at::Tensor gradOffset, at::Tensor weight,
-                                    at::Tensor columns, int kW, int kH, int dW,
-                                    int dH, int padW, int padH, int dilationW,
-                                    int dilationH, int group,
-                                    int deformable_group, int im2col_step) 
-{
-  shape_check(input, offset, &gradOutput, weight, kH, kW, dH, dW, padH, padW,
-              dilationH, dilationW, group, deformable_group);
-
-  input = input.contiguous();
-  offset = offset.contiguous();
-  gradOutput = gradOutput.contiguous();
-  weight = weight.contiguous();
-
-  int batch = 1;
-
-  if (input.ndimension() == 3) {
-    // Force batch
-    batch = 0;
-    input = input.view({1, input.size(0), input.size(1), input.size(2)});
-    offset = offset.view({1, offset.size(0), offset.size(1), offset.size(2)});
-    gradOutput = gradOutput.view(
-        {1, gradOutput.size(0), gradOutput.size(1), gradOutput.size(2)});
-  }
-
-  long batchSize = input.size(0);
-  long nInputPlane = input.size(1);
-  long inputHeight = input.size(2);
-  long inputWidth = input.size(3);
-
-  long nOutputPlane = weight.size(0);
-
-  long outputWidth =
-      (inputWidth + 2 * padW - (dilationW * (kW - 1) + 1)) / dW + 1;
-  long outputHeight =
-      (inputHeight + 2 * padH - (dilationH * (kH - 1) + 1)) / dH + 1;
-
-  AT_CHECK((offset.size(0) == batchSize), 3, "invalid batch size of offset");
-  gradInput = gradInput.view({batchSize, nInputPlane, inputHeight, inputWidth});
-  columns = at::zeros(
-      {nInputPlane * kW * kH, im2col_step * outputHeight * outputWidth},
-      input.options());
-
-  // change order of grad output
-  gradOutput = gradOutput.view({batchSize / im2col_step, im2col_step,
-                                nOutputPlane, outputHeight, outputWidth});
-  gradOutput.transpose_(1, 2);
-
-  gradInput = gradInput.view({batchSize / im2col_step, im2col_step, nInputPlane,
-                              inputHeight, inputWidth});
-  input = input.view({batchSize / im2col_step, im2col_step, nInputPlane,
-                      inputHeight, inputWidth});
-  gradOffset = gradOffset.view({batchSize / im2col_step, im2col_step,
-                                deformable_group * 2 * kH * kW, outputHeight,
-                                outputWidth});
-  offset =
-      offset.view({batchSize / im2col_step, im2col_step,
-                   deformable_group * 2 * kH * kW, outputHeight, outputWidth});
-
-  for (int elt = 0; elt < batchSize / im2col_step; elt++) {
-    // divide into groups
-    columns = columns.view({group, columns.size(0) / group, columns.size(1)});
-    weight = weight.view({group, weight.size(0) / group, weight.size(1),
-                          weight.size(2), weight.size(3)});
-    gradOutput = gradOutput.view(
-        {gradOutput.size(0), group, gradOutput.size(1) / group,
-         gradOutput.size(2), gradOutput.size(3), gradOutput.size(4)});
-
-    for (int g = 0; g < group; g++) {
-      columns[g] = columns[g].addmm_(weight[g].flatten(1).transpose(0, 1),
-                                     gradOutput[elt][g].flatten(1), 0.0f, 1.0f);
-    }
-
-    columns =
-        columns.view({columns.size(0) * columns.size(1), columns.size(2)});
-    gradOutput = gradOutput.view(
-        {gradOutput.size(0), gradOutput.size(1) * gradOutput.size(2),
-         gradOutput.size(3), gradOutput.size(4), gradOutput.size(5)});
-
-    deformable_col2im_coord(columns, input[elt], offset[elt], nInputPlane,
-                            inputHeight, inputWidth, kH, kW, padH, padW, dH, dW,
-                            dilationH, dilationW, im2col_step, deformable_group,
-                            gradOffset[elt]);
-
-    deformable_col2im(columns, offset[elt], nInputPlane, inputHeight,
-                      inputWidth, kH, kW, padH, padW, dH, dW, dilationH,
-                      dilationW, im2col_step, deformable_group, gradInput[elt]);
-  }
-
-  gradOutput.transpose_(1, 2);
-  gradOutput =
-      gradOutput.view({batchSize, nOutputPlane, outputHeight, outputWidth});
-
-  gradInput = gradInput.view({batchSize, nInputPlane, inputHeight, inputWidth});
-  input = input.view({batchSize, nInputPlane, inputHeight, inputWidth});
-  gradOffset = gradOffset.view(
-      {batchSize, deformable_group * 2 * kH * kW, outputHeight, outputWidth});
-  offset = offset.view(
-      {batchSize, deformable_group * 2 * kH * kW, outputHeight, outputWidth});
-
-  if (batch == 0) {
-    gradOutput = gradOutput.view({nOutputPlane, outputHeight, outputWidth});
-    input = input.view({nInputPlane, inputHeight, inputWidth});
-    gradInput = gradInput.view({nInputPlane, inputHeight, inputWidth});
-    offset = offset.view({offset.size(1), offset.size(2), offset.size(3)});
-    gradOffset =
-        gradOffset.view({offset.size(1), offset.size(2), offset.size(3)});
-  }
-
-  return 1;
-}
-
-int deform_conv_backward_parameters_cuda(
-    at::Tensor input, at::Tensor offset, at::Tensor gradOutput,
-    at::Tensor gradWeight,  // at::Tensor gradBias,
-    at::Tensor columns, at::Tensor ones, int kW, int kH, int dW, int dH,
-    int padW, int padH, int dilationW, int dilationH, int group,
-    int deformable_group, float scale, int im2col_step) 
-{
-  // todo: transpose and reshape outGrad
-  // todo: reshape columns
-  // todo: add im2col_step as input
-
-  shape_check(input, offset, &gradOutput, gradWeight, kH, kW, dH, dW, padH,
-              padW, dilationH, dilationW, group, deformable_group);
-
-  input = input.contiguous();
-  offset = offset.contiguous();
-  gradOutput = gradOutput.contiguous();
-
-  int batch = 1;
-
-  if (input.ndimension() == 3) {
-    // Force batch
-    batch = 0;
-    input = input.view(
-        at::IntList({1, input.size(0), input.size(1), input.size(2)}));
-    gradOutput = gradOutput.view(
-        {1, gradOutput.size(0), gradOutput.size(1), gradOutput.size(2)});
-  }
-
-  long batchSize = input.size(0);
-  long nInputPlane = input.size(1);
-  long inputHeight = input.size(2);
-  long inputWidth = input.size(3);
-
-  long nOutputPlane = gradWeight.size(0);
-
-  long outputWidth =
-      (inputWidth + 2 * padW - (dilationW * (kW - 1) + 1)) / dW + 1;
-  long outputHeight =
-      (inputHeight + 2 * padH - (dilationH * (kH - 1) + 1)) / dH + 1;
-
-  AT_CHECK((offset.size(0) == batchSize), "invalid batch size of offset");
-
-  columns = at::zeros(
-      {nInputPlane * kW * kH, im2col_step * outputHeight * outputWidth},
-      input.options());
-
-  gradOutput = gradOutput.view({batchSize / im2col_step, im2col_step,
-                                nOutputPlane, outputHeight, outputWidth});
-  gradOutput.transpose_(1, 2);
-
-  at::Tensor gradOutputBuffer = at::zeros_like(gradOutput);
-  gradOutputBuffer =
-      gradOutputBuffer.view({batchSize / im2col_step, nOutputPlane, im2col_step,
-                             outputHeight, outputWidth});
-  gradOutputBuffer.copy_(gradOutput);
-  gradOutputBuffer =
-      gradOutputBuffer.view({batchSize / im2col_step, nOutputPlane,
-                             im2col_step * outputHeight, outputWidth});
-
-  gradOutput.transpose_(1, 2);
-  gradOutput =
-      gradOutput.view({batchSize, nOutputPlane, outputHeight, outputWidth});
-
-  input = input.view({batchSize / im2col_step, im2col_step, nInputPlane,
-                      inputHeight, inputWidth});
-  offset =
-      offset.view({batchSize / im2col_step, im2col_step,
-                   deformable_group * 2 * kH * kW, outputHeight, outputWidth});
-
-  for (int elt = 0; elt < batchSize / im2col_step; elt++) {
-    deformable_im2col(input[elt], offset[elt], nInputPlane, inputHeight,
-                      inputWidth, kH, kW, padH, padW, dH, dW, dilationH,
-                      dilationW, im2col_step, deformable_group, columns);
-
-    // divide into group
-    gradOutputBuffer = gradOutputBuffer.view(
-        {gradOutputBuffer.size(0), group, gradOutputBuffer.size(1) / group,
-         gradOutputBuffer.size(2), gradOutputBuffer.size(3)});
-    columns = columns.view({group, columns.size(0) / group, columns.size(1)});
-    gradWeight =
-        gradWeight.view({group, gradWeight.size(0) / group, gradWeight.size(1),
-                         gradWeight.size(2), gradWeight.size(3)});
-
-    for (int g = 0; g < group; g++) {
-      gradWeight[g] = gradWeight[g]
-                          .flatten(1)
-                          .addmm_(gradOutputBuffer[elt][g].flatten(1),
-                                  columns[g].transpose(1, 0), 1.0, scale)
-                          .view_as(gradWeight[g]);
-    }
-    gradOutputBuffer = gradOutputBuffer.view(
-        {gradOutputBuffer.size(0),
-         gradOutputBuffer.size(1) * gradOutputBuffer.size(2),
-         gradOutputBuffer.size(3), gradOutputBuffer.size(4)});
-    columns =
-        columns.view({columns.size(0) * columns.size(1), columns.size(2)});
-    gradWeight = gradWeight.view({gradWeight.size(0) * gradWeight.size(1),
-                                  gradWeight.size(2), gradWeight.size(3),
-                                  gradWeight.size(4)});
-  }
-
-  input = input.view({batchSize, nInputPlane, inputHeight, inputWidth});
-  offset = offset.view(
-      {batchSize, deformable_group * 2 * kH * kW, outputHeight, outputWidth});
-
-  if (batch == 0) {
-    gradOutput = gradOutput.view({nOutputPlane, outputHeight, outputWidth});
-    input = input.view({nInputPlane, inputHeight, inputWidth});
-  }
-
-  return 1;
-}
-
-void modulated_deform_conv_cuda_forward(
-    at::Tensor input, at::Tensor weight, at::Tensor bias, at::Tensor ones,
-    at::Tensor offset, at::Tensor mask, at::Tensor output, at::Tensor columns,
-    int kernel_h, int kernel_w, const int stride_h, const int stride_w,
-    const int pad_h, const int pad_w, const int dilation_h,
-    const int dilation_w, const int group, const int deformable_group,
-    const bool with_bias) 
-{
-  AT_CHECK(input.is_contiguous(), "input tensor has to be contiguous");
-  AT_CHECK(weight.is_contiguous(), "weight tensor has to be contiguous");
-
-  const int batch = input.size(0);
-  const int channels = input.size(1);
-  const int height = input.size(2);
-  const int width = input.size(3);
-
-  const int channels_out = weight.size(0);
-  const int channels_kernel = weight.size(1);
-  const int kernel_h_ = weight.size(2);
-  const int kernel_w_ = weight.size(3);
-
-  if (kernel_h_ != kernel_h || kernel_w_ != kernel_w)
-    AT_ERROR("Input shape and kernel shape wont match: (%d x %d vs %d x %d).",
-             kernel_h_, kernel_w, kernel_h_, kernel_w_);
-  if (channels != channels_kernel * group)
-    AT_ERROR("Input shape and kernel channels wont match: (%d vs %d).",
-             channels, channels_kernel * group);
-
-  const int height_out =
-      (height + 2 * pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1;
-  const int width_out =
-      (width + 2 * pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1;
-
-  if (ones.ndimension() != 2 ||
-      ones.size(0) * ones.size(1) < height_out * width_out) {
-    // Resize plane and fill with ones...
-    ones = at::ones({height_out, width_out}, input.options());
-  }
-
-  // resize output
-  output = output.view({batch, channels_out, height_out, width_out}).zero_();
-  // resize temporary columns
-  columns =
-      at::zeros({channels * kernel_h * kernel_w, 1 * height_out * width_out},
-                input.options());
-
-  output = output.view({output.size(0), group, output.size(1) / group,
-                        output.size(2), output.size(3)});
-
-  for (int b = 0; b < batch; b++) {
-    modulated_deformable_im2col_cuda(
-        input[b], offset[b], mask[b], 1, channels, height, width, height_out,
-        width_out, kernel_h, kernel_w, pad_h, pad_w, stride_h, stride_w,
-        dilation_h, dilation_w, deformable_group, columns);
-
-    // divide into group
-    weight = weight.view({group, weight.size(0) / group, weight.size(1),
-                          weight.size(2), weight.size(3)});
-    columns = columns.view({group, columns.size(0) / group, columns.size(1)});
-
-    for (int g = 0; g < group; g++) {
-      output[b][g] = output[b][g]
-                         .flatten(1)
-                         .addmm_(weight[g].flatten(1), columns[g])
-                         .view_as(output[b][g]);
-    }
-
-    weight = weight.view({weight.size(0) * weight.size(1), weight.size(2),
-                          weight.size(3), weight.size(4)});
-    columns =
-        columns.view({columns.size(0) * columns.size(1), columns.size(2)});
-  }
-
-  output = output.view({output.size(0), output.size(1) * output.size(2),
-                        output.size(3), output.size(4)});
-
-  if (with_bias) {
-    output += bias.view({1, bias.size(0), 1, 1});
-  }
-}
-
-void modulated_deform_conv_cuda_backward(
-    at::Tensor input, at::Tensor weight, at::Tensor bias, at::Tensor ones,
-    at::Tensor offset, at::Tensor mask, at::Tensor columns,
-    at::Tensor grad_input, at::Tensor grad_weight, at::Tensor grad_bias,
-    at::Tensor grad_offset, at::Tensor grad_mask, at::Tensor grad_output,
-    int kernel_h, int kernel_w, int stride_h, int stride_w, int pad_h,
-    int pad_w, int dilation_h, int dilation_w, int group, int deformable_group,
-    const bool with_bias) 
-{
-  AT_CHECK(input.is_contiguous(), "input tensor has to be contiguous");
-  AT_CHECK(weight.is_contiguous(), "weight tensor has to be contiguous");
-
-  const int batch = input.size(0);
-  const int channels = input.size(1);
-  const int height = input.size(2);
-  const int width = input.size(3);
-
-  const int channels_kernel = weight.size(1);
-  const int kernel_h_ = weight.size(2);
-  const int kernel_w_ = weight.size(3);
-  if (kernel_h_ != kernel_h || kernel_w_ != kernel_w)
-    AT_ERROR("Input shape and kernel shape wont match: (%d x %d vs %d x %d).",
-             kernel_h_, kernel_w, kernel_h_, kernel_w_);
-  if (channels != channels_kernel * group)
-    AT_ERROR("Input shape and kernel channels wont match: (%d vs %d).",
-             channels, channels_kernel * group);
-
-  const int height_out =
-      (height + 2 * pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1;
-  const int width_out =
-      (width + 2 * pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1;
-
-  if (ones.ndimension() != 2 ||
-      ones.size(0) * ones.size(1) < height_out * width_out) {
-    // Resize plane and fill with ones...
-    ones = at::ones({height_out, width_out}, input.options());
-  }
-
-  grad_input = grad_input.view({batch, channels, height, width});
-  columns = at::zeros({channels * kernel_h * kernel_w, height_out * width_out},
-                      input.options());
-
-  grad_output =
-      grad_output.view({grad_output.size(0), group, grad_output.size(1) / group,
-                        grad_output.size(2), grad_output.size(3)});
-
-  for (int b = 0; b < batch; b++) {
-    // divide int group
-    columns = columns.view({group, columns.size(0) / group, columns.size(1)});
-    weight = weight.view({group, weight.size(0) / group, weight.size(1),
-                          weight.size(2), weight.size(3)});
-
-    for (int g = 0; g < group; g++) {
-      columns[g].addmm_(weight[g].flatten(1).transpose(0, 1),
-                        grad_output[b][g].flatten(1), 0.0f, 1.0f);
-    }
-
-    columns =
-        columns.view({columns.size(0) * columns.size(1), columns.size(2)});
-    weight = weight.view({weight.size(0) * weight.size(1), weight.size(2),
-                          weight.size(3), weight.size(4)});
-
-    // gradient w.r.t. input coordinate data
-    modulated_deformable_col2im_coord_cuda(
-        columns, input[b], offset[b], mask[b], 1, channels, height, width,
-        height_out, width_out, kernel_h, kernel_w, pad_h, pad_w, stride_h,
-        stride_w, dilation_h, dilation_w, deformable_group, grad_offset[b],
-        grad_mask[b]);
-    // gradient w.r.t. input data
-    modulated_deformable_col2im_cuda(
-        columns, offset[b], mask[b], 1, channels, height, width, height_out,
-        width_out, kernel_h, kernel_w, pad_h, pad_w, stride_h, stride_w,
-        dilation_h, dilation_w, deformable_group, grad_input[b]);
-
-    // gradient w.r.t. weight, dWeight should accumulate across the batch and
-    // group
-    modulated_deformable_im2col_cuda(
-        input[b], offset[b], mask[b], 1, channels, height, width, height_out,
-        width_out, kernel_h, kernel_w, pad_h, pad_w, stride_h, stride_w,
-        dilation_h, dilation_w, deformable_group, columns);
-
-    columns = columns.view({group, columns.size(0) / group, columns.size(1)});
-    grad_weight = grad_weight.view({group, grad_weight.size(0) / group,
-                                    grad_weight.size(1), grad_weight.size(2),
-                                    grad_weight.size(3)});
-    if (with_bias)
-      grad_bias = grad_bias.view({group, grad_bias.size(0) / group});
-
-    for (int g = 0; g < group; g++) {
-      grad_weight[g] =
-          grad_weight[g]
-              .flatten(1)
-              .addmm_(grad_output[b][g].flatten(1), columns[g].transpose(0, 1))
-              .view_as(grad_weight[g]);
-      if (with_bias) {
-        grad_bias[g] =
-            grad_bias[g]
-                .view({-1, 1})
-                .addmm_(grad_output[b][g].flatten(1), ones.view({-1, 1}))
-                .view(-1);
-      }
-    }
-
-    columns =
-        columns.view({columns.size(0) * columns.size(1), columns.size(2)});
-    grad_weight = grad_weight.view({grad_weight.size(0) * grad_weight.size(1),
-                                    grad_weight.size(2), grad_weight.size(3),
-                                    grad_weight.size(4)});
-    if (with_bias)
-      grad_bias = grad_bias.view({grad_bias.size(0) * grad_bias.size(1)});
-  }
-  grad_output = grad_output.view({grad_output.size(0) * grad_output.size(1),
-                                  grad_output.size(2), grad_output.size(3),
-                                  grad_output.size(4)});
-}
diff --git a/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu b/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu
deleted file mode 100644
index b4f8813..0000000
--- a/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu
+++ /dev/null
@@ -1,874 +0,0 @@
-/*!
- ******************* BEGIN Caffe Copyright Notice and Disclaimer ****************
- *
- * COPYRIGHT
- *
- * All contributions by the University of California:
- * Copyright (c) 2014-2017 The Regents of the University of California (Regents)
- * All rights reserved.
- *
- * All other contributions:
- * Copyright (c) 2014-2017, the respective contributors
- * All rights reserved.
- *
- * Caffe uses a shared copyright model: each contributor holds copyright over
- * their contributions to Caffe. The project versioning records all such
- * contribution and copyright details. If a contributor wants to further mark
- * their specific copyright on a particular contribution, they should indicate
- * their copyright solely in the commit message of the change when it is
- * committed.
- *
- * LICENSE
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions are met:
- *
- * 1. Redistributions of source code must retain the above copyright notice, this
- * list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright notice,
- * this list of conditions and the following disclaimer in the documentation
- * and/or other materials provided with the distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
- * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
- * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
- * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
- * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
- * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
- * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- * CONTRIBUTION AGREEMENT
- *
- * By contributing to the BVLC/caffe repository through pull-request, comment,
- * or otherwise, the contributor releases their content to the
- * license and copyright terms herein.
- *
- ***************** END Caffe Copyright Notice and Disclaimer ********************
- *
- * Copyright (c) 2018 Microsoft
- * Licensed under The MIT License [see LICENSE for details]
- * \file modulated_deformable_im2col.cuh
- * \brief Function definitions of converting an image to
- * column matrix based on kernel, padding, dilation, and offset.
- * These functions are mainly used in deformable convolution operators.
- * \ref: https://arxiv.org/abs/1703.06211
- * \author Yuwen Xiong, Haozhi Qi, Jifeng Dai, Xizhou Zhu, Han Hu, Dazhi Cheng
- */
-
-// modify from https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/blob/mmdetection/mmdet/ops/dcn/src/deform_conv_cuda_kernel.cu
-
-
-#include <ATen/ATen.h>
-#include <THC/THCAtomics.cuh>
-#include <stdio.h>
-#include <math.h>
-#include <float.h>
-
-using namespace at;
-
-#define CUDA_KERNEL_LOOP(i, n)                                 \
-  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < (n); \
-       i += blockDim.x * gridDim.x)
-
-const int CUDA_NUM_THREADS = 1024;
-const int kMaxGridNum = 65535;
-inline int GET_BLOCKS(const int N)
-{
-  return std::min(kMaxGridNum, (N + CUDA_NUM_THREADS - 1) / CUDA_NUM_THREADS);
-}
-
-/*
-const int CUDA_NUM_THREADS = 1024;
-
-inline int GET_BLOCKS(const int N)
-{
-  return (N + CUDA_NUM_THREADS - 1) / CUDA_NUM_THREADS;
-}*/
-
-template <typename scalar_t>
-__device__ scalar_t deformable_im2col_bilinear(const scalar_t *bottom_data, const int data_width,
-                                               const int height, const int width, scalar_t h, scalar_t w)
-{
-
-  int h_low = floor(h);
-  int w_low = floor(w);
-  int h_high = h_low + 1;
-  int w_high = w_low + 1;
-
-  scalar_t lh = h - h_low;
-  scalar_t lw = w - w_low;
-  scalar_t hh = 1 - lh, hw = 1 - lw;
-
-  scalar_t v1 = 0;
-  if (h_low >= 0 && w_low >= 0)
-    v1 = bottom_data[h_low * data_width + w_low];
-  scalar_t v2 = 0;
-  if (h_low >= 0 && w_high <= width - 1)
-    v2 = bottom_data[h_low * data_width + w_high];
-  scalar_t v3 = 0;
-  if (h_high <= height - 1 && w_low >= 0)
-    v3 = bottom_data[h_high * data_width + w_low];
-  scalar_t v4 = 0;
-  if (h_high <= height - 1 && w_high <= width - 1)
-    v4 = bottom_data[h_high * data_width + w_high];
-
-  scalar_t w1 = hh * hw, w2 = hh * lw, w3 = lh * hw, w4 = lh * lw;
-
-  scalar_t val = (w1 * v1 + w2 * v2 + w3 * v3 + w4 * v4);
-  return val;
-}
-
-template <typename scalar_t>
-__device__ scalar_t get_gradient_weight(scalar_t argmax_h, scalar_t argmax_w,
-                                        const int h, const int w, const int height, const int width)
-{
-
-  if (argmax_h <= -1 || argmax_h >= height || argmax_w <= -1 || argmax_w >= width)
-  {
-    //empty
-    return 0;
-  }
-
-  int argmax_h_low = floor(argmax_h);
-  int argmax_w_low = floor(argmax_w);
-  int argmax_h_high = argmax_h_low + 1;
-  int argmax_w_high = argmax_w_low + 1;
-
-  scalar_t weight = 0;
-  if (h == argmax_h_low && w == argmax_w_low)
-    weight = (h + 1 - argmax_h) * (w + 1 - argmax_w);
-  if (h == argmax_h_low && w == argmax_w_high)
-    weight = (h + 1 - argmax_h) * (argmax_w + 1 - w);
-  if (h == argmax_h_high && w == argmax_w_low)
-    weight = (argmax_h + 1 - h) * (w + 1 - argmax_w);
-  if (h == argmax_h_high && w == argmax_w_high)
-    weight = (argmax_h + 1 - h) * (argmax_w + 1 - w);
-  return weight;
-}
-
-template <typename scalar_t>
-__device__ scalar_t get_coordinate_weight(scalar_t argmax_h, scalar_t argmax_w,
-                                          const int height, const int width, const scalar_t *im_data,
-                                          const int data_width, const int bp_dir)
-{
-
-  if (argmax_h <= -1 || argmax_h >= height || argmax_w <= -1 || argmax_w >= width)
-  {
-    //empty
-    return 0;
-  }
-
-  int argmax_h_low = floor(argmax_h);
-  int argmax_w_low = floor(argmax_w);
-  int argmax_h_high = argmax_h_low + 1;
-  int argmax_w_high = argmax_w_low + 1;
-
-  scalar_t weight = 0;
-
-  if (bp_dir == 0)
-  {
-    if (argmax_h_low >= 0 && argmax_w_low >= 0)
-      weight += -1 * (argmax_w_low + 1 - argmax_w) * im_data[argmax_h_low * data_width + argmax_w_low];
-    if (argmax_h_low >= 0 && argmax_w_high <= width - 1)
-      weight += -1 * (argmax_w - argmax_w_low) * im_data[argmax_h_low * data_width + argmax_w_high];
-    if (argmax_h_high <= height - 1 && argmax_w_low >= 0)
-      weight += (argmax_w_low + 1 - argmax_w) * im_data[argmax_h_high * data_width + argmax_w_low];
-    if (argmax_h_high <= height - 1 && argmax_w_high <= width - 1)
-      weight += (argmax_w - argmax_w_low) * im_data[argmax_h_high * data_width + argmax_w_high];
-  }
-  else if (bp_dir == 1)
-  {
-    if (argmax_h_low >= 0 && argmax_w_low >= 0)
-      weight += -1 * (argmax_h_low + 1 - argmax_h) * im_data[argmax_h_low * data_width + argmax_w_low];
-    if (argmax_h_low >= 0 && argmax_w_high <= width - 1)
-      weight += (argmax_h_low + 1 - argmax_h) * im_data[argmax_h_low * data_width + argmax_w_high];
-    if (argmax_h_high <= height - 1 && argmax_w_low >= 0)
-      weight += -1 * (argmax_h - argmax_h_low) * im_data[argmax_h_high * data_width + argmax_w_low];
-    if (argmax_h_high <= height - 1 && argmax_w_high <= width - 1)
-      weight += (argmax_h - argmax_h_low) * im_data[argmax_h_high * data_width + argmax_w_high];
-  }
-
-  return weight;
-}
-
-template <typename scalar_t>
-__global__ void deformable_im2col_gpu_kernel(const int n, const scalar_t *data_im, const scalar_t *data_offset,
-                                             const int height, const int width, const int kernel_h, const int kernel_w,
-                                             const int pad_h, const int pad_w, const int stride_h, const int stride_w,
-                                             const int dilation_h, const int dilation_w, const int channel_per_deformable_group,
-                                             const int batch_size, const int num_channels, const int deformable_group,
-                                             const int height_col, const int width_col,
-                                             scalar_t *data_col)
-{
-  CUDA_KERNEL_LOOP(index, n)
-  {
-    // index index of output matrix
-    const int w_col = index % width_col;
-    const int h_col = (index / width_col) % height_col;
-    const int b_col = (index / width_col / height_col) % batch_size;
-    const int c_im = (index / width_col / height_col) / batch_size;
-    const int c_col = c_im * kernel_h * kernel_w;
-
-    // compute deformable group index
-    const int deformable_group_index = c_im / channel_per_deformable_group;
-
-    const int h_in = h_col * stride_h - pad_h;
-    const int w_in = w_col * stride_w - pad_w;
-    scalar_t *data_col_ptr = data_col + ((c_col * batch_size + b_col) * height_col + h_col) * width_col + w_col;
-    //const scalar_t* data_im_ptr = data_im + ((b_col * num_channels + c_im) * height + h_in) * width + w_in;
-    const scalar_t *data_im_ptr = data_im + (b_col * num_channels + c_im) * height * width;
-    const scalar_t *data_offset_ptr = data_offset + (b_col * deformable_group + deformable_group_index) * 2 * kernel_h * kernel_w * height_col * width_col;
-
-    for (int i = 0; i < kernel_h; ++i)
-    {
-      for (int j = 0; j < kernel_w; ++j)
-      {
-        const int data_offset_h_ptr = ((2 * (i * kernel_w + j)) * height_col + h_col) * width_col + w_col;
-        const int data_offset_w_ptr = ((2 * (i * kernel_w + j) + 1) * height_col + h_col) * width_col + w_col;
-        const scalar_t offset_h = data_offset_ptr[data_offset_h_ptr];
-        const scalar_t offset_w = data_offset_ptr[data_offset_w_ptr];
-        scalar_t val = static_cast<scalar_t>(0);
-        const scalar_t h_im = h_in + i * dilation_h + offset_h;
-        const scalar_t w_im = w_in + j * dilation_w + offset_w;
-        if (h_im > -1 && w_im > -1 && h_im < height && w_im < width)
-        {
-          //const scalar_t map_h = i * dilation_h + offset_h;
-          //const scalar_t map_w = j * dilation_w + offset_w;
-          //const int cur_height = height - h_in;
-          //const int cur_width = width - w_in;
-          //val = deformable_im2col_bilinear(data_im_ptr, width, cur_height, cur_width, map_h, map_w);
-          val = deformable_im2col_bilinear(data_im_ptr, width, height, width, h_im, w_im);
-        }
-        *data_col_ptr = val;
-        data_col_ptr += batch_size * height_col * width_col;
-      }
-    }
-  }
-}
-
-void deformable_im2col(
-    const at::Tensor data_im, const at::Tensor data_offset, const int channels,
-    const int height, const int width, const int ksize_h, const int ksize_w,
-    const int pad_h, const int pad_w, const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w, const int parallel_imgs,
-    const int deformable_group, at::Tensor data_col)
-{
-  // num_axes should be smaller than block size
-  // todo: check parallel_imgs is correctly passed in
-  int height_col = (height + 2 * pad_h - (dilation_h * (ksize_h - 1) + 1)) / stride_h + 1;
-  int width_col = (width + 2 * pad_w - (dilation_w * (ksize_w - 1) + 1)) / stride_w + 1;
-  int num_kernels = channels * height_col * width_col * parallel_imgs;
-  int channel_per_deformable_group = channels / deformable_group;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      data_im.type(), "deformable_im2col_gpu", ([&] {
-        const scalar_t *data_im_ = data_im.data<scalar_t>();
-        const scalar_t *data_offset_ = data_offset.data<scalar_t>();
-        scalar_t *data_col_ = data_col.data<scalar_t>();
-
-        deformable_im2col_gpu_kernel<<<GET_BLOCKS(num_kernels), CUDA_NUM_THREADS>>>(
-            num_kernels, data_im_, data_offset_, height, width, ksize_h, ksize_w,
-            pad_h, pad_w, stride_h, stride_w, dilation_h, dilation_w,
-            channel_per_deformable_group, parallel_imgs, channels, deformable_group,
-            height_col, width_col, data_col_);
-      }));
-
-  cudaError_t err = cudaGetLastError();
-  if (err != cudaSuccess)
-  {
-    printf("error in deformable_im2col: %s\n", cudaGetErrorString(err));
-  }
-}
-
-template <typename scalar_t>
-__global__ void deformable_col2im_gpu_kernel(
-    const int n, const scalar_t *data_col, const scalar_t *data_offset,
-    const int channels, const int height, const int width,
-    const int kernel_h, const int kernel_w,
-    const int pad_h, const int pad_w,
-    const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w,
-    const int channel_per_deformable_group,
-    const int batch_size, const int deformable_group,
-    const int height_col, const int width_col,
-    scalar_t *grad_im)
-{
-  CUDA_KERNEL_LOOP(index, n)
-  {
-    const int j = (index / width_col / height_col / batch_size) % kernel_w;
-    const int i = (index / width_col / height_col / batch_size / kernel_w) % kernel_h;
-    const int c = index / width_col / height_col / batch_size / kernel_w / kernel_h;
-    // compute the start and end of the output
-
-    const int deformable_group_index = c / channel_per_deformable_group;
-
-    int w_out = index % width_col;
-    int h_out = (index / width_col) % height_col;
-    int b = (index / width_col / height_col) % batch_size;
-    int w_in = w_out * stride_w - pad_w;
-    int h_in = h_out * stride_h - pad_h;
-
-    const scalar_t *data_offset_ptr = data_offset + (b * deformable_group + deformable_group_index) *
-                                                        2 * kernel_h * kernel_w * height_col * width_col;
-    const int data_offset_h_ptr = ((2 * (i * kernel_w + j)) * height_col + h_out) * width_col + w_out;
-    const int data_offset_w_ptr = ((2 * (i * kernel_w + j) + 1) * height_col + h_out) * width_col + w_out;
-    const scalar_t offset_h = data_offset_ptr[data_offset_h_ptr];
-    const scalar_t offset_w = data_offset_ptr[data_offset_w_ptr];
-    const scalar_t cur_inv_h_data = h_in + i * dilation_h + offset_h;
-    const scalar_t cur_inv_w_data = w_in + j * dilation_w + offset_w;
-
-    const scalar_t cur_top_grad = data_col[index];
-    const int cur_h = (int)cur_inv_h_data;
-    const int cur_w = (int)cur_inv_w_data;
-    for (int dy = -2; dy <= 2; dy++)
-    {
-      for (int dx = -2; dx <= 2; dx++)
-      {
-        if (cur_h + dy >= 0 && cur_h + dy < height &&
-            cur_w + dx >= 0 && cur_w + dx < width &&
-            abs(cur_inv_h_data - (cur_h + dy)) < 1 &&
-            abs(cur_inv_w_data - (cur_w + dx)) < 1)
-        {
-          int cur_bottom_grad_pos = ((b * channels + c) * height + cur_h + dy) * width + cur_w + dx;
-          scalar_t weight = get_gradient_weight(cur_inv_h_data, cur_inv_w_data, cur_h + dy, cur_w + dx, height, width);
-          atomicAdd(grad_im + cur_bottom_grad_pos, weight * cur_top_grad);
-        }
-      }
-    }
-  }
-}
-
-void deformable_col2im(
-    const at::Tensor data_col, const at::Tensor data_offset, const int channels,
-    const int height, const int width, const int ksize_h,
-    const int ksize_w, const int pad_h, const int pad_w,
-    const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w,
-    const int parallel_imgs, const int deformable_group,
-    at::Tensor grad_im)
-{
-
-  // todo: make sure parallel_imgs is passed in correctly
-  int height_col = (height + 2 * pad_h - (dilation_h * (ksize_h - 1) + 1)) / stride_h + 1;
-  int width_col = (width + 2 * pad_w - (dilation_w * (ksize_w - 1) + 1)) / stride_w + 1;
-  int num_kernels = channels * ksize_h * ksize_w * height_col * width_col * parallel_imgs;
-  int channel_per_deformable_group = channels / deformable_group;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      data_col.type(), "deformable_col2im_gpu", ([&] {
-        const scalar_t *data_col_ = data_col.data<scalar_t>();
-        const scalar_t *data_offset_ = data_offset.data<scalar_t>();
-        scalar_t *grad_im_ = grad_im.data<scalar_t>();
-
-        deformable_col2im_gpu_kernel<<<GET_BLOCKS(num_kernels), CUDA_NUM_THREADS>>>(
-            num_kernels, data_col_, data_offset_, channels, height, width, ksize_h,
-            ksize_w, pad_h, pad_w, stride_h, stride_w,
-            dilation_h, dilation_w, channel_per_deformable_group,
-            parallel_imgs, deformable_group, height_col, width_col, grad_im_);
-      }));
-
-  cudaError_t err = cudaGetLastError();
-  if (err != cudaSuccess)
-  {
-    printf("error in deformable_col2im: %s\n", cudaGetErrorString(err));
-  }
-}
-
-template <typename scalar_t>
-__global__ void deformable_col2im_coord_gpu_kernel(const int n, const scalar_t *data_col,
-                                                   const scalar_t *data_im, const scalar_t *data_offset,
-                                                   const int channels, const int height, const int width,
-                                                   const int kernel_h, const int kernel_w,
-                                                   const int pad_h, const int pad_w,
-                                                   const int stride_h, const int stride_w,
-                                                   const int dilation_h, const int dilation_w,
-                                                   const int channel_per_deformable_group,
-                                                   const int batch_size, const int offset_channels, const int deformable_group,
-                                                   const int height_col, const int width_col, scalar_t *grad_offset)
-{
-  CUDA_KERNEL_LOOP(index, n)
-  {
-    scalar_t val = 0;
-    int w = index % width_col;
-    int h = (index / width_col) % height_col;
-    int c = (index / width_col / height_col) % offset_channels;
-    int b = (index / width_col / height_col) / offset_channels;
-    // compute the start and end of the output
-
-    const int deformable_group_index = c / (2 * kernel_h * kernel_w);
-    const int col_step = kernel_h * kernel_w;
-    int cnt = 0;
-    const scalar_t *data_col_ptr = data_col + deformable_group_index * channel_per_deformable_group *
-                                                  batch_size * width_col * height_col;
-    const scalar_t *data_im_ptr = data_im + (b * deformable_group + deformable_group_index) *
-                                                channel_per_deformable_group / kernel_h / kernel_w * height * width;
-    const scalar_t *data_offset_ptr = data_offset + (b * deformable_group + deformable_group_index) * 2 *
-                                                        kernel_h * kernel_w * height_col * width_col;
-
-    const int offset_c = c - deformable_group_index * 2 * kernel_h * kernel_w;
-
-    for (int col_c = (offset_c / 2); col_c < channel_per_deformable_group; col_c += col_step)
-    {
-      const int col_pos = (((col_c * batch_size + b) * height_col) + h) * width_col + w;
-      const int bp_dir = offset_c % 2;
-
-      int j = (col_pos / width_col / height_col / batch_size) % kernel_w;
-      int i = (col_pos / width_col / height_col / batch_size / kernel_w) % kernel_h;
-      int w_out = col_pos % width_col;
-      int h_out = (col_pos / width_col) % height_col;
-      int w_in = w_out * stride_w - pad_w;
-      int h_in = h_out * stride_h - pad_h;
-      const int data_offset_h_ptr = (((2 * (i * kernel_w + j)) * height_col + h_out) * width_col + w_out);
-      const int data_offset_w_ptr = (((2 * (i * kernel_w + j) + 1) * height_col + h_out) * width_col + w_out);
-      const scalar_t offset_h = data_offset_ptr[data_offset_h_ptr];
-      const scalar_t offset_w = data_offset_ptr[data_offset_w_ptr];
-      scalar_t inv_h = h_in + i * dilation_h + offset_h;
-      scalar_t inv_w = w_in + j * dilation_w + offset_w;
-      if (inv_h <= -1 || inv_w <= -1 || inv_h >= height || inv_w >= width)
-      {
-        inv_h = inv_w = -2;
-      }
-      const scalar_t weight = get_coordinate_weight(
-          inv_h, inv_w,
-          height, width, data_im_ptr + cnt * height * width, width, bp_dir);
-      val += weight * data_col_ptr[col_pos];
-      cnt += 1;
-    }
-
-    grad_offset[index] = val;
-  }
-}
-
-void deformable_col2im_coord(
-    const at::Tensor data_col, const at::Tensor data_im, const at::Tensor data_offset,
-    const int channels, const int height, const int width, const int ksize_h,
-    const int ksize_w, const int pad_h, const int pad_w, const int stride_h,
-    const int stride_w, const int dilation_h, const int dilation_w,
-    const int parallel_imgs, const int deformable_group, at::Tensor grad_offset)
-{
-
-  int height_col = (height + 2 * pad_h - (dilation_h * (ksize_h - 1) + 1)) / stride_h + 1;
-  int width_col = (width + 2 * pad_w - (dilation_w * (ksize_w - 1) + 1)) / stride_w + 1;
-  int num_kernels = height_col * width_col * 2 * ksize_h * ksize_w * deformable_group * parallel_imgs;
-  int channel_per_deformable_group = channels * ksize_h * ksize_w / deformable_group;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      data_col.type(), "deformable_col2im_coord_gpu", ([&] {
-        const scalar_t *data_col_ = data_col.data<scalar_t>();
-        const scalar_t *data_im_ = data_im.data<scalar_t>();
-        const scalar_t *data_offset_ = data_offset.data<scalar_t>();
-        scalar_t *grad_offset_ = grad_offset.data<scalar_t>();
-
-        deformable_col2im_coord_gpu_kernel<<<GET_BLOCKS(num_kernels), CUDA_NUM_THREADS>>>(
-            num_kernels, data_col_, data_im_, data_offset_, channels, height, width,
-            ksize_h, ksize_w, pad_h, pad_w, stride_h, stride_w,
-            dilation_h, dilation_w, channel_per_deformable_group,
-            parallel_imgs, 2 * ksize_h * ksize_w * deformable_group, deformable_group,
-            height_col, width_col, grad_offset_);
-      }));
-}
-
-template <typename scalar_t>
-__device__ scalar_t dmcn_im2col_bilinear(const scalar_t *bottom_data, const int data_width,
-                                         const int height, const int width, scalar_t h, scalar_t w)
-{
-  int h_low = floor(h);
-  int w_low = floor(w);
-  int h_high = h_low + 1;
-  int w_high = w_low + 1;
-
-  scalar_t lh = h - h_low;
-  scalar_t lw = w - w_low;
-  scalar_t hh = 1 - lh, hw = 1 - lw;
-
-  scalar_t v1 = 0;
-  if (h_low >= 0 && w_low >= 0)
-    v1 = bottom_data[h_low * data_width + w_low];
-  scalar_t v2 = 0;
-  if (h_low >= 0 && w_high <= width - 1)
-    v2 = bottom_data[h_low * data_width + w_high];
-  scalar_t v3 = 0;
-  if (h_high <= height - 1 && w_low >= 0)
-    v3 = bottom_data[h_high * data_width + w_low];
-  scalar_t v4 = 0;
-  if (h_high <= height - 1 && w_high <= width - 1)
-    v4 = bottom_data[h_high * data_width + w_high];
-
-  scalar_t w1 = hh * hw, w2 = hh * lw, w3 = lh * hw, w4 = lh * lw;
-
-  scalar_t val = (w1 * v1 + w2 * v2 + w3 * v3 + w4 * v4);
-  return val;
-}
-
-template <typename scalar_t>
-__device__ scalar_t dmcn_get_gradient_weight(scalar_t argmax_h, scalar_t argmax_w,
-                                             const int h, const int w, const int height, const int width)
-{
-  if (argmax_h <= -1 || argmax_h >= height || argmax_w <= -1 || argmax_w >= width)
-  {
-    //empty
-    return 0;
-  }
-
-  int argmax_h_low = floor(argmax_h);
-  int argmax_w_low = floor(argmax_w);
-  int argmax_h_high = argmax_h_low + 1;
-  int argmax_w_high = argmax_w_low + 1;
-
-  scalar_t weight = 0;
-  if (h == argmax_h_low && w == argmax_w_low)
-    weight = (h + 1 - argmax_h) * (w + 1 - argmax_w);
-  if (h == argmax_h_low && w == argmax_w_high)
-    weight = (h + 1 - argmax_h) * (argmax_w + 1 - w);
-  if (h == argmax_h_high && w == argmax_w_low)
-    weight = (argmax_h + 1 - h) * (w + 1 - argmax_w);
-  if (h == argmax_h_high && w == argmax_w_high)
-    weight = (argmax_h + 1 - h) * (argmax_w + 1 - w);
-  return weight;
-}
-
-template <typename scalar_t>
-__device__ scalar_t dmcn_get_coordinate_weight(scalar_t argmax_h, scalar_t argmax_w,
-                                               const int height, const int width, const scalar_t *im_data,
-                                               const int data_width, const int bp_dir)
-{
-  if (argmax_h <= -1 || argmax_h >= height || argmax_w <= -1 || argmax_w >= width)
-  {
-    //empty
-    return 0;
-  }
-
-  int argmax_h_low = floor(argmax_h);
-  int argmax_w_low = floor(argmax_w);
-  int argmax_h_high = argmax_h_low + 1;
-  int argmax_w_high = argmax_w_low + 1;
-
-  scalar_t weight = 0;
-
-  if (bp_dir == 0)
-  {
-    if (argmax_h_low >= 0 && argmax_w_low >= 0)
-      weight += -1 * (argmax_w_low + 1 - argmax_w) * im_data[argmax_h_low * data_width + argmax_w_low];
-    if (argmax_h_low >= 0 && argmax_w_high <= width - 1)
-      weight += -1 * (argmax_w - argmax_w_low) * im_data[argmax_h_low * data_width + argmax_w_high];
-    if (argmax_h_high <= height - 1 && argmax_w_low >= 0)
-      weight += (argmax_w_low + 1 - argmax_w) * im_data[argmax_h_high * data_width + argmax_w_low];
-    if (argmax_h_high <= height - 1 && argmax_w_high <= width - 1)
-      weight += (argmax_w - argmax_w_low) * im_data[argmax_h_high * data_width + argmax_w_high];
-  }
-  else if (bp_dir == 1)
-  {
-    if (argmax_h_low >= 0 && argmax_w_low >= 0)
-      weight += -1 * (argmax_h_low + 1 - argmax_h) * im_data[argmax_h_low * data_width + argmax_w_low];
-    if (argmax_h_low >= 0 && argmax_w_high <= width - 1)
-      weight += (argmax_h_low + 1 - argmax_h) * im_data[argmax_h_low * data_width + argmax_w_high];
-    if (argmax_h_high <= height - 1 && argmax_w_low >= 0)
-      weight += -1 * (argmax_h - argmax_h_low) * im_data[argmax_h_high * data_width + argmax_w_low];
-    if (argmax_h_high <= height - 1 && argmax_w_high <= width - 1)
-      weight += (argmax_h - argmax_h_low) * im_data[argmax_h_high * data_width + argmax_w_high];
-  }
-
-  return weight;
-}
-
-template <typename scalar_t>
-__global__ void modulated_deformable_im2col_gpu_kernel(const int n,
-                                                       const scalar_t *data_im, const scalar_t *data_offset, const scalar_t *data_mask,
-                                                       const int height, const int width, const int kernel_h, const int kernel_w,
-                                                       const int pad_h, const int pad_w,
-                                                       const int stride_h, const int stride_w,
-                                                       const int dilation_h, const int dilation_w,
-                                                       const int channel_per_deformable_group,
-                                                       const int batch_size, const int num_channels, const int deformable_group,
-                                                       const int height_col, const int width_col,
-                                                       scalar_t *data_col)
-{
-  CUDA_KERNEL_LOOP(index, n)
-  {
-    // index index of output matrix
-    const int w_col = index % width_col;
-    const int h_col = (index / width_col) % height_col;
-    const int b_col = (index / width_col / height_col) % batch_size;
-    const int c_im = (index / width_col / height_col) / batch_size;
-    const int c_col = c_im * kernel_h * kernel_w;
-
-    // compute deformable group index
-    const int deformable_group_index = c_im / channel_per_deformable_group;
-
-    const int h_in = h_col * stride_h - pad_h;
-    const int w_in = w_col * stride_w - pad_w;
-
-    scalar_t *data_col_ptr = data_col + ((c_col * batch_size + b_col) * height_col + h_col) * width_col + w_col;
-    //const float* data_im_ptr = data_im + ((b_col * num_channels + c_im) * height + h_in) * width + w_in;
-    const scalar_t *data_im_ptr = data_im + (b_col * num_channels + c_im) * height * width;
-    const scalar_t *data_offset_ptr = data_offset + (b_col * deformable_group + deformable_group_index) * 2 * kernel_h * kernel_w * height_col * width_col;
-
-    const scalar_t *data_mask_ptr = data_mask + (b_col * deformable_group + deformable_group_index) * kernel_h * kernel_w * height_col * width_col;
-
-    for (int i = 0; i < kernel_h; ++i)
-    {
-      for (int j = 0; j < kernel_w; ++j)
-      {
-        const int data_offset_h_ptr = ((2 * (i * kernel_w + j)) * height_col + h_col) * width_col + w_col;
-        const int data_offset_w_ptr = ((2 * (i * kernel_w + j) + 1) * height_col + h_col) * width_col + w_col;
-        const int data_mask_hw_ptr = ((i * kernel_w + j) * height_col + h_col) * width_col + w_col;
-        const scalar_t offset_h = data_offset_ptr[data_offset_h_ptr];
-        const scalar_t offset_w = data_offset_ptr[data_offset_w_ptr];
-        const scalar_t mask = data_mask_ptr[data_mask_hw_ptr];
-        scalar_t val = static_cast<scalar_t>(0);
-        const scalar_t h_im = h_in + i * dilation_h + offset_h;
-        const scalar_t w_im = w_in + j * dilation_w + offset_w;
-        //if (h_im >= 0 && w_im >= 0 && h_im < height && w_im < width) {
-        if (h_im > -1 && w_im > -1 && h_im < height && w_im < width)
-        {
-          //const float map_h = i * dilation_h + offset_h;
-          //const float map_w = j * dilation_w + offset_w;
-          //const int cur_height = height - h_in;
-          //const int cur_width = width - w_in;
-          //val = dmcn_im2col_bilinear(data_im_ptr, width, cur_height, cur_width, map_h, map_w);
-          val = dmcn_im2col_bilinear(data_im_ptr, width, height, width, h_im, w_im);
-        }
-        *data_col_ptr = val * mask;
-        data_col_ptr += batch_size * height_col * width_col;
-        //data_col_ptr += height_col * width_col;
-      }
-    }
-  }
-}
-
-template <typename scalar_t>
-__global__ void modulated_deformable_col2im_gpu_kernel(const int n,
-                                                       const scalar_t *data_col, const scalar_t *data_offset, const scalar_t *data_mask,
-                                                       const int channels, const int height, const int width,
-                                                       const int kernel_h, const int kernel_w,
-                                                       const int pad_h, const int pad_w,
-                                                       const int stride_h, const int stride_w,
-                                                       const int dilation_h, const int dilation_w,
-                                                       const int channel_per_deformable_group,
-                                                       const int batch_size, const int deformable_group,
-                                                       const int height_col, const int width_col,
-                                                       scalar_t *grad_im)
-{
-  CUDA_KERNEL_LOOP(index, n)
-  {
-    const int j = (index / width_col / height_col / batch_size) % kernel_w;
-    const int i = (index / width_col / height_col / batch_size / kernel_w) % kernel_h;
-    const int c = index / width_col / height_col / batch_size / kernel_w / kernel_h;
-    // compute the start and end of the output
-
-    const int deformable_group_index = c / channel_per_deformable_group;
-
-    int w_out = index % width_col;
-    int h_out = (index / width_col) % height_col;
-    int b = (index / width_col / height_col) % batch_size;
-    int w_in = w_out * stride_w - pad_w;
-    int h_in = h_out * stride_h - pad_h;
-
-    const scalar_t *data_offset_ptr = data_offset + (b * deformable_group + deformable_group_index) * 2 * kernel_h * kernel_w * height_col * width_col;
-    const scalar_t *data_mask_ptr = data_mask + (b * deformable_group + deformable_group_index) * kernel_h * kernel_w * height_col * width_col;
-    const int data_offset_h_ptr = ((2 * (i * kernel_w + j)) * height_col + h_out) * width_col + w_out;
-    const int data_offset_w_ptr = ((2 * (i * kernel_w + j) + 1) * height_col + h_out) * width_col + w_out;
-    const int data_mask_hw_ptr = ((i * kernel_w + j) * height_col + h_out) * width_col + w_out;
-    const scalar_t offset_h = data_offset_ptr[data_offset_h_ptr];
-    const scalar_t offset_w = data_offset_ptr[data_offset_w_ptr];
-    const scalar_t mask = data_mask_ptr[data_mask_hw_ptr];
-    const scalar_t cur_inv_h_data = h_in + i * dilation_h + offset_h;
-    const scalar_t cur_inv_w_data = w_in + j * dilation_w + offset_w;
-
-    const scalar_t cur_top_grad = data_col[index] * mask;
-    const int cur_h = (int)cur_inv_h_data;
-    const int cur_w = (int)cur_inv_w_data;
-    for (int dy = -2; dy <= 2; dy++)
-    {
-      for (int dx = -2; dx <= 2; dx++)
-      {
-        if (cur_h + dy >= 0 && cur_h + dy < height &&
-            cur_w + dx >= 0 && cur_w + dx < width &&
-            abs(cur_inv_h_data - (cur_h + dy)) < 1 &&
-            abs(cur_inv_w_data - (cur_w + dx)) < 1)
-        {
-          int cur_bottom_grad_pos = ((b * channels + c) * height + cur_h + dy) * width + cur_w + dx;
-          scalar_t weight = dmcn_get_gradient_weight(cur_inv_h_data, cur_inv_w_data, cur_h + dy, cur_w + dx, height, width);
-          atomicAdd(grad_im + cur_bottom_grad_pos, weight * cur_top_grad);
-        }
-      }
-    }
-  }
-}
-
-template <typename scalar_t>
-__global__ void modulated_deformable_col2im_coord_gpu_kernel(const int n,
-                                                             const scalar_t *data_col, const scalar_t *data_im,
-                                                             const scalar_t *data_offset, const scalar_t *data_mask,
-                                                             const int channels, const int height, const int width,
-                                                             const int kernel_h, const int kernel_w,
-                                                             const int pad_h, const int pad_w,
-                                                             const int stride_h, const int stride_w,
-                                                             const int dilation_h, const int dilation_w,
-                                                             const int channel_per_deformable_group,
-                                                             const int batch_size, const int offset_channels, const int deformable_group,
-                                                             const int height_col, const int width_col,
-                                                             scalar_t *grad_offset, scalar_t *grad_mask)
-{
-  CUDA_KERNEL_LOOP(index, n)
-  {
-    scalar_t val = 0, mval = 0;
-    int w = index % width_col;
-    int h = (index / width_col) % height_col;
-    int c = (index / width_col / height_col) % offset_channels;
-    int b = (index / width_col / height_col) / offset_channels;
-    // compute the start and end of the output
-
-    const int deformable_group_index = c / (2 * kernel_h * kernel_w);
-    const int col_step = kernel_h * kernel_w;
-    int cnt = 0;
-    const scalar_t *data_col_ptr = data_col + deformable_group_index * channel_per_deformable_group * batch_size * width_col * height_col;
-    const scalar_t *data_im_ptr = data_im + (b * deformable_group + deformable_group_index) * channel_per_deformable_group / kernel_h / kernel_w * height * width;
-    const scalar_t *data_offset_ptr = data_offset + (b * deformable_group + deformable_group_index) * 2 * kernel_h * kernel_w * height_col * width_col;
-    const scalar_t *data_mask_ptr = data_mask + (b * deformable_group + deformable_group_index) * kernel_h * kernel_w * height_col * width_col;
-
-    const int offset_c = c - deformable_group_index * 2 * kernel_h * kernel_w;
-
-    for (int col_c = (offset_c / 2); col_c < channel_per_deformable_group; col_c += col_step)
-    {
-      const int col_pos = (((col_c * batch_size + b) * height_col) + h) * width_col + w;
-      const int bp_dir = offset_c % 2;
-
-      int j = (col_pos / width_col / height_col / batch_size) % kernel_w;
-      int i = (col_pos / width_col / height_col / batch_size / kernel_w) % kernel_h;
-      int w_out = col_pos % width_col;
-      int h_out = (col_pos / width_col) % height_col;
-      int w_in = w_out * stride_w - pad_w;
-      int h_in = h_out * stride_h - pad_h;
-      const int data_offset_h_ptr = (((2 * (i * kernel_w + j)) * height_col + h_out) * width_col + w_out);
-      const int data_offset_w_ptr = (((2 * (i * kernel_w + j) + 1) * height_col + h_out) * width_col + w_out);
-      const int data_mask_hw_ptr = (((i * kernel_w + j) * height_col + h_out) * width_col + w_out);
-      const scalar_t offset_h = data_offset_ptr[data_offset_h_ptr];
-      const scalar_t offset_w = data_offset_ptr[data_offset_w_ptr];
-      const scalar_t mask = data_mask_ptr[data_mask_hw_ptr];
-      scalar_t inv_h = h_in + i * dilation_h + offset_h;
-      scalar_t inv_w = w_in + j * dilation_w + offset_w;
-      if (inv_h <= -1 || inv_w <= -1 || inv_h >= height || inv_w >= width)
-      {
-        inv_h = inv_w = -2;
-      }
-      else
-      {
-        mval += data_col_ptr[col_pos] * dmcn_im2col_bilinear(data_im_ptr + cnt * height * width, width, height, width, inv_h, inv_w);
-      }
-      const scalar_t weight = dmcn_get_coordinate_weight(
-          inv_h, inv_w,
-          height, width, data_im_ptr + cnt * height * width, width, bp_dir);
-      val += weight * data_col_ptr[col_pos] * mask;
-      cnt += 1;
-    }
-    // KERNEL_ASSIGN(grad_offset[index], offset_req, val);
-    grad_offset[index] = val;
-    if (offset_c % 2 == 0)
-      // KERNEL_ASSIGN(grad_mask[(((b * deformable_group + deformable_group_index) * kernel_h * kernel_w + offset_c / 2) * height_col + h) * width_col + w], mask_req, mval);
-      grad_mask[(((b * deformable_group + deformable_group_index) * kernel_h * kernel_w + offset_c / 2) * height_col + h) * width_col + w] = mval;
-  }
-}
-
-void modulated_deformable_im2col_cuda(
-    const at::Tensor data_im, const at::Tensor data_offset, const at::Tensor data_mask,
-    const int batch_size, const int channels, const int height_im, const int width_im,
-    const int height_col, const int width_col, const int kernel_h, const int kenerl_w,
-    const int pad_h, const int pad_w, const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w,
-    const int deformable_group, at::Tensor data_col)
-{
-  // num_axes should be smaller than block size
-  const int channel_per_deformable_group = channels / deformable_group;
-  const int num_kernels = channels * batch_size * height_col * width_col;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      data_im.type(), "modulated_deformable_im2col_gpu", ([&] {
-        const scalar_t *data_im_ = data_im.data<scalar_t>();
-        const scalar_t *data_offset_ = data_offset.data<scalar_t>();
-        const scalar_t *data_mask_ = data_mask.data<scalar_t>();
-        scalar_t *data_col_ = data_col.data<scalar_t>();
-
-        modulated_deformable_im2col_gpu_kernel<<<GET_BLOCKS(num_kernels), CUDA_NUM_THREADS>>>(
-            num_kernels, data_im_, data_offset_, data_mask_, height_im, width_im, kernel_h, kenerl_w,
-            pad_h, pad_w, stride_h, stride_w, dilation_h, dilation_w, channel_per_deformable_group,
-            batch_size, channels, deformable_group, height_col, width_col, data_col_);
-      }));
-
-  cudaError_t err = cudaGetLastError();
-  if (err != cudaSuccess)
-  {
-    printf("error in modulated_deformable_im2col_cuda: %s\n", cudaGetErrorString(err));
-  }
-}
-
-void modulated_deformable_col2im_cuda(
-    const at::Tensor data_col, const at::Tensor data_offset, const at::Tensor data_mask,
-    const int batch_size, const int channels, const int height_im, const int width_im,
-    const int height_col, const int width_col, const int kernel_h, const int kernel_w,
-    const int pad_h, const int pad_w, const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w,
-    const int deformable_group, at::Tensor grad_im)
-{
-
-  const int channel_per_deformable_group = channels / deformable_group;
-  const int num_kernels = channels * kernel_h * kernel_w * batch_size * height_col * width_col;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      data_col.type(), "modulated_deformable_col2im_gpu", ([&] {
-        const scalar_t *data_col_ = data_col.data<scalar_t>();
-        const scalar_t *data_offset_ = data_offset.data<scalar_t>();
-        const scalar_t *data_mask_ = data_mask.data<scalar_t>();
-        scalar_t *grad_im_ = grad_im.data<scalar_t>();
-
-        modulated_deformable_col2im_gpu_kernel<<<GET_BLOCKS(num_kernels), CUDA_NUM_THREADS>>>(
-            num_kernels, data_col_, data_offset_, data_mask_, channels, height_im, width_im,
-            kernel_h, kernel_w, pad_h, pad_h, stride_h, stride_w,
-            dilation_h, dilation_w, channel_per_deformable_group,
-            batch_size, deformable_group, height_col, width_col, grad_im_);
-      }));
-
-  cudaError_t err = cudaGetLastError();
-  if (err != cudaSuccess)
-  {
-    printf("error in modulated_deformable_col2im_cuda: %s\n", cudaGetErrorString(err));
-  }
-}
-
-void modulated_deformable_col2im_coord_cuda(
-    const at::Tensor data_col, const at::Tensor data_im, const at::Tensor data_offset, const at::Tensor data_mask,
-    const int batch_size, const int channels, const int height_im, const int width_im,
-    const int height_col, const int width_col, const int kernel_h, const int kernel_w,
-    const int pad_h, const int pad_w, const int stride_h, const int stride_w,
-    const int dilation_h, const int dilation_w,
-    const int deformable_group,
-    at::Tensor grad_offset, at::Tensor grad_mask)
-{
-  const int num_kernels = batch_size * height_col * width_col * 2 * kernel_h * kernel_w * deformable_group;
-  const int channel_per_deformable_group = channels * kernel_h * kernel_w / deformable_group;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      data_col.type(), "modulated_deformable_col2im_coord_gpu", ([&] {
-        const scalar_t *data_col_ = data_col.data<scalar_t>();
-        const scalar_t *data_im_ = data_im.data<scalar_t>();
-        const scalar_t *data_offset_ = data_offset.data<scalar_t>();
-        const scalar_t *data_mask_ = data_mask.data<scalar_t>();
-        scalar_t *grad_offset_ = grad_offset.data<scalar_t>();
-        scalar_t *grad_mask_ = grad_mask.data<scalar_t>();
-
-        modulated_deformable_col2im_coord_gpu_kernel<<<GET_BLOCKS(num_kernels), CUDA_NUM_THREADS>>>(
-            num_kernels, data_col_, data_im_, data_offset_, data_mask_, channels, height_im, width_im,
-            kernel_h, kernel_w, pad_h, pad_w, stride_h, stride_w,
-            dilation_h, dilation_w, channel_per_deformable_group,
-            batch_size, 2 * kernel_h * kernel_w * deformable_group, deformable_group, height_col, width_col,
-            grad_offset_, grad_mask_);
-      }));
-  cudaError_t err = cudaGetLastError();
-  if (err != cudaSuccess)
-  {
-    printf("error in modulated_deformable_col2im_coord_cuda: %s\n", cudaGetErrorString(err));
-  }
-}
diff --git a/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.cu b/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.cu
deleted file mode 100644
index 71f305a..0000000
--- a/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.cu
+++ /dev/null
@@ -1,87 +0,0 @@
-// modify from
-// https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/blob/mmdetection/mmdet/ops/dcn/src/modulated_dcn_cuda.c
-
-// based on
-// author: Charles Shang
-// https://github.com/torch/cunn/blob/master/lib/THCUNN/generic/SpatialConvolutionMM.cu
-
-#include <ATen/ATen.h>
-#include <ATen/cuda/CUDAContext.h>
-
-#include <THC/THC.h>
-#include <THC/THCDeviceUtils.cuh>
-
-#include <vector>
-#include <iostream>
-#include <cmath>
-
-
-void DeformablePSROIPoolForward(
-    const at::Tensor data, const at::Tensor bbox, const at::Tensor trans,
-    at::Tensor out, at::Tensor top_count, const int batch, const int channels,
-    const int height, const int width, const int num_bbox,
-    const int channels_trans, const int no_trans, const float spatial_scale,
-    const int output_dim, const int group_size, const int pooled_size,
-    const int part_size, const int sample_per_part, const float trans_std);
-
-void DeformablePSROIPoolBackwardAcc(
-    const at::Tensor out_grad, const at::Tensor data, const at::Tensor bbox,
-    const at::Tensor trans, const at::Tensor top_count, at::Tensor in_grad,
-    at::Tensor trans_grad, const int batch, const int channels,
-    const int height, const int width, const int num_bbox,
-    const int channels_trans, const int no_trans, const float spatial_scale,
-    const int output_dim, const int group_size, const int pooled_size,
-    const int part_size, const int sample_per_part, const float trans_std);
-
-void deform_psroi_pooling_cuda_forward(
-    at::Tensor input, at::Tensor bbox, at::Tensor trans, at::Tensor out,
-    at::Tensor top_count, const int no_trans, const float spatial_scale,
-    const int output_dim, const int group_size, const int pooled_size,
-    const int part_size, const int sample_per_part, const float trans_std) 
-{
-  AT_CHECK(input.is_contiguous(), "input tensor has to be contiguous");
-
-  const int batch = input.size(0);
-  const int channels = input.size(1);
-  const int height = input.size(2);
-  const int width = input.size(3);
-  const int channels_trans = no_trans ? 2 : trans.size(1);
-
-  const int num_bbox = bbox.size(0);
-  if (num_bbox != out.size(0))
-    AT_ERROR("Output shape and bbox number wont match: (%d vs %d).",
-             out.size(0), num_bbox);
-
-  DeformablePSROIPoolForward(
-      input, bbox, trans, out, top_count, batch, channels, height, width,
-      num_bbox, channels_trans, no_trans, spatial_scale, output_dim, group_size,
-      pooled_size, part_size, sample_per_part, trans_std);
-}
-
-void deform_psroi_pooling_cuda_backward(
-    at::Tensor out_grad, at::Tensor input, at::Tensor bbox, at::Tensor trans,
-    at::Tensor top_count, at::Tensor input_grad, at::Tensor trans_grad,
-    const int no_trans, const float spatial_scale, const int output_dim,
-    const int group_size, const int pooled_size, const int part_size,
-    const int sample_per_part, const float trans_std) 
-{
-  AT_CHECK(out_grad.is_contiguous(), "out_grad tensor has to be contiguous");
-  AT_CHECK(input.is_contiguous(), "input tensor has to be contiguous");
-
-  const int batch = input.size(0);
-  const int channels = input.size(1);
-  const int height = input.size(2);
-  const int width = input.size(3);
-  const int channels_trans = no_trans ? 2 : trans.size(1);
-
-  const int num_bbox = bbox.size(0);
-  if (num_bbox != out_grad.size(0))
-    AT_ERROR("Output shape and bbox number wont match: (%d vs %d).",
-             out_grad.size(0), num_bbox);
-
-  DeformablePSROIPoolBackwardAcc(
-      out_grad, input, bbox, trans, top_count, input_grad, trans_grad, batch,
-      channels, height, width, num_bbox, channels_trans, no_trans,
-      spatial_scale, output_dim, group_size, pooled_size, part_size,
-      sample_per_part, trans_std);
-}
diff --git a/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu b/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu
deleted file mode 100644
index 127899e..0000000
--- a/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu
+++ /dev/null
@@ -1,365 +0,0 @@
-/*!
- * Copyright (c) 2017 Microsoft
- * Licensed under The MIT License [see LICENSE for details]
- * \file deformable_psroi_pooling.cu
- * \brief
- * \author Yi Li, Guodong Zhang, Jifeng Dai
-*/
-/***************** Adapted by Charles Shang *********************/
-// modify from https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/blob/mmdetection/mmdet/ops/dcn/src/cuda/deform_psroi_pooling_cuda.cu
-
-
-#include <ATen/ATen.h>
-#include <THC/THCAtomics.cuh>
-#include <stdio.h>
-#include <math.h>
-#include <algorithm>
-
-using namespace at;
-
-#define CUDA_KERNEL_LOOP(i, n)                        \
-  for (int i = blockIdx.x * blockDim.x + threadIdx.x; \
-       i < (n);                                       \
-       i += blockDim.x * gridDim.x)
-
-const int CUDA_NUM_THREADS = 1024;
-inline int GET_BLOCKS(const int N)
-{
-  return (N + CUDA_NUM_THREADS - 1) / CUDA_NUM_THREADS;
-}
-
-template <typename scalar_t>
-__device__ scalar_t bilinear_interp(
-    const scalar_t *data,
-    const scalar_t x,
-    const scalar_t y,
-    const int width,
-    const int height)
-{
-  int x1 = floor(x);
-  int x2 = ceil(x);
-  int y1 = floor(y);
-  int y2 = ceil(y);
-  scalar_t dist_x = (scalar_t)(x - x1);
-  scalar_t dist_y = (scalar_t)(y - y1);
-  scalar_t value11 = data[y1 * width + x1];
-  scalar_t value12 = data[y2 * width + x1];
-  scalar_t value21 = data[y1 * width + x2];
-  scalar_t value22 = data[y2 * width + x2];
-  scalar_t value = (1 - dist_x) * (1 - dist_y) * value11 + (1 - dist_x) * dist_y * value12 + dist_x * (1 - dist_y) * value21 + dist_x * dist_y * value22;
-  return value;
-}
-
-template <typename scalar_t>
-__global__ void DeformablePSROIPoolForwardKernel(
-    const int count,
-    const scalar_t *bottom_data,
-    const scalar_t spatial_scale,
-    const int channels,
-    const int height, const int width,
-    const int pooled_height, const int pooled_width,
-    const scalar_t *bottom_rois, const scalar_t *bottom_trans,
-    const int no_trans,
-    const scalar_t trans_std,
-    const int sample_per_part,
-    const int output_dim,
-    const int group_size,
-    const int part_size,
-    const int num_classes,
-    const int channels_each_class,
-    scalar_t *top_data,
-    scalar_t *top_count)
-{
-  CUDA_KERNEL_LOOP(index, count)
-  {
-    // The output is in order (n, ctop, ph, pw)
-    int pw = index % pooled_width;
-    int ph = (index / pooled_width) % pooled_height;
-    int ctop = (index / pooled_width / pooled_height) % output_dim;
-    int n = index / pooled_width / pooled_height / output_dim;
-
-    // [start, end) interval for spatial sampling
-    const scalar_t *offset_bottom_rois = bottom_rois + n * 5;
-    int roi_batch_ind = offset_bottom_rois[0];
-    scalar_t roi_start_w = (scalar_t)(round(offset_bottom_rois[1])) * spatial_scale - 0.5;
-    scalar_t roi_start_h = (scalar_t)(round(offset_bottom_rois[2])) * spatial_scale - 0.5;
-    scalar_t roi_end_w = (scalar_t)(round(offset_bottom_rois[3]) + 1.) * spatial_scale - 0.5;
-    scalar_t roi_end_h = (scalar_t)(round(offset_bottom_rois[4]) + 1.) * spatial_scale - 0.5;
-
-    // Force too small ROIs to be 1x1
-    scalar_t roi_width = max(roi_end_w - roi_start_w, 0.1); //avoid 0
-    scalar_t roi_height = max(roi_end_h - roi_start_h, 0.1);
-
-    // Compute w and h at bottom
-    scalar_t bin_size_h = roi_height / (scalar_t)(pooled_height);
-    scalar_t bin_size_w = roi_width / (scalar_t)(pooled_width);
-
-    scalar_t sub_bin_size_h = bin_size_h / (scalar_t)(sample_per_part);
-    scalar_t sub_bin_size_w = bin_size_w / (scalar_t)(sample_per_part);
-
-    int part_h = floor((scalar_t)(ph) / pooled_height * part_size);
-    int part_w = floor((scalar_t)(pw) / pooled_width * part_size);
-    int class_id = ctop / channels_each_class;
-    scalar_t trans_x = no_trans ? (scalar_t)(0) : bottom_trans[(((n * num_classes + class_id) * 2) * part_size + part_h) * part_size + part_w] * (scalar_t)trans_std;
-    scalar_t trans_y = no_trans ? (scalar_t)(0) : bottom_trans[(((n * num_classes + class_id) * 2 + 1) * part_size + part_h) * part_size + part_w] * (scalar_t)trans_std;
-
-    scalar_t wstart = (scalar_t)(pw)*bin_size_w + roi_start_w;
-    wstart += trans_x * roi_width;
-    scalar_t hstart = (scalar_t)(ph)*bin_size_h + roi_start_h;
-    hstart += trans_y * roi_height;
-
-    scalar_t sum = 0;
-    int count = 0;
-    int gw = floor((scalar_t)(pw)*group_size / pooled_width);
-    int gh = floor((scalar_t)(ph)*group_size / pooled_height);
-    gw = min(max(gw, 0), group_size - 1);
-    gh = min(max(gh, 0), group_size - 1);
-
-    const scalar_t *offset_bottom_data = bottom_data + (roi_batch_ind * channels) * height * width;
-    for (int ih = 0; ih < sample_per_part; ih++)
-    {
-      for (int iw = 0; iw < sample_per_part; iw++)
-      {
-        scalar_t w = wstart + iw * sub_bin_size_w;
-        scalar_t h = hstart + ih * sub_bin_size_h;
-        // bilinear interpolation
-        if (w < -0.5 || w > width - 0.5 || h < -0.5 || h > height - 0.5)
-        {
-          continue;
-        }
-        w = min(max(w, 0.), width - 1.);
-        h = min(max(h, 0.), height - 1.);
-        int c = (ctop * group_size + gh) * group_size + gw;
-        scalar_t val = bilinear_interp(offset_bottom_data + c * height * width, w, h, width, height);
-        sum += val;
-        count++;
-      }
-    }
-    top_data[index] = count == 0 ? (scalar_t)(0) : sum / count;
-    top_count[index] = count;
-  }
-}
-
-template <typename scalar_t>
-__global__ void DeformablePSROIPoolBackwardAccKernel(
-    const int count,
-    const scalar_t *top_diff,
-    const scalar_t *top_count,
-    const int num_rois,
-    const scalar_t spatial_scale,
-    const int channels,
-    const int height, const int width,
-    const int pooled_height, const int pooled_width,
-    const int output_dim,
-    scalar_t *bottom_data_diff, scalar_t *bottom_trans_diff,
-    const scalar_t *bottom_data,
-    const scalar_t *bottom_rois,
-    const scalar_t *bottom_trans,
-    const int no_trans,
-    const scalar_t trans_std,
-    const int sample_per_part,
-    const int group_size,
-    const int part_size,
-    const int num_classes,
-    const int channels_each_class)
-{
-  CUDA_KERNEL_LOOP(index, count)
-  {
-    // The output is in order (n, ctop, ph, pw)
-    int pw = index % pooled_width;
-    int ph = (index / pooled_width) % pooled_height;
-    int ctop = (index / pooled_width / pooled_height) % output_dim;
-    int n = index / pooled_width / pooled_height / output_dim;
-
-    // [start, end) interval for spatial sampling
-    const scalar_t *offset_bottom_rois = bottom_rois + n * 5;
-    int roi_batch_ind = offset_bottom_rois[0];
-    scalar_t roi_start_w = (scalar_t)(round(offset_bottom_rois[1])) * spatial_scale - 0.5;
-    scalar_t roi_start_h = (scalar_t)(round(offset_bottom_rois[2])) * spatial_scale - 0.5;
-    scalar_t roi_end_w = (scalar_t)(round(offset_bottom_rois[3]) + 1.) * spatial_scale - 0.5;
-    scalar_t roi_end_h = (scalar_t)(round(offset_bottom_rois[4]) + 1.) * spatial_scale - 0.5;
-
-    // Force too small ROIs to be 1x1
-    scalar_t roi_width = max(roi_end_w - roi_start_w, 0.1); //avoid 0
-    scalar_t roi_height = max(roi_end_h - roi_start_h, 0.1);
-
-    // Compute w and h at bottom
-    scalar_t bin_size_h = roi_height / (scalar_t)(pooled_height);
-    scalar_t bin_size_w = roi_width / (scalar_t)(pooled_width);
-
-    scalar_t sub_bin_size_h = bin_size_h / (scalar_t)(sample_per_part);
-    scalar_t sub_bin_size_w = bin_size_w / (scalar_t)(sample_per_part);
-
-    int part_h = floor((scalar_t)(ph) / pooled_height * part_size);
-    int part_w = floor((scalar_t)(pw) / pooled_width * part_size);
-    int class_id = ctop / channels_each_class;
-    scalar_t trans_x = no_trans ? (scalar_t)(0) : bottom_trans[(((n * num_classes + class_id) * 2) * part_size + part_h) * part_size + part_w] * (scalar_t)trans_std;
-    scalar_t trans_y = no_trans ? (scalar_t)(0) : bottom_trans[(((n * num_classes + class_id) * 2 + 1) * part_size + part_h) * part_size + part_w] * (scalar_t)trans_std;
-
-    scalar_t wstart = (scalar_t)(pw)*bin_size_w + roi_start_w;
-    wstart += trans_x * roi_width;
-    scalar_t hstart = (scalar_t)(ph)*bin_size_h + roi_start_h;
-    hstart += trans_y * roi_height;
-
-    if (top_count[index] <= 0)
-    {
-      continue;
-    }
-    scalar_t diff_val = top_diff[index] / top_count[index];
-    const scalar_t *offset_bottom_data = bottom_data + roi_batch_ind * channels * height * width;
-    scalar_t *offset_bottom_data_diff = bottom_data_diff + roi_batch_ind * channels * height * width;
-    int gw = floor((scalar_t)(pw)*group_size / pooled_width);
-    int gh = floor((scalar_t)(ph)*group_size / pooled_height);
-    gw = min(max(gw, 0), group_size - 1);
-    gh = min(max(gh, 0), group_size - 1);
-
-    for (int ih = 0; ih < sample_per_part; ih++)
-    {
-      for (int iw = 0; iw < sample_per_part; iw++)
-      {
-        scalar_t w = wstart + iw * sub_bin_size_w;
-        scalar_t h = hstart + ih * sub_bin_size_h;
-        // bilinear interpolation
-        if (w < -0.5 || w > width - 0.5 || h < -0.5 || h > height - 0.5)
-        {
-          continue;
-        }
-        w = min(max(w, 0.), width - 1.);
-        h = min(max(h, 0.), height - 1.);
-        int c = (ctop * group_size + gh) * group_size + gw;
-        // backward on feature
-        int x0 = floor(w);
-        int x1 = ceil(w);
-        int y0 = floor(h);
-        int y1 = ceil(h);
-        scalar_t dist_x = w - x0, dist_y = h - y0;
-        scalar_t q00 = (1 - dist_x) * (1 - dist_y);
-        scalar_t q01 = (1 - dist_x) * dist_y;
-        scalar_t q10 = dist_x * (1 - dist_y);
-        scalar_t q11 = dist_x * dist_y;
-        int bottom_index_base = c * height * width;
-        atomicAdd(offset_bottom_data_diff + bottom_index_base + y0 * width + x0, q00 * diff_val);
-        atomicAdd(offset_bottom_data_diff + bottom_index_base + y1 * width + x0, q01 * diff_val);
-        atomicAdd(offset_bottom_data_diff + bottom_index_base + y0 * width + x1, q10 * diff_val);
-        atomicAdd(offset_bottom_data_diff + bottom_index_base + y1 * width + x1, q11 * diff_val);
-
-        if (no_trans)
-        {
-          continue;
-        }
-        scalar_t U00 = offset_bottom_data[bottom_index_base + y0 * width + x0];
-        scalar_t U01 = offset_bottom_data[bottom_index_base + y1 * width + x0];
-        scalar_t U10 = offset_bottom_data[bottom_index_base + y0 * width + x1];
-        scalar_t U11 = offset_bottom_data[bottom_index_base + y1 * width + x1];
-        scalar_t diff_x = (U11 * dist_y + U10 * (1 - dist_y) - U01 * dist_y - U00 * (1 - dist_y)) * trans_std * diff_val;
-        diff_x *= roi_width;
-        scalar_t diff_y = (U11 * dist_x + U01 * (1 - dist_x) - U10 * dist_x - U00 * (1 - dist_x)) * trans_std * diff_val;
-        diff_y *= roi_height;
-
-        atomicAdd(bottom_trans_diff + (((n * num_classes + class_id) * 2) * part_size + part_h) * part_size + part_w, diff_x);
-        atomicAdd(bottom_trans_diff + (((n * num_classes + class_id) * 2 + 1) * part_size + part_h) * part_size + part_w, diff_y);
-      }
-    }
-  }
-}
-
-void DeformablePSROIPoolForward(const at::Tensor data,
-                                const at::Tensor bbox,
-                                const at::Tensor trans,
-                                at::Tensor out,
-                                at::Tensor top_count,
-                                const int batch,
-                                const int channels,
-                                const int height,
-                                const int width,
-                                const int num_bbox,
-                                const int channels_trans,
-                                const int no_trans,
-                                const float spatial_scale,
-                                const int output_dim,
-                                const int group_size,
-                                const int pooled_size,
-                                const int part_size,
-                                const int sample_per_part,
-                                const float trans_std)
-{
-  const int pooled_height = pooled_size;
-  const int pooled_width = pooled_size;
-  const int count = num_bbox * output_dim * pooled_height * pooled_width;
-  const int num_classes = no_trans ? 1 : channels_trans / 2;
-  const int channels_each_class = no_trans ? output_dim : output_dim / num_classes;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      data.type(), "deformable_psroi_pool_forward", ([&] {
-        const scalar_t *bottom_data = data.data<scalar_t>();
-        const scalar_t *bottom_rois = bbox.data<scalar_t>();
-        const scalar_t *bottom_trans = no_trans ? NULL : trans.data<scalar_t>();
-        scalar_t *top_data = out.data<scalar_t>();
-        scalar_t *top_count_data = top_count.data<scalar_t>();
-
-        DeformablePSROIPoolForwardKernel<<<GET_BLOCKS(count), CUDA_NUM_THREADS>>>(
-            count, bottom_data, (scalar_t)spatial_scale, channels, height, width, pooled_height, pooled_width,
-            bottom_rois, bottom_trans, no_trans, (scalar_t)trans_std, sample_per_part, output_dim,
-            group_size, part_size, num_classes, channels_each_class, top_data, top_count_data);
-      }));
-
-  cudaError_t err = cudaGetLastError();
-  if (err != cudaSuccess)
-  {
-    printf("error in DeformablePSROIPoolForward: %s\n", cudaGetErrorString(err));
-  }
-}
-
-void DeformablePSROIPoolBackwardAcc(const at::Tensor out_grad,
-                                    const at::Tensor data,
-                                    const at::Tensor bbox,
-                                    const at::Tensor trans,
-                                    const at::Tensor top_count,
-                                    at::Tensor in_grad,
-                                    at::Tensor trans_grad,
-                                    const int batch,
-                                    const int channels,
-                                    const int height,
-                                    const int width,
-                                    const int num_bbox,
-                                    const int channels_trans,
-                                    const int no_trans,
-                                    const float spatial_scale,
-                                    const int output_dim,
-                                    const int group_size,
-                                    const int pooled_size,
-                                    const int part_size,
-                                    const int sample_per_part,
-                                    const float trans_std)
-{
-  // LOG(INFO) << "DeformablePSROIPoolBackward";
-  const int num_rois = num_bbox;
-  const int pooled_height = pooled_size;
-  const int pooled_width = pooled_size;
-  const int count = num_bbox * output_dim * pooled_height * pooled_width;
-  const int num_classes = no_trans ? 1 : channels_trans / 2;
-  const int channels_each_class = no_trans ? output_dim : output_dim / num_classes;
-
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-      out_grad.type(), "deformable_psroi_pool_backward_acc", ([&] {
-        const scalar_t *top_diff = out_grad.data<scalar_t>();
-        const scalar_t *bottom_data = data.data<scalar_t>();
-        const scalar_t *bottom_rois = bbox.data<scalar_t>();
-        const scalar_t *bottom_trans = no_trans ? NULL : trans.data<scalar_t>();
-        scalar_t *bottom_data_diff = in_grad.data<scalar_t>();
-        scalar_t *bottom_trans_diff = no_trans ? NULL : trans_grad.data<scalar_t>();
-        const scalar_t *top_count_data = top_count.data<scalar_t>();
-
-        DeformablePSROIPoolBackwardAccKernel<<<GET_BLOCKS(count), CUDA_NUM_THREADS>>>(
-            count, top_diff, top_count_data, num_rois, (scalar_t)spatial_scale, channels, height, width,
-            pooled_height, pooled_width, output_dim, bottom_data_diff, bottom_trans_diff,
-            bottom_data, bottom_rois, bottom_trans, no_trans, (scalar_t)trans_std, sample_per_part,
-            group_size, part_size, num_classes, channels_each_class);
-      }));
-
-  cudaError_t err = cudaGetLastError();
-  if (err != cudaSuccess)
-  {
-    printf("error in DeformablePSROIPoolForward: %s\n", cudaGetErrorString(err));
-  }
-}
\ No newline at end of file
diff --git a/maskrcnn_benchmark/csrc/cuda/vision.h b/maskrcnn_benchmark/csrc/cuda/vision.h
index 32d3c69..6d9f887 100644
--- a/maskrcnn_benchmark/csrc/cuda/vision.h
+++ b/maskrcnn_benchmark/csrc/cuda/vision.h
@@ -58,59 +58,6 @@ at::Tensor ROIPool_backward_cuda(const at::Tensor& grad,
 at::Tensor nms_cuda(const at::Tensor boxes, float nms_overlap_thresh);
 
 
-int deform_conv_forward_cuda(at::Tensor input, at::Tensor weight,
-                             at::Tensor offset, at::Tensor output,
-                             at::Tensor columns, at::Tensor ones, int kW,
-                             int kH, int dW, int dH, int padW, int padH,
-                             int dilationW, int dilationH, int group,
-                             int deformable_group, int im2col_step);
-
-int deform_conv_backward_input_cuda(at::Tensor input, at::Tensor offset,
-                                    at::Tensor gradOutput, at::Tensor gradInput,
-                                    at::Tensor gradOffset, at::Tensor weight,
-                                    at::Tensor columns, int kW, int kH, int dW,
-                                    int dH, int padW, int padH, int dilationW,
-                                    int dilationH, int group,
-                                    int deformable_group, int im2col_step);
-
-int deform_conv_backward_parameters_cuda(
-    at::Tensor input, at::Tensor offset, at::Tensor gradOutput,
-    at::Tensor gradWeight,  // at::Tensor gradBias,
-    at::Tensor columns, at::Tensor ones, int kW, int kH, int dW, int dH,
-    int padW, int padH, int dilationW, int dilationH, int group,
-    int deformable_group, float scale, int im2col_step);
-
-void modulated_deform_conv_cuda_forward(
-    at::Tensor input, at::Tensor weight, at::Tensor bias, at::Tensor ones,
-    at::Tensor offset, at::Tensor mask, at::Tensor output, at::Tensor columns,
-    int kernel_h, int kernel_w, const int stride_h, const int stride_w,
-    const int pad_h, const int pad_w, const int dilation_h,
-    const int dilation_w, const int group, const int deformable_group,
-    const bool with_bias);
-
-void modulated_deform_conv_cuda_backward(
-    at::Tensor input, at::Tensor weight, at::Tensor bias, at::Tensor ones,
-    at::Tensor offset, at::Tensor mask, at::Tensor columns,
-    at::Tensor grad_input, at::Tensor grad_weight, at::Tensor grad_bias,
-    at::Tensor grad_offset, at::Tensor grad_mask, at::Tensor grad_output,
-    int kernel_h, int kernel_w, int stride_h, int stride_w, int pad_h,
-    int pad_w, int dilation_h, int dilation_w, int group, int deformable_group,
-    const bool with_bias);
-
-void deform_psroi_pooling_cuda_forward(
-    at::Tensor input, at::Tensor bbox, at::Tensor trans, at::Tensor out,
-    at::Tensor top_count, const int no_trans, const float spatial_scale,
-    const int output_dim, const int group_size, const int pooled_size,
-    const int part_size, const int sample_per_part, const float trans_std);
-
-void deform_psroi_pooling_cuda_backward(
-    at::Tensor out_grad, at::Tensor input, at::Tensor bbox, at::Tensor trans,
-    at::Tensor top_count, at::Tensor input_grad, at::Tensor trans_grad,
-    const int no_trans, const float spatial_scale, const int output_dim,
-    const int group_size, const int pooled_size, const int part_size,
-    const int sample_per_part, const float trans_std);
-
-
 at::Tensor compute_flow_cuda(const at::Tensor& boxes,
                              const int height,
                              const int width);
diff --git a/maskrcnn_benchmark/csrc/deform_conv.h b/maskrcnn_benchmark/csrc/deform_conv.h
deleted file mode 100644
index a5930e3..0000000
--- a/maskrcnn_benchmark/csrc/deform_conv.h
+++ /dev/null
@@ -1,191 +0,0 @@
-// Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-#pragma once
-#include "cpu/vision.h"
-
-#ifdef WITH_CUDA
-#include "cuda/vision.h"
-#endif
-
-
-// Interface for Python
-int deform_conv_forward(
-    at::Tensor input, 
-    at::Tensor weight,
-    at::Tensor offset, 
-    at::Tensor output,
-    at::Tensor columns, 
-    at::Tensor ones, 
-    int kW,
-    int kH, 
-    int dW, 
-    int dH, 
-    int padW, 
-    int padH,
-    int dilationW, 
-    int dilationH, 
-    int group,
-    int deformable_group, 
-    int im2col_step)
-{
-  if (input.type().is_cuda()) {
-#ifdef WITH_CUDA
-    return deform_conv_forward_cuda(
-        input, weight, offset, output, columns, ones,
-        kW, kH, dW, dH, padW, padH, dilationW, dilationH,
-        group, deformable_group, im2col_step
-    );
-#else
-    AT_ERROR("Not compiled with GPU support");
-#endif
-  }
-  AT_ERROR("Not implemented on the CPU");
-}
-
-
-int deform_conv_backward_input(
-    at::Tensor input, 
-    at::Tensor offset,
-    at::Tensor gradOutput, 
-    at::Tensor gradInput,
-    at::Tensor gradOffset, 
-    at::Tensor weight,
-    at::Tensor columns, 
-    int kW, 
-    int kH, 
-    int dW,
-    int dH, 
-    int padW, 
-    int padH, 
-    int dilationW,
-    int dilationH, 
-    int group,
-    int deformable_group, 
-    int im2col_step)
-{
-  if (input.type().is_cuda()) {
-#ifdef WITH_CUDA
-    return deform_conv_backward_input_cuda(
-        input, offset, gradOutput, gradInput, gradOffset, weight, columns,
-        kW, kH, dW, dH, padW, padH, dilationW, dilationH, 
-        group, deformable_group, im2col_step
-    );
-#else
-    AT_ERROR("Not compiled with GPU support");
-#endif
-  }
-  AT_ERROR("Not implemented on the CPU");
-}
-
-
-int deform_conv_backward_parameters(
-    at::Tensor input, 
-    at::Tensor offset, 
-    at::Tensor gradOutput,
-    at::Tensor gradWeight,  // at::Tensor gradBias,
-    at::Tensor columns, 
-    at::Tensor ones, 
-    int kW, 
-    int kH, 
-    int dW, 
-    int dH,
-    int padW, 
-    int padH, 
-    int dilationW, 
-    int dilationH, 
-    int group,
-    int deformable_group, 
-    float scale, 
-    int im2col_step)
-{
-  if (input.type().is_cuda()) {
-#ifdef WITH_CUDA
-    return deform_conv_backward_parameters_cuda(
-        input, offset, gradOutput, gradWeight, columns, ones,
-        kW, kH, dW, dH, padW, padH, dilationW, dilationH,
-        group, deformable_group, scale, im2col_step
-    );
-#else
-    AT_ERROR("Not compiled with GPU support");
-#endif
-  }
-  AT_ERROR("Not implemented on the CPU");
-}
-
-
-void modulated_deform_conv_forward(
-    at::Tensor input, 
-    at::Tensor weight, 
-    at::Tensor bias, 
-    at::Tensor ones,
-    at::Tensor offset, 
-    at::Tensor mask, 
-    at::Tensor output, 
-    at::Tensor columns,
-    int kernel_h, 
-    int kernel_w, 
-    const int stride_h, 
-    const int stride_w,
-    const int pad_h, 
-    const int pad_w, 
-    const int dilation_h,
-    const int dilation_w, 
-    const int group, 
-    const int deformable_group,
-    const bool with_bias)
-{
-  if (input.type().is_cuda()) {
-#ifdef WITH_CUDA
-    return modulated_deform_conv_cuda_forward(
-        input, weight, bias, ones, offset, mask, output, columns,
-        kernel_h, kernel_w, stride_h, stride_w, 
-        pad_h, pad_w, dilation_h, dilation_w,
-        group, deformable_group, with_bias
-    );
-#else
-    AT_ERROR("Not compiled with GPU support");
-#endif
-  }
-  AT_ERROR("Not implemented on the CPU");
-}
-
-
-void modulated_deform_conv_backward(
-    at::Tensor input, 
-    at::Tensor weight, 
-    at::Tensor bias, 
-    at::Tensor ones,
-    at::Tensor offset, 
-    at::Tensor mask, 
-    at::Tensor columns,
-    at::Tensor grad_input, 
-    at::Tensor grad_weight, 
-    at::Tensor grad_bias,
-    at::Tensor grad_offset, 
-    at::Tensor grad_mask, 
-    at::Tensor grad_output,
-    int kernel_h, 
-    int kernel_w, 
-    int stride_h, 
-    int stride_w, 
-    int pad_h,
-    int pad_w, 
-    int dilation_h, 
-    int dilation_w, 
-    int group, 
-    int deformable_group,
-    const bool with_bias)
-{
-  if (input.type().is_cuda()) {
-#ifdef WITH_CUDA
-    return modulated_deform_conv_cuda_backward(
-        input, weight, bias, ones, offset, mask, columns, 
-        grad_input, grad_weight, grad_bias, grad_offset, grad_mask, grad_output,
-        kernel_h, kernel_w, stride_h, stride_w, pad_h, pad_w, dilation_h, dilation_w,
-        group, deformable_group, with_bias
-    );
-#else
-    AT_ERROR("Not compiled with GPU support");
-#endif
-  }
-  AT_ERROR("Not implemented on the CPU");
-}
\ No newline at end of file
diff --git a/maskrcnn_benchmark/csrc/deform_pool.h b/maskrcnn_benchmark/csrc/deform_pool.h
deleted file mode 100644
index 2342238..0000000
--- a/maskrcnn_benchmark/csrc/deform_pool.h
+++ /dev/null
@@ -1,70 +0,0 @@
-// Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-#pragma once
-#include "cpu/vision.h"
-
-#ifdef WITH_CUDA
-#include "cuda/vision.h"
-#endif
-
-
-// Interface for Python
-void deform_psroi_pooling_forward(
-    at::Tensor input, 
-    at::Tensor bbox, 
-    at::Tensor trans, 
-    at::Tensor out,
-    at::Tensor top_count, 
-    const int no_trans, 
-    const float spatial_scale,
-    const int output_dim, 
-    const int group_size, 
-    const int pooled_size,
-    const int part_size, 
-    const int sample_per_part, 
-    const float trans_std)
-{
-  if (input.type().is_cuda()) {
-#ifdef WITH_CUDA
-    return deform_psroi_pooling_cuda_forward(
-        input, bbox, trans, out, top_count, 
-        no_trans, spatial_scale, output_dim, group_size,
-        pooled_size, part_size, sample_per_part, trans_std
-    );
-#else
-    AT_ERROR("Not compiled with GPU support");
-#endif
-  }
-  AT_ERROR("Not implemented on the CPU");
-}
-
-
-void deform_psroi_pooling_backward(
-    at::Tensor out_grad, 
-    at::Tensor input, 
-    at::Tensor bbox, 
-    at::Tensor trans,
-    at::Tensor top_count, 
-    at::Tensor input_grad, 
-    at::Tensor trans_grad,
-    const int no_trans, 
-    const float spatial_scale, 
-    const int output_dim,
-    const int group_size, 
-    const int pooled_size, 
-    const int part_size,
-    const int sample_per_part, 
-    const float trans_std) 
-{
-  if (input.type().is_cuda()) {
-#ifdef WITH_CUDA
-    return deform_psroi_pooling_cuda_backward(
-        out_grad, input, bbox, trans, top_count, input_grad, trans_grad,
-        no_trans, spatial_scale, output_dim, group_size, pooled_size, 
-        part_size, sample_per_part, trans_std
-    );
-#else
-    AT_ERROR("Not compiled with GPU support");
-#endif
-  }
-  AT_ERROR("Not implemented on the CPU");
-}
diff --git a/maskrcnn_benchmark/csrc/vision.cpp b/maskrcnn_benchmark/csrc/vision.cpp
index 3097199..8234f43 100644
--- a/maskrcnn_benchmark/csrc/vision.cpp
+++ b/maskrcnn_benchmark/csrc/vision.cpp
@@ -3,8 +3,6 @@
 #include "ROIAlign.h"
 #include "ROIPool.h"
 #include "SigmoidFocalLoss.h"
-#include "deform_conv.h"
-#include "deform_pool.h"
 
 PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
   m.def("nms", &nms, "non-maximum suppression");
@@ -14,12 +12,4 @@ PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
   m.def("roi_pool_backward", &ROIPool_backward, "ROIPool_backward");
   m.def("sigmoid_focalloss_forward", &SigmoidFocalLoss_forward, "SigmoidFocalLoss_forward");
   m.def("sigmoid_focalloss_backward", &SigmoidFocalLoss_backward, "SigmoidFocalLoss_backward");
-  // dcn-v2
-  m.def("deform_conv_forward", &deform_conv_forward, "deform_conv_forward");
-  m.def("deform_conv_backward_input", &deform_conv_backward_input, "deform_conv_backward_input");
-  m.def("deform_conv_backward_parameters", &deform_conv_backward_parameters, "deform_conv_backward_parameters");
-  m.def("modulated_deform_conv_forward", &modulated_deform_conv_forward, "modulated_deform_conv_forward");
-  m.def("modulated_deform_conv_backward", &modulated_deform_conv_backward, "modulated_deform_conv_backward");
-  m.def("deform_psroi_pooling_forward", &deform_psroi_pooling_forward, "deform_psroi_pooling_forward");
-  m.def("deform_psroi_pooling_backward", &deform_psroi_pooling_backward, "deform_psroi_pooling_backward");
-}
\ No newline at end of file
+}
diff --git a/maskrcnn_benchmark/data/README.md b/maskrcnn_benchmark/data/README.md
index 8ae85e0..ef6508f 100644
--- a/maskrcnn_benchmark/data/README.md
+++ b/maskrcnn_benchmark/data/README.md
@@ -33,7 +33,7 @@ cd ~/github/maskrcnn-benchmark
 mkdir -p datasets/voc/VOC<year>
 ln -s /path/to/VOC<year> /datasets/voc/VOC<year>
 ```
-Example configuration files for PASCAL VOC could be found [here](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/configs/pascal_voc/).
+Example configuration files for PASCAL VOC could be found [here](https://github.com/facebookresearch/maskrcnn-benchmark/blob/main/configs/pascal_voc/).
 
 ### PASCAL VOC Annotations in COCO Format
 To output COCO-style evaluation result, PASCAL VOC annotations in COCO json format is required and could be downloaded from [here](https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip)
@@ -70,10 +70,8 @@ ln -s /path/to/cityscapes datasets/data/cityscapes
 1. Download gtFine_trainvaltest.zip from https://www.cityscapes-dataset.com/downloads/ (login required)
 2. Extract it to /path/to/gtFine_trainvaltest
 ```
-cityscapes
-|_ gtFine_trainvaltest.zip
-|_ gtFine_trainvaltest
-   |_ gtFine
+gtFine_trainvaltest
+|_ gtFine
 ```
 3. Run the below commands to convert the annotations
 
@@ -81,10 +79,10 @@ cityscapes
 cd ~/github
 git clone https://github.com/mcordts/cityscapesScripts.git
 cd cityscapesScripts
-cp ~/github/maskrcnn-benchmark/tools/cityscapes/instances2dict_with_polygons.py cityscapesscripts/evaluation
+cp ~/github/maskrcnn-benchmark/tool/cityscapes/instances2dict_with_polygons.py cityscapesscripts/evaluation
 python setup.py install
 cd ~/github/maskrcnn-benchmark
-python tools/cityscapes/convert_cityscapes_to_coco.py --datadir /path/to/cityscapes --outdir /path/to/cityscapes/annotations
+python tools/cityscapes/convert_cityscapes_to_coco.py --datadir /path/to/gtFine_trainvaltest --outdir /path/to/cityscapes/annotations
 ```
 
 Example configuration files for Cityscapes could be found [here](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/configs/cityscapes/).
diff --git a/maskrcnn_benchmark/data/__init__.py b/maskrcnn_benchmark/data/__init__.py
index 2ba1e52..f96d3a3 100644
--- a/maskrcnn_benchmark/data/__init__.py
+++ b/maskrcnn_benchmark/data/__init__.py
@@ -1,2 +1,15 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .build import make_data_loader
diff --git a/maskrcnn_benchmark/data/build.py b/maskrcnn_benchmark/data/build.py
index 090e631..2a179eb 100644
--- a/maskrcnn_benchmark/data/build.py
+++ b/maskrcnn_benchmark/data/build.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import bisect
 import copy
@@ -6,12 +19,11 @@ import logging
 import torch.utils.data
 from maskrcnn_benchmark.utils.comm import get_world_size
 from maskrcnn_benchmark.utils.imports import import_file
-from maskrcnn_benchmark.utils.miscellaneous import save_labels
 
 from . import datasets as D
 from . import samplers
 
-from .collate_batch import BatchCollator, BBoxAugCollator
+from .collate_batch import BatchCollator
 from .transforms import build_transforms
 
 
@@ -19,7 +31,7 @@ def build_dataset(dataset_list, transforms, dataset_catalog, is_train=True):
     """
     Arguments:
         dataset_list (list[str]): Contains the names of the datasets, i.e.,
-            coco_2014_train, coco_2014_val, etc
+            coco_2014_trian, coco_2014_val, etc
         transforms (callable): transforms to apply to each (image, target) sample
         dataset_catalog (DatasetCatalog): contains the information on how to
             construct a dataset.
@@ -30,6 +42,7 @@ def build_dataset(dataset_list, transforms, dataset_catalog, is_train=True):
             "dataset_list should be a list of strings, got {}".format(dataset_list)
         )
     datasets = []
+    total_datasets_size = 0
     for dataset_name in dataset_list:
         data = dataset_catalog.get(dataset_name)
         factory = getattr(D, data["factory"])
@@ -43,18 +56,19 @@ def build_dataset(dataset_list, transforms, dataset_catalog, is_train=True):
         args["transforms"] = transforms
         # make dataset from factory
         dataset = factory(**args)
+        total_datasets_size += len(dataset)
         datasets.append(dataset)
 
     # for testing, return a list of datasets
     if not is_train:
-        return datasets
+        return datasets, total_datasets_size
 
     # for training, concatenate all datasets into a single one
     dataset = datasets[0]
     if len(datasets) > 1:
         dataset = D.ConcatDataset(datasets)
 
-    return [dataset]
+    return [dataset], total_datasets_size
 
 
 def make_data_sampler(dataset, shuffle, distributed):
@@ -84,7 +98,7 @@ def _compute_aspect_ratios(dataset):
 
 
 def make_batch_data_sampler(
-    dataset, sampler, aspect_grouping, images_per_batch, num_iters=None, start_iter=0
+    dataset, sampler, aspect_grouping, images_per_batch, num_iters=None, start_iter=0, random_number_generator=None,
 ):
     if aspect_grouping:
         if not isinstance(aspect_grouping, (list, tuple)):
@@ -100,31 +114,33 @@ def make_batch_data_sampler(
         )
     if num_iters is not None:
         batch_sampler = samplers.IterationBasedBatchSampler(
-            batch_sampler, num_iters, start_iter
+            batch_sampler, num_iters, start_iter, random_number_generator
         )
     return batch_sampler
 
 
-def make_data_loader(cfg, is_train=True, is_distributed=False, start_iter=0, is_for_period=False):
+def make_data_loader(cfg, is_train=True, is_distributed=False, start_iter=0, random_number_generator=None, is_calib=False, iters=None):
     num_gpus = get_world_size()
     if is_train:
         images_per_batch = cfg.SOLVER.IMS_PER_BATCH
         assert (
             images_per_batch % num_gpus == 0
-        ), "SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.".format(
-            images_per_batch, num_gpus)
+        ), "SOLVER.IMS_PER_BATCH ({}) must be divisible by the number "
+        "of GPUs ({}) used.".format(images_per_batch, num_gpus)
         images_per_gpu = images_per_batch // num_gpus
         shuffle = True
         num_iters = cfg.SOLVER.MAX_ITER
     else:
-        images_per_batch = cfg.TEST.IMS_PER_BATCH
+        # images_per_batch = cfg.TEST.IMS_PER_BATCH
+        images_per_batch = 1 if is_calib else cfg.TEST.IMS_PER_BATCH
         assert (
             images_per_batch % num_gpus == 0
-        ), "TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.".format(
-            images_per_batch, num_gpus)
+        ), "TEST.IMS_PER_BATCH ({}) must be divisible by the number "
+        "of GPUs ({}) used.".format(images_per_batch, num_gpus)
         images_per_gpu = images_per_batch // num_gpus
         shuffle = False if not is_distributed else True
-        num_iters = None
+        # num_iters = None
+        num_iters = iters
         start_iter = 0
 
     if images_per_gpu > 1:
@@ -151,22 +167,16 @@ def make_data_loader(cfg, is_train=True, is_distributed=False, start_iter=0, is_
     DatasetCatalog = paths_catalog.DatasetCatalog
     dataset_list = cfg.DATASETS.TRAIN if is_train else cfg.DATASETS.TEST
 
-    # If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later
-    transforms = None if not is_train and cfg.TEST.BBOX_AUG.ENABLED else build_transforms(cfg, is_train)
-    datasets = build_dataset(dataset_list, transforms, DatasetCatalog, is_train or is_for_period)
-
-    if is_train:
-        # save category_id to label name mapping
-        save_labels(datasets, cfg.OUTPUT_DIR)
+    transforms = build_transforms(cfg, is_train)
+    datasets, epoch_size = build_dataset(dataset_list, transforms, DatasetCatalog, is_train)
 
     data_loaders = []
     for dataset in datasets:
         sampler = make_data_sampler(dataset, shuffle, is_distributed)
         batch_sampler = make_batch_data_sampler(
-            dataset, sampler, aspect_grouping, images_per_gpu, num_iters, start_iter
+            dataset, sampler, aspect_grouping, images_per_gpu, num_iters, start_iter, random_number_generator,
         )
-        collator = BBoxAugCollator() if not is_train and cfg.TEST.BBOX_AUG.ENABLED else \
-            BatchCollator(cfg.DATALOADER.SIZE_DIVISIBILITY)
+        collator = BatchCollator(cfg.DATALOADER.SIZE_DIVISIBILITY)
         num_workers = cfg.DATALOADER.NUM_WORKERS
         data_loader = torch.utils.data.DataLoader(
             dataset,
@@ -175,8 +185,9 @@ def make_data_loader(cfg, is_train=True, is_distributed=False, start_iter=0, is_
             collate_fn=collator,
         )
         data_loaders.append(data_loader)
-    if is_train or is_for_period:
+    if is_train:
         # during training, a single (possibly concatenated) data_loader is returned
         assert len(data_loaders) == 1
-        return data_loaders[0]
+        iterations_per_epoch = epoch_size // images_per_batch + 1
+        return data_loaders[0], iterations_per_epoch
     return data_loaders
diff --git a/maskrcnn_benchmark/data/collate_batch.py b/maskrcnn_benchmark/data/collate_batch.py
index 56571f1..2c87378 100644
--- a/maskrcnn_benchmark/data/collate_batch.py
+++ b/maskrcnn_benchmark/data/collate_batch.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from maskrcnn_benchmark.structures.image_list import to_image_list
 
@@ -18,15 +31,3 @@ class BatchCollator(object):
         targets = transposed_batch[1]
         img_ids = transposed_batch[2]
         return images, targets, img_ids
-
-
-class BBoxAugCollator(object):
-    """
-    From a list of samples from the dataset,
-    returns the images and targets.
-    Images should be converted to batched images in `im_detect_bbox_aug`
-    """
-
-    def __call__(self, batch):
-        return list(zip(*batch))
-
diff --git a/maskrcnn_benchmark/data/datasets/__init__.py b/maskrcnn_benchmark/data/datasets/__init__.py
index eefa7ca..3a17017 100644
--- a/maskrcnn_benchmark/data/datasets/__init__.py
+++ b/maskrcnn_benchmark/data/datasets/__init__.py
@@ -1,15 +1,19 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-
 from .coco import COCODataset
 from .voc import PascalVOCDataset
 from .concat_dataset import ConcatDataset
-from .abstract import AbstractDataset
-from .cityscapes import CityScapesDataset
 
-__all__ = [
-    "COCODataset",
-    "ConcatDataset",
-    "PascalVOCDataset",
-    "AbstractDataset",
-    "CityScapesDataset",
-]
+__all__ = ["COCODataset", "ConcatDataset", "PascalVOCDataset"]
diff --git a/maskrcnn_benchmark/data/datasets/abstract.py b/maskrcnn_benchmark/data/datasets/abstract.py
deleted file mode 100644
index c479434..0000000
--- a/maskrcnn_benchmark/data/datasets/abstract.py
+++ /dev/null
@@ -1,68 +0,0 @@
-import torch
-
-class AbstractDataset(torch.utils.data.Dataset):
-    """
-    Serves as a common interface to reduce boilerplate and help dataset
-    customization
-
-    A generic Dataset for the maskrcnn_benchmark must have the following
-    non-trivial fields / methods implemented:
-        CLASSES - list/tuple:
-            A list of strings representing the classes. It must have
-            "__background__" as its 0th element for correct id mapping.
-
-        __getitem__ - function(idx):
-            This has to return three things: img, target, idx.
-            img is the input image, which has to be load as a PIL Image object
-            implementing the target requires the most effort, since it must have
-            multiple fields: the size, bounding boxes, labels (contiguous), and
-            masks (either COCO-style Polygons, RLE or torch BinaryMask).
-            Usually the target is a BoxList instance with extra fields.
-            Lastly, idx is simply the input argument of the function.
-
-    also the following is required:
-        __len__ - function():
-            return the size of the dataset
-        get_img_info - function(idx):
-            return metadata, at least width and height of the input image
-    """
-
-    def __init__(self, *args, **kwargs):
-        self.name_to_id = None
-        self.id_to_name = None
-
-
-    def __getitem__(self, idx):
-        raise NotImplementedError
-
-
-    def initMaps(self):
-        """
-        Can be called optionally to initialize the id<->category name mapping
-
-
-        Initialize default mapping between:
-            class <==> index
-        class: this is a string that represents the class
-        index: positive int, used directly by the ROI heads.
-
-
-        NOTE:
-            make sure that the background is always indexed by 0.
-            "__background__" <==> 0
-
-            if initialized by hand, double check that the indexing is correct.
-        """
-        assert isinstance(self.CLASSES, (list, tuple))
-        assert self.CLASSES[0] == "__background__"
-        cls = self.CLASSES
-        self.name_to_id = dict(zip(cls, range(len(cls))))
-        self.id_to_name = dict(zip(range(len(cls)), cls))
-
-
-    def get_img_info(self, index):
-        raise NotImplementedError
-
-
-    def __len__(self):
-        raise NotImplementedError
diff --git a/maskrcnn_benchmark/data/datasets/cityscapes.py b/maskrcnn_benchmark/data/datasets/cityscapes.py
deleted file mode 100644
index f5b9784..0000000
--- a/maskrcnn_benchmark/data/datasets/cityscapes.py
+++ /dev/null
@@ -1,236 +0,0 @@
-import os
-import glob
-import json
-from PIL import Image
-
-
-import numpy as np
-import torch
-import torchvision
-
-
-from maskrcnn_benchmark.structures.bounding_box import BoxList
-from maskrcnn_benchmark.structures.segmentation_mask import SegmentationMask
-from .abstract import AbstractDataset
-
-from cityscapesscripts.helpers import csHelpers
-
-
-class CityScapesDataset(AbstractDataset):
-    def __init__(
-        self,
-        img_dir,
-        ann_dir,
-        split,
-        mode="mask",
-        transforms=None,
-        min_area=0,
-        mini=None,
-    ):
-        """
-        Arguments:
-            img_dir: /path/to/leftImg8bit/      has to contain {train,val,test}
-            ann_dir: /path/to/gtFine/           has to contain {train,val,test}
-            split: "train" or "val" or "test"
-            mode: "poly" or "mask", which annotation format to use
-            transforms: apply transformations to input/annotation
-            min_area: exclude intances below a specific area (bbox area)
-            mini: limit the size of the dataset, so len(dataset) == mini for
-                debugging purposes
-        """
-        assert split in ["train", "val", "test"]
-
-        img_dir = os.path.abspath(os.path.join(img_dir, split))
-        ann_dir = os.path.abspath(os.path.join(ann_dir, split))
-
-        assert os.path.exists(img_dir), img_dir
-        assert os.path.exists(ann_dir), ann_dr
-
-        self.ann_dir = ann_dir
-
-        self.split = split
-        self.CLASSES = ["__background__"]
-        self.CLASSES += [l.name for l in csHelpers.labels if l.hasInstances]
-
-        # Adds name_to_id and id_to_name mapping
-        self.initMaps()
-
-        # This is required for parsing binary masks
-        self.cityscapesID_to_ind = {
-            l.id: self.name_to_id[l.name] for l in csHelpers.labels if l.hasInstances
-        }
-
-        self.transforms = transforms
-        self.min_area = int(min_area)
-
-        img_pattern = os.path.join(img_dir, "*", "*_leftImg8bit.png")
-        img_paths = sorted(glob.glob(img_pattern))
-
-        if mode == "mask":
-            ann_pattern = os.path.join(ann_dir, "*", "*_instanceIds.png")
-        elif mode == "poly":
-            ann_pattern = os.path.join(ann_dir, "*", "*_polygons.json")
-        else:
-            raise NotImplementedError("Mode is not implemented yet: %s" % mode)
-
-        self.mode = mode
-        ann_paths = sorted(glob.glob(ann_pattern))
-
-        if mini is not None:
-            # Keep the mini dataset diverse by setting the stride
-            img_paths = img_paths[:: len(img_paths) // mini + 1]
-            ann_paths = ann_paths[:: len(ann_paths) // mini + 1]
-
-        assert len(img_paths) == len(ann_paths)
-
-        self.img_paths = img_paths
-        self.ann_paths = ann_paths
-
-    def __getitem__(self, idx):
-        img_path = self.img_paths[idx]
-        ann_path = self.ann_paths[idx]
-
-        if self.mode == "mask":
-            ann = torch.from_numpy(np.asarray(Image.open(ann_path)))
-            # masks are represented with tensors
-            boxes, segmentations, labels = self._processBinayMasks(ann)
-        else:
-            with open(ann_path, "r") as ann_file:
-                ann = json.load(ann_file)
-            # masks are represented with polygons
-            boxes, segmentations, labels = self._processPolygons(ann)
-
-        boxes, segmentations, labels = self._filterGT(boxes, segmentations, labels)
-
-        if len(segmentations) == 0:
-            empty_ann_path = self.get_img_info(idx)["ann_path"]
-            print("EMPTY ENTRY:", empty_ann_path)
-            # self.img_paths.pop(idx)
-            # self.ann_paths.pop(idx)
-            img, target, _ = self[(idx + 1) % len(self)]
-
-            # just override this image with the next
-            return img, target, idx
-
-        img = Image.open(img_path)
-        # Compose all into a BoxList instance
-        target = BoxList(boxes, img.size, mode="xyxy")
-        target.add_field("labels", torch.tensor(labels))
-        masks = SegmentationMask(segmentations, img.size, mode=self.mode)
-        target.add_field("masks", masks)
-        if self.transforms is not None:
-            img, target = self.transforms(img, target)
-
-        return img, target, idx
-
-    def _filterGT(self, boxes, segmentations, labels):
-        filtered_boxes = []
-        filtered_segmentations = []
-        filtered_labels = []
-        assert len(segmentations) == len(labels) == len(boxes)
-
-        for box, segmentation, label in zip(boxes, segmentations, labels):
-            xmin, ymin, xmax, ymax = box
-            area = (xmax - xmin) * (ymax - ymin)
-            if area < self.min_area:
-                continue
-
-            filtered_boxes.append(box)
-            filtered_segmentations.append(segmentation)
-            filtered_labels.append(label)
-
-        if len(filtered_boxes) < 1:
-            filtered_boxes = torch.empty(0, 4)
-
-        return filtered_boxes, filtered_segmentations, filtered_labels
-
-    def _processPolygons(self, ann):
-        # For a single object polygon annotations are stored in CityScapes like
-        # [[x1, y1], [x2, y2]...] and we need them in the following format:
-        # [x1, y1, x2, y2, x3, y3 ...]
-        polys = []
-        labels = []
-        boxes = []
-
-        def poly_to_tight_box(poly):
-            xmin = int(min(poly[::2]))
-            ymin = int(min(poly[1::2]))
-            xmax = int(max(poly[::2]))
-            ymax = int(max(poly[1::2]))
-            bbox = xmin, ymin, xmax, ymax
-            return bbox
-
-        for inst in ann["objects"]:
-            label = inst["label"]
-            if label not in self.CLASSES:
-                continue
-
-            label = self.name_to_id[label]
-
-            cityscapes_poly = inst["polygon"]
-            poly = []
-            for xy in cityscapes_poly:
-                # Equivalent with `poly += xy` but this is more verbose
-                x = xy[0]
-                y = xy[1]
-                poly.append(x)
-                poly.append(y)
-
-            # In CityScapes instances are described with single polygons only
-            box = poly_to_tight_box(poly)
-
-            boxes.append(box)
-            polys.append([poly])
-            labels.append(label)
-
-        if len(boxes) < 1:
-            boxes = torch.empty(0, 4)
-
-        return boxes, polys, labels
-
-    def _processBinayMasks(self, ann):
-        boxes = []
-        masks = []
-        labels = []
-
-        def mask_to_tight_box(mask):
-            a = mask.nonzero()
-            bbox = [
-                torch.min(a[:, 1]),
-                torch.min(a[:, 0]),
-                torch.max(a[:, 1]),
-                torch.max(a[:, 0]),
-            ]
-            bbox = list(map(int, bbox))
-            return bbox  # xmin, ymin, xmax, ymax
-
-        # Sort for consistent order between instances as the polygon annotation
-        instIds = torch.sort(torch.unique(ann))[0]
-        for instId in instIds:
-            if instId < 1000:  # group labels
-                continue
-
-            mask = ann == instId
-            label = int(instId / 1000)
-            label = self.cityscapesID_to_ind[label]
-            box = mask_to_tight_box(mask)
-
-            boxes.append(box)
-            masks.append(mask)
-            labels.append(label)
-
-        return boxes, masks, labels
-
-    def __len__(self):
-        return len(self.img_paths)
-
-    def get_img_info(self, index):
-        # Reverse engineered from voc.py
-        # All the images have the same size
-        return {
-            "height": 1024,
-            "width": 2048,
-            "idx": index,
-            "img_path": self.img_paths[index],
-            "ann_path": self.ann_paths[index],
-        }
diff --git a/maskrcnn_benchmark/data/datasets/coco.py b/maskrcnn_benchmark/data/datasets/coco.py
index cc10f29..eaf543b 100644
--- a/maskrcnn_benchmark/data/datasets/coco.py
+++ b/maskrcnn_benchmark/data/datasets/coco.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 import torchvision
@@ -54,8 +67,6 @@ class COCODataset(torchvision.datasets.coco.CocoDetection):
                     ids.append(img_id)
             self.ids = ids
 
-        self.categories = {cat['id']: cat['name'] for cat in self.coco.cats.values()}
-
         self.json_category_id_to_contiguous_id = {
             v: i + 1 for i, v in enumerate(self.coco.getCatIds())
         }
@@ -81,10 +92,9 @@ class COCODataset(torchvision.datasets.coco.CocoDetection):
         classes = torch.tensor(classes)
         target.add_field("labels", classes)
 
-        if anno and "segmentation" in anno[0]:
-            masks = [obj["segmentation"] for obj in anno]
-            masks = SegmentationMask(masks, img.size, mode='poly')
-            target.add_field("masks", masks)
+        masks = [obj["segmentation"] for obj in anno]
+        masks = SegmentationMask(masks, img.size)
+        target.add_field("masks", masks)
 
         if anno and "keypoints" in anno[0]:
             keypoints = [obj["keypoints"] for obj in anno]
diff --git a/maskrcnn_benchmark/data/datasets/concat_dataset.py b/maskrcnn_benchmark/data/datasets/concat_dataset.py
index e5e087c..3d1974c 100644
--- a/maskrcnn_benchmark/data/datasets/concat_dataset.py
+++ b/maskrcnn_benchmark/data/datasets/concat_dataset.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import bisect
 
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/__init__.py b/maskrcnn_benchmark/data/datasets/evaluation/__init__.py
index 249643e..c1fa3b4 100644
--- a/maskrcnn_benchmark/data/datasets/evaluation/__init__.py
+++ b/maskrcnn_benchmark/data/datasets/evaluation/__init__.py
@@ -1,8 +1,21 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 from maskrcnn_benchmark.data import datasets
 
 from .coco import coco_evaluation
 from .voc import voc_evaluation
-from .cityscapes import abs_cityscapes_evaluation
+
 
 def evaluate(dataset, predictions, output_folder, **kwargs):
     """evaluate dataset using different methods based on dataset type.
@@ -22,8 +35,6 @@ def evaluate(dataset, predictions, output_folder, **kwargs):
         return coco_evaluation(**args)
     elif isinstance(dataset, datasets.PascalVOCDataset):
         return voc_evaluation(**args)
-    elif isinstance(dataset, datasets.AbstractDataset):
-        return abs_cityscapes_evaluation(**args)
     else:
         dataset_name = dataset.__class__.__name__
         raise NotImplementedError("Unsupported dataset type {}.".format(dataset_name))
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/__init__.py b/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/__init__.py
deleted file mode 100644
index 34428cd..0000000
--- a/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/__init__.py
+++ /dev/null
@@ -1,21 +0,0 @@
-from .cityscapes_eval import do_cityscapes_evaluation
-
-
-def abs_cityscapes_evaluation(
-    dataset,
-    predictions,
-    box_only,
-    output_folder,
-    iou_types,
-    expected_results,
-    expected_results_sigma_tol,
-):
-    return do_cityscapes_evaluation(
-        dataset=dataset,
-        predictions=predictions,
-        box_only=box_only,
-        output_folder=output_folder,
-        iou_types=iou_types,
-        expected_results=expected_results,
-        expected_results_sigma_tol=expected_results_sigma_tol,
-    )
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/cityscapes_eval.py b/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/cityscapes_eval.py
deleted file mode 100644
index 8100462..0000000
--- a/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/cityscapes_eval.py
+++ /dev/null
@@ -1,103 +0,0 @@
-import logging
-import tempfile
-import os
-import torch
-from collections import OrderedDict
-from tqdm import tqdm
-from copy import deepcopy
-
-import torch
-import numpy as np
-
-from maskrcnn_benchmark.modeling.roi_heads.mask_head.inference import Masker
-from maskrcnn_benchmark.structures.bounding_box import BoxList
-from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou
-
-from maskrcnn_benchmark.data.datasets.evaluation.cityscapes import eval_instances
-
-
-from cityscapesscripts.helpers.csHelpers import writeDict2JSON, ensurePath
-
-
-def do_cityscapes_evaluation(
-    dataset,
-    predictions,
-    box_only,
-    output_folder,
-    iou_types,
-    expected_results,
-    expected_results_sigma_tol,
-):
-
-    logger = logging.getLogger("maskrcnn_benchmark.inference")
-    logger.info(f"CityScapes evaluation on [{dataset}]:")
-    # Set default args for evaluation
-    args = deepcopy(eval_instances.defaultArgs)
-
-    # Set output folder
-    output_folder = os.path.join(output_folder, "evaluationResults")
-    ensurePath(output_folder)
-
-    # Set custom fields
-    args.exportMatchFile = os.path.join(output_folder, "matches.json")
-    args.exportBoxFile = os.path.join(output_folder, "boxResult.json")
-    args.exportMaskFile = os.path.join(output_folder, "maskResult.json")
-    args.instLabels = list(dataset.CLASSES)
-
-    logger.info("Evaluation arguments")
-    logger.info("%s" % args)
-    logger.info("Matching GT instances with Predictions")
-    if "bbox" in iou_types or "segm" in iou_types:
-        # Match and compute IoU of mask and box in one iteration:
-        matches = eval_instances.matchGtsWithPreds(dataset, predictions)
-        writeDict2JSON(matches, args.exportMatchFile)
-    else:
-        NotImplementedError(f"IoU type not implemented {iou_types}")
-
-    # printing
-    strResults = ""
-    if "bbox" in iou_types:
-        # evaluate matches
-        logger.info("Evaluating BBox matches")
-        boxApScores = eval_instances.evaluateBoxMatches(matches, args)
-
-        # averages
-        logger.info("Average Box scores")
-        boxAvgDict = eval_instances.computeAverages(boxApScores, args)
-
-        # logging
-        boxResDict = eval_instances.prepareJSONDataForResults(
-            boxAvgDict, boxApScores, args
-        )
-        if args.JSONOutput:
-            # create output folder if necessary
-            path = os.path.dirname(args.exportBoxFile)
-            ensurePath(path)
-            # Write APs to JSON
-            eval_instances.writeDict2JSON(boxResDict, args.exportBoxFile)
-        strBoxResults = eval_instances.printResults(boxAvgDict, args)
-        strResults += "\nBBox\n" + strBoxResults
-
-    if "segm" in iou_types:
-        # evaluate matches
-        logger.info("Evaluating Mask matches")
-        maskApScores = eval_instances.evaluateMaskMatches(matches, args)
-
-        # averages
-        logger.info("Average Mask scores")
-        maskAvgDict = eval_instances.computeAverages(maskApScores, args)
-
-        # logging
-        maskResDict = eval_instances.prepareJSONDataForResults(
-            maskAvgDict, maskApScores, args
-        )
-        if args.JSONOutput:
-            # create output folder if necessary
-            path = os.path.dirname(args.exportMaskFile)
-            ensurePath(path)
-            # Write APs to JSON
-            eval_instances.writeDict2JSON(maskResDict, args.exportMaskFile)
-        strMaskResults = eval_instances.printResults(maskAvgDict, args)
-        strResults += "\nMask\n" + strMaskResults
-
-    logger.info(strResults)
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/eval_instances.py b/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/eval_instances.py
deleted file mode 100644
index 6090ede..0000000
--- a/maskrcnn_benchmark/data/datasets/evaluation/cityscapes/eval_instances.py
+++ /dev/null
@@ -1,908 +0,0 @@
-#!/usr/bin/python
-#
-# The evaluation script for instance-level semantic labeling.
-# We use this script to evaluate your approach on the test set.
-# You can use the script to evaluate on the validation set.
-#
-# Please check the description of the "getPrediction" method below
-# and set the required environment variables as needed, such that
-# this script can locate your results.
-# If the default implementation of the method works, then it's most likely
-# that our evaluation server will be able to process your results as well.
-#
-# To run this script, make sure that your results contain text files
-# (one for each test set image) with the content:
-#   relPathPrediction1 labelIDPrediction1 confidencePrediction1
-#   relPathPrediction2 labelIDPrediction2 confidencePrediction2
-#   relPathPrediction3 labelIDPrediction3 confidencePrediction3
-#   ...
-#
-# - The given paths "relPathPrediction" point to images that contain
-# binary masks for the described predictions, where any non-zero is
-# part of the predicted instance. The paths must not contain spaces,
-# must be relative to the root directory and must point to locations
-# within the root directory.
-# - The label IDs "labelIDPrediction" specify the class of that mask,
-# encoded as defined in labels.py. Note that the regular ID is used,
-# not the train ID.
-# - The field "confidencePrediction" is a float value that assigns a
-# confidence score to the mask.
-#
-# Note that this tool creates a file named "gtInstances.json" during its
-# first run. This file helps to speed up computation and should be deleted
-# whenever anything changes in the ground truth annotations or anything
-# goes wrong.
-
-# python imports
-from __future__ import print_function, absolute_import, division
-import os, sys
-import fnmatch
-from copy import deepcopy
-import io
-from contextlib import redirect_stdout
-from tqdm import tqdm
-
-
-import torch
-import logging
-
-import numpy as np
-from maskrcnn_benchmark.modeling.roi_heads.mask_head.inference import Masker
-from maskrcnn_benchmark.layers.misc import interpolate
-
-# Cityscapes imports
-from cityscapesscripts.helpers.csHelpers import writeDict2JSON
-from cityscapesscripts.helpers.csHelpers import ensurePath
-from cityscapesscripts.helpers.csHelpers import colors, getColorEntry
-
-
-######################
-# Parameters
-######################
-
-
-# A dummy class to collect all bunch of data
-class CArgs(object):
-    def __repr__(self):
-        """
-        A weird looking pretty print for Evaluation Arguments
-        """
-        longest_key = max([len(str(k)) for k in self.__dict__.keys()])
-        longest_val = max([len(str(v)) for v in self.__dict__.values()])
-        s = "\n" + "#" * max(79, (longest_key + longest_val + 3)) + "\n"
-        for k, v in self.__dict__.items():
-            s += "%{}s : %s\n".format(longest_key) % (k, v)
-        s += "#" * max(79, (longest_key + longest_val + 3)) + "\n"
-        return s
-
-
-# And a global object of that class
-defaultArgs = CArgs()
-
-# Parameters that should be modified by user
-defaultArgs.exportBoxFile = os.path.join("evaluationResults", "boxResult.json")
-defaultArgs.exportMaskFile = os.path.join("evaluationResults", "maskResult.json")
-
-# overlaps for evaluation
-defaultArgs.overlaps = np.arange(0.5, 1.0, 0.05)
-# minimum region size for evaluation [pixels]
-defaultArgs.minRegionSizes = np.array([100])
-# defaultArgs.minRegionSizes     = np.array( [ 400 ] )
-
-defaultArgs.JSONOutput = True
-defaultArgs.quiet = False
-defaultArgs.csv = False
-defaultArgs.colorized = True
-defaultArgs.instLabels = []
-
-
-def matchGtsWithPreds(dataset, predictions):
-    """
-    Go through the `dataset` and `predictions` one-by-one, and list all
-    instances with any non-zero intersection.
-
-    This function handles matching when only BBoxes are used, and when
-    instnace segmentation is available it computes the pixel-wise overlap as
-    well
-
-    The implementation is heavily based on the original CityScapes eval script:
-    https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/evalInstanceLevelSemanticLabeling.py
-
-
-    Original match structure looks like:
-    {"filename1":
-        "groundTruth":gtInstances
-        "prediction":predInstances
-    }
-    # Filenames are not necessary, replace them with idx
-
-
-    <gt/pred>Instances=
-    {
-        "category_name1":[<gt/pred>Instance1, <gt/pred>Instance2, ...]
-        "category_name2":[<gt/pred>Instance3, <gt/pred>Instance4, ...]
-    ...
-    }
-
-    gtInstance=
-    {
-        "labelID":int(labelID)
-        "instID":int(instID)
-        "boxArea":np.count_nonzero(npArray binary mask)
-        "intersection": pixel count (ONLY IF the dict is in the inner list of a predInstance["matchedGt"])
-        "voidIntersection":REMOVE THIS!!!
-        "matchedPred":list(predInstance) which has nonzero intersection
-    }
-
-    predInstance=
-    {
-        "imgName":"path/to/input/img"
-        "predID":<a counter's current state>
-        "labelID":int(labelID)
-        "boxArea":pixel count (ONLY IF the dict is in the inner list of a predInstance["matchedGt"])
-        "confidence":float(confidence)
-        "intersection":np.count_nonzero( np.logical_and( gtNp == gtInstance["instID"] , boolPredInst) )
-        "voidIntersection":REMOVE THIS!!!
-        "matchedGt":list(gtInstance) which has nonzero intersection
-    }
-    """
-
-    assert len(dataset) == len(predictions), f"{len(dataset)} != {len(predictions)}"
-
-    matches = []
-    for idx in tqdm(range(len(predictions)), desc="Matching Preds with GT"):
-        matches.append(matchGtWithPred(dataset, predictions, idx))
-
-    return matches
-
-
-def isOverlapping(box1, box2):
-    x1min, y1min, x1max, y1max = box1
-    x2min, y2min, x2max, y2max = box2
-    ret = x1min < x2max and x2min < x1max and y1min < y2max and y2min < y1max
-    return ret
-
-
-def getUnionBox(box1, box2):
-    x1min, y1min, x1max, y1max = map(int, box1)
-    x2min, y2min, x2max, y2max = map(int, box2)
-
-    xmin = min(x1min, x2min)
-    ymin = min(y1min, y2min)
-    xmax = max(x1max, x2max)
-    ymax = max(y1max, y2max)
-
-    unionBox = xmin, ymin, xmax, ymax
-    return unionBox
-
-
-def getIntersectionBox(box1, box2):
-    x1min, y1min, x1max, y1max = map(int, box1)
-    x2min, y2min, x2max, y2max = map(int, box2)
-
-    xmin = max(x1min, x2min)
-    ymin = max(y1min, y2min)
-    xmax = min(x1max, x2max)
-    ymax = min(y1max, y2max)
-
-    intersectionBox = xmin, ymin, xmax, ymax
-    return intersectionBox
-
-
-def computeBoxIntersection(gt, pred):
-    """
-    Compute intersection between GT instance and prediction.
-    """
-    xmin, ymin, xmax, ymax = getIntersectionBox(gt["box"], pred["box"])
-    intersection = (xmax - xmin) * (ymax - ymin)
-    return intersection
-
-
-def computeMaskIntersection(gt, gtMask, pred, predMask):
-    """
-    Compute intersection between GT instance and prediction.
-    Increase efficiency by computing elementwise product between masks
-    only inside the tight bounding box of the union of the prediction and
-    target masks.
-    """
-    if gtMask is None or predMask is None:
-        return 0
-
-    assert gtMask.shape == predMask.shape
-    assert len(gtMask.shape) == len(predMask.shape) == 2
-
-    xmin, ymin, xmax, ymax = getUnionBox(gt["box"], pred["box"])
-    gtMask_crop = gtMask[ymin:ymax, xmin:xmax]
-    predMask_crop = predMask[ymin:ymax, xmin:xmax]
-
-    # elementwise AND
-    intersection = torch.sum(torch.mul(gtMask_crop, predMask_crop)).item()
-    return intersection
-
-
-def matchGtWithPred(dataset, predictions, idx):
-    # Collect instances from gt and pred separately per image
-    # TODO: not parallel! parallelize this process safely
-    perImgGtInstances, gtMasks = prepareGtImage(dataset, idx)
-    perImgPredInstances, predMasks = preparePredImage(dataset, predictions, idx)
-
-    # If no masks are provided, the segmentation score will be 0
-    for gt, gtMask in zip(perImgGtInstances, gtMasks):
-        for pred, predMask in zip(perImgPredInstances, predMasks):
-            if not isOverlapping(gt["box"], pred["box"]):
-                continue
-
-            boxIntersection = computeBoxIntersection(gt, pred)
-            maskIntersection = computeMaskIntersection(gt, gtMask, pred, predMask)
-
-            if boxIntersection > 0:
-                # Copy metadata only, and register the matched pairs
-                # this step is redundant but informative
-                # intersection score would be enough
-                gtCopy = gt.copy()
-                predCopy = pred.copy()
-
-                # remove linking field (an empty list) to avoid confusion
-                gtCopy.pop("matchedPred")
-                predCopy.pop("matchedGt")
-
-                gtCopy["boxIntersection"] = boxIntersection
-                gtCopy["maskIntersection"] = maskIntersection
-                predCopy["boxIntersection"] = boxIntersection
-                predCopy["maskIntersection"] = maskIntersection
-
-                gt["matchedPred"].append(predCopy)
-                pred["matchedGt"].append(gtCopy)
-
-    # Group by classes
-    groupedGtInstances = {labelName: [] for labelName in dataset.CLASSES}
-    groupedPredInstances = {labelName: [] for labelName in dataset.CLASSES}
-
-    for gt in perImgGtInstances:
-        gtLabelName = dataset.id_to_name[gt["labelID"]]
-        groupedGtInstances[gtLabelName].append(gt)
-
-    for pred in perImgPredInstances:
-        predLabelName = dataset.id_to_name[pred["labelID"]]
-        groupedPredInstances[predLabelName].append(pred)
-
-    match = {"groundTruth": groupedGtInstances, "prediction": groupedPredInstances}
-
-    return match
-
-
-def prepareGtImage(dataset, idx):
-    _, perImageGts, _ = dataset[idx]
-    perImageInstances = []
-    maskTensor = [None] * len(perImageGts)
-    if len(perImageGts) == 0:
-        return perImageInstances, maskTensor
-
-    # Resize to original image size
-    imgInfo = dataset.get_img_info(idx)
-    origSize = imgInfo["width"], imgInfo["height"]
-    if perImageGts.size != origSize:
-        perImageGts = perImageGts.resize(size=origSize)
-
-    # Compute box areas
-    perImageGts = perImageGts.convert("xyxy")
-    bbs = perImageGts.bbox.long()
-    xmins, ymins, xmaxs, ymaxs = bbs[:, 0], bbs[:, 1], bbs[:, 2], bbs[:, 3]
-    boxAreas = ((xmaxs - xmins) * (ymaxs - ymins)).tolist()
-    bbs = bbs.tolist()
-
-    # object label for each prediction
-    labels = perImageGts.get_field("labels").tolist()
-    if "masks" in perImageGts.fields():
-        # Get the binary mask for each instance in a contiguous array
-        maskTensor = perImageGts.get_field("masks").get_mask_tensor()
-
-        # In case of single mask then add a new axis
-        if len(maskTensor.shape) == 2:
-            maskTensor = maskTensor[None]
-
-        # unique_values = set(torch.unique(maskTensor).tolist())
-        # assert len(unique_values) == 2, "Not binary mask: %s" % unique_values
-        # pixelCounts = maskTensor.clamp_(0, 1).sum(dim=[1, 2])
-        pixelCounts = []
-        for (xmin, ymin, xmax, ymax), instanceMask in zip(bbs, maskTensor):
-            pixelCounts.append(instanceMask[ymin:ymax, xmin:xmax].sum().item())
-
-    for instID in range(len(perImageGts)):
-        xmin, ymin, xmax, ymax = bbs[instID]
-        pixelCount = pixelCounts[instID] if maskTensor[0] is not None else 0
-        gtInstance = {
-            "labelID": labels[instID],
-            "instID": instID,
-            "boxArea": boxAreas[instID],
-            "pixelCount": pixelCount,
-            "box": (xmin, ymin, xmax, ymax),
-            "matchedPred": [],
-        }
-        perImageInstances.append(gtInstance)
-
-    return perImageInstances, maskTensor
-
-
-def preparePredImage(dataset, predictions, idx):
-    perImagePredictions = predictions[idx]
-
-    # A list will hold statistics and meta-data about the image
-    perImageInstances = []
-
-    # maskTensor represents binary masks of all predicted instance segmentations
-    # if present
-    maskTensor = [None] * len(perImagePredictions)
-
-    # No predictions for this image
-    if len(perImagePredictions) == 0:
-        return perImageInstances, maskTensor
-
-    # Resize to original image size
-    imgInfo = dataset.get_img_info(idx)
-    origSize = imgInfo["width"], imgInfo["height"]
-    if perImagePredictions.size != origSize:
-        perImagePredictions = perImagePredictions.resize(size=origSize)
-
-    # Bounding boxes and areas
-    perImagePredictions = perImagePredictions.convert("xyxy")
-    bbs = perImagePredictions.bbox.long()
-    xmins, ymins, xmaxs, ymaxs = bbs[:, 0], bbs[:, 1], bbs[:, 2], bbs[:, 3]
-    boxAreas = ((xmaxs - xmins) * (ymaxs - ymins)).tolist()
-    bbs = bbs.tolist()
-
-    # object label and "Objectness" score for each prediction
-    labels = perImagePredictions.get_field("labels").tolist()
-    scores = perImagePredictions.get_field("scores").tolist()
-
-    # Get the mask for each instance in a contiguous array
-    if "mask" in perImagePredictions.fields():
-        maskTensor = perImagePredictions.get_field("mask")
-
-        # sanity checks
-        assert len(perImagePredictions) == len(maskTensor), (
-            "number of masks (%d) do not match the number of boxes (%d)"
-            % (len(perImagePredictions), len(maskTensor))
-        )
-
-        maskTensor = maskTensor.float()
-        # We assume that the maskTensors are coming right out of the maskRCNN
-        # having values between [0, 1] inclusive
-        #
-        # assert maskTensor.min() >= 0.0 and maskTensor.max() <= 1.0, [
-        #     maskTensor.max(),
-        #     maskTensor.min(),
-        # ]
-
-        # Project masks to the boxes
-        # TODO: Issue #527 - bad Masker interface
-        #
-        # The predicted masks are in the shape of i.e. [N, 1, 28, 28] where N is
-        # the number of instances predicted, and they represent the interior
-        # of the bounding boxes.
-        #
-        # Masker projects these predictions on an empty canvas with the full
-        # size of the input image using the predicted bounding boxes
-        maskTensor = Masker(threshold=0.5).forward_single_image(
-            maskTensor, perImagePredictions
-        )[:, 0, :, :]
-
-        pixelCounts = []
-        for (xmin, ymin, xmax, ymax), instanceMask in zip(bbs, maskTensor):
-            pixelCounts.append(instanceMask[ymin:ymax, xmin:xmax].sum().item())
-
-    for predID in range(len(perImagePredictions)):
-        xmin, ymin, xmax, ymax = bbs[predID]
-        # if we have instance segmentation prediction then we update pixelCount
-        pixelCount = 0
-        if maskTensor[0] is not None:
-            pixelCount = pixelCounts[predID]
-            if pixelCount == 0:
-                continue
-
-        predInstance = {
-            "imgName": idx,
-            "predID": predID,
-            "labelID": labels[predID],
-            "boxArea": boxAreas[predID],
-            "pixelCount": pixelCount,
-            "confidence": scores[predID],
-            "box": (xmin, ymin, xmax, ymax),
-            "matchedGt": [],
-        }
-        perImageInstances.append(predInstance)
-
-    return perImageInstances, maskTensor
-
-
-def evaluateBoxMatches(matches, args):
-    # In the end, we need two vectors for each class and for each overlap
-    # The first vector (y_true) is binary and is 1, where the ground truth says true,
-    # and is 0 otherwise.
-    # The second vector (y_score) is float [0...1] and represents the confidence of
-    # the prediction.
-    #
-    # We represent the following cases as:
-    #                                       | y_true |   y_score
-    #   gt instance with matched prediction |    1   | confidence
-    #   gt instance w/o  matched prediction |    1   |     0.0
-    #          false positive prediction    |    0   | confidence
-    #
-    # The current implementation makes only sense for an overlap threshold >= 0.5,
-    # since only then, a single prediction can either be ignored or matched, but
-    # never both. Further, it can never match to two gt instances.
-    # For matching, we vary the overlap and do the following steps:
-    #   1.) remove all predictions that satisfy the overlap criterion with an ignore region (either void or *group)
-    #   2.) remove matches that do not satisfy the overlap
-    #   3.) mark non-matched predictions as false positive
-
-    # AP
-    overlaps = args.overlaps
-    # region size
-    minRegionSizes = args.minRegionSizes
-
-    # only keep the first, if distances are not available
-    # if not args.distanceAvailable:
-    #     minRegionSizes = [ minRegionSizes[0] ]
-    #     distThs        = [ distThs       [0] ]
-    #     distConfs      = [ distConfs     [0] ]
-
-    # Here we hold the results
-    # First dimension is class, second overlap
-    ap = np.zeros((len(minRegionSizes), len(args.instLabels), len(overlaps)), np.float)
-
-    for dI, minRegionSize in enumerate(minRegionSizes):
-        for (oI, overlapTh) in enumerate(overlaps):
-            for (lI, labelName) in enumerate(args.instLabels):
-                y_true = np.empty(0)
-                y_score = np.empty(0)
-                # count hard false negatives
-                hardFns = 0
-                # found at least one gt and predicted instance?
-                haveGt = False
-                havePred = False
-
-                for img in matches:
-                    predInstances = img["prediction"][labelName]
-                    gtInstances = img["groundTruth"][labelName]
-                    # filter groups in ground truth
-                    gtInstances = [
-                        gt for gt in gtInstances if gt["boxArea"] >= minRegionSize
-                    ]
-
-                    if gtInstances:
-                        haveGt = True
-                    if predInstances:
-                        havePred = True
-
-                    curTrue = np.ones(len(gtInstances))
-                    curScore = np.ones(len(gtInstances)) * (-float("inf"))
-                    curMatch = np.zeros(len(gtInstances), dtype=np.bool)
-
-                    # collect matches
-                    for (gtI, gt) in enumerate(gtInstances):
-                        foundMatch = False
-                        for pred in gt["matchedPred"]:
-                            overlap = float(pred["boxIntersection"]) / (
-                                gt["boxArea"]
-                                + pred["boxArea"]
-                                - pred["boxIntersection"]
-                            )
-                            if overlap > overlapTh:
-                                # the score
-                                confidence = pred["confidence"]
-
-                                # if we already hat a prediction for this groundtruth
-                                # the prediction with the lower score is automatically a false positive
-                                if curMatch[gtI]:
-                                    maxScore = max(curScore[gtI], confidence)
-                                    minScore = min(curScore[gtI], confidence)
-                                    curScore[gtI] = maxScore
-                                    # append false positive
-                                    curTrue = np.append(curTrue, 0)
-                                    curScore = np.append(curScore, minScore)
-                                    curMatch = np.append(curMatch, True)
-                                # otherwise set score
-                                else:
-                                    foundMatch = True
-                                    curMatch[gtI] = True
-                                    curScore[gtI] = confidence
-
-                        if not foundMatch:
-                            hardFns += 1
-
-                    # remove non-matched ground truth instances
-                    curTrue = curTrue[curMatch == True]
-                    curScore = curScore[curMatch == True]
-
-                    # collect non-matched predictions as false positive
-                    for pred in predInstances:
-                        foundGt = False
-                        for gt in pred["matchedGt"]:
-                            overlap = float(gt["boxIntersection"]) / (
-                                gt["boxArea"] + pred["boxArea"] - gt["boxIntersection"]
-                            )
-                            if overlap > overlapTh:
-                                foundGt = True
-                                break
-                        if not foundGt:
-                            # collect number of void and *group pixels
-                            nbIgnorePixels = 0
-                            for gt in pred["matchedGt"]:
-                                # small ground truth instances
-                                if gt["boxArea"] < minRegionSize:
-                                    nbIgnorePixels += gt["boxIntersection"]
-                            if pred["boxArea"] > 0:
-                                proportionIgnore = (
-                                    float(nbIgnorePixels) / pred["boxArea"]
-                                )
-                            else:
-                                proportionIgnore = 0
-                            # if not ignored
-                            # append false positive
-                            if proportionIgnore <= overlapTh:
-                                curTrue = np.append(curTrue, 0)
-                                confidence = pred["confidence"]
-                                curScore = np.append(curScore, confidence)
-
-                    # append to overall results
-                    y_true = np.append(y_true, curTrue)
-                    y_score = np.append(y_score, curScore)
-
-                # compute the average precision
-                if haveGt and havePred:
-                    # compute precision recall curve first
-
-                    # sorting and cumsum
-                    scoreArgSort = np.argsort(y_score)
-                    yScoreSorted = y_score[scoreArgSort]
-                    yTrueSorted = y_true[scoreArgSort]
-                    yTrueSortedCumsum = np.cumsum(yTrueSorted)
-
-                    # unique thresholds
-                    (thresholds, uniqueIndices) = np.unique(
-                        yScoreSorted, return_index=True
-                    )
-
-                    # since we need to add an artificial point to the precision-recall curve
-                    # increase its length by 1
-                    nbPrecRecall = len(uniqueIndices) + 1
-
-                    # prepare precision recall
-                    nbExamples = len(yScoreSorted)
-                    nbTrueExamples = yTrueSortedCumsum[-1]
-                    precision = np.zeros(nbPrecRecall)
-                    recall = np.zeros(nbPrecRecall)
-
-                    # deal with the first point
-                    # only thing we need to do, is to append a zero to the cumsum at the end.
-                    # an index of -1 uses that zero then
-                    yTrueSortedCumsum = np.append(yTrueSortedCumsum, 0)
-
-                    # deal with remaining
-                    for idxRes, idxScores in enumerate(uniqueIndices):
-                        cumSum = yTrueSortedCumsum[idxScores - 1]
-                        tp = nbTrueExamples - cumSum
-                        fp = nbExamples - idxScores - tp
-                        fn = cumSum + hardFns
-                        p = float(tp) / (tp + fp)
-                        r = float(tp) / (tp + fn)
-                        precision[idxRes] = p
-                        recall[idxRes] = r
-
-                    # first point in curve is artificial
-                    precision[-1] = 1.0
-                    recall[-1] = 0.0
-
-                    # compute average of precision-recall curve
-                    # integration is performed via zero order, or equivalently step-wise integration
-                    # first compute the widths of each step:
-                    # use a convolution with appropriate kernel, manually deal with the boundaries first
-                    recallForConv = np.copy(recall)
-                    recallForConv = np.append(recallForConv[0], recallForConv)
-                    recallForConv = np.append(recallForConv, 0.0)
-
-                    stepWidths = np.convolve(recallForConv, [-0.5, 0, 0.5], "valid")
-
-                    # integrate is now simply a dot product
-                    apCurrent = np.dot(precision, stepWidths)
-
-                elif haveGt:
-                    apCurrent = 0.0
-                else:
-                    apCurrent = float("nan")
-                ap[dI, lI, oI] = apCurrent
-
-    return ap
-
-
-def evaluateMaskMatches(matches, args):
-    # In the end, we need two vectors for each class and for each overlap
-    # The first vector (y_true) is binary and is 1, where the ground truth says true,
-    # and is 0 otherwise.
-    # The second vector (y_score) is float [0...1] and represents the confidence of
-    # the prediction.
-    #
-    # We represent the following cases as:
-    #                                       | y_true |   y_score
-    #   gt instance with matched prediction |    1   | confidence
-    #   gt instance w/o  matched prediction |    1   |     0.0
-    #          false positive prediction    |    0   | confidence
-    #
-    # The current implementation makes only sense for an overlap threshold >= 0.5,
-    # since only then, a single prediction can either be ignored or matched, but
-    # never both. Further, it can never match to two gt instances.
-    # For matching, we vary the overlap and do the following steps:
-    #   1.) remove all predictions that satisfy the overlap criterion with an ignore region (either void or *group)
-    #   2.) remove matches that do not satisfy the overlap
-    #   3.) mark non-matched predictions as false positive
-
-    # AP
-    overlaps = args.overlaps
-    # region size
-    minRegionSizes = args.minRegionSizes
-
-    # only keep the first, if distances are not available
-    # if not args.distanceAvailable:
-    #     minRegionSizes = [ minRegionSizes[0] ]
-    #     distThs        = [ distThs       [0] ]
-    #     distConfs      = [ distConfs     [0] ]
-
-    # Here we hold the results
-    # First dimension is class, second overlap
-    ap = np.zeros((len(minRegionSizes), len(args.instLabels), len(overlaps)), np.float)
-
-    for dI, minRegionSize in enumerate(minRegionSizes):
-        for (oI, overlapTh) in enumerate(overlaps):
-            for (lI, labelName) in enumerate(args.instLabels):
-                y_true = np.empty(0)
-                y_score = np.empty(0)
-                # count hard false negatives
-                hardFns = 0
-                # found at least one gt and predicted instance?
-                haveGt = False
-                havePred = False
-
-                for img in matches:
-                    predInstances = img["prediction"][labelName]
-                    gtInstances = img["groundTruth"][labelName]
-                    # filter groups in ground truth
-                    gtInstances = [
-                        gt for gt in gtInstances if gt["pixelCount"] >= minRegionSize
-                    ]
-
-                    if gtInstances:
-                        haveGt = True
-                    if predInstances:
-                        havePred = True
-
-                    curTrue = np.ones(len(gtInstances))
-                    curScore = np.ones(len(gtInstances)) * (-float("inf"))
-                    curMatch = np.zeros(len(gtInstances), dtype=np.bool)
-
-                    # collect matches
-                    for (gtI, gt) in enumerate(gtInstances):
-                        foundMatch = False
-                        for pred in gt["matchedPred"]:
-                            overlap = float(pred["maskIntersection"]) / (
-                                gt["pixelCount"]
-                                + pred["pixelCount"]
-                                - pred["maskIntersection"]
-                            )
-                            if overlap > overlapTh:
-                                # the score
-                                confidence = pred["confidence"]
-
-                                # if we already hat a prediction for this groundtruth
-                                # the prediction with the lower score is automatically a false positive
-                                if curMatch[gtI]:
-                                    maxScore = max(curScore[gtI], confidence)
-                                    minScore = min(curScore[gtI], confidence)
-                                    curScore[gtI] = maxScore
-                                    # append false positive
-                                    curTrue = np.append(curTrue, 0)
-                                    curScore = np.append(curScore, minScore)
-                                    curMatch = np.append(curMatch, True)
-                                # otherwise set score
-                                else:
-                                    foundMatch = True
-                                    curMatch[gtI] = True
-                                    curScore[gtI] = confidence
-
-                        if not foundMatch:
-                            hardFns += 1
-
-                    # remove non-matched ground truth instances
-                    curTrue = curTrue[curMatch == True]
-                    curScore = curScore[curMatch == True]
-
-                    # collect non-matched predictions as false positive
-                    for pred in predInstances:
-                        foundGt = False
-                        for gt in pred["matchedGt"]:
-                            overlap = float(gt["maskIntersection"]) / (
-                                gt["pixelCount"]
-                                + pred["pixelCount"]
-                                - gt["maskIntersection"]
-                            )
-                            if overlap > overlapTh:
-                                foundGt = True
-                                break
-                        if not foundGt:
-                            # collect number of void and *group pixels
-                            nbIgnorePixels = 0
-                            for gt in pred["matchedGt"]:
-                                # small ground truth instances
-                                if gt["pixelCount"] < minRegionSize:
-                                    nbIgnorePixels += gt["maskIntersection"]
-
-                            if pred["pixelCount"] <= 0:
-                                proportionIgnore = 0
-                            else:
-                                proportionIgnore = (
-                                    float(nbIgnorePixels) / pred["pixelCount"]
-                                )
-                            # if not ignored
-                            # append false positive
-                            if proportionIgnore <= overlapTh:
-                                curTrue = np.append(curTrue, 0)
-                                confidence = pred["confidence"]
-                                curScore = np.append(curScore, confidence)
-
-                    # append to overall results
-                    y_true = np.append(y_true, curTrue)
-                    y_score = np.append(y_score, curScore)
-
-                # compute the average precision
-                if haveGt and havePred:
-                    # compute precision recall curve first
-
-                    # sorting and cumsum
-                    scoreArgSort = np.argsort(y_score)
-                    yScoreSorted = y_score[scoreArgSort]
-                    yTrueSorted = y_true[scoreArgSort]
-                    yTrueSortedCumsum = np.cumsum(yTrueSorted)
-
-                    # unique thresholds
-                    (thresholds, uniqueIndices) = np.unique(
-                        yScoreSorted, return_index=True
-                    )
-
-                    # since we need to add an artificial point to the precision-recall curve
-                    # increase its length by 1
-                    nbPrecRecall = len(uniqueIndices) + 1
-
-                    # prepare precision recall
-                    nbExamples = len(yScoreSorted)
-                    nbTrueExamples = yTrueSortedCumsum[-1]
-                    precision = np.zeros(nbPrecRecall)
-                    recall = np.zeros(nbPrecRecall)
-
-                    # deal with the first point
-                    # only thing we need to do, is to append a zero to the cumsum at the end.
-                    # an index of -1 uses that zero then
-                    yTrueSortedCumsum = np.append(yTrueSortedCumsum, 0)
-
-                    # deal with remaining
-                    for idxRes, idxScores in enumerate(uniqueIndices):
-                        cumSum = yTrueSortedCumsum[idxScores - 1]
-                        tp = nbTrueExamples - cumSum
-                        fp = nbExamples - idxScores - tp
-                        fn = cumSum + hardFns
-                        p = float(tp) / (tp + fp)
-                        r = float(tp) / (tp + fn)
-                        precision[idxRes] = p
-                        recall[idxRes] = r
-
-                    # first point in curve is artificial
-                    precision[-1] = 1.0
-                    recall[-1] = 0.0
-
-                    # compute average of precision-recall curve
-                    # integration is performed via zero order, or equivalently step-wise integration
-                    # first compute the widths of each step:
-                    # use a convolution with appropriate kernel, manually deal with the boundaries first
-                    recallForConv = np.copy(recall)
-                    recallForConv = np.append(recallForConv[0], recallForConv)
-                    recallForConv = np.append(recallForConv, 0.0)
-
-                    stepWidths = np.convolve(recallForConv, [-0.5, 0, 0.5], "valid")
-
-                    # integrate is now simply a dot product
-                    apCurrent = np.dot(precision, stepWidths)
-
-                elif haveGt:
-                    apCurrent = 0.0
-                else:
-                    apCurrent = float("nan")
-                ap[dI, lI, oI] = apCurrent
-
-    return ap
-
-
-def computeAverages(aps, args):
-    # max distance index
-    # dInf  = np.argmax( args.distanceThs )
-    # d50m  = np.where( np.isclose( args.distanceThs ,  50. ) )
-    # d100m = np.where( np.isclose( args.distanceThs , 100. ) )
-    dInf = np.argmin(args.minRegionSizes)
-    o50 = np.where(np.isclose(args.overlaps, 0.5))
-    o75 = np.where(np.isclose(args.overlaps, 0.75))
-
-    avgDict = {}
-    avgDict["allAp"] = np.nanmean(aps[dInf, :, :])
-    avgDict["allAp50%"] = np.nanmean(aps[dInf, :, o50])
-    avgDict["allAp75%"] = np.nanmean(aps[dInf, :, o75])
-
-    avgDict["classes"] = {}
-    for (lI, labelName) in enumerate(args.instLabels):
-        avgDict["classes"][labelName] = {}
-        avgDict["classes"][labelName]["ap"] = np.average(aps[dInf, lI, :])
-        avgDict["classes"][labelName]["ap50%"] = np.average(aps[dInf, lI, o50])
-        avgDict["classes"][labelName]["ap75%"] = np.average(aps[dInf, lI, o75])
-
-    return avgDict
-
-
-def printResults(avgDict, args):
-    strbuffer = io.StringIO()
-    # redirect all the print functions to a string buffer
-    with redirect_stdout(strbuffer):
-
-        sep = "," if args.csv else ""
-        col1 = ":" if not args.csv else ""
-        noCol = colors.ENDC if args.colorized else ""
-        bold = colors.BOLD if args.colorized else ""
-        lineLen = 65
-
-        print("")
-        if not args.csv:
-            print("#" * lineLen)
-        line = bold
-        line += "{:<15}".format("what") + sep + col1
-        line += "{:>15}".format("AP") + sep
-        line += "{:>15}".format("AP_50%") + sep
-        line += "{:>15}".format("AP_75%") + sep
-        line += noCol
-        print(line)
-        if not args.csv:
-            print("#" * lineLen)
-
-        for (lI, labelName) in enumerate(args.instLabels):
-            apAvg = avgDict["classes"][labelName]["ap"]
-            ap50o = avgDict["classes"][labelName]["ap50%"]
-            ap75o = avgDict["classes"][labelName]["ap75%"]
-
-            line = "{:<15}".format(labelName) + sep + col1
-            line += getColorEntry(apAvg, args) + sep + "{:>15.3f}".format(apAvg) + sep
-            line += getColorEntry(ap50o, args) + sep + "{:>15.3f}".format(ap50o) + sep
-            line += getColorEntry(ap75o, args) + sep + "{:>15.3f}".format(ap75o) + sep
-            line += noCol
-            print(line)
-
-        allApAvg = avgDict["allAp"]
-        allAp50o = avgDict["allAp50%"]
-        allAp75o = avgDict["allAp75%"]
-
-        if not args.csv:
-            print("-" * lineLen)
-        line = "{:<15}".format("average") + sep + col1
-        line += getColorEntry(allApAvg, args) + sep + "{:>15.3f}".format(allApAvg) + sep
-        line += getColorEntry(allAp50o, args) + sep + "{:>15.3f}".format(allAp50o) + sep
-        line += getColorEntry(allAp75o, args) + sep + "{:>15.3f}".format(allAp75o) + sep
-        line += noCol
-        print(line)
-        print("")
-
-        return strbuffer.getvalue()
-
-
-def prepareJSONDataForResults(avgDict, aps, args):
-    JSONData = {}
-    JSONData["averages"] = avgDict
-    JSONData["overlaps"] = args.overlaps.tolist()
-    JSONData["minRegionSizes"] = args.minRegionSizes.tolist()
-    JSONData["instLabels"] = args.instLabels
-    JSONData["resultApMatrix"] = aps.tolist()
-
-    return JSONData
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py b/maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py
index 4cb5b63..cc04a89 100644
--- a/maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py
+++ b/maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py
@@ -1,6 +1,17 @@
-from .coco_eval import do_coco_evaluation as do_orig_coco_evaluation
-from .coco_eval_wrapper import do_coco_evaluation as do_wrapped_coco_evaluation
-from maskrcnn_benchmark.data.datasets import AbstractDataset, COCODataset
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+from .coco_eval import do_coco_evaluation
 
 
 def coco_evaluation(
@@ -12,31 +23,12 @@ def coco_evaluation(
     expected_results,
     expected_results_sigma_tol,
 ):
-    if isinstance(dataset, COCODataset):
-        return do_orig_coco_evaluation(
-            dataset=dataset,
-            predictions=predictions,
-            box_only=box_only,
-            output_folder=output_folder,
-            iou_types=iou_types,
-            expected_results=expected_results,
-            expected_results_sigma_tol=expected_results_sigma_tol,
-        )
-    elif isinstance(dataset, AbstractDataset):
-        return do_wrapped_coco_evaluation(
-            dataset=dataset,
-            predictions=predictions,
-            box_only=box_only,
-            output_folder=output_folder,
-            iou_types=iou_types,
-            expected_results=expected_results,
-            expected_results_sigma_tol=expected_results_sigma_tol,
-        )
-    else:
-        raise NotImplementedError(
-            (
-                "Ground truth dataset is not a COCODataset, "
-                "nor it is derived from AbstractDataset: type(dataset)="
-                "%s" % type(dataset)
-            )
-        )
+    return do_coco_evaluation(
+        dataset=dataset,
+        predictions=predictions,
+        box_only=box_only,
+        output_folder=output_folder,
+        iou_types=iou_types,
+        expected_results=expected_results,
+        expected_results_sigma_tol=expected_results_sigma_tol,
+    )
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/coco/abs_to_coco.py b/maskrcnn_benchmark/data/datasets/evaluation/coco/abs_to_coco.py
deleted file mode 100644
index ebfbc12..0000000
--- a/maskrcnn_benchmark/data/datasets/evaluation/coco/abs_to_coco.py
+++ /dev/null
@@ -1,198 +0,0 @@
-# COCO style evaluation for custom datasets derived from AbstractDataset
-# Warning! area is computed using binary maps, therefore results may differ
-# because of the precomputed COCO areas
-# by botcs@github
-
-import numpy as np
-import torch
-import pycocotools.mask as mask_util
-
-from maskrcnn_benchmark.data.datasets.abstract import AbstractDataset
-from maskrcnn_benchmark.structures.bounding_box import BoxList
-
-import logging
-from datetime import datetime
-from tqdm import tqdm
-
-
-def convert_abstract_to_coco(dataset, num_workers=None, chunksize=100):
-    """
-    Convert any dataset derived from AbstractDataset to COCO style
-    for evaluating with the pycocotools lib
-
-    Conversion imitates required fields of COCO instance segmentation
-    ground truth files like: ".../annotations/instances_train2014.json"
-
-    After th conversion is done a dict is returned that follows the same
-    format as COCO json files.
-
-    By default .coco_eval_wrapper.py saves it to the hard-drive in json format
-    and loads it with the maskrcnn_benchmark's default COCODataset
-
-    Args:
-        dataset: any dataset derived from AbstractDataset
-        num_workers (optional): number of worker threads to parallelize the
-            conversion (default is to use all cores for conversion)
-        chunk_size (optional): how many entries one thread processes before
-            requesting new task. The larger the less overhead there is.
-    """
-
-    logger = logging.getLogger("maskrcnn_benchmark.inference")
-    assert isinstance(dataset, AbstractDataset)
-    # Official COCO annotations have these fields
-    # 'info', 'licenses', 'images', 'type', 'annotations', 'categories'
-    coco_dict = {}
-    coco_dict["info"] = {
-        "description": (
-            "This is an automatically generated COCO annotation"
-            " file using maskrcnn_benchmark"
-        ),
-        "date_created": "%s" % datetime.now(),
-    }
-    coco_dict["type"] = "instances"
-
-    images = []
-    annotations = []
-
-    if num_workers is None:
-        num_workers = torch.multiprocessing.cpu_count()
-    else:
-        num_workers = min(num_workers, torch.multiprocessing.cpu_count())
-
-    dataset_name = dataset.__class__.__name__
-    num_images = len(dataset)
-    logger.info(
-        (
-            "Parsing each entry in "
-            "%s, total=%d. "
-            "Using N=%d workers and chunksize=%d"
-        )
-        % (dataset_name, num_images, num_workers, chunksize)
-    )
-
-    with torch.multiprocessing.Pool(num_workers) as pool:
-        with tqdm(total=num_images) as progress_bar:
-            args = [(dataset, idx) for idx in range(num_images)]
-            iterator = pool.imap(process_single_image, args, chunksize=100)
-            for img_annots_pair in iterator:
-                image, per_img_annotations = img_annots_pair
-
-                images.append(image)
-                annotations.extend(per_img_annotations)
-                progress_bar.update()
-
-    for ann_id, ann in enumerate(annotations, 1):
-        ann["id"] = ann_id
-
-    logger.info("Parsing categories:")
-    # CATEGORY DATA
-    categories = [
-        {"id": category_id, "name": name}
-        for category_id, name in dataset.id_to_name.items()
-        if name != "__background__"
-    ]
-    # Logging categories
-    for cat in categories:
-        logger.info(str(cat))
-
-    coco_dict["images"] = images
-    coco_dict["annotations"] = annotations
-    coco_dict["categories"] = categories
-    return coco_dict
-
-
-def process_single_image(args):
-    dataset, idx = args
-    # IMAGE DATA
-    img_id = idx + 1
-    image = {}
-    # Official COCO "images" entries have these fields
-    # 'license', 'url', 'file_name', 'height', 'width', 'date_captured', 'id'
-
-    img, target, ret_idx = dataset[idx]
-    img_info = dataset.get_img_info(idx)
-    assert isinstance(img_info, dict)
-    image.update(img_info)
-    image["width"], image["height"] = target.size
-
-    if "id" not in image.keys():
-        # Start indexing from 1 if "id" field is not present
-        image["id"] = img_id
-    else:
-        img_id = image["id"]
-
-    # ANNOTATION DATA
-    per_img_annotations = []
-    # Official COCO "annotations" entries have these fields
-    # 'segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'
-
-    #
-
-    assert ret_idx == idx, (ret_idx, idx)
-    assert isinstance(target, BoxList)
-
-    bboxes = target.convert("xywh").bbox.tolist()
-    segm_available = "masks" in target.fields()
-    if segm_available:
-        masks = target.get_field("masks").get_mask_tensor()  # [N, H, W]
-        if masks.dim() == 2:
-            masks = masks.unsqueeze(0)
-        rles = masks_to_rles(masks)
-        """
-        !!!WARNING!!!
-        At this point the area value differs from the precomputed
-        original COCO area values, because we compute the area
-        by counting the nonzero entries of the binary mask
-        while COCO areas are computed directly from the polygons
-
-        Example:
-        Reference image data
-        {'license': 2,
-         'url': 'http://farm9.staticflickr.com/8035/8024364858_9c41dc1666_z.jpg',
-         'file_name': 'COCO_val2014_000000000139.jpg',
-         'height': 426,
-         'width': 640,
-         'date_captured': '2013-11-21 01:34:01',
-         'id': 139}
-
-        Original COCO area values
-        [  531.8071, 13244.6572,  5833.1182,  2245.3435,  1833.7841,  1289.3734,
-           210.1482,  2913.1104,   435.1450,   217.7192,  2089.9749,   338.6089,
-           322.5936,   225.6642,  2171.6189,   178.1851,    90.9873,   189.5601,
-           120.2320,  2362.4897]
-
-        Area values using the binary masks
-        [  531, 13247,  5846,  2251,  1850,  1292,   212,  2922,   439,   224,
-           2060,   342,   324,   226,  2171,   178,    90,   187,   120,  2372]
-        """
-        areas = (masks != 0).sum([1, 2]).tolist()
-    else:
-        areas = target.area().tolist()
-
-    cat_ids = target.get_field("labels").long().tolist()
-    assert len(bboxes) == len(areas) == len(cat_ids)
-    num_instances = len(target)
-    for ann_idx in range(num_instances):
-        annotation = {}
-        if segm_available:
-            annotation["segmentation"] = rles[ann_idx]
-        annotation["area"] = areas[ann_idx]
-        annotation["iscrowd"] = 0
-        annotation["image_id"] = img_id
-        annotation["bbox"] = bboxes[ann_idx]
-        annotation["category_id"] = cat_ids[ann_idx]
-        per_img_annotations.append(annotation)
-
-    return image, per_img_annotations
-
-
-def masks_to_rles(masks_tensor):
-    # TODO: parallelize
-    rles = []
-    for instance_mask in masks_tensor:
-        np_mask = np.array(instance_mask[:, :, None], order="F")
-        rle = mask_util.encode(np_mask)[0]
-        rle["counts"] = rle["counts"].decode("utf-8")
-        rles.append(rle)
-
-    return rles
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py b/maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py
index a8fdc28..78371a0 100644
--- a/maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py
+++ b/maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import logging
 import tempfile
 import os
@@ -9,6 +22,10 @@ from maskrcnn_benchmark.modeling.roi_heads.mask_head.inference import Masker
 from maskrcnn_benchmark.structures.bounding_box import BoxList
 from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou
 
+def remove_dup(l):
+    seen = set()
+    seen_add = seen.add
+    return [x for x in l if not (x in seen or seen_add(x))]
 
 def do_coco_evaluation(
     dataset,
@@ -307,8 +324,11 @@ def evaluate_predictions_on_coco(
 ):
     import json
 
+    set_of_json = remove_dup([json.dumps(d) for d in coco_results])
+    unique_list = [json.loads(s) for s in set_of_json]
+
     with open(json_result_file, "w") as f:
-        json.dump(coco_results, f)
+        json.dump(unique_list, f)
 
     from pycocotools.coco import COCO
     from pycocotools.cocoeval import COCOeval
@@ -364,14 +384,8 @@ class COCOResults(object):
             res[metric] = s[idx]
 
     def __repr__(self):
-        results = '\n'
-        for task, metrics in self.results.items():
-            results += 'Task: {}\n'.format(task)
-            metric_names = metrics.keys()
-            metric_vals = ['{:.4f}'.format(v) for v in metrics.values()]
-            results += (', '.join(metric_names) + '\n')
-            results += (', '.join(metric_vals) + '\n')
-        return results
+        # TODO make it pretty
+        return repr(self.results)
 
 
 def check_expected_results(results, expected_results, sigma_tol):
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval_wrapper.py b/maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval_wrapper.py
deleted file mode 100644
index e372067..0000000
--- a/maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval_wrapper.py
+++ /dev/null
@@ -1,49 +0,0 @@
-# COCO style evaluation for custom datasets derived from AbstractDataset
-# by botcs@github
-
-import logging
-import os
-import json
-
-from maskrcnn_benchmark.data.datasets.coco import COCODataset
-from .coco_eval import do_coco_evaluation as orig_evaluation
-from .abs_to_coco import convert_abstract_to_coco
-
-
-def do_coco_evaluation(
-    dataset,
-    predictions,
-    box_only,
-    output_folder,
-    iou_types,
-    expected_results,
-    expected_results_sigma_tol,
-):
-
-    logger = logging.getLogger("maskrcnn_benchmark.inference")
-    logger.info("Converting annotations to COCO format...")
-    coco_annotation_dict = convert_abstract_to_coco(dataset)
-
-    dataset_name = dataset.__class__.__name__
-    coco_annotation_path = os.path.join(output_folder, dataset_name + ".json")
-    logger.info("Saving annotations to %s" % coco_annotation_path)
-    with open(coco_annotation_path, "w") as f:
-        json.dump(coco_annotation_dict, f, indent=2)
-
-    logger.info("Loading annotations as COCODataset")
-    coco_dataset = COCODataset(
-        ann_file=coco_annotation_path,
-        root="",
-        remove_images_without_annotations=False,
-        transforms=None,  # transformations should be already saved to the json
-    )
-
-    return orig_evaluation(
-        dataset=coco_dataset,
-        predictions=predictions,
-        box_only=box_only,
-        output_folder=output_folder,
-        iou_types=iou_types,
-        expected_results=expected_results,
-        expected_results_sigma_tol=expected_results,
-    )
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py b/maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py
index 1dde641..fbad915 100644
--- a/maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py
+++ b/maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import logging
 
 from .voc_eval import do_voc_evaluation
diff --git a/maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py b/maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py
index 6937109..5dc5c80 100644
--- a/maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py
+++ b/maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # A modification version from chainercv repository.
 # (See https://github.com/chainer/chainercv/blob/master/chainercv/evaluations/eval_detection_voc.py)
 from __future__ import division
@@ -16,6 +29,8 @@ def do_voc_evaluation(dataset, predictions, output_folder, logger):
     gt_boxlists = []
     for image_id, prediction in enumerate(predictions):
         img_info = dataset.get_img_info(image_id)
+        if len(prediction) == 0:
+            continue
         image_width = img_info["width"]
         image_height = img_info["height"]
         prediction = prediction.resize((image_width, image_height))
diff --git a/maskrcnn_benchmark/data/datasets/list_dataset.py b/maskrcnn_benchmark/data/datasets/list_dataset.py
index 9058d35..e074cd3 100644
--- a/maskrcnn_benchmark/data/datasets/list_dataset.py
+++ b/maskrcnn_benchmark/data/datasets/list_dataset.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 Simple dataset class that wraps a list of path names
diff --git a/maskrcnn_benchmark/data/datasets/voc.py b/maskrcnn_benchmark/data/datasets/voc.py
index ab4075e..a06cc4e 100644
--- a/maskrcnn_benchmark/data/datasets/voc.py
+++ b/maskrcnn_benchmark/data/datasets/voc.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import os
 
 import torch
@@ -57,7 +70,6 @@ class PascalVOCDataset(torch.utils.data.Dataset):
 
         cls = PascalVOCDataset.CLASSES
         self.class_to_ind = dict(zip(cls, range(len(cls))))
-        self.categories = dict(zip(range(len(cls)), cls))
 
     def __getitem__(self, index):
         img_id = self.ids[index]
@@ -90,7 +102,7 @@ class PascalVOCDataset(torch.utils.data.Dataset):
         gt_classes = []
         difficult_boxes = []
         TO_REMOVE = 1
-
+        
         for obj in target.iter("object"):
             difficult = int(obj.find("difficult").text) == 1
             if not self.keep_difficult and difficult:
@@ -100,9 +112,9 @@ class PascalVOCDataset(torch.utils.data.Dataset):
             # Make pixel indexes 0-based
             # Refer to "https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/pascal_voc.py#L208-L211"
             box = [
-                bb.find("xmin").text,
-                bb.find("ymin").text,
-                bb.find("xmax").text,
+                bb.find("xmin").text, 
+                bb.find("ymin").text, 
+                bb.find("xmax").text, 
                 bb.find("ymax").text,
             ]
             bndbox = tuple(
diff --git a/maskrcnn_benchmark/data/samplers/__init__.py b/maskrcnn_benchmark/data/samplers/__init__.py
index 27982cb..99377af 100644
--- a/maskrcnn_benchmark/data/samplers/__init__.py
+++ b/maskrcnn_benchmark/data/samplers/__init__.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .distributed import DistributedSampler
 from .grouped_batch_sampler import GroupedBatchSampler
diff --git a/maskrcnn_benchmark/data/samplers/distributed.py b/maskrcnn_benchmark/data/samplers/distributed.py
index 27a280f..1ddbed3 100644
--- a/maskrcnn_benchmark/data/samplers/distributed.py
+++ b/maskrcnn_benchmark/data/samplers/distributed.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 # Code is copy-pasted exactly as in torch.utils.data.distributed.
 # FIXME remove this once c10d fixes the bug it has
diff --git a/maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py b/maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py
index d72e2f0..4430556 100644
--- a/maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py
+++ b/maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import itertools
 
diff --git a/maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py b/maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py
index 93452b6..26ba107 100644
--- a/maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py
+++ b/maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from torch.utils.data.sampler import BatchSampler
 
@@ -8,10 +21,11 @@ class IterationBasedBatchSampler(BatchSampler):
     a specified number of iterations have been sampled
     """
 
-    def __init__(self, batch_sampler, num_iterations, start_iter=0):
+    def __init__(self, batch_sampler, num_iterations, start_iter=0, random_number_generator=None):
         self.batch_sampler = batch_sampler
         self.num_iterations = num_iterations
         self.start_iter = start_iter
+        self.random_number_generator = random_number_generator
 
     def __iter__(self):
         iteration = self.start_iter
@@ -20,7 +34,11 @@ class IterationBasedBatchSampler(BatchSampler):
             # DistributedSampler, used for making each process see
             # a different split of the dataset, then set it
             if hasattr(self.batch_sampler.sampler, "set_epoch"):
-                self.batch_sampler.sampler.set_epoch(iteration)
+                if self.random_number_generator is not None:
+                    iteration_seed = self.random_number_generator.randint(0, 2 ** 32 - 1)
+                    self.batch_sampler.sampler.set_epoch(iteration_seed)
+                else:
+                    self.batch_sampler.sampler.set_epoch(iteration)
             for batch in self.batch_sampler:
                 iteration += 1
                 if iteration > self.num_iterations:
diff --git a/maskrcnn_benchmark/data/transforms/__init__.py b/maskrcnn_benchmark/data/transforms/__init__.py
index 0001297..ef944d8 100644
--- a/maskrcnn_benchmark/data/transforms/__init__.py
+++ b/maskrcnn_benchmark/data/transforms/__init__.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .transforms import Compose
 from .transforms import Resize
diff --git a/maskrcnn_benchmark/data/transforms/build.py b/maskrcnn_benchmark/data/transforms/build.py
index 098da11..9407f2f 100644
--- a/maskrcnn_benchmark/data/transforms/build.py
+++ b/maskrcnn_benchmark/data/transforms/build.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from . import transforms as T
 
@@ -6,39 +19,21 @@ def build_transforms(cfg, is_train=True):
     if is_train:
         min_size = cfg.INPUT.MIN_SIZE_TRAIN
         max_size = cfg.INPUT.MAX_SIZE_TRAIN
-        flip_horizontal_prob = cfg.INPUT.HORIZONTAL_FLIP_PROB_TRAIN
-        flip_vertical_prob = cfg.INPUT.VERTICAL_FLIP_PROB_TRAIN
-        brightness = cfg.INPUT.BRIGHTNESS
-        contrast = cfg.INPUT.CONTRAST
-        saturation = cfg.INPUT.SATURATION
-        hue = cfg.INPUT.HUE
+        flip_prob = 0.5  # cfg.INPUT.FLIP_PROB_TRAIN
     else:
         min_size = cfg.INPUT.MIN_SIZE_TEST
         max_size = cfg.INPUT.MAX_SIZE_TEST
-        flip_horizontal_prob = 0.0
-        flip_vertical_prob = 0.0
-        brightness = 0.0
-        contrast = 0.0
-        saturation = 0.0
-        hue = 0.0
+        flip_prob = 0
 
     to_bgr255 = cfg.INPUT.TO_BGR255
     normalize_transform = T.Normalize(
         mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD, to_bgr255=to_bgr255
     )
-    color_jitter = T.ColorJitter(
-        brightness=brightness,
-        contrast=contrast,
-        saturation=saturation,
-        hue=hue,
-    )
 
     transform = T.Compose(
         [
-            color_jitter,
             T.Resize(min_size, max_size),
-            T.RandomHorizontalFlip(flip_horizontal_prob),
-            T.RandomVerticalFlip(flip_vertical_prob),
+            T.RandomHorizontalFlip(flip_prob),
             T.ToTensor(),
             normalize_transform,
         ]
diff --git a/maskrcnn_benchmark/data/transforms/transforms.py b/maskrcnn_benchmark/data/transforms/transforms.py
index 2d37dc7..ffe1efd 100644
--- a/maskrcnn_benchmark/data/transforms/transforms.py
+++ b/maskrcnn_benchmark/data/transforms/transforms.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import random
 
@@ -54,11 +67,9 @@ class Resize(object):
 
         return (oh, ow)
 
-    def __call__(self, image, target=None):
+    def __call__(self, image, target):
         size = self.get_size(image.size)
         image = F.resize(image, size)
-        if target is None:
-            return image
         target = target.resize(image.size)
         return image, target
 
@@ -73,33 +84,6 @@ class RandomHorizontalFlip(object):
             target = target.transpose(0)
         return image, target
 
-class RandomVerticalFlip(object):
-    def __init__(self, prob=0.5):
-        self.prob = prob
-
-    def __call__(self, image, target):
-        if random.random() < self.prob:
-            image = F.vflip(image)
-            target = target.transpose(1)
-        return image, target
-
-class ColorJitter(object):
-    def __init__(self,
-                 brightness=None,
-                 contrast=None,
-                 saturation=None,
-                 hue=None,
-                 ):
-        self.color_jitter = torchvision.transforms.ColorJitter(
-            brightness=brightness,
-            contrast=contrast,
-            saturation=saturation,
-            hue=hue,)
-
-    def __call__(self, image, target):
-        image = self.color_jitter(image)
-        return image, target
-
 
 class ToTensor(object):
     def __call__(self, image, target):
@@ -112,10 +96,8 @@ class Normalize(object):
         self.std = std
         self.to_bgr255 = to_bgr255
 
-    def __call__(self, image, target=None):
+    def __call__(self, image, target):
         if self.to_bgr255:
             image = image[[2, 1, 0]] * 255
         image = F.normalize(image, mean=self.mean, std=self.std)
-        if target is None:
-            return image
         return image, target
diff --git a/maskrcnn_benchmark/engine/__init__.py b/maskrcnn_benchmark/engine/__init__.py
index 5c7f19c..dcf712f 100644
--- a/maskrcnn_benchmark/engine/__init__.py
+++ b/maskrcnn_benchmark/engine/__init__.py
@@ -1 +1,14 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
diff --git a/maskrcnn_benchmark/engine/bbox_aug.py b/maskrcnn_benchmark/engine/bbox_aug.py
deleted file mode 100644
index 4444165..0000000
--- a/maskrcnn_benchmark/engine/bbox_aug.py
+++ /dev/null
@@ -1,118 +0,0 @@
-import torch
-import torchvision.transforms as TT
-
-from maskrcnn_benchmark.config import cfg
-from maskrcnn_benchmark.data import transforms as T
-from maskrcnn_benchmark.structures.image_list import to_image_list
-from maskrcnn_benchmark.structures.bounding_box import BoxList
-from maskrcnn_benchmark.modeling.roi_heads.box_head.inference import make_roi_box_post_processor
-
-
-def im_detect_bbox_aug(model, images, device):
-    # Collect detections computed under different transformations
-    boxlists_ts = []
-    for _ in range(len(images)):
-        boxlists_ts.append([])
-
-    def add_preds_t(boxlists_t):
-        for i, boxlist_t in enumerate(boxlists_t):
-            if len(boxlists_ts[i]) == 0:
-                # The first one is identity transform, no need to resize the boxlist
-                boxlists_ts[i].append(boxlist_t)
-            else:
-                # Resize the boxlist as the first one
-                boxlists_ts[i].append(boxlist_t.resize(boxlists_ts[i][0].size))
-
-    # Compute detections for the original image (identity transform)
-    boxlists_i = im_detect_bbox(
-        model, images, cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MAX_SIZE_TEST, device
-    )
-    add_preds_t(boxlists_i)
-
-    # Perform detection on the horizontally flipped image
-    if cfg.TEST.BBOX_AUG.H_FLIP:
-        boxlists_hf = im_detect_bbox_hflip(
-            model, images, cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MAX_SIZE_TEST, device
-        )
-        add_preds_t(boxlists_hf)
-
-    # Compute detections at different scales
-    for scale in cfg.TEST.BBOX_AUG.SCALES:
-        max_size = cfg.TEST.BBOX_AUG.MAX_SIZE
-        boxlists_scl = im_detect_bbox_scale(
-            model, images, scale, max_size, device
-        )
-        add_preds_t(boxlists_scl)
-
-        if cfg.TEST.BBOX_AUG.SCALE_H_FLIP:
-            boxlists_scl_hf = im_detect_bbox_scale(
-                model, images, scale, max_size, device, hflip=True
-            )
-            add_preds_t(boxlists_scl_hf)
-
-    # Merge boxlists detected by different bbox aug params
-    boxlists = []
-    for i, boxlist_ts in enumerate(boxlists_ts):
-        bbox = torch.cat([boxlist_t.bbox for boxlist_t in boxlist_ts])
-        scores = torch.cat([boxlist_t.get_field('scores') for boxlist_t in boxlist_ts])
-        boxlist = BoxList(bbox, boxlist_ts[0].size, boxlist_ts[0].mode)
-        boxlist.add_field('scores', scores)
-        boxlists.append(boxlist)
-
-    # Apply NMS and limit the final detections
-    results = []
-    post_processor = make_roi_box_post_processor(cfg)
-    for boxlist in boxlists:
-        results.append(post_processor.filter_results(boxlist, cfg.MODEL.ROI_BOX_HEAD.NUM_CLASSES))
-
-    return results
-
-
-def im_detect_bbox(model, images, target_scale, target_max_size, device):
-    """
-    Performs bbox detection on the original image.
-    """
-    transform = TT.Compose([
-        T.Resize(target_scale, target_max_size),
-        TT.ToTensor(),
-        T.Normalize(
-            mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD, to_bgr255=cfg.INPUT.TO_BGR255
-        )
-    ])
-    images = [transform(image) for image in images]
-    images = to_image_list(images, cfg.DATALOADER.SIZE_DIVISIBILITY)
-    return model(images.to(device))
-
-
-def im_detect_bbox_hflip(model, images, target_scale, target_max_size, device):
-    """
-    Performs bbox detection on the horizontally flipped image.
-    Function signature is the same as for im_detect_bbox.
-    """
-    transform = TT.Compose([
-        T.Resize(target_scale, target_max_size),
-        TT.RandomHorizontalFlip(1.0),
-        TT.ToTensor(),
-        T.Normalize(
-            mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD, to_bgr255=cfg.INPUT.TO_BGR255
-        )
-    ])
-    images = [transform(image) for image in images]
-    images = to_image_list(images, cfg.DATALOADER.SIZE_DIVISIBILITY)
-    boxlists = model(images.to(device))
-
-    # Invert the detections computed on the flipped image
-    boxlists_inv = [boxlist.transpose(0) for boxlist in boxlists]
-    return boxlists_inv
-
-
-def im_detect_bbox_scale(model, images, target_scale, target_max_size, device, hflip=False):
-    """
-    Computes bbox detections at the given scale.
-    Returns predictions in the scaled image space.
-    """
-    if hflip:
-        boxlists_scl = im_detect_bbox_hflip(model, images, target_scale, target_max_size, device)
-    else:
-        boxlists_scl = im_detect_bbox(model, images, target_scale, target_max_size, device)
-    return boxlists_scl
diff --git a/maskrcnn_benchmark/engine/inference.py b/maskrcnn_benchmark/engine/inference.py
index 6bb5cac..f0c74ba 100644
--- a/maskrcnn_benchmark/engine/inference.py
+++ b/maskrcnn_benchmark/engine/inference.py
@@ -1,4 +1,18 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
+import datetime
 import logging
 import time
 import os
@@ -7,30 +21,20 @@ import torch
 from tqdm import tqdm
 
 from maskrcnn_benchmark.data.datasets.evaluation import evaluate
-from ..utils.comm import is_main_process, get_world_size
+from ..utils.comm import is_main_process
 from ..utils.comm import all_gather
 from ..utils.comm import synchronize
-from ..utils.timer import Timer, get_time_str
-from .bbox_aug import im_detect_bbox_aug
 
 
-def compute_on_dataset(model, data_loader, device, bbox_aug, timer=None):
+def compute_on_dataset(model, data_loader, device):
     model.eval()
     results_dict = {}
     cpu_device = torch.device("cpu")
-    for _, batch in enumerate(tqdm(data_loader)):
+    for i, batch in enumerate(tqdm(data_loader)):
         images, targets, image_ids = batch
+        images = images.to(device)
         with torch.no_grad():
-            if timer:
-                timer.tic()
-            if bbox_aug:
-                output = im_detect_bbox_aug(model, images, device)
-            else:
-                output = model(images.to(device))
-            if timer:
-                if not device.type == 'cpu':
-                    torch.cuda.synchronize()
-                timer.toc()
+            output = model(images)
             output = [o.to(cpu_device) for o in output]
         results_dict.update(
             {img_id: result for img_id, result in zip(image_ids, output)}
@@ -66,7 +70,6 @@ def inference(
         dataset_name,
         iou_types=("bbox",),
         box_only=False,
-        bbox_aug=False,
         device="cuda",
         expected_results=(),
         expected_results_sigma_tol=4,
@@ -74,29 +77,37 @@ def inference(
 ):
     # convert to a torch.device for efficiency
     device = torch.device(device)
-    num_devices = get_world_size()
+    num_devices = (
+        torch.distributed.get_world_size()
+        if torch.distributed.is_initialized()
+        else 1
+    )
     logger = logging.getLogger("maskrcnn_benchmark.inference")
-    dataset = data_loader.dataset
-    logger.info("Start evaluation on {} dataset({} images).".format(dataset_name, len(dataset)))
-    total_timer = Timer()
-    inference_timer = Timer()
-    total_timer.tic()
-    predictions = compute_on_dataset(model, data_loader, device, bbox_aug, inference_timer)
+    if hasattr(data_loader.batch_sampler, 'num_iterations'):
+        len_dataset = data_loader.batch_sampler.num_iterations * \
+                      data_loader.batch_sampler.batch_sampler.batch_size
+    else:
+        len_dataset = len(data_loader.dataset)
+    logger.info("Start evaluation on {} dataset({} images).".format(dataset_name, len_dataset))
+    start_time = time.time()
+    predictions = compute_on_dataset(model, data_loader, device)
     # wait for all processes to complete before measuring the time
     synchronize()
-    total_time = total_timer.toc()
-    total_time_str = get_time_str(total_time)
+    total_time = time.time() - start_time
+    total_time_str = str(datetime.timedelta(seconds=total_time))
+    logger.info(
+        "Total inference time: {}".format(
+            total_time_str
+        )
+    )
     logger.info(
-        "Total run time: {} ({} s / img per device, on {} devices)".format(
-            total_time_str, total_time * num_devices / len(dataset), num_devices
+        "Latency: {} ms / img per device, on {} devices".format(
+            total_time * num_devices / len_dataset * 1000, num_devices
         )
     )
-    total_infer_time = get_time_str(inference_timer.total_time)
     logger.info(
-        "Model inference time: {} ({} s / img per device, on {} devices)".format(
-            total_infer_time,
-            inference_timer.total_time * num_devices / len(dataset),
-            num_devices,
+        "Throughput: {} img/s per device, on {} devices".format(
+            len_dataset / total_time / num_devices, num_devices
         )
     )
 
@@ -114,7 +125,7 @@ def inference(
         expected_results_sigma_tol=expected_results_sigma_tol,
     )
 
-    return evaluate(dataset=dataset,
+    return evaluate(dataset=data_loader.dataset,
                     predictions=predictions,
                     output_folder=output_folder,
                     **extra_args)
diff --git a/maskrcnn_benchmark/engine/trainer.py b/maskrcnn_benchmark/engine/trainer.py
index 5d9cae7..8601072 100644
--- a/maskrcnn_benchmark/engine/trainer.py
+++ b/maskrcnn_benchmark/engine/trainer.py
@@ -1,19 +1,26 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import datetime
 import logging
-import os
 import time
 
 import torch
 import torch.distributed as dist
-from tqdm import tqdm
 
-from maskrcnn_benchmark.data import make_data_loader
-from maskrcnn_benchmark.utils.comm import get_world_size, synchronize
+from maskrcnn_benchmark.utils.comm import get_world_size, is_main_process
 from maskrcnn_benchmark.utils.metric_logger import MetricLogger
-from maskrcnn_benchmark.engine.inference import inference
-
-from apex import amp
 
 def reduce_loss_dict(loss_dict):
     """
@@ -39,19 +46,24 @@ def reduce_loss_dict(loss_dict):
         reduced_losses = {k: v for k, v in zip(loss_names, all_losses)}
     return reduced_losses
 
+# Instead of zeroing, set parameter grads to None
+# Prevents extraneous copy as we're not accumulating
+def set_grads_to_none(model):
+    for param in model.parameters():
+        param.grad = None
+
 
 def do_train(
-    cfg,
     model,
     data_loader,
-    data_loader_val,
     optimizer,
     scheduler,
     checkpointer,
     device,
     checkpoint_period,
-    test_period,
     arguments,
+    per_iter_start_callback_fn=None,
+    per_iter_end_callback_fn=None,
 ):
     logger = logging.getLogger("maskrcnn_benchmark.trainer")
     logger.info("Start training")
@@ -62,22 +74,17 @@ def do_train(
     start_training_time = time.time()
     end = time.time()
 
-    iou_types = ("bbox",)
-    if cfg.MODEL.MASK_ON:
-        iou_types = iou_types + ("segm",)
-    if cfg.MODEL.KEYPOINT_ON:
-        iou_types = iou_types + ("keypoints",)
-    dataset_names = cfg.DATASETS.TEST
-
     for iteration, (images, targets, _) in enumerate(data_loader, start_iter):
-        
-        if any(len(target) < 1 for target in targets):
-            logger.error(f"Iteration={iteration + 1} || Image Ids used for training {_} || targets Length={[len(target) for target in targets]}" )
-            continue
+
+        if per_iter_start_callback_fn is not None:
+            per_iter_start_callback_fn(iteration=iteration)
+
         data_time = time.time() - end
         iteration = iteration + 1
         arguments["iteration"] = iteration
 
+        scheduler.step()
+
         images = images.to(device)
         targets = [target.to(device) for target in targets]
 
@@ -90,13 +97,10 @@ def do_train(
         losses_reduced = sum(loss for loss in loss_dict_reduced.values())
         meters.update(loss=losses_reduced, **loss_dict_reduced)
 
-        optimizer.zero_grad()
-        # Note: If mixed precision is not used, this ends up doing nothing
-        # Otherwise apply loss scaling for mixed-precision recipe
-        with amp.scale_loss(losses, optimizer) as scaled_losses:
-            scaled_losses.backward()
+        losses.backward()
+
         optimizer.step()
-        scheduler.step()
+        optimizer.zero_grad()
 
         batch_time = time.time() - end
         end = time.time()
@@ -123,58 +127,20 @@ def do_train(
                     memory=torch.cuda.max_memory_allocated() / 1024.0 / 1024.0,
                 )
             )
-        if iteration % checkpoint_period == 0:
+        if iteration % checkpoint_period == 0 and arguments["save_checkpoints"]:
             checkpointer.save("model_{:07d}".format(iteration), **arguments)
-        if data_loader_val is not None and test_period > 0 and iteration % test_period == 0:
-            meters_val = MetricLogger(delimiter="  ")
-            synchronize()
-            _ = inference(  # The result can be used for additional logging, e. g. for TensorBoard
-                model,
-                # The method changes the segmentation mask format in a data loader,
-                # so every time a new data loader is created:
-                make_data_loader(cfg, is_train=False, is_distributed=(get_world_size() > 1), is_for_period=True),
-                dataset_name="[Validation]",
-                iou_types=iou_types,
-                box_only=False if cfg.MODEL.RETINANET_ON else cfg.MODEL.RPN_ONLY,
-                device=cfg.MODEL.DEVICE,
-                expected_results=cfg.TEST.EXPECTED_RESULTS,
-                expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL,
-                output_folder=None,
-            )
-            synchronize()
-            model.train()
-            with torch.no_grad():
-                # Should be one image for each GPU:
-                for iteration_val, (images_val, targets_val, _) in enumerate(tqdm(data_loader_val)):
-                    images_val = images_val.to(device)
-                    targets_val = [target.to(device) for target in targets_val]
-                    loss_dict = model(images_val, targets_val)
-                    losses = sum(loss for loss in loss_dict.values())
-                    loss_dict_reduced = reduce_loss_dict(loss_dict)
-                    losses_reduced = sum(loss for loss in loss_dict_reduced.values())
-                    meters_val.update(loss=losses_reduced, **loss_dict_reduced)
-            synchronize()
-            logger.info(
-                meters_val.delimiter.join(
-                    [
-                        "[Validation]: ",
-                        "eta: {eta}",
-                        "iter: {iter}",
-                        "{meters}",
-                        "lr: {lr:.6f}",
-                        "max mem: {memory:.0f}",
-                    ]
-                ).format(
-                    eta=eta_string,
-                    iter=iteration,
-                    meters=str(meters_val),
-                    lr=optimizer.param_groups[0]["lr"],
-                    memory=torch.cuda.max_memory_allocated() / 1024.0 / 1024.0,
-                )
-            )
-        if iteration == max_iter:
+        if iteration == max_iter and arguments["save_checkpoints"]:
             checkpointer.save("model_final", **arguments)
 
+        # per-epoch work (testing)
+        if per_iter_end_callback_fn is not None:
+            # Note: iteration has been incremented previously for
+            # human-readable checkpoint names (i.e. 60000 instead of 59999)
+            # so need to adjust again here
+            early_exit = per_iter_end_callback_fn(iteration=iteration-1)
+            if early_exit:
+                break
+
     total_training_time = time.time() - start_training_time
     total_time_str = str(datetime.timedelta(seconds=total_training_time))
     logger.info(
@@ -182,3 +148,10 @@ def do_train(
             total_time_str, total_training_time / (max_iter)
         )
     )
+    if per_iter_end_callback_fn is not None:
+        if early_exit:
+            return True
+        else:
+            return False
+    else:
+        return None
diff --git a/maskrcnn_benchmark/layers/__init__.py b/maskrcnn_benchmark/layers/__init__.py
index 0e1ccc5..812eeca 100644
--- a/maskrcnn_benchmark/layers/__init__.py
+++ b/maskrcnn_benchmark/layers/__init__.py
@@ -1,11 +1,22 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
 from .batch_norm import FrozenBatchNorm2d
 from .misc import Conv2d
-from .misc import DFConv2d
 from .misc import ConvTranspose2d
-from .misc import BatchNorm2d
 from .misc import interpolate
 from .nms import nms
 from .roi_align import ROIAlign
@@ -14,34 +25,9 @@ from .roi_pool import ROIPool
 from .roi_pool import roi_pool
 from .smooth_l1_loss import smooth_l1_loss
 from .sigmoid_focal_loss import SigmoidFocalLoss
-from .dcn.deform_conv_func import deform_conv, modulated_deform_conv
-from .dcn.deform_conv_module import DeformConv, ModulatedDeformConv, ModulatedDeformConvPack
-from .dcn.deform_pool_func import deform_roi_pooling
-from .dcn.deform_pool_module import DeformRoIPooling, DeformRoIPoolingPack, ModulatedDeformRoIPoolingPack
 
-
-__all__ = [
-    "nms",
-    "roi_align",
-    "ROIAlign",
-    "roi_pool",
-    "ROIPool",
-    "smooth_l1_loss",
-    "Conv2d",
-    "DFConv2d",
-    "ConvTranspose2d",
-    "interpolate",
-    "BatchNorm2d",
-    "FrozenBatchNorm2d",
-    "SigmoidFocalLoss",
-    'deform_conv',
-    'modulated_deform_conv',
-    'DeformConv',
-    'ModulatedDeformConv',
-    'ModulatedDeformConvPack',
-    'deform_roi_pooling',
-    'DeformRoIPooling',
-    'DeformRoIPoolingPack',
-    'ModulatedDeformRoIPoolingPack',
-]
+__all__ = ["nms", "roi_align", "ROIAlign", "roi_pool", "ROIPool",
+           "smooth_l1_loss", "Conv2d", "ConvTranspose2d", "interpolate",
+           "FrozenBatchNorm2d", "SigmoidFocalLoss"
+          ]
 
diff --git a/maskrcnn_benchmark/layers/_utils.py b/maskrcnn_benchmark/layers/_utils.py
index 3dabc12..89fd07d 100644
--- a/maskrcnn_benchmark/layers/_utils.py
+++ b/maskrcnn_benchmark/layers/_utils.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import glob
 import os.path
diff --git a/maskrcnn_benchmark/layers/batch_norm.py b/maskrcnn_benchmark/layers/batch_norm.py
index 3762e49..1805efa 100644
--- a/maskrcnn_benchmark/layers/batch_norm.py
+++ b/maskrcnn_benchmark/layers/batch_norm.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch import nn
@@ -17,13 +30,6 @@ class FrozenBatchNorm2d(nn.Module):
         self.register_buffer("running_var", torch.ones(n))
 
     def forward(self, x):
-        # Cast all fixed parameters to half() if necessary
-        if x.dtype == torch.float16:
-            self.weight = self.weight.half()
-            self.bias = self.bias.half()
-            self.running_mean = self.running_mean.half()
-            self.running_var = self.running_var.half()
-
         scale = self.weight * self.running_var.rsqrt()
         bias = self.bias - self.running_mean * scale
         scale = scale.reshape(1, -1, 1, 1)
diff --git a/maskrcnn_benchmark/layers/dcn/__init__.py b/maskrcnn_benchmark/layers/dcn/__init__.py
deleted file mode 100644
index bb5af25..0000000
--- a/maskrcnn_benchmark/layers/dcn/__init__.py
+++ /dev/null
@@ -1,3 +0,0 @@
-#
-# Copied From [mmdetection](https://github.com/open-mmlab/mmdetection/tree/master/mmdet/ops/dcn)
-#
diff --git a/maskrcnn_benchmark/layers/dcn/deform_conv_func.py b/maskrcnn_benchmark/layers/dcn/deform_conv_func.py
deleted file mode 100644
index 388bacf..0000000
--- a/maskrcnn_benchmark/layers/dcn/deform_conv_func.py
+++ /dev/null
@@ -1,262 +0,0 @@
-import torch
-from torch.autograd import Function
-from torch.autograd.function import once_differentiable
-from torch.nn.modules.utils import _pair
-
-from maskrcnn_benchmark import _C
-
-
-class DeformConvFunction(Function):
-
-    @staticmethod
-    def forward(
-        ctx,
-        input,
-        offset,
-        weight,
-        stride=1,
-        padding=0,
-        dilation=1,
-        groups=1,
-        deformable_groups=1,
-        im2col_step=64
-    ):
-        if input is not None and input.dim() != 4:
-            raise ValueError(
-                "Expected 4D tensor as input, got {}D tensor instead.".format(
-                    input.dim()))
-        ctx.stride = _pair(stride)
-        ctx.padding = _pair(padding)
-        ctx.dilation = _pair(dilation)
-        ctx.groups = groups
-        ctx.deformable_groups = deformable_groups
-        ctx.im2col_step = im2col_step
-
-        ctx.save_for_backward(input, offset, weight)
-
-        output = input.new_empty(
-            DeformConvFunction._output_size(input, weight, ctx.padding,
-                                            ctx.dilation, ctx.stride))
-
-        ctx.bufs_ = [input.new_empty(0), input.new_empty(0)]  # columns, ones
-
-        if not input.is_cuda:
-            raise NotImplementedError
-        else:
-            cur_im2col_step = min(ctx.im2col_step, input.shape[0])
-            assert (input.shape[0] %
-                    cur_im2col_step) == 0, 'im2col step must divide batchsize'
-            _C.deform_conv_forward(
-                input,
-                weight,
-                offset,
-                output,
-                ctx.bufs_[0],
-                ctx.bufs_[1],
-                weight.size(3),
-                weight.size(2),
-                ctx.stride[1],
-                ctx.stride[0],
-                ctx.padding[1],
-                ctx.padding[0],
-                ctx.dilation[1],
-                ctx.dilation[0],
-                ctx.groups,
-                ctx.deformable_groups,
-                cur_im2col_step
-            )
-        return output
-
-    @staticmethod
-    @once_differentiable
-    def backward(ctx, grad_output):
-        input, offset, weight = ctx.saved_tensors
-
-        grad_input = grad_offset = grad_weight = None
-
-        if not grad_output.is_cuda:
-            raise NotImplementedError
-        else:
-            cur_im2col_step = min(ctx.im2col_step, input.shape[0])
-            assert (input.shape[0] %
-                    cur_im2col_step) == 0, 'im2col step must divide batchsize'
-
-            if ctx.needs_input_grad[0] or ctx.needs_input_grad[1]:
-                grad_input = torch.zeros_like(input)
-                grad_offset = torch.zeros_like(offset)
-                _C.deform_conv_backward_input(
-                    input,
-                    offset,
-                    grad_output,
-                    grad_input,
-                    grad_offset,
-                    weight,
-                    ctx.bufs_[0],
-                    weight.size(3),
-                    weight.size(2),
-                    ctx.stride[1],
-                    ctx.stride[0],
-                    ctx.padding[1],
-                    ctx.padding[0],
-                    ctx.dilation[1],
-                    ctx.dilation[0],
-                    ctx.groups,
-                    ctx.deformable_groups,
-                    cur_im2col_step
-                )
-
-            if ctx.needs_input_grad[2]:
-                grad_weight = torch.zeros_like(weight)
-                _C.deform_conv_backward_parameters(
-                    input,
-                    offset,
-                    grad_output,
-                    grad_weight,
-                    ctx.bufs_[0],
-                    ctx.bufs_[1],
-                    weight.size(3),
-                    weight.size(2),
-                    ctx.stride[1],
-                    ctx.stride[0],
-                    ctx.padding[1],
-                    ctx.padding[0],
-                    ctx.dilation[1],
-                    ctx.dilation[0],
-                    ctx.groups,
-                    ctx.deformable_groups,
-                    1,
-                    cur_im2col_step
-                )
-
-        return (grad_input, grad_offset, grad_weight, None, None, None, None, None)
-
-    @staticmethod
-    def _output_size(input, weight, padding, dilation, stride):
-        channels = weight.size(0)
-        output_size = (input.size(0), channels)
-        for d in range(input.dim() - 2):
-            in_size = input.size(d + 2)
-            pad = padding[d]
-            kernel = dilation[d] * (weight.size(d + 2) - 1) + 1
-            stride_ = stride[d]
-            output_size += ((in_size + (2 * pad) - kernel) // stride_ + 1, )
-        if not all(map(lambda s: s > 0, output_size)):
-            raise ValueError(
-                "convolution input is too small (output would be {})".format(
-                    'x'.join(map(str, output_size))))
-        return output_size
-
-
-class ModulatedDeformConvFunction(Function):
-
-    @staticmethod
-    def forward(
-        ctx,
-        input,
-        offset,
-        mask,
-        weight,
-        bias=None,
-        stride=1,
-        padding=0,
-        dilation=1,
-        groups=1,
-        deformable_groups=1
-    ):
-        ctx.stride = stride
-        ctx.padding = padding
-        ctx.dilation = dilation
-        ctx.groups = groups
-        ctx.deformable_groups = deformable_groups
-        ctx.with_bias = bias is not None
-        if not ctx.with_bias:
-            bias = input.new_empty(1)  # fake tensor
-        if not input.is_cuda:
-            raise NotImplementedError
-        if weight.requires_grad or mask.requires_grad or offset.requires_grad \
-                or input.requires_grad:
-            ctx.save_for_backward(input, offset, mask, weight, bias)
-        output = input.new_empty(
-            ModulatedDeformConvFunction._infer_shape(ctx, input, weight))
-        ctx._bufs = [input.new_empty(0), input.new_empty(0)]
-        _C.modulated_deform_conv_forward(
-            input,
-            weight,
-            bias,
-            ctx._bufs[0],
-            offset,
-            mask,
-            output,
-            ctx._bufs[1],
-            weight.shape[2],
-            weight.shape[3],
-            ctx.stride,
-            ctx.stride,
-            ctx.padding,
-            ctx.padding,
-            ctx.dilation,
-            ctx.dilation,
-            ctx.groups,
-            ctx.deformable_groups,
-            ctx.with_bias
-        )
-        return output
-
-    @staticmethod
-    @once_differentiable
-    def backward(ctx, grad_output):
-        if not grad_output.is_cuda:
-            raise NotImplementedError
-        input, offset, mask, weight, bias = ctx.saved_tensors
-        grad_input = torch.zeros_like(input)
-        grad_offset = torch.zeros_like(offset)
-        grad_mask = torch.zeros_like(mask)
-        grad_weight = torch.zeros_like(weight)
-        grad_bias = torch.zeros_like(bias)
-        _C.modulated_deform_conv_backward(
-            input,
-            weight,
-            bias,
-            ctx._bufs[0],
-            offset,
-            mask,
-            ctx._bufs[1],
-            grad_input,
-            grad_weight,
-            grad_bias,
-            grad_offset,
-            grad_mask,
-            grad_output,
-            weight.shape[2],
-            weight.shape[3],
-            ctx.stride,
-            ctx.stride,
-            ctx.padding,
-            ctx.padding,
-            ctx.dilation,
-            ctx.dilation,
-            ctx.groups,
-            ctx.deformable_groups,
-            ctx.with_bias
-        )
-        if not ctx.with_bias:
-            grad_bias = None
-
-        return (grad_input, grad_offset, grad_mask, grad_weight, grad_bias,
-                None, None, None, None, None)
-
-    @staticmethod
-    def _infer_shape(ctx, input, weight):
-        n = input.size(0)
-        channels_out = weight.size(0)
-        height, width = input.shape[2:4]
-        kernel_h, kernel_w = weight.shape[2:4]
-        height_out = (height + 2 * ctx.padding -
-                      (ctx.dilation * (kernel_h - 1) + 1)) // ctx.stride + 1
-        width_out = (width + 2 * ctx.padding -
-                     (ctx.dilation * (kernel_w - 1) + 1)) // ctx.stride + 1
-        return n, channels_out, height_out, width_out
-
-
-deform_conv = DeformConvFunction.apply
-modulated_deform_conv = ModulatedDeformConvFunction.apply
diff --git a/maskrcnn_benchmark/layers/dcn/deform_conv_module.py b/maskrcnn_benchmark/layers/dcn/deform_conv_module.py
deleted file mode 100644
index e6b58c8..0000000
--- a/maskrcnn_benchmark/layers/dcn/deform_conv_module.py
+++ /dev/null
@@ -1,177 +0,0 @@
-import math
-
-import torch
-import torch.nn as nn
-from torch.nn.modules.utils import _pair
-
-from .deform_conv_func import deform_conv, modulated_deform_conv
-
-
-class DeformConv(nn.Module):
-
-    def __init__(
-        self,
-        in_channels,
-        out_channels,
-        kernel_size,
-        stride=1,
-        padding=0,
-        dilation=1,
-        groups=1,
-        deformable_groups=1,
-        bias=False
-    ):
-        assert not bias
-        super(DeformConv, self).__init__()
-        self.with_bias = bias
-
-        assert in_channels % groups == 0, \
-            'in_channels {} cannot be divisible by groups {}'.format(
-                in_channels, groups)
-        assert out_channels % groups == 0, \
-            'out_channels {} cannot be divisible by groups {}'.format(
-                out_channels, groups)
-        self.in_channels = in_channels
-        self.out_channels = out_channels
-        self.kernel_size = _pair(kernel_size)
-        self.stride = _pair(stride)
-        self.padding = _pair(padding)
-        self.dilation = _pair(dilation)
-        self.groups = groups
-        self.deformable_groups = deformable_groups
-
-        self.weight = nn.Parameter(
-            torch.Tensor(out_channels, in_channels // self.groups,
-                         *self.kernel_size))
-
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        n = self.in_channels
-        for k in self.kernel_size:
-            n *= k
-        stdv = 1. / math.sqrt(n)
-        self.weight.data.uniform_(-stdv, stdv)
-
-    def forward(self, input, offset):
-        return deform_conv(input, offset, self.weight, self.stride,
-                           self.padding, self.dilation, self.groups,
-                           self.deformable_groups)
-
-    def __repr__(self):
-        return "".join([
-            "{}(".format(self.__class__.__name__),
-            "in_channels={}, ".format(self.in_channels),
-            "out_channels={}, ".format(self.out_channels),
-            "kernel_size={}, ".format(self.kernel_size),
-            "stride={}, ".format(self.stride),
-            "dilation={}, ".format(self.dilation),
-            "padding={}, ".format(self.padding),
-            "groups={}, ".format(self.groups),
-            "deformable_groups={}, ".format(self.deformable_groups),
-            "bias={})".format(self.with_bias),
-        ])
-
-
-class ModulatedDeformConv(nn.Module):
-
-    def __init__(
-        self,
-        in_channels,
-        out_channels,
-        kernel_size,
-        stride=1,
-        padding=0,
-        dilation=1,
-        groups=1,
-        deformable_groups=1,
-        bias=True
-    ):
-        super(ModulatedDeformConv, self).__init__()
-        self.in_channels = in_channels
-        self.out_channels = out_channels
-        self.kernel_size = _pair(kernel_size)
-        self.stride = stride
-        self.padding = padding
-        self.dilation = dilation
-        self.groups = groups
-        self.deformable_groups = deformable_groups
-        self.with_bias = bias
-
-        self.weight = nn.Parameter(torch.Tensor(
-            out_channels, 
-            in_channels // groups,
-            *self.kernel_size
-        ))
-        if bias:
-            self.bias = nn.Parameter(torch.Tensor(out_channels))
-        else:
-            self.register_parameter('bias', None)
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        n = self.in_channels
-        for k in self.kernel_size:
-            n *= k
-        stdv = 1. / math.sqrt(n)
-        self.weight.data.uniform_(-stdv, stdv)
-        if self.bias is not None:
-            self.bias.data.zero_()
-
-    def forward(self, input, offset, mask):
-        return modulated_deform_conv(
-            input, offset, mask, self.weight, self.bias, self.stride,
-            self.padding, self.dilation, self.groups, self.deformable_groups)
-
-    def __repr__(self):
-        return "".join([
-            "{}(".format(self.__class__.__name__),
-            "in_channels={}, ".format(self.in_channels),
-            "out_channels={}, ".format(self.out_channels),
-            "kernel_size={}, ".format(self.kernel_size),
-            "stride={}, ".format(self.stride),
-            "dilation={}, ".format(self.dilation),
-            "padding={}, ".format(self.padding),
-            "groups={}, ".format(self.groups),
-            "deformable_groups={}, ".format(self.deformable_groups),
-            "bias={})".format(self.with_bias),
-        ])
-
-class ModulatedDeformConvPack(ModulatedDeformConv):
-
-    def __init__(self,
-                 in_channels,
-                 out_channels,
-                 kernel_size,
-                 stride=1,
-                 padding=0,
-                 dilation=1,
-                 groups=1,
-                 deformable_groups=1,
-                 bias=True):
-        super(ModulatedDeformConvPack, self).__init__(
-            in_channels, out_channels, kernel_size, stride, padding, dilation,
-            groups, deformable_groups, bias)
-
-        self.conv_offset_mask = nn.Conv2d(
-            self.in_channels // self.groups,
-            self.deformable_groups * 3 * self.kernel_size[0] *
-            self.kernel_size[1],
-            kernel_size=self.kernel_size,
-            stride=_pair(self.stride),
-            padding=_pair(self.padding),
-            bias=True)
-        self.init_offset()
-
-    def init_offset(self):
-        self.conv_offset_mask.weight.data.zero_()
-        self.conv_offset_mask.bias.data.zero_()
-
-    def forward(self, input):
-        out = self.conv_offset_mask(input)
-        o1, o2, mask = torch.chunk(out, 3, dim=1)
-        offset = torch.cat((o1, o2), dim=1)
-        mask = torch.sigmoid(mask)
-        return modulated_deform_conv(
-            input, offset, mask, self.weight, self.bias, self.stride,
-            self.padding, self.dilation, self.groups, self.deformable_groups)
diff --git a/maskrcnn_benchmark/layers/dcn/deform_pool_func.py b/maskrcnn_benchmark/layers/dcn/deform_pool_func.py
deleted file mode 100644
index e083b00..0000000
--- a/maskrcnn_benchmark/layers/dcn/deform_pool_func.py
+++ /dev/null
@@ -1,95 +0,0 @@
-import torch
-from torch.autograd import Function
-from torch.autograd.function import once_differentiable
-
-from maskrcnn_benchmark import _C
-
-
-class DeformRoIPoolingFunction(Function):
-
-    @staticmethod
-    def forward(
-        ctx,
-        data,
-        rois,
-        offset,
-        spatial_scale,
-        out_size,
-        out_channels,
-        no_trans,
-        group_size=1,
-        part_size=None,
-        sample_per_part=4,
-        trans_std=.0
-    ):
-        ctx.spatial_scale = spatial_scale
-        ctx.out_size = out_size
-        ctx.out_channels = out_channels
-        ctx.no_trans = no_trans
-        ctx.group_size = group_size
-        ctx.part_size = out_size if part_size is None else part_size
-        ctx.sample_per_part = sample_per_part
-        ctx.trans_std = trans_std
-
-        assert 0.0 <= ctx.trans_std <= 1.0
-        if not data.is_cuda:
-            raise NotImplementedError
-
-        n = rois.shape[0]
-        output = data.new_empty(n, out_channels, out_size, out_size)
-        output_count = data.new_empty(n, out_channels, out_size, out_size)
-        _C.deform_psroi_pooling_forward(
-            data,
-            rois,
-            offset,
-            output,
-            output_count,
-            ctx.no_trans,
-            ctx.spatial_scale,
-            ctx.out_channels,
-            ctx.group_size,
-            ctx.out_size,
-            ctx.part_size,
-            ctx.sample_per_part,
-            ctx.trans_std
-        )
-
-        if data.requires_grad or rois.requires_grad or offset.requires_grad:
-            ctx.save_for_backward(data, rois, offset)
-        ctx.output_count = output_count
-
-        return output
-
-    @staticmethod
-    @once_differentiable
-    def backward(ctx, grad_output):
-        if not grad_output.is_cuda:
-            raise NotImplementedError
-
-        data, rois, offset = ctx.saved_tensors
-        output_count = ctx.output_count
-        grad_input = torch.zeros_like(data)
-        grad_rois = None
-        grad_offset = torch.zeros_like(offset)
-
-        _C.deform_psroi_pooling_backward(
-            grad_output,
-            data,
-            rois,
-            offset,
-            output_count,
-            grad_input,
-            grad_offset,
-            ctx.no_trans,
-            ctx.spatial_scale,
-            ctx.out_channels,
-            ctx.group_size,
-            ctx.out_size,
-            ctx.part_size,
-            ctx.sample_per_part,
-            ctx.trans_std
-        )
-        return (grad_input, grad_rois, grad_offset, None, None, None, None, None, None, None, None)
-
-
-deform_roi_pooling = DeformRoIPoolingFunction.apply
diff --git a/maskrcnn_benchmark/layers/dcn/deform_pool_module.py b/maskrcnn_benchmark/layers/dcn/deform_pool_module.py
deleted file mode 100644
index bab6c26..0000000
--- a/maskrcnn_benchmark/layers/dcn/deform_pool_module.py
+++ /dev/null
@@ -1,150 +0,0 @@
-from torch import nn
-
-from .deform_pool_func import deform_roi_pooling
-
-
-class DeformRoIPooling(nn.Module):
-
-    def __init__(self,
-                 spatial_scale,
-                 out_size,
-                 out_channels,
-                 no_trans,
-                 group_size=1,
-                 part_size=None,
-                 sample_per_part=4,
-                 trans_std=.0):
-        super(DeformRoIPooling, self).__init__()
-        self.spatial_scale = spatial_scale
-        self.out_size = out_size
-        self.out_channels = out_channels
-        self.no_trans = no_trans
-        self.group_size = group_size
-        self.part_size = out_size if part_size is None else part_size
-        self.sample_per_part = sample_per_part
-        self.trans_std = trans_std
-
-    def forward(self, data, rois, offset):
-        if self.no_trans:
-            offset = data.new_empty(0)
-        return deform_roi_pooling(
-            data, rois, offset, self.spatial_scale, self.out_size,
-            self.out_channels, self.no_trans, self.group_size, self.part_size,
-            self.sample_per_part, self.trans_std)
-
-
-class DeformRoIPoolingPack(DeformRoIPooling):
-
-    def __init__(self,
-                 spatial_scale,
-                 out_size,
-                 out_channels,
-                 no_trans,
-                 group_size=1,
-                 part_size=None,
-                 sample_per_part=4,
-                 trans_std=.0,
-                 deform_fc_channels=1024):
-        super(DeformRoIPoolingPack,
-              self).__init__(spatial_scale, out_size, out_channels, no_trans,
-                             group_size, part_size, sample_per_part, trans_std)
-
-        self.deform_fc_channels = deform_fc_channels
-
-        if not no_trans:
-            self.offset_fc = nn.Sequential(
-                nn.Linear(self.out_size * self.out_size * self.out_channels,
-                          self.deform_fc_channels),
-                nn.ReLU(inplace=True),
-                nn.Linear(self.deform_fc_channels, self.deform_fc_channels),
-                nn.ReLU(inplace=True),
-                nn.Linear(self.deform_fc_channels,
-                          self.out_size * self.out_size * 2))
-            self.offset_fc[-1].weight.data.zero_()
-            self.offset_fc[-1].bias.data.zero_()
-
-    def forward(self, data, rois):
-        assert data.size(1) == self.out_channels
-        if self.no_trans:
-            offset = data.new_empty(0)
-            return deform_roi_pooling(
-                data, rois, offset, self.spatial_scale, self.out_size,
-                self.out_channels, self.no_trans, self.group_size,
-                self.part_size, self.sample_per_part, self.trans_std)
-        else:
-            n = rois.shape[0]
-            offset = data.new_empty(0)
-            x = deform_roi_pooling(data, rois, offset, self.spatial_scale,
-                                   self.out_size, self.out_channels, True,
-                                   self.group_size, self.part_size,
-                                   self.sample_per_part, self.trans_std)
-            offset = self.offset_fc(x.view(n, -1))
-            offset = offset.view(n, 2, self.out_size, self.out_size)
-            return deform_roi_pooling(
-                data, rois, offset, self.spatial_scale, self.out_size,
-                self.out_channels, self.no_trans, self.group_size,
-                self.part_size, self.sample_per_part, self.trans_std)
-
-
-class ModulatedDeformRoIPoolingPack(DeformRoIPooling):
-
-    def __init__(self,
-                 spatial_scale,
-                 out_size,
-                 out_channels,
-                 no_trans,
-                 group_size=1,
-                 part_size=None,
-                 sample_per_part=4,
-                 trans_std=.0,
-                 deform_fc_channels=1024):
-        super(ModulatedDeformRoIPoolingPack, self).__init__(
-            spatial_scale, out_size, out_channels, no_trans, group_size,
-            part_size, sample_per_part, trans_std)
-
-        self.deform_fc_channels = deform_fc_channels
-
-        if not no_trans:
-            self.offset_fc = nn.Sequential(
-                nn.Linear(self.out_size * self.out_size * self.out_channels,
-                          self.deform_fc_channels),
-                nn.ReLU(inplace=True),
-                nn.Linear(self.deform_fc_channels, self.deform_fc_channels),
-                nn.ReLU(inplace=True),
-                nn.Linear(self.deform_fc_channels,
-                          self.out_size * self.out_size * 2))
-            self.offset_fc[-1].weight.data.zero_()
-            self.offset_fc[-1].bias.data.zero_()
-            self.mask_fc = nn.Sequential(
-                nn.Linear(self.out_size * self.out_size * self.out_channels,
-                          self.deform_fc_channels),
-                nn.ReLU(inplace=True),
-                nn.Linear(self.deform_fc_channels,
-                          self.out_size * self.out_size * 1),
-                nn.Sigmoid())
-            self.mask_fc[2].weight.data.zero_()
-            self.mask_fc[2].bias.data.zero_()
-
-    def forward(self, data, rois):
-        assert data.size(1) == self.out_channels
-        if self.no_trans:
-            offset = data.new_empty(0)
-            return deform_roi_pooling(
-                data, rois, offset, self.spatial_scale, self.out_size,
-                self.out_channels, self.no_trans, self.group_size,
-                self.part_size, self.sample_per_part, self.trans_std)
-        else:
-            n = rois.shape[0]
-            offset = data.new_empty(0)
-            x = deform_roi_pooling(data, rois, offset, self.spatial_scale,
-                                   self.out_size, self.out_channels, True,
-                                   self.group_size, self.part_size,
-                                   self.sample_per_part, self.trans_std)
-            offset = self.offset_fc(x.view(n, -1))
-            offset = offset.view(n, 2, self.out_size, self.out_size)
-            mask = self.mask_fc(x.view(n, -1))
-            mask = mask.view(n, 1, self.out_size, self.out_size)
-            return deform_roi_pooling(
-                data, rois, offset, self.spatial_scale, self.out_size,
-                self.out_channels, self.no_trans, self.group_size,
-                self.part_size, self.sample_per_part, self.trans_std) * mask
diff --git a/maskrcnn_benchmark/layers/misc.py b/maskrcnn_benchmark/layers/misc.py
index 8711324..696acca 100644
--- a/maskrcnn_benchmark/layers/misc.py
+++ b/maskrcnn_benchmark/layers/misc.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 helper class that supports empty tensors on some nn functions.
@@ -11,7 +24,6 @@ is implemented
 
 import math
 import torch
-from torch import nn
 from torch.nn.modules.utils import _ntuple
 
 
@@ -27,6 +39,7 @@ class _NewEmptyTensorOp(torch.autograd.Function):
         return _NewEmptyTensorOp.apply(grad, shape), None
 
 
+
 class Conv2d(torch.nn.Conv2d):
     def forward(self, x):
         if x.numel() > 0:
@@ -64,15 +77,6 @@ class ConvTranspose2d(torch.nn.ConvTranspose2d):
         return _NewEmptyTensorOp.apply(x, output_shape)
 
 
-class BatchNorm2d(torch.nn.BatchNorm2d):
-    def forward(self, x):
-        if x.numel() > 0:
-            return super(BatchNorm2d, self).forward(x)
-        # get output shape
-        output_shape = x.shape
-        return _NewEmptyTensorOp.apply(x, output_shape)
-
-
 def interpolate(
     input, size=None, scale_factor=None, mode="nearest", align_corners=None
 ):
@@ -109,95 +113,3 @@ def interpolate(
     output_shape = tuple(_output_size(2))
     output_shape = input.shape[:-2] + output_shape
     return _NewEmptyTensorOp.apply(input, output_shape)
-
-
-class DFConv2d(nn.Module):
-    """Deformable convolutional layer"""
-    def __init__(
-        self,
-        in_channels,
-        out_channels,
-        with_modulated_dcn=True,
-        kernel_size=3,
-        stride=1,
-        groups=1,
-        dilation=1,
-        deformable_groups=1,
-        bias=False
-    ):
-        super(DFConv2d, self).__init__()
-        if isinstance(kernel_size, (list, tuple)):
-            assert isinstance(stride, (list, tuple))
-            assert isinstance(dilation, (list, tuple))
-            assert len(kernel_size) == 2
-            assert len(stride) == 2
-            assert len(dilation) == 2
-            padding = (
-                dilation[0] * (kernel_size[0] - 1) // 2,
-                dilation[1] * (kernel_size[1] - 1) // 2
-            )
-            offset_base_channels = kernel_size[0] * kernel_size[1]
-        else:
-            padding = dilation * (kernel_size - 1) // 2
-            offset_base_channels = kernel_size * kernel_size
-        if with_modulated_dcn:
-            from maskrcnn_benchmark.layers import ModulatedDeformConv
-            offset_channels = offset_base_channels * 3 #default: 27
-            conv_block = ModulatedDeformConv
-        else:
-            from maskrcnn_benchmark.layers import DeformConv
-            offset_channels = offset_base_channels * 2 #default: 18
-            conv_block = DeformConv
-        self.offset = Conv2d(
-            in_channels,
-            deformable_groups * offset_channels,
-            kernel_size=kernel_size,
-            stride=stride,
-            padding=padding,
-            groups=1,
-            dilation=dilation
-        )
-        for l in [self.offset,]:
-            nn.init.kaiming_uniform_(l.weight, a=1)
-            torch.nn.init.constant_(l.bias, 0.)
-        self.conv = conv_block(
-            in_channels,
-            out_channels,
-            kernel_size=kernel_size,
-            stride=stride,
-            padding=padding,
-            dilation=dilation,
-            groups=groups,
-            deformable_groups=deformable_groups,
-            bias=bias
-        )
-        self.with_modulated_dcn = with_modulated_dcn
-        self.kernel_size = kernel_size
-        self.stride = stride
-        self.padding = padding
-        self.dilation = dilation
-
-    def forward(self, x):
-        if x.numel() > 0:
-            if not self.with_modulated_dcn:
-                offset = self.offset(x)
-                x = self.conv(x, offset)
-            else:
-                offset_mask = self.offset(x)
-                offset = offset_mask[:, :18, :, :]
-                mask = offset_mask[:, -9:, :, :].sigmoid()
-                x = self.conv(x, offset, mask)
-            return x
-        # get output shape
-        output_shape = [
-            (i + 2 * p - (di * (k - 1) + 1)) // d + 1
-            for i, p, di, k, d in zip(
-                x.shape[-2:],
-                self.padding,
-                self.dilation,
-                self.kernel_size,
-                self.stride
-            )
-        ]
-        output_shape = [x.shape[0], self.conv.weight.shape[0]] + output_shape
-        return _NewEmptyTensorOp.apply(x, output_shape)
diff --git a/maskrcnn_benchmark/layers/nms.py b/maskrcnn_benchmark/layers/nms.py
index 39bff82..4112332 100644
--- a/maskrcnn_benchmark/layers/nms.py
+++ b/maskrcnn_benchmark/layers/nms.py
@@ -1,11 +1,20 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 # from ._utils import _C
 from maskrcnn_benchmark import _C
 
-from apex import amp
-
-# Only valid with fp32 inputs - give AMP the hint
-nms = amp.float_function(_C.nms)
-
+nms = _C.nms
 # nms.__doc__ = """
 # This function performs Non-maximum suppresion"""
diff --git a/maskrcnn_benchmark/layers/roi_align.py b/maskrcnn_benchmark/layers/roi_align.py
index ec797ed..8659b62 100644
--- a/maskrcnn_benchmark/layers/roi_align.py
+++ b/maskrcnn_benchmark/layers/roi_align.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch import nn
@@ -7,7 +20,6 @@ from torch.nn.modules.utils import _pair
 
 from maskrcnn_benchmark import _C
 
-from apex import amp
 
 class _ROIAlign(Function):
     @staticmethod
@@ -47,6 +59,7 @@ class _ROIAlign(Function):
 
 roi_align = _ROIAlign.apply
 
+
 class ROIAlign(nn.Module):
     def __init__(self, output_size, spatial_scale, sampling_ratio):
         super(ROIAlign, self).__init__()
@@ -54,7 +67,6 @@ class ROIAlign(nn.Module):
         self.spatial_scale = spatial_scale
         self.sampling_ratio = sampling_ratio
 
-    @amp.float_function
     def forward(self, input, rois):
         return roi_align(
             input, rois, self.output_size, self.spatial_scale, self.sampling_ratio
diff --git a/maskrcnn_benchmark/layers/roi_pool.py b/maskrcnn_benchmark/layers/roi_pool.py
index 5863390..b2749ed 100644
--- a/maskrcnn_benchmark/layers/roi_pool.py
+++ b/maskrcnn_benchmark/layers/roi_pool.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch import nn
@@ -7,7 +20,6 @@ from torch.nn.modules.utils import _pair
 
 from maskrcnn_benchmark import _C
 
-from apex import amp
 
 class _ROIPool(Function):
     @staticmethod
@@ -53,7 +65,6 @@ class ROIPool(nn.Module):
         self.output_size = output_size
         self.spatial_scale = spatial_scale
 
-    @amp.float_function
     def forward(self, input, rois):
         return roi_pool(input, rois, self.output_size, self.spatial_scale)
 
diff --git a/maskrcnn_benchmark/layers/sigmoid_focal_loss.py b/maskrcnn_benchmark/layers/sigmoid_focal_loss.py
index 22b8018..617e44f 100644
--- a/maskrcnn_benchmark/layers/sigmoid_focal_loss.py
+++ b/maskrcnn_benchmark/layers/sigmoid_focal_loss.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import torch
 from torch import nn
 from torch.autograd import Function
@@ -39,6 +52,8 @@ sigmoid_focal_loss_cuda = _SigmoidFocalLoss.apply
 
 def sigmoid_focal_loss_cpu(logits, targets, gamma, alpha):
     num_classes = logits.shape[1]
+    gamma = gamma[0]
+    alpha = alpha[0]
     dtype = targets.dtype
     device = targets.device
     class_range = torch.arange(1, num_classes+1, dtype=dtype, device=device).unsqueeze(0)
diff --git a/maskrcnn_benchmark/layers/smooth_l1_loss.py b/maskrcnn_benchmark/layers/smooth_l1_loss.py
index 9c4664b..ee6557e 100644
--- a/maskrcnn_benchmark/layers/smooth_l1_loss.py
+++ b/maskrcnn_benchmark/layers/smooth_l1_loss.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
diff --git a/maskrcnn_benchmark/modeling/__init__.py b/maskrcnn_benchmark/modeling/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/modeling/__init__.py
+++ b/maskrcnn_benchmark/modeling/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/modeling/backbone/__init__.py b/maskrcnn_benchmark/modeling/backbone/__init__.py
index 537ebe5..5c2a4b3 100644
--- a/maskrcnn_benchmark/modeling/backbone/__init__.py
+++ b/maskrcnn_benchmark/modeling/backbone/__init__.py
@@ -1,3 +1,15 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .backbone import build_backbone
-from . import fbnet
diff --git a/maskrcnn_benchmark/modeling/backbone/backbone.py b/maskrcnn_benchmark/modeling/backbone/backbone.py
index 6033d6f..7e6d7f2 100644
--- a/maskrcnn_benchmark/modeling/backbone/backbone.py
+++ b/maskrcnn_benchmark/modeling/backbone/backbone.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from collections import OrderedDict
 
@@ -16,7 +29,6 @@ from . import resnet
 def build_resnet_backbone(cfg):
     body = resnet.ResNet(cfg)
     model = nn.Sequential(OrderedDict([("body", body)]))
-    model.out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
     return model
 
 
@@ -26,7 +38,7 @@ def build_resnet_backbone(cfg):
 def build_resnet_fpn_backbone(cfg):
     body = resnet.ResNet(cfg)
     in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
-    out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
+    out_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS
     fpn = fpn_module.FPN(
         in_channels_list=[
             in_channels_stage2,
@@ -41,16 +53,14 @@ def build_resnet_fpn_backbone(cfg):
         top_blocks=fpn_module.LastLevelMaxPool(),
     )
     model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)]))
-    model.out_channels = out_channels
     return model
 
-
 @registry.BACKBONES.register("R-50-FPN-RETINANET")
 @registry.BACKBONES.register("R-101-FPN-RETINANET")
 def build_resnet_fpn_p3p7_backbone(cfg):
     body = resnet.ResNet(cfg)
     in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
-    out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
+    out_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS
     in_channels_p6p7 = in_channels_stage2 * 8 if cfg.MODEL.RETINANET.USE_C5 \
         else out_channels
     fpn = fpn_module.FPN(
@@ -67,10 +77,8 @@ def build_resnet_fpn_p3p7_backbone(cfg):
         top_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7, out_channels),
     )
     model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)]))
-    model.out_channels = out_channels
     return model
 
-
 def build_backbone(cfg):
     assert cfg.MODEL.BACKBONE.CONV_BODY in registry.BACKBONES, \
         "cfg.MODEL.BACKBONE.CONV_BODY: {} are not registered in registry".format(
diff --git a/maskrcnn_benchmark/modeling/backbone/fbnet.py b/maskrcnn_benchmark/modeling/backbone/fbnet.py
deleted file mode 100755
index 0d8cf15..0000000
--- a/maskrcnn_benchmark/modeling/backbone/fbnet.py
+++ /dev/null
@@ -1,252 +0,0 @@
-from __future__ import absolute_import, division, print_function, unicode_literals
-
-import copy
-import json
-import logging
-from collections import OrderedDict
-
-from . import (
-    fbnet_builder as mbuilder,
-    fbnet_modeldef as modeldef,
-)
-import torch.nn as nn
-from maskrcnn_benchmark.modeling import registry
-from maskrcnn_benchmark.modeling.rpn import rpn
-from maskrcnn_benchmark.modeling import poolers
-
-
-logger = logging.getLogger(__name__)
-
-
-def create_builder(cfg):
-    bn_type = cfg.MODEL.FBNET.BN_TYPE
-    if bn_type == "gn":
-        bn_type = (bn_type, cfg.GROUP_NORM.NUM_GROUPS)
-    factor = cfg.MODEL.FBNET.SCALE_FACTOR
-
-    arch = cfg.MODEL.FBNET.ARCH
-    arch_def = cfg.MODEL.FBNET.ARCH_DEF
-    if len(arch_def) > 0:
-        arch_def = json.loads(arch_def)
-    if arch in modeldef.MODEL_ARCH:
-        if len(arch_def) > 0:
-            assert (
-                arch_def == modeldef.MODEL_ARCH[arch]
-            ), "Two architectures with the same name {},\n{},\n{}".format(
-                arch, arch_def, modeldef.MODEL_ARCH[arch]
-            )
-        arch_def = modeldef.MODEL_ARCH[arch]
-    else:
-        assert arch_def is not None and len(arch_def) > 0
-    arch_def = mbuilder.unify_arch_def(arch_def)
-
-    rpn_stride = arch_def.get("rpn_stride", None)
-    if rpn_stride is not None:
-        assert (
-            cfg.MODEL.RPN.ANCHOR_STRIDE[0] == rpn_stride
-        ), "Needs to set cfg.MODEL.RPN.ANCHOR_STRIDE to {}, got {}".format(
-            rpn_stride, cfg.MODEL.RPN.ANCHOR_STRIDE
-        )
-    width_divisor = cfg.MODEL.FBNET.WIDTH_DIVISOR
-    dw_skip_bn = cfg.MODEL.FBNET.DW_CONV_SKIP_BN
-    dw_skip_relu = cfg.MODEL.FBNET.DW_CONV_SKIP_RELU
-
-    logger.info(
-        "Building fbnet model with arch {} (without scaling):\n{}".format(
-            arch, arch_def
-        )
-    )
-
-    builder = mbuilder.FBNetBuilder(
-        width_ratio=factor,
-        bn_type=bn_type,
-        width_divisor=width_divisor,
-        dw_skip_bn=dw_skip_bn,
-        dw_skip_relu=dw_skip_relu,
-    )
-
-    return builder, arch_def
-
-
-def _get_trunk_cfg(arch_def):
-    """ Get all stages except the last one """
-    num_stages = mbuilder.get_num_stages(arch_def)
-    trunk_stages = arch_def.get("backbone", range(num_stages - 1))
-    ret = mbuilder.get_blocks(arch_def, stage_indices=trunk_stages)
-    return ret
-
-
-class FBNetTrunk(nn.Module):
-    def __init__(
-        self, builder, arch_def, dim_in,
-    ):
-        super(FBNetTrunk, self).__init__()
-        self.first = builder.add_first(arch_def["first"], dim_in=dim_in)
-        trunk_cfg = _get_trunk_cfg(arch_def)
-        self.stages = builder.add_blocks(trunk_cfg["stages"])
-
-    # return features for each stage
-    def forward(self, x):
-        y = self.first(x)
-        y = self.stages(y)
-        ret = [y]
-        return ret
-
-
-@registry.BACKBONES.register("FBNet")
-def add_conv_body(cfg, dim_in=3):
-    builder, arch_def = create_builder(cfg)
-
-    body = FBNetTrunk(builder, arch_def, dim_in)
-    model = nn.Sequential(OrderedDict([("body", body)]))
-    model.out_channels = builder.last_depth
-
-    return model
-
-
-def _get_rpn_stage(arch_def, num_blocks):
-    rpn_stage = arch_def.get("rpn")
-    ret = mbuilder.get_blocks(arch_def, stage_indices=rpn_stage)
-    if num_blocks > 0:
-        logger.warn('Use last {} blocks in {} as rpn'.format(num_blocks, ret))
-        block_count = len(ret["stages"])
-        assert num_blocks <= block_count, "use block {}, block count {}".format(
-            num_blocks, block_count
-        )
-        blocks = range(block_count - num_blocks, block_count)
-        ret = mbuilder.get_blocks(ret, block_indices=blocks)
-    return ret["stages"]
-
-
-class FBNetRPNHead(nn.Module):
-    def __init__(
-        self, cfg, in_channels, builder, arch_def,
-    ):
-        super(FBNetRPNHead, self).__init__()
-        assert in_channels == builder.last_depth
-
-        rpn_bn_type = cfg.MODEL.FBNET.RPN_BN_TYPE
-        if len(rpn_bn_type) > 0:
-            builder.bn_type = rpn_bn_type
-
-        use_blocks = cfg.MODEL.FBNET.RPN_HEAD_BLOCKS
-        stages = _get_rpn_stage(arch_def, use_blocks)
-
-        self.head = builder.add_blocks(stages)
-        self.out_channels = builder.last_depth
-
-    def forward(self, x):
-        x = [self.head(y) for y in x]
-        return x
-
-
-@registry.RPN_HEADS.register("FBNet.rpn_head")
-def add_rpn_head(cfg, in_channels, num_anchors):
-    builder, model_arch = create_builder(cfg)
-    builder.last_depth = in_channels
-
-    assert in_channels == builder.last_depth
-    # builder.name_prefix = "[rpn]"
-
-    rpn_feature = FBNetRPNHead(cfg, in_channels, builder, model_arch)
-    rpn_regressor = rpn.RPNHeadConvRegressor(
-        cfg, rpn_feature.out_channels, num_anchors)
-    return nn.Sequential(rpn_feature, rpn_regressor)
-
-
-def _get_head_stage(arch, head_name, blocks):
-    # use default name 'head' if the specific name 'head_name' does not existed
-    if head_name not in arch:
-        head_name = "head"
-    head_stage = arch.get(head_name)
-    ret = mbuilder.get_blocks(arch, stage_indices=head_stage, block_indices=blocks)
-    return ret["stages"]
-
-
-# name mapping for head names in arch def and cfg
-ARCH_CFG_NAME_MAPPING = {
-    "bbox": "ROI_BOX_HEAD",
-    "kpts": "ROI_KEYPOINT_HEAD",
-    "mask": "ROI_MASK_HEAD",
-}
-
-
-class FBNetROIHead(nn.Module):
-    def __init__(
-        self, cfg, in_channels, builder, arch_def,
-        head_name, use_blocks, stride_init, last_layer_scale,
-    ):
-        super(FBNetROIHead, self).__init__()
-        assert in_channels == builder.last_depth
-        assert isinstance(use_blocks, list)
-
-        head_cfg_name = ARCH_CFG_NAME_MAPPING[head_name]
-        self.pooler = poolers.make_pooler(cfg, head_cfg_name)
-
-        stage = _get_head_stage(arch_def, head_name, use_blocks)
-
-        assert stride_init in [0, 1, 2]
-        if stride_init != 0:
-            stage[0]["block"][3] = stride_init
-        blocks = builder.add_blocks(stage)
-
-        last_info = copy.deepcopy(arch_def["last"])
-        last_info[1] = last_layer_scale
-        last = builder.add_last(last_info)
-
-        self.head = nn.Sequential(OrderedDict([
-            ("blocks", blocks),
-            ("last", last)
-        ]))
-
-        self.out_channels = builder.last_depth
-
-    def forward(self, x, proposals):
-        x = self.pooler(x, proposals)
-        x = self.head(x)
-        return x
-
-
-@registry.ROI_BOX_FEATURE_EXTRACTORS.register("FBNet.roi_head")
-def add_roi_head(cfg, in_channels):
-    builder, model_arch = create_builder(cfg)
-    builder.last_depth = in_channels
-    # builder.name_prefix = "_[bbox]_"
-
-    return FBNetROIHead(
-        cfg, in_channels, builder, model_arch,
-        head_name="bbox",
-        use_blocks=cfg.MODEL.FBNET.DET_HEAD_BLOCKS,
-        stride_init=cfg.MODEL.FBNET.DET_HEAD_STRIDE,
-        last_layer_scale=cfg.MODEL.FBNET.DET_HEAD_LAST_SCALE,
-    )
-
-
-@registry.ROI_KEYPOINT_FEATURE_EXTRACTORS.register("FBNet.roi_head_keypoints")
-def add_roi_head_keypoints(cfg, in_channels):
-    builder, model_arch = create_builder(cfg)
-    builder.last_depth = in_channels
-    # builder.name_prefix = "_[kpts]_"
-
-    return FBNetROIHead(
-        cfg, in_channels, builder, model_arch,
-        head_name="kpts",
-        use_blocks=cfg.MODEL.FBNET.KPTS_HEAD_BLOCKS,
-        stride_init=cfg.MODEL.FBNET.KPTS_HEAD_STRIDE,
-        last_layer_scale=cfg.MODEL.FBNET.KPTS_HEAD_LAST_SCALE,
-    )
-
-
-@registry.ROI_MASK_FEATURE_EXTRACTORS.register("FBNet.roi_head_mask")
-def add_roi_head_mask(cfg, in_channels):
-    builder, model_arch = create_builder(cfg)
-    builder.last_depth = in_channels
-    # builder.name_prefix = "_[mask]_"
-
-    return FBNetROIHead(
-        cfg, in_channels, builder, model_arch,
-        head_name="mask",
-        use_blocks=cfg.MODEL.FBNET.MASK_HEAD_BLOCKS,
-        stride_init=cfg.MODEL.FBNET.MASK_HEAD_STRIDE,
-        last_layer_scale=cfg.MODEL.FBNET.MASK_HEAD_LAST_SCALE,
-    )
diff --git a/maskrcnn_benchmark/modeling/backbone/fbnet_builder.py b/maskrcnn_benchmark/modeling/backbone/fbnet_builder.py
deleted file mode 100755
index 112a040..0000000
--- a/maskrcnn_benchmark/modeling/backbone/fbnet_builder.py
+++ /dev/null
@@ -1,829 +0,0 @@
-"""
-FBNet model builder
-"""
-
-from __future__ import absolute_import, division, print_function, unicode_literals
-
-import copy
-import logging
-import math
-from collections import OrderedDict
-
-import torch
-import torch.nn as nn
-from maskrcnn_benchmark.layers import (
-    BatchNorm2d,
-    Conv2d,
-    FrozenBatchNorm2d,
-    interpolate,
-)
-from maskrcnn_benchmark.layers.misc import _NewEmptyTensorOp
-
-
-logger = logging.getLogger(__name__)
-
-
-def _py2_round(x):
-    return math.floor(x + 0.5) if x >= 0.0 else math.ceil(x - 0.5)
-
-
-def _get_divisible_by(num, divisible_by, min_val):
-    ret = int(num)
-    if divisible_by > 0 and num % divisible_by != 0:
-        ret = int((_py2_round(num / divisible_by) or min_val) * divisible_by)
-    return ret
-
-
-PRIMITIVES = {
-    "skip": lambda C_in, C_out, expansion, stride, **kwargs: Identity(
-        C_in, C_out, stride
-    ),
-    "ir_k3": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, expansion, stride, **kwargs
-    ),
-    "ir_k5": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, expansion, stride, kernel=5, **kwargs
-    ),
-    "ir_k7": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, expansion, stride, kernel=7, **kwargs
-    ),
-    "ir_k1": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, expansion, stride, kernel=1, **kwargs
-    ),
-    "shuffle": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, expansion, stride, shuffle_type="mid", pw_group=4, **kwargs
-    ),
-    "basic_block": lambda C_in, C_out, expansion, stride, **kwargs: CascadeConv3x3(
-        C_in, C_out, stride
-    ),
-    "shift_5x5": lambda C_in, C_out, expansion, stride, **kwargs: ShiftBlock5x5(
-        C_in, C_out, expansion, stride
-    ),
-    # layer search 2
-    "ir_k3_e1": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=3, **kwargs
-    ),
-    "ir_k3_e3": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 3, stride, kernel=3, **kwargs
-    ),
-    "ir_k3_e6": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 6, stride, kernel=3, **kwargs
-    ),
-    "ir_k3_s4": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 4, stride, kernel=3, shuffle_type="mid", pw_group=4, **kwargs
-    ),
-    "ir_k5_e1": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=5, **kwargs
-    ),
-    "ir_k5_e3": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 3, stride, kernel=5, **kwargs
-    ),
-    "ir_k5_e6": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 6, stride, kernel=5, **kwargs
-    ),
-    "ir_k5_s4": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 4, stride, kernel=5, shuffle_type="mid", pw_group=4, **kwargs
-    ),
-    # layer search se
-    "ir_k3_e1_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=3, se=True, **kwargs
-    ),
-    "ir_k3_e3_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 3, stride, kernel=3, se=True, **kwargs
-    ),
-    "ir_k3_e6_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 6, stride, kernel=3, se=True, **kwargs
-    ),
-    "ir_k3_s4_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in,
-        C_out,
-        4,
-        stride,
-        kernel=3,
-        shuffle_type="mid",
-        pw_group=4,
-        se=True,
-        **kwargs
-    ),
-    "ir_k5_e1_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=5, se=True, **kwargs
-    ),
-    "ir_k5_e3_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 3, stride, kernel=5, se=True, **kwargs
-    ),
-    "ir_k5_e6_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 6, stride, kernel=5, se=True, **kwargs
-    ),
-    "ir_k5_s4_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in,
-        C_out,
-        4,
-        stride,
-        kernel=5,
-        shuffle_type="mid",
-        pw_group=4,
-        se=True,
-        **kwargs
-    ),
-    # layer search 3 (in addition to layer search 2)
-    "ir_k3_s2": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=3, shuffle_type="mid", pw_group=2, **kwargs
-    ),
-    "ir_k5_s2": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=5, shuffle_type="mid", pw_group=2, **kwargs
-    ),
-    "ir_k3_s2_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in,
-        C_out,
-        1,
-        stride,
-        kernel=3,
-        shuffle_type="mid",
-        pw_group=2,
-        se=True,
-        **kwargs
-    ),
-    "ir_k5_s2_se": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in,
-        C_out,
-        1,
-        stride,
-        kernel=5,
-        shuffle_type="mid",
-        pw_group=2,
-        se=True,
-        **kwargs
-    ),
-    # layer search 4 (in addition to layer search 3)
-    "ir_k3_sep": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, expansion, stride, kernel=3, cdw=True, **kwargs
-    ),
-    "ir_k33_e1": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=3, cdw=True, **kwargs
-    ),
-    "ir_k33_e3": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 3, stride, kernel=3, cdw=True, **kwargs
-    ),
-    "ir_k33_e6": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 6, stride, kernel=3, cdw=True, **kwargs
-    ),
-    # layer search 5 (in addition to layer search 4)
-    "ir_k7_e1": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=7, **kwargs
-    ),
-    "ir_k7_e3": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 3, stride, kernel=7, **kwargs
-    ),
-    "ir_k7_e6": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 6, stride, kernel=7, **kwargs
-    ),
-    "ir_k7_sep": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, expansion, stride, kernel=7, cdw=True, **kwargs
-    ),
-    "ir_k7_sep_e1": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 1, stride, kernel=7, cdw=True, **kwargs
-    ),
-    "ir_k7_sep_e3": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 3, stride, kernel=7, cdw=True, **kwargs
-    ),
-    "ir_k7_sep_e6": lambda C_in, C_out, expansion, stride, **kwargs: IRFBlock(
-        C_in, C_out, 6, stride, kernel=7, cdw=True, **kwargs
-    ),
-}
-
-
-class Identity(nn.Module):
-    def __init__(self, C_in, C_out, stride):
-        super(Identity, self).__init__()
-        self.conv = (
-            ConvBNRelu(
-                C_in,
-                C_out,
-                kernel=1,
-                stride=stride,
-                pad=0,
-                no_bias=1,
-                use_relu="relu",
-                bn_type="bn",
-            )
-            if C_in != C_out or stride != 1
-            else None
-        )
-
-    def forward(self, x):
-        if self.conv:
-            out = self.conv(x)
-        else:
-            out = x
-        return out
-
-
-class CascadeConv3x3(nn.Sequential):
-    def __init__(self, C_in, C_out, stride):
-        assert stride in [1, 2]
-        ops = [
-            Conv2d(C_in, C_in, 3, stride, 1, bias=False),
-            BatchNorm2d(C_in),
-            nn.ReLU(inplace=True),
-            Conv2d(C_in, C_out, 3, 1, 1, bias=False),
-            BatchNorm2d(C_out),
-        ]
-        super(CascadeConv3x3, self).__init__(*ops)
-        self.res_connect = (stride == 1) and (C_in == C_out)
-
-    def forward(self, x):
-        y = super(CascadeConv3x3, self).forward(x)
-        if self.res_connect:
-            y += x
-        return y
-
-
-class Shift(nn.Module):
-    def __init__(self, C, kernel_size, stride, padding):
-        super(Shift, self).__init__()
-        self.C = C
-        kernel = torch.zeros((C, 1, kernel_size, kernel_size), dtype=torch.float32)
-        ch_idx = 0
-
-        assert stride in [1, 2]
-        self.stride = stride
-        self.padding = padding
-        self.kernel_size = kernel_size
-        self.dilation = 1
-
-        hks = kernel_size // 2
-        ksq = kernel_size ** 2
-
-        for i in range(kernel_size):
-            for j in range(kernel_size):
-                if i == hks and j == hks:
-                    num_ch = C // ksq + C % ksq
-                else:
-                    num_ch = C // ksq
-                kernel[ch_idx : ch_idx + num_ch, 0, i, j] = 1
-                ch_idx += num_ch
-
-        self.register_parameter("bias", None)
-        self.kernel = nn.Parameter(kernel, requires_grad=False)
-
-    def forward(self, x):
-        if x.numel() > 0:
-            return nn.functional.conv2d(
-                x,
-                self.kernel,
-                self.bias,
-                (self.stride, self.stride),
-                (self.padding, self.padding),
-                self.dilation,
-                self.C,  # groups
-            )
-
-        output_shape = [
-            (i + 2 * p - (di * (k - 1) + 1)) // d + 1
-            for i, p, di, k, d in zip(
-                x.shape[-2:],
-                (self.padding, self.dilation),
-                (self.dilation, self.dilation),
-                (self.kernel_size, self.kernel_size),
-                (self.stride, self.stride),
-            )
-        ]
-        output_shape = [x.shape[0], self.C] + output_shape
-        return _NewEmptyTensorOp.apply(x, output_shape)
-
-
-class ShiftBlock5x5(nn.Sequential):
-    def __init__(self, C_in, C_out, expansion, stride):
-        assert stride in [1, 2]
-        self.res_connect = (stride == 1) and (C_in == C_out)
-
-        C_mid = _get_divisible_by(C_in * expansion, 8, 8)
-
-        ops = [
-            # pw
-            Conv2d(C_in, C_mid, 1, 1, 0, bias=False),
-            BatchNorm2d(C_mid),
-            nn.ReLU(inplace=True),
-            # shift
-            Shift(C_mid, 5, stride, 2),
-            # pw-linear
-            Conv2d(C_mid, C_out, 1, 1, 0, bias=False),
-            BatchNorm2d(C_out),
-        ]
-        super(ShiftBlock5x5, self).__init__(*ops)
-
-    def forward(self, x):
-        y = super(ShiftBlock5x5, self).forward(x)
-        if self.res_connect:
-            y += x
-        return y
-
-
-class ChannelShuffle(nn.Module):
-    def __init__(self, groups):
-        super(ChannelShuffle, self).__init__()
-        self.groups = groups
-
-    def forward(self, x):
-        """Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]"""
-        N, C, H, W = x.size()
-        g = self.groups
-        assert C % g == 0, "Incompatible group size {} for input channel {}".format(
-            g, C
-        )
-        return (
-            x.view(N, g, int(C / g), H, W)
-            .permute(0, 2, 1, 3, 4)
-            .contiguous()
-            .view(N, C, H, W)
-        )
-
-
-class ConvBNRelu(nn.Sequential):
-    def __init__(
-        self,
-        input_depth,
-        output_depth,
-        kernel,
-        stride,
-        pad,
-        no_bias,
-        use_relu,
-        bn_type,
-        group=1,
-        *args,
-        **kwargs
-    ):
-        super(ConvBNRelu, self).__init__()
-
-        assert use_relu in ["relu", None]
-        if isinstance(bn_type, (list, tuple)):
-            assert len(bn_type) == 2
-            assert bn_type[0] == "gn"
-            gn_group = bn_type[1]
-            bn_type = bn_type[0]
-        assert bn_type in ["bn", "af", "gn", None]
-        assert stride in [1, 2, 4]
-
-        op = Conv2d(
-            input_depth,
-            output_depth,
-            kernel_size=kernel,
-            stride=stride,
-            padding=pad,
-            bias=not no_bias,
-            groups=group,
-            *args,
-            **kwargs
-        )
-        nn.init.kaiming_normal_(op.weight, mode="fan_out", nonlinearity="relu")
-        if op.bias is not None:
-            nn.init.constant_(op.bias, 0.0)
-        self.add_module("conv", op)
-
-        if bn_type == "bn":
-            bn_op = BatchNorm2d(output_depth)
-        elif bn_type == "gn":
-            bn_op = nn.GroupNorm(num_groups=gn_group, num_channels=output_depth)
-        elif bn_type == "af":
-            bn_op = FrozenBatchNorm2d(output_depth)
-        if bn_type is not None:
-            self.add_module("bn", bn_op)
-
-        if use_relu == "relu":
-            self.add_module("relu", nn.ReLU(inplace=True))
-
-
-class SEModule(nn.Module):
-    reduction = 4
-
-    def __init__(self, C):
-        super(SEModule, self).__init__()
-        mid = max(C // self.reduction, 8)
-        conv1 = Conv2d(C, mid, 1, 1, 0)
-        conv2 = Conv2d(mid, C, 1, 1, 0)
-
-        self.op = nn.Sequential(
-            nn.AdaptiveAvgPool2d(1), conv1, nn.ReLU(inplace=True), conv2, nn.Sigmoid()
-        )
-
-    def forward(self, x):
-        return x * self.op(x)
-
-
-class Upsample(nn.Module):
-    def __init__(self, scale_factor, mode, align_corners=None):
-        super(Upsample, self).__init__()
-        self.scale = scale_factor
-        self.mode = mode
-        self.align_corners = align_corners
-
-    def forward(self, x):
-        return interpolate(
-            x, scale_factor=self.scale, mode=self.mode,
-            align_corners=self.align_corners
-        )
-
-
-def _get_upsample_op(stride):
-    assert (
-        stride in [1, 2, 4]
-        or stride in [-1, -2, -4]
-        or (isinstance(stride, tuple) and all(x in [-1, -2, -4] for x in stride))
-    )
-
-    scales = stride
-    ret = None
-    if isinstance(stride, tuple) or stride < 0:
-        scales = [-x for x in stride] if isinstance(stride, tuple) else -stride
-        stride = 1
-        ret = Upsample(scale_factor=scales, mode="nearest", align_corners=None)
-
-    return ret, stride
-
-
-class IRFBlock(nn.Module):
-    def __init__(
-        self,
-        input_depth,
-        output_depth,
-        expansion,
-        stride,
-        bn_type="bn",
-        kernel=3,
-        width_divisor=1,
-        shuffle_type=None,
-        pw_group=1,
-        se=False,
-        cdw=False,
-        dw_skip_bn=False,
-        dw_skip_relu=False,
-    ):
-        super(IRFBlock, self).__init__()
-
-        assert kernel in [1, 3, 5, 7], kernel
-
-        self.use_res_connect = stride == 1 and input_depth == output_depth
-        self.output_depth = output_depth
-
-        mid_depth = int(input_depth * expansion)
-        mid_depth = _get_divisible_by(mid_depth, width_divisor, width_divisor)
-
-        # pw
-        self.pw = ConvBNRelu(
-            input_depth,
-            mid_depth,
-            kernel=1,
-            stride=1,
-            pad=0,
-            no_bias=1,
-            use_relu="relu",
-            bn_type=bn_type,
-            group=pw_group,
-        )
-
-        # negative stride to do upsampling
-        self.upscale, stride = _get_upsample_op(stride)
-
-        # dw
-        if kernel == 1:
-            self.dw = nn.Sequential()
-        elif cdw:
-            dw1 = ConvBNRelu(
-                mid_depth,
-                mid_depth,
-                kernel=kernel,
-                stride=stride,
-                pad=(kernel // 2),
-                group=mid_depth,
-                no_bias=1,
-                use_relu="relu",
-                bn_type=bn_type,
-            )
-            dw2 = ConvBNRelu(
-                mid_depth,
-                mid_depth,
-                kernel=kernel,
-                stride=1,
-                pad=(kernel // 2),
-                group=mid_depth,
-                no_bias=1,
-                use_relu="relu" if not dw_skip_relu else None,
-                bn_type=bn_type if not dw_skip_bn else None,
-            )
-            self.dw = nn.Sequential(OrderedDict([("dw1", dw1), ("dw2", dw2)]))
-        else:
-            self.dw = ConvBNRelu(
-                mid_depth,
-                mid_depth,
-                kernel=kernel,
-                stride=stride,
-                pad=(kernel // 2),
-                group=mid_depth,
-                no_bias=1,
-                use_relu="relu" if not dw_skip_relu else None,
-                bn_type=bn_type if not dw_skip_bn else None,
-            )
-
-        # pw-linear
-        self.pwl = ConvBNRelu(
-            mid_depth,
-            output_depth,
-            kernel=1,
-            stride=1,
-            pad=0,
-            no_bias=1,
-            use_relu=None,
-            bn_type=bn_type,
-            group=pw_group,
-        )
-
-        self.shuffle_type = shuffle_type
-        if shuffle_type is not None:
-            self.shuffle = ChannelShuffle(pw_group)
-
-        self.se4 = SEModule(output_depth) if se else nn.Sequential()
-
-        self.output_depth = output_depth
-
-    def forward(self, x):
-        y = self.pw(x)
-        if self.shuffle_type == "mid":
-            y = self.shuffle(y)
-        if self.upscale is not None:
-            y = self.upscale(y)
-        y = self.dw(y)
-        y = self.pwl(y)
-        if self.use_res_connect:
-            y += x
-        y = self.se4(y)
-        return y
-
-
-def _expand_block_cfg(block_cfg):
-    assert isinstance(block_cfg, list)
-    ret = []
-    for idx in range(block_cfg[2]):
-        cur = copy.deepcopy(block_cfg)
-        cur[2] = 1
-        cur[3] = 1 if idx >= 1 else cur[3]
-        ret.append(cur)
-    return ret
-
-
-def expand_stage_cfg(stage_cfg):
-    """ For a single stage """
-    assert isinstance(stage_cfg, list)
-    ret = []
-    for x in stage_cfg:
-        ret += _expand_block_cfg(x)
-    return ret
-
-
-def expand_stages_cfg(stage_cfgs):
-    """ For a list of stages """
-    assert isinstance(stage_cfgs, list)
-    ret = []
-    for x in stage_cfgs:
-        ret.append(expand_stage_cfg(x))
-    return ret
-
-
-def _block_cfgs_to_list(block_cfgs):
-    assert isinstance(block_cfgs, list)
-    ret = []
-    for stage_idx, stage in enumerate(block_cfgs):
-        stage = expand_stage_cfg(stage)
-        for block_idx, block in enumerate(stage):
-            cur = {"stage_idx": stage_idx, "block_idx": block_idx, "block": block}
-            ret.append(cur)
-    return ret
-
-
-def _add_to_arch(arch, info, name):
-    """ arch = [{block_0}, {block_1}, ...]
-        info = [
-            # stage 0
-            [
-                block0_info,
-                block1_info,
-                ...
-            ], ...
-        ]
-        convert to:
-        arch = [
-            {
-                block_0,
-                name: block0_info,
-            },
-            {
-                block_1,
-                name: block1_info,
-            }, ...
-        ]
-    """
-    assert isinstance(arch, list) and all(isinstance(x, dict) for x in arch)
-    assert isinstance(info, list) and all(isinstance(x, list) for x in info)
-    idx = 0
-    for stage_idx, stage in enumerate(info):
-        for block_idx, block in enumerate(stage):
-            assert (
-                arch[idx]["stage_idx"] == stage_idx
-                and arch[idx]["block_idx"] == block_idx
-            ), "Index ({}, {}) does not match for block {}".format(
-                stage_idx, block_idx, arch[idx]
-            )
-            assert name not in arch[idx]
-            arch[idx][name] = block
-            idx += 1
-
-
-def unify_arch_def(arch_def):
-    """ unify the arch_def to:
-        {
-            ...,
-            "arch": [
-                {
-                    "stage_idx": idx,
-                    "block_idx": idx,
-                    ...
-                },
-                {}, ...
-            ]
-        }
-    """
-    ret = copy.deepcopy(arch_def)
-
-    assert "block_cfg" in arch_def and "stages" in arch_def["block_cfg"]
-    assert "stages" not in ret
-    # copy 'first', 'last' etc. inside arch_def['block_cfg'] to ret
-    ret.update({x: arch_def["block_cfg"][x] for x in arch_def["block_cfg"]})
-    ret["stages"] = _block_cfgs_to_list(arch_def["block_cfg"]["stages"])
-    del ret["block_cfg"]
-
-    assert "block_op_type" in arch_def
-    _add_to_arch(ret["stages"], arch_def["block_op_type"], "block_op_type")
-    del ret["block_op_type"]
-
-    return ret
-
-
-def get_num_stages(arch_def):
-    ret = 0
-    for x in arch_def["stages"]:
-        ret = max(x["stage_idx"], ret)
-    ret = ret + 1
-    return ret
-
-
-def get_blocks(arch_def, stage_indices=None, block_indices=None):
-    ret = copy.deepcopy(arch_def)
-    ret["stages"] = []
-    for block in arch_def["stages"]:
-        keep = True
-        if stage_indices not in (None, []) and block["stage_idx"] not in stage_indices:
-            keep = False
-        if block_indices not in (None, []) and block["block_idx"] not in block_indices:
-            keep = False
-        if keep:
-            ret["stages"].append(block)
-    return ret
-
-
-class FBNetBuilder(object):
-    def __init__(
-        self,
-        width_ratio,
-        bn_type="bn",
-        width_divisor=1,
-        dw_skip_bn=False,
-        dw_skip_relu=False,
-    ):
-        self.width_ratio = width_ratio
-        self.last_depth = -1
-        self.bn_type = bn_type
-        self.width_divisor = width_divisor
-        self.dw_skip_bn = dw_skip_bn
-        self.dw_skip_relu = dw_skip_relu
-
-    def add_first(self, stage_info, dim_in=3, pad=True):
-        # stage_info: [c, s, kernel]
-        assert len(stage_info) >= 2
-        channel = stage_info[0]
-        stride = stage_info[1]
-        out_depth = self._get_divisible_width(int(channel * self.width_ratio))
-        kernel = 3
-        if len(stage_info) > 2:
-            kernel = stage_info[2]
-
-        out = ConvBNRelu(
-            dim_in,
-            out_depth,
-            kernel=kernel,
-            stride=stride,
-            pad=kernel // 2 if pad else 0,
-            no_bias=1,
-            use_relu="relu",
-            bn_type=self.bn_type,
-        )
-        self.last_depth = out_depth
-        return out
-
-    def add_blocks(self, blocks):
-        """ blocks: [{}, {}, ...]
-        """
-        assert isinstance(blocks, list) and all(
-            isinstance(x, dict) for x in blocks
-        ), blocks
-
-        modules = OrderedDict()
-        for block in blocks:
-            stage_idx = block["stage_idx"]
-            block_idx = block["block_idx"]
-            block_op_type = block["block_op_type"]
-            tcns = block["block"]
-            n = tcns[2]
-            assert n == 1
-            nnblock = self.add_ir_block(tcns, [block_op_type])
-            nn_name = "xif{}_{}".format(stage_idx, block_idx)
-            assert nn_name not in modules
-            modules[nn_name] = nnblock
-        ret = nn.Sequential(modules)
-        return ret
-
-    def add_last(self, stage_info):
-        """ skip last layer if channel_scale == 0
-            use the same output channel if channel_scale < 0
-        """
-        assert len(stage_info) == 2
-        channels = stage_info[0]
-        channel_scale = stage_info[1]
-
-        if channel_scale == 0.0:
-            return nn.Sequential()
-
-        if channel_scale > 0:
-            last_channel = (
-                int(channels * self.width_ratio) if self.width_ratio > 1.0 else channels
-            )
-            last_channel = int(last_channel * channel_scale)
-        else:
-            last_channel = int(self.last_depth * (-channel_scale))
-        last_channel = self._get_divisible_width(last_channel)
-
-        if last_channel == 0:
-            return nn.Sequential()
-
-        dim_in = self.last_depth
-        ret = ConvBNRelu(
-            dim_in,
-            last_channel,
-            kernel=1,
-            stride=1,
-            pad=0,
-            no_bias=1,
-            use_relu="relu",
-            bn_type=self.bn_type,
-        )
-        self.last_depth = last_channel
-        return ret
-
-    # def add_final_pool(self, model, blob_in, kernel_size):
-    #     ret = model.AveragePool(blob_in, "final_avg", kernel=kernel_size, stride=1)
-    #     return ret
-
-    def _add_ir_block(
-        self, dim_in, dim_out, stride, expand_ratio, block_op_type, **kwargs
-    ):
-        ret = PRIMITIVES[block_op_type](
-            dim_in,
-            dim_out,
-            expansion=expand_ratio,
-            stride=stride,
-            bn_type=self.bn_type,
-            width_divisor=self.width_divisor,
-            dw_skip_bn=self.dw_skip_bn,
-            dw_skip_relu=self.dw_skip_relu,
-            **kwargs
-        )
-        return ret, ret.output_depth
-
-    def add_ir_block(self, tcns, block_op_types, **kwargs):
-        t, c, n, s = tcns
-        assert n == 1
-        out_depth = self._get_divisible_width(int(c * self.width_ratio))
-        dim_in = self.last_depth
-        op, ret_depth = self._add_ir_block(
-            dim_in,
-            out_depth,
-            stride=s,
-            expand_ratio=t,
-            block_op_type=block_op_types[0],
-            **kwargs
-        )
-        self.last_depth = ret_depth
-        return op
-
-    def _get_divisible_width(self, width):
-        ret = _get_divisible_by(int(width), self.width_divisor, self.width_divisor)
-        return ret
diff --git a/maskrcnn_benchmark/modeling/backbone/fbnet_modeldef.py b/maskrcnn_benchmark/modeling/backbone/fbnet_modeldef.py
deleted file mode 100755
index fb1c96b..0000000
--- a/maskrcnn_benchmark/modeling/backbone/fbnet_modeldef.py
+++ /dev/null
@@ -1,218 +0,0 @@
-from __future__ import absolute_import, division, print_function, unicode_literals
-
-
-def add_archs(archs):
-    global MODEL_ARCH
-    for x in archs:
-        assert x not in MODEL_ARCH, "Duplicated model name {} existed".format(x)
-        MODEL_ARCH[x] = archs[x]
-
-
-MODEL_ARCH = {
-    "default": {
-        "block_op_type": [
-            # stage 0
-            ["ir_k3"],
-            # stage 1
-            ["ir_k3"] * 2,
-            # stage 2
-            ["ir_k3"] * 3,
-            # stage 3
-            ["ir_k3"] * 7,
-            # stage 4, bbox head
-            ["ir_k3"] * 4,
-            # stage 5, rpn
-            ["ir_k3"] * 3,
-            # stage 5, mask head
-            ["ir_k3"] * 5,
-        ],
-        "block_cfg": {
-            "first": [32, 2],
-            "stages": [
-                # [t, c, n, s]
-                # stage 0
-                [[1, 16, 1, 1]],
-                # stage 1
-                [[6, 24, 2, 2]],
-                # stage 2
-                [[6, 32, 3, 2]],
-                # stage 3
-                [[6, 64, 4, 2], [6, 96, 3, 1]],
-                # stage 4, bbox head
-                [[4, 160, 1, 2], [6, 160, 2, 1], [6, 240, 1, 1]],
-                # [[6, 160, 3, 2], [6, 320, 1, 1]],
-                # stage 5, rpn head
-                [[6, 96, 3, 1]],
-                # stage 6, mask head
-                [[4, 160, 1, 1], [6, 160, 3, 1], [3, 80, 1, -2]],
-            ],
-            # [c, channel_scale]
-            "last": [0, 0.0],
-            "backbone": [0, 1, 2, 3],
-            "rpn": [5],
-            "bbox": [4],
-            "mask": [6],
-        },
-    },
-    "xirb16d_dsmask": {
-        "block_op_type": [
-            # stage 0
-            ["ir_k3"],
-            # stage 1
-            ["ir_k3"] * 2,
-            # stage 2
-            ["ir_k3"] * 3,
-            # stage 3
-            ["ir_k3"] * 7,
-            # stage 4, bbox head
-            ["ir_k3"] * 4,
-            # stage 5, mask head
-            ["ir_k3"] * 5,
-            # stage 6, rpn
-            ["ir_k3"] * 3,
-        ],
-        "block_cfg": {
-            "first": [16, 2],
-            "stages": [
-                # [t, c, n, s]
-                # stage 0
-                [[1, 16, 1, 1]],
-                # stage 1
-                [[6, 32, 2, 2]],
-                # stage 2
-                [[6, 48, 3, 2]],
-                # stage 3
-                [[6, 96, 4, 2], [6, 128, 3, 1]],
-                # stage 4, bbox head
-                [[4, 128, 1, 2], [6, 128, 2, 1], [6, 160, 1, 1]],
-                # stage 5, mask head
-                [[4, 128, 1, 2], [6, 128, 2, 1], [6, 128, 1, -2], [3, 64, 1, -2]],
-                # stage 6, rpn head
-                [[6, 128, 3, 1]],
-            ],
-            # [c, channel_scale]
-            "last": [0, 0.0],
-            "backbone": [0, 1, 2, 3],
-            "rpn": [6],
-            "bbox": [4],
-            "mask": [5],
-        },
-    },
-    "mobilenet_v2": {
-        "block_op_type": [
-            # stage 0
-            ["ir_k3"],
-            # stage 1
-            ["ir_k3"] * 2,
-            # stage 2
-            ["ir_k3"] * 3,
-            # stage 3
-            ["ir_k3"] * 7,
-            # stage 4
-            ["ir_k3"] * 4,
-        ],
-        "block_cfg": {
-            "first": [32, 2],
-            "stages": [
-                # [t, c, n, s]
-                # stage 0
-                [[1, 16, 1, 1]],
-                # stage 1
-                [[6, 24, 2, 2]],
-                # stage 2
-                [[6, 32, 3, 2]],
-                # stage 3
-                [[6, 64, 4, 2], [6, 96, 3, 1]],
-                # stage 4
-                [[6, 160, 3, 1], [6, 320, 1, 1]],
-            ],
-            # [c, channel_scale]
-            "last": [0, 0.0],
-            "backbone": [0, 1, 2, 3],
-            "bbox": [4],
-        },
-    },
-}
-
-
-MODEL_ARCH_CHAM = {
-    "cham_v1a": {
-        "block_op_type": [
-            # stage 0
-            ["ir_k3"],
-            # stage 1
-            ["ir_k7"] * 2,
-            # stage 2
-            ["ir_k3"] * 5,
-            # stage 3
-            ["ir_k5"] * 7 + ["ir_k3"] * 5,
-            # stage 4, bbox head
-            ["ir_k3"] * 5,
-            # stage 5, rpn
-            ["ir_k3"] * 3,
-        ],
-        "block_cfg": {
-            "first": [32, 2],
-            "stages": [
-                # [t, c, n, s]
-                # stage 0
-                [[1, 24, 1, 1]],
-                # stage 1
-                [[4, 48, 2, 2]],
-                # stage 2
-                [[7, 64, 5, 2]],
-                # stage 3
-                [[12, 56, 7, 2], [8, 88, 5, 1]],
-                # stage 4, bbox head
-                [[7, 152, 4, 2], [10, 104, 1, 1]],
-                # stage 5, rpn head
-                [[8, 88, 3, 1]],
-            ],
-            # [c, channel_scale]
-            "last": [0, 0.0],
-            "backbone": [0, 1, 2, 3],
-            "rpn": [5],
-            "bbox": [4],
-        },
-    },
-    "cham_v2": {
-        "block_op_type": [
-            # stage 0
-            ["ir_k3"],
-            # stage 1
-            ["ir_k5"] * 4,
-            # stage 2
-            ["ir_k7"] * 6,
-            # stage 3
-            ["ir_k5"] * 3 + ["ir_k3"] * 6,
-            # stage 4, bbox head
-            ["ir_k3"] * 7,
-            # stage 5, rpn
-            ["ir_k3"] * 1,
-        ],
-        "block_cfg": {
-            "first": [32, 2],
-            "stages": [
-                # [t, c, n, s]
-                # stage 0
-                [[1, 24, 1, 1]],
-                # stage 1
-                [[8, 32, 4, 2]],
-                # stage 2
-                [[5, 48, 6, 2]],
-                # stage 3
-                [[9, 56, 3, 2], [6, 56, 6, 1]],
-                # stage 4, bbox head
-                [[2, 160, 6, 2], [6, 112, 1, 1]],
-                # stage 5, rpn head
-                [[6, 56, 1, 1]],
-            ],
-            # [c, channel_scale]
-            "last": [0, 0.0],
-            "backbone": [0, 1, 2, 3],
-            "rpn": [5],
-            "bbox": [4],
-        },
-    },
-}
-add_archs(MODEL_ARCH_CHAM)
diff --git a/maskrcnn_benchmark/modeling/backbone/fpn.py b/maskrcnn_benchmark/modeling/backbone/fpn.py
index edf4d04..f3d2ea8 100644
--- a/maskrcnn_benchmark/modeling/backbone/fpn.py
+++ b/maskrcnn_benchmark/modeling/backbone/fpn.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 import torch.nn.functional as F
diff --git a/maskrcnn_benchmark/modeling/backbone/resnet.py b/maskrcnn_benchmark/modeling/backbone/resnet.py
index 3fd2d41..cacc04c 100644
--- a/maskrcnn_benchmark/modeling/backbone/resnet.py
+++ b/maskrcnn_benchmark/modeling/backbone/resnet.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 Variant of the resnet module that takes cfg as an argument.
@@ -22,9 +35,10 @@ import torch
 import torch.nn.functional as F
 from torch import nn
 
-from maskrcnn_benchmark.layers import FrozenBatchNorm2d
-from maskrcnn_benchmark.layers import Conv2d
-from maskrcnn_benchmark.layers import DFConv2d
+# from maskrcnn_benchmark.layers import FrozenBatchNorm2d
+# from maskrcnn_benchmark.layers import Conv2d
+from torch.nn import BatchNorm2d as FrozenBatchNorm2d
+from torch.nn import Conv2d
 from maskrcnn_benchmark.modeling.make_layers import group_norm
 from maskrcnn_benchmark.utils.registry import Registry
 
@@ -34,7 +48,7 @@ StageSpec = namedtuple(
     "StageSpec",
     [
         "index",  # Index of the stage, eg 1, 2, ..,. 5
-        "block_count",  # Number of residual blocks in the stage
+        "block_count",  # Numer of residual blocks in the stage
         "return_features",  # True => return the last feature map from this stage
     ],
 )
@@ -107,7 +121,6 @@ class ResNet(nn.Module):
             stage2_relative_factor = 2 ** (stage_spec.index - 1)
             bottleneck_channels = stage2_bottleneck_channels * stage2_relative_factor
             out_channels = stage2_out_channels * stage2_relative_factor
-            stage_with_dcn = cfg.MODEL.RESNETS.STAGE_WITH_DCN[stage_spec.index -1]
             module = _make_stage(
                 transformation_module,
                 in_channels,
@@ -117,11 +130,6 @@ class ResNet(nn.Module):
                 num_groups,
                 cfg.MODEL.RESNETS.STRIDE_IN_1X1,
                 first_stride=int(stage_spec.index > 1) + 1,
-                dcn_config={
-                    "stage_with_dcn": stage_with_dcn,
-                    "with_modulated_dcn": cfg.MODEL.RESNETS.WITH_MODULATED_DCN,
-                    "deformable_groups": cfg.MODEL.RESNETS.DEFORMABLE_GROUPS,
-                }
             )
             in_channels = out_channels
             self.add_module(name, module)
@@ -162,8 +170,7 @@ class ResNetHead(nn.Module):
         stride_in_1x1=True,
         stride_init=None,
         res2_out_channels=256,
-        dilation=1,
-        dcn_config={}
+        dilation=1
     ):
         super(ResNetHead, self).__init__()
 
@@ -190,13 +197,11 @@ class ResNetHead(nn.Module):
                 num_groups,
                 stride_in_1x1,
                 first_stride=stride,
-                dilation=dilation,
-                dcn_config=dcn_config
+                dilation=dilation
             )
             stride = None
             self.add_module(name, module)
             self.stages.append(name)
-        self.out_channels = out_channels
 
     def forward(self, x):
         for stage in self.stages:
@@ -213,8 +218,7 @@ def _make_stage(
     num_groups,
     stride_in_1x1,
     first_stride,
-    dilation=1,
-    dcn_config={}
+    dilation=1
 ):
     blocks = []
     stride = first_stride
@@ -227,8 +231,7 @@ def _make_stage(
                 num_groups,
                 stride_in_1x1,
                 stride,
-                dilation=dilation,
-                dcn_config=dcn_config
+                dilation=dilation
             )
         )
         stride = 1
@@ -246,8 +249,7 @@ class Bottleneck(nn.Module):
         stride_in_1x1,
         stride,
         dilation,
-        norm_func,
-        dcn_config
+        norm_func
     ):
         super(Bottleneck, self).__init__()
 
@@ -283,42 +285,26 @@ class Bottleneck(nn.Module):
         )
         self.bn1 = norm_func(bottleneck_channels)
         # TODO: specify init for the above
-        with_dcn = dcn_config.get("stage_with_dcn", False)
-        if with_dcn:
-            deformable_groups = dcn_config.get("deformable_groups", 1)
-            with_modulated_dcn = dcn_config.get("with_modulated_dcn", False)
-            self.conv2 = DFConv2d(
-                bottleneck_channels,
-                bottleneck_channels,
-                with_modulated_dcn=with_modulated_dcn,
-                kernel_size=3,
-                stride=stride_3x3,
-                groups=num_groups,
-                dilation=dilation,
-                deformable_groups=deformable_groups,
-                bias=False
-            )
-        else:
-            self.conv2 = Conv2d(
-                bottleneck_channels,
-                bottleneck_channels,
-                kernel_size=3,
-                stride=stride_3x3,
-                padding=dilation,
-                bias=False,
-                groups=num_groups,
-                dilation=dilation
-            )
-            nn.init.kaiming_uniform_(self.conv2.weight, a=1)
 
+        self.conv2 = Conv2d(
+            bottleneck_channels,
+            bottleneck_channels,
+            kernel_size=3,
+            stride=stride_3x3,
+            padding=dilation,
+            bias=False,
+            groups=num_groups,
+            dilation=dilation
+        )
         self.bn2 = norm_func(bottleneck_channels)
 
         self.conv3 = Conv2d(
             bottleneck_channels, out_channels, kernel_size=1, bias=False
         )
         self.bn3 = norm_func(out_channels)
+        self.relu = nn.ReLU(inplace=True)
 
-        for l in [self.conv1, self.conv3,]:
+        for l in [self.conv1, self.conv2, self.conv3,]:
             nn.init.kaiming_uniform_(l.weight, a=1)
 
     def forward(self, x):
@@ -326,20 +312,23 @@ class Bottleneck(nn.Module):
 
         out = self.conv1(x)
         out = self.bn1(out)
-        out = F.relu_(out)
+        # out = F.relu_(out)
+        out = self.relu(out)
 
         out = self.conv2(out)
         out = self.bn2(out)
-        out = F.relu_(out)
+        # out = F.relu_(out)
+        out = self.relu(out)
 
-        out = self.conv3(out)
-        out = self.bn3(out)
+        out0 = self.conv3(out)
+        out = self.bn3(out0)
 
         if self.downsample is not None:
             identity = self.downsample(x)
 
         out += identity
-        out = F.relu_(out)
+        # out = F.relu_(out)
+        out = self.relu(out)
 
         return out
 
@@ -354,6 +343,7 @@ class BaseStem(nn.Module):
             3, out_channels, kernel_size=7, stride=2, padding=3, bias=False
         )
         self.bn1 = norm_func(out_channels)
+        self.relu = nn.ReLU(inplace=True)
 
         for l in [self.conv1,]:
             nn.init.kaiming_uniform_(l.weight, a=1)
@@ -361,7 +351,8 @@ class BaseStem(nn.Module):
     def forward(self, x):
         x = self.conv1(x)
         x = self.bn1(x)
-        x = F.relu_(x)
+        # x = F.relu_(x)
+        x = self.relu(x)
         x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)
         return x
 
@@ -375,8 +366,7 @@ class BottleneckWithFixedBatchNorm(Bottleneck):
         num_groups=1,
         stride_in_1x1=True,
         stride=1,
-        dilation=1,
-        dcn_config={}
+        dilation=1
     ):
         super(BottleneckWithFixedBatchNorm, self).__init__(
             in_channels=in_channels,
@@ -386,8 +376,7 @@ class BottleneckWithFixedBatchNorm(Bottleneck):
             stride_in_1x1=stride_in_1x1,
             stride=stride,
             dilation=dilation,
-            norm_func=FrozenBatchNorm2d,
-            dcn_config=dcn_config
+            norm_func=FrozenBatchNorm2d
         )
 
 
@@ -407,8 +396,7 @@ class BottleneckWithGN(Bottleneck):
         num_groups=1,
         stride_in_1x1=True,
         stride=1,
-        dilation=1,
-        dcn_config={}
+        dilation=1
     ):
         super(BottleneckWithGN, self).__init__(
             in_channels=in_channels,
@@ -418,8 +406,7 @@ class BottleneckWithGN(Bottleneck):
             stride_in_1x1=stride_in_1x1,
             stride=stride,
             dilation=dilation,
-            norm_func=group_norm,
-            dcn_config=dcn_config
+            norm_func=group_norm
         )
 
 
diff --git a/maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py b/maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py
index 52a332d..d3667de 100644
--- a/maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py
+++ b/maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
@@ -11,7 +24,7 @@ class BalancedPositiveNegativeSampler(object):
         """
         Arguments:
             batch_size_per_image (int): number of elements to be selected per image
-            positive_fraction (float): percentage of positive elements per batch
+            positive_fraction (float): percentace of positive elements per batch
         """
         self.batch_size_per_image = batch_size_per_image
         self.positive_fraction = positive_fraction
@@ -54,10 +67,10 @@ class BalancedPositiveNegativeSampler(object):
 
             # create binary mask from indices
             pos_idx_per_image_mask = torch.zeros_like(
-                matched_idxs_per_image, dtype=torch.bool
+                matched_idxs_per_image, dtype=torch.uint8
             )
             neg_idx_per_image_mask = torch.zeros_like(
-                matched_idxs_per_image, dtype=torch.bool
+                matched_idxs_per_image, dtype=torch.uint8
             )
             pos_idx_per_image_mask[pos_idx_per_image] = 1
             neg_idx_per_image_mask[neg_idx_per_image] = 1
diff --git a/maskrcnn_benchmark/modeling/box_coder.py b/maskrcnn_benchmark/modeling/box_coder.py
index 46a4acb..7636bab 100644
--- a/maskrcnn_benchmark/modeling/box_coder.py
+++ b/maskrcnn_benchmark/modeling/box_coder.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import math
 
diff --git a/maskrcnn_benchmark/modeling/detector/__init__.py b/maskrcnn_benchmark/modeling/detector/__init__.py
index ff421e2..2a0316a 100644
--- a/maskrcnn_benchmark/modeling/detector/__init__.py
+++ b/maskrcnn_benchmark/modeling/detector/__init__.py
@@ -1,2 +1,15 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .detectors import build_detection_model
diff --git a/maskrcnn_benchmark/modeling/detector/detectors.py b/maskrcnn_benchmark/modeling/detector/detectors.py
index af2100c..aa7775a 100644
--- a/maskrcnn_benchmark/modeling/detector/detectors.py
+++ b/maskrcnn_benchmark/modeling/detector/detectors.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .generalized_rcnn import GeneralizedRCNN
 
diff --git a/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py b/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py
index 38dfd3a..08e0e43 100644
--- a/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py
+++ b/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 Implements the Generalized R-CNN framework
@@ -7,6 +20,7 @@ import torch
 from torch import nn
 
 from maskrcnn_benchmark.structures.image_list import to_image_list
+import torch.fx; torch.fx.wrap('to_image_list')
 
 from ..backbone import build_backbone
 from ..rpn.rpn import build_rpn
@@ -27,8 +41,8 @@ class GeneralizedRCNN(nn.Module):
         super(GeneralizedRCNN, self).__init__()
 
         self.backbone = build_backbone(cfg)
-        self.rpn = build_rpn(cfg, self.backbone.out_channels)
-        self.roi_heads = build_roi_heads(cfg, self.backbone.out_channels)
+        self.rpn = build_rpn(cfg)
+        self.roi_heads = build_roi_heads(cfg)
 
     def forward(self, images, targets=None):
         """
diff --git a/maskrcnn_benchmark/modeling/make_layers.py b/maskrcnn_benchmark/modeling/make_layers.py
index 049aee6..aeaafb8 100644
--- a/maskrcnn_benchmark/modeling/make_layers.py
+++ b/maskrcnn_benchmark/modeling/make_layers.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 Miscellaneous utility functions
@@ -7,7 +20,8 @@ import torch
 from torch import nn
 from torch.nn import functional as F
 from maskrcnn_benchmark.config import cfg
-from maskrcnn_benchmark.layers import Conv2d
+# from maskrcnn_benchmark.layers import Conv2d
+from torch.nn import Conv2d
 from maskrcnn_benchmark.modeling.poolers import Pooler
 
 
@@ -34,29 +48,29 @@ def group_norm(out_channels, affine=True, divisor=1):
     num_groups = cfg.MODEL.GROUP_NORM.NUM_GROUPS // divisor
     eps = cfg.MODEL.GROUP_NORM.EPSILON # default: 1e-5
     return torch.nn.GroupNorm(
-        get_group_gn(out_channels, dim_per_gp, num_groups),
-        out_channels,
-        eps,
+        get_group_gn(out_channels, dim_per_gp, num_groups), 
+        out_channels, 
+        eps, 
         affine
     )
 
 
 def make_conv3x3(
-    in_channels,
-    out_channels,
-    dilation=1,
-    stride=1,
+    in_channels, 
+    out_channels, 
+    dilation=1, 
+    stride=1, 
     use_gn=False,
     use_relu=False,
     kaiming_init=True
 ):
     conv = Conv2d(
-        in_channels,
-        out_channels,
-        kernel_size=3,
-        stride=stride,
-        padding=dilation,
-        dilation=dilation,
+        in_channels, 
+        out_channels, 
+        kernel_size=3, 
+        stride=stride, 
+        padding=dilation, 
+        dilation=dilation, 
         bias=False if use_gn else True
     )
     if kaiming_init:
@@ -97,12 +111,12 @@ def conv_with_kaiming_uniform(use_gn=False, use_relu=False):
         in_channels, out_channels, kernel_size, stride=1, dilation=1
     ):
         conv = Conv2d(
-            in_channels,
-            out_channels,
-            kernel_size=kernel_size,
-            stride=stride,
-            padding=dilation * (kernel_size - 1) // 2,
-            dilation=dilation,
+            in_channels, 
+            out_channels, 
+            kernel_size=kernel_size, 
+            stride=stride, 
+            padding=dilation * (kernel_size - 1) // 2, 
+            dilation=dilation, 
             bias=False if use_gn else True
         )
         # Caffe2 implementation uses XavierFill, which in fact
diff --git a/maskrcnn_benchmark/modeling/matcher.py b/maskrcnn_benchmark/modeling/matcher.py
index 35ec5f1..0f735c2 100644
--- a/maskrcnn_benchmark/modeling/matcher.py
+++ b/maskrcnn_benchmark/modeling/matcher.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
diff --git a/maskrcnn_benchmark/modeling/poolers.py b/maskrcnn_benchmark/modeling/poolers.py
index 519440e..7ae2096 100644
--- a/maskrcnn_benchmark/modeling/poolers.py
+++ b/maskrcnn_benchmark/modeling/poolers.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 import torch.nn.functional as F
@@ -6,6 +19,12 @@ from torch import nn
 from maskrcnn_benchmark.layers import ROIAlign
 
 from .utils import cat
+import torch.fx
+
+
+# @torch.fx.wrap
+# def defined_sqrt(boxlists):
+#     return torch.sqrt(cat([boxlist.area() for boxlist in boxlists]))
 
 
 class LevelMapper(object):
@@ -35,12 +54,27 @@ class LevelMapper(object):
         """
         # Compute level ids
         s = torch.sqrt(cat([boxlist.area() for boxlist in boxlists]))
+        # s = defined_sqrt(boxlists)
 
         # Eqn.(1) in FPN paper
         target_lvls = torch.floor(self.lvl0 + torch.log2(s / self.s0 + self.eps))
         target_lvls = torch.clamp(target_lvls, min=self.k_min, max=self.k_max)
         return target_lvls.to(torch.int64) - self.k_min
 
+@torch.fx.wrap
+def convert_to_roi_format(boxes):
+        concat_boxes = cat([b.bbox for b in boxes], dim=0)
+        device, dtype = concat_boxes.device, concat_boxes.dtype
+        ids = cat(
+            [
+                torch.full((len(b), 1), i, dtype=dtype, device=device)
+                for i, b in enumerate(boxes)
+            ],
+            dim=0,
+        )
+        rois = torch.cat([ids, concat_boxes], dim=1)
+        return rois
+
 
 class Pooler(nn.Module):
     """
@@ -116,18 +150,6 @@ class Pooler(nn.Module):
         for level, (per_level_feature, pooler) in enumerate(zip(x, self.poolers)):
             idx_in_level = torch.nonzero(levels == level).squeeze(1)
             rois_per_level = rois[idx_in_level]
-            result[idx_in_level] = pooler(per_level_feature, rois_per_level).to(dtype)
+            result[idx_in_level] = pooler(per_level_feature, rois_per_level)
 
         return result
-
-
-def make_pooler(cfg, head_name):
-    resolution = cfg.MODEL[head_name].POOLER_RESOLUTION
-    scales = cfg.MODEL[head_name].POOLER_SCALES
-    sampling_ratio = cfg.MODEL[head_name].POOLER_SAMPLING_RATIO
-    pooler = Pooler(
-        output_size=(resolution, resolution),
-        scales=scales,
-        sampling_ratio=sampling_ratio,
-    )
-    return pooler
diff --git a/maskrcnn_benchmark/modeling/registry.py b/maskrcnn_benchmark/modeling/registry.py
index e14fb11..733a445 100644
--- a/maskrcnn_benchmark/modeling/registry.py
+++ b/maskrcnn_benchmark/modeling/registry.py
@@ -1,12 +1,21 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 
 from maskrcnn_benchmark.utils.registry import Registry
 
 BACKBONES = Registry()
-RPN_HEADS = Registry()
 ROI_BOX_FEATURE_EXTRACTORS = Registry()
 ROI_BOX_PREDICTOR = Registry()
-ROI_KEYPOINT_FEATURE_EXTRACTORS = Registry()
-ROI_KEYPOINT_PREDICTOR = Registry()
-ROI_MASK_FEATURE_EXTRACTORS = Registry()
-ROI_MASK_PREDICTOR = Registry()
+RPN_HEADS = Registry()
diff --git a/maskrcnn_benchmark/modeling/roi_heads/__init__.py b/maskrcnn_benchmark/modeling/roi_heads/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/__init__.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py b/maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py b/maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py
index 482081b..044f9ee 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch import nn
@@ -13,11 +26,10 @@ class ROIBoxHead(torch.nn.Module):
     Generic Box Head class.
     """
 
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(ROIBoxHead, self).__init__()
-        self.feature_extractor = make_roi_box_feature_extractor(cfg, in_channels)
-        self.predictor = make_roi_box_predictor(
-            cfg, self.feature_extractor.out_channels)
+        self.feature_extractor = make_roi_box_feature_extractor(cfg)
+        self.predictor = make_roi_box_predictor(cfg)
         self.post_processor = make_roi_box_post_processor(cfg)
         self.loss_evaluator = make_roi_box_loss_evaluator(cfg)
 
@@ -62,10 +74,10 @@ class ROIBoxHead(torch.nn.Module):
         )
 
 
-def build_roi_box_head(cfg, in_channels):
+def build_roi_box_head(cfg):
     """
     Constructs a new box head.
     By default, uses ROIBoxHead, but if it turns out not to be enough, just register a new class
     and make it a parameter in the config
     """
-    return ROIBoxHead(cfg, in_channels)
+    return ROIBoxHead(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py b/maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py
index 818d7b4..461d054 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 import torch.nn.functional as F
@@ -22,8 +35,7 @@ class PostProcessor(nn.Module):
         nms=0.5,
         detections_per_img=100,
         box_coder=None,
-        cls_agnostic_bbox_reg=False,
-        bbox_aug_enabled=False
+        cls_agnostic_bbox_reg=False
     ):
         """
         Arguments:
@@ -40,7 +52,6 @@ class PostProcessor(nn.Module):
             box_coder = BoxCoder(weights=(10., 10., 5., 5.))
         self.box_coder = box_coder
         self.cls_agnostic_bbox_reg = cls_agnostic_bbox_reg
-        self.bbox_aug_enabled = bbox_aug_enabled
 
     def forward(self, x, boxes):
         """
@@ -48,7 +59,7 @@ class PostProcessor(nn.Module):
             x (tuple[tensor, tensor]): x contains the class logits
                 and the box_regression from the model.
             boxes (list[BoxList]): bounding boxes that are used as
-                reference, one for each image
+                reference, one for ech image
 
         Returns:
             results (list[BoxList]): one BoxList for each image, containing
@@ -81,8 +92,7 @@ class PostProcessor(nn.Module):
         ):
             boxlist = self.prepare_boxlist(boxes_per_img, prob, image_shape)
             boxlist = boxlist.clip_to_image(remove_empty=False)
-            if not self.bbox_aug_enabled:  # If bbox aug is enabled, we will do it later
-                boxlist = self.filter_results(boxlist, num_classes)
+            boxlist = self.filter_results(boxlist, num_classes)
             results.append(boxlist)
         return results
 
@@ -159,14 +169,12 @@ def make_roi_box_post_processor(cfg):
     nms_thresh = cfg.MODEL.ROI_HEADS.NMS
     detections_per_img = cfg.MODEL.ROI_HEADS.DETECTIONS_PER_IMG
     cls_agnostic_bbox_reg = cfg.MODEL.CLS_AGNOSTIC_BBOX_REG
-    bbox_aug_enabled = cfg.TEST.BBOX_AUG.ENABLED
 
     postprocessor = PostProcessor(
         score_thresh,
         nms_thresh,
         detections_per_img,
         box_coder,
-        cls_agnostic_bbox_reg,
-        bbox_aug_enabled
+        cls_agnostic_bbox_reg
     )
     return postprocessor
diff --git a/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py b/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py
index a1fdd23..ea25196 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch.nn import functional as F
@@ -19,10 +32,10 @@ class FastRCNNLossComputation(object):
     """
 
     def __init__(
-        self,
-        proposal_matcher,
-        fg_bg_sampler,
-        box_coder,
+        self, 
+        proposal_matcher, 
+        fg_bg_sampler, 
+        box_coder, 
         cls_agnostic_bbox_reg=False
     ):
         """
@@ -184,9 +197,9 @@ def make_roi_box_loss_evaluator(cfg):
     cls_agnostic_bbox_reg = cfg.MODEL.CLS_AGNOSTIC_BBOX_REG
 
     loss_evaluator = FastRCNNLossComputation(
-        matcher,
-        fg_bg_sampler,
-        box_coder,
+        matcher, 
+        fg_bg_sampler, 
+        box_coder, 
         cls_agnostic_bbox_reg
     )
 
diff --git a/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py b/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py
index e477147..55e04d6 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch import nn
@@ -12,7 +25,7 @@ from maskrcnn_benchmark.modeling.make_layers import make_fc
 
 @registry.ROI_BOX_FEATURE_EXTRACTORS.register("ResNet50Conv5ROIFeatureExtractor")
 class ResNet50Conv5ROIFeatureExtractor(nn.Module):
-    def __init__(self, config, in_channels):
+    def __init__(self, config):
         super(ResNet50Conv5ROIFeatureExtractor, self).__init__()
 
         resolution = config.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION
@@ -38,7 +51,6 @@ class ResNet50Conv5ROIFeatureExtractor(nn.Module):
 
         self.pooler = pooler
         self.head = head
-        self.out_channels = head.out_channels
 
     def forward(self, x, proposals):
         x = self.pooler(x, proposals)
@@ -52,7 +64,7 @@ class FPN2MLPFeatureExtractor(nn.Module):
     Heads for FPN for classification
     """
 
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(FPN2MLPFeatureExtractor, self).__init__()
 
         resolution = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION
@@ -63,13 +75,12 @@ class FPN2MLPFeatureExtractor(nn.Module):
             scales=scales,
             sampling_ratio=sampling_ratio,
         )
-        input_size = in_channels * resolution ** 2
+        input_size = cfg.MODEL.BACKBONE.OUT_CHANNELS * resolution ** 2
         representation_size = cfg.MODEL.ROI_BOX_HEAD.MLP_HEAD_DIM
         use_gn = cfg.MODEL.ROI_BOX_HEAD.USE_GN
         self.pooler = pooler
         self.fc6 = make_fc(input_size, representation_size, use_gn)
         self.fc7 = make_fc(representation_size, representation_size, use_gn)
-        self.out_channels = representation_size
 
     def forward(self, x, proposals):
         x = self.pooler(x, proposals)
@@ -87,7 +98,7 @@ class FPNXconv1fcFeatureExtractor(nn.Module):
     Heads for FPN for classification
     """
 
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(FPNXconv1fcFeatureExtractor, self).__init__()
 
         resolution = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION
@@ -99,8 +110,9 @@ class FPNXconv1fcFeatureExtractor(nn.Module):
             sampling_ratio=sampling_ratio,
         )
         self.pooler = pooler
-
+        
         use_gn = cfg.MODEL.ROI_BOX_HEAD.USE_GN
+        in_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS
         conv_head_dim = cfg.MODEL.ROI_BOX_HEAD.CONV_HEAD_DIM
         num_stacked_convs = cfg.MODEL.ROI_BOX_HEAD.NUM_STACKED_CONVS
         dilation = cfg.MODEL.ROI_BOX_HEAD.DILATION
@@ -134,7 +146,6 @@ class FPNXconv1fcFeatureExtractor(nn.Module):
         input_size = conv_head_dim * resolution ** 2
         representation_size = cfg.MODEL.ROI_BOX_HEAD.MLP_HEAD_DIM
         self.fc6 = make_fc(input_size, representation_size, use_gn=False)
-        self.out_channels = representation_size
 
     def forward(self, x, proposals):
         x = self.pooler(x, proposals)
@@ -144,8 +155,8 @@ class FPNXconv1fcFeatureExtractor(nn.Module):
         return x
 
 
-def make_roi_box_feature_extractor(cfg, in_channels):
+def make_roi_box_feature_extractor(cfg):
     func = registry.ROI_BOX_FEATURE_EXTRACTORS[
         cfg.MODEL.ROI_BOX_HEAD.FEATURE_EXTRACTOR
     ]
-    return func(cfg, in_channels)
+    return func(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py b/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py
index 66ee4ac..1a6be87 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from maskrcnn_benchmark.modeling import registry
 from torch import nn
@@ -5,14 +18,16 @@ from torch import nn
 
 @registry.ROI_BOX_PREDICTOR.register("FastRCNNPredictor")
 class FastRCNNPredictor(nn.Module):
-    def __init__(self, config, in_channels):
+    def __init__(self, config, pretrained=None):
         super(FastRCNNPredictor, self).__init__()
-        assert in_channels is not None
 
-        num_inputs = in_channels
+        stage_index = 4
+        stage2_relative_factor = 2 ** (stage_index - 1)
+        res2_out_channels = config.MODEL.RESNETS.RES2_OUT_CHANNELS
+        num_inputs = res2_out_channels * stage2_relative_factor
 
         num_classes = config.MODEL.ROI_BOX_HEAD.NUM_CLASSES
-        self.avgpool = nn.AdaptiveAvgPool2d(1)
+        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=7)
         self.cls_score = nn.Linear(num_inputs, num_classes)
         num_bbox_reg_classes = 2 if config.MODEL.CLS_AGNOSTIC_BBOX_REG else num_classes
         self.bbox_pred = nn.Linear(num_inputs, num_bbox_reg_classes * 4)
@@ -33,10 +48,10 @@ class FastRCNNPredictor(nn.Module):
 
 @registry.ROI_BOX_PREDICTOR.register("FPNPredictor")
 class FPNPredictor(nn.Module):
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(FPNPredictor, self).__init__()
         num_classes = cfg.MODEL.ROI_BOX_HEAD.NUM_CLASSES
-        representation_size = in_channels
+        representation_size = cfg.MODEL.ROI_BOX_HEAD.MLP_HEAD_DIM
 
         self.cls_score = nn.Linear(representation_size, num_classes)
         num_bbox_reg_classes = 2 if cfg.MODEL.CLS_AGNOSTIC_BBOX_REG else num_classes
@@ -48,15 +63,12 @@ class FPNPredictor(nn.Module):
             nn.init.constant_(l.bias, 0)
 
     def forward(self, x):
-        if x.ndimension() == 4:
-            assert list(x.shape[2:]) == [1, 1]
-            x = x.view(x.size(0), -1)
         scores = self.cls_score(x)
         bbox_deltas = self.bbox_pred(x)
 
         return scores, bbox_deltas
 
 
-def make_roi_box_predictor(cfg, in_channels):
+def make_roi_box_predictor(cfg):
     func = registry.ROI_BOX_PREDICTOR[cfg.MODEL.ROI_BOX_HEAD.PREDICTOR]
-    return func(cfg, in_channels)
+    return func(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/__init__.py b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/__init__.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py
index 1f6fe2b..6481ebe 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import torch
 from torch import nn
 
diff --git a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py
index 5a842ca..d4e6366 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import torch
 
 from .roi_keypoint_feature_extractors import make_roi_keypoint_feature_extractor
@@ -7,12 +20,11 @@ from .loss import make_roi_keypoint_loss_evaluator
 
 
 class ROIKeypointHead(torch.nn.Module):
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(ROIKeypointHead, self).__init__()
         self.cfg = cfg.clone()
-        self.feature_extractor = make_roi_keypoint_feature_extractor(cfg, in_channels)
-        self.predictor = make_roi_keypoint_predictor(
-            cfg, self.feature_extractor.out_channels)
+        self.feature_extractor = make_roi_keypoint_feature_extractor(cfg)
+        self.predictor = make_roi_keypoint_predictor(cfg)
         self.post_processor = make_roi_keypoint_post_processor(cfg)
         self.loss_evaluator = make_roi_keypoint_loss_evaluator(cfg)
 
@@ -47,5 +59,5 @@ class ROIKeypointHead(torch.nn.Module):
         return x, proposals, dict(loss_kp=loss_kp)
 
 
-def build_roi_keypoint_head(cfg, in_channels):
-    return ROIKeypointHead(cfg, in_channels)
+def build_roi_keypoint_head(cfg):
+    return ROIKeypointHead(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py
index 5c0c7ac..d970627 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import torch
 from torch.nn import functional as F
 
@@ -154,7 +167,7 @@ class KeypointRCNNLossComputation(object):
             valid.append(valid_per_image.view(-1))
 
         keypoint_targets = cat(heatmaps, dim=0)
-        valid = cat(valid, dim=0).to(dtype=torch.bool)
+        valid = cat(valid, dim=0).to(dtype=torch.uint8)
         valid = torch.nonzero(valid).squeeze(1)
 
         # torch.mean (in binary_cross_entropy_with_logits) does'nt
diff --git a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py
index 952ae81..942bbba 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py
@@ -1,15 +1,26 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 from torch import nn
 from torch.nn import functional as F
 
-from maskrcnn_benchmark.modeling import registry
 from maskrcnn_benchmark.modeling.poolers import Pooler
 
 from maskrcnn_benchmark.layers import Conv2d
 
 
-@registry.ROI_KEYPOINT_FEATURE_EXTRACTORS.register("KeypointRCNNFeatureExtractor")
 class KeypointRCNNFeatureExtractor(nn.Module):
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(KeypointRCNNFeatureExtractor, self).__init__()
 
         resolution = cfg.MODEL.ROI_KEYPOINT_HEAD.POOLER_RESOLUTION
@@ -22,7 +33,7 @@ class KeypointRCNNFeatureExtractor(nn.Module):
         )
         self.pooler = pooler
 
-        input_features = in_channels
+        input_features = cfg.MODEL.BACKBONE.OUT_CHANNELS
         layers = cfg.MODEL.ROI_KEYPOINT_HEAD.CONV_LAYERS
         next_feature = input_features
         self.blocks = []
@@ -34,7 +45,6 @@ class KeypointRCNNFeatureExtractor(nn.Module):
             self.add_module(layer_name, module)
             next_feature = layer_features
             self.blocks.append(layer_name)
-        self.out_channels = layer_features
 
     def forward(self, x, proposals):
         x = self.pooler(x, proposals)
@@ -43,8 +53,13 @@ class KeypointRCNNFeatureExtractor(nn.Module):
         return x
 
 
-def make_roi_keypoint_feature_extractor(cfg, in_channels):
-    func = registry.ROI_KEYPOINT_FEATURE_EXTRACTORS[
+_ROI_KEYPOINT_FEATURE_EXTRACTORS = {
+    "KeypointRCNNFeatureExtractor": KeypointRCNNFeatureExtractor
+}
+
+
+def make_roi_keypoint_feature_extractor(cfg):
+    func = _ROI_KEYPOINT_FEATURE_EXTRACTORS[
         cfg.MODEL.ROI_KEYPOINT_HEAD.FEATURE_EXTRACTOR
     ]
-    return func(cfg, in_channels)
+    return func(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_predictors.py b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_predictors.py
index 7193efc..d212c25 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_predictors.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_predictors.py
@@ -1,17 +1,31 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 from torch import nn
+from torch.nn import functional as F
 
 from maskrcnn_benchmark import layers
-from maskrcnn_benchmark.modeling import registry
+from torch.nn import ConvTranspose2d
 
 
-@registry.ROI_KEYPOINT_PREDICTOR.register("KeypointRCNNPredictor")
 class KeypointRCNNPredictor(nn.Module):
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(KeypointRCNNPredictor, self).__init__()
-        input_features = in_channels
+        input_features = cfg.MODEL.ROI_KEYPOINT_HEAD.CONV_LAYERS[-1]
         num_keypoints = cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_CLASSES
         deconv_kernel = 4
-        self.kps_score_lowres = layers.ConvTranspose2d(
+        # self.kps_score_lowres = layers.ConvTranspose2d(
+        self.kps_score_lowres = ConvTranspose2d(
             input_features,
             num_keypoints,
             deconv_kernel,
@@ -23,7 +37,6 @@ class KeypointRCNNPredictor(nn.Module):
         )
         nn.init.constant_(self.kps_score_lowres.bias, 0)
         self.up_scale = 2
-        self.out_channels = num_keypoints
 
     def forward(self, x):
         x = self.kps_score_lowres(x)
@@ -33,6 +46,9 @@ class KeypointRCNNPredictor(nn.Module):
         return x
 
 
-def make_roi_keypoint_predictor(cfg, in_channels):
-    func = registry.ROI_KEYPOINT_PREDICTOR[cfg.MODEL.ROI_KEYPOINT_HEAD.PREDICTOR]
-    return func(cfg, in_channels)
+_ROI_KEYPOINT_PREDICTOR = {"KeypointRCNNPredictor": KeypointRCNNPredictor}
+
+
+def make_roi_keypoint_predictor(cfg):
+    func = _ROI_KEYPOINT_PREDICTOR[cfg.MODEL.ROI_KEYPOINT_HEAD.PREDICTOR]
+    return func(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py b/maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py b/maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py
index 953bb52..4eb3a64 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py
@@ -1,8 +1,21 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import numpy as np
 import torch
 from torch import nn
-from maskrcnn_benchmark.layers.misc import interpolate
+import torch.nn.functional as F
 
 from maskrcnn_benchmark.structures.bounding_box import BoxList
 
@@ -29,7 +42,7 @@ class MaskPostProcessor(nn.Module):
         Arguments:
             x (Tensor): the mask logits
             boxes (list[BoxList]): bounding boxes that are used as
-                reference, one for each image
+                reference, one for ech image
 
         Returns:
             results (list[BoxList]): one BoxList for each image, containing
@@ -111,16 +124,11 @@ def expand_masks(mask, padding):
     pad2 = 2 * padding
     scale = float(M + pad2) / M
     padded_mask = mask.new_zeros((N, 1, M + pad2, M + pad2))
-
     padded_mask[:, :, padding:-padding, padding:-padding] = mask
     return padded_mask, scale
 
 
 def paste_mask_in_image(mask, box, im_h, im_w, thresh=0.5, padding=1):
-    # Need to work on the CPU, where fp16 isn't supported - cast to float to avoid this
-    mask = mask.float()
-    box = box.float()
-
     padded_mask, scale = expand_masks(mask[None], padding=padding)
     mask = padded_mask[0, 0]
     box = expand_boxes(box[None], scale)[0]
@@ -137,7 +145,7 @@ def paste_mask_in_image(mask, box, im_h, im_w, thresh=0.5, padding=1):
 
     # Resize mask
     mask = mask.to(torch.float32)
-    mask = interpolate(mask, size=(h, w), mode='bilinear', align_corners=False)
+    mask = F.interpolate(mask, size=(h, w), mode='bilinear', align_corners=False)
     mask = mask[0][0]
 
     if thresh >= 0:
@@ -145,9 +153,9 @@ def paste_mask_in_image(mask, box, im_h, im_w, thresh=0.5, padding=1):
     else:
         # for visualization and debugging, we also
         # allow it to return an unmodified mask
-        mask = (mask * 255).to(torch.bool)
+        mask = (mask * 255).to(torch.uint8)
 
-    im_mask = torch.zeros((im_h, im_w), dtype=torch.bool)
+    im_mask = torch.zeros((im_h, im_w), dtype=torch.uint8)
     x_0 = max(box[0], 0)
     x_1 = min(box[2] + 1, im_w)
     y_0 = max(box[1], 0)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py b/maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py
index d4c5e36..2e12ac8 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch.nn import functional as F
@@ -27,15 +40,17 @@ def project_masks_on_boxes(segmentation_masks, proposals, discretization_size):
     assert segmentation_masks.size == proposals.size, "{}, {}".format(
         segmentation_masks, proposals
     )
-
-    # FIXME: CPU computation bottleneck, this should be parallelized
+    # TODO put the proposals on the CPU, as the representation for the
+    # masks is not efficient GPU-wise (possibly several small tensors for
+    # representing a single instance mask)
     proposals = proposals.bbox.to(torch.device("cpu"))
     for segmentation_mask, proposal in zip(segmentation_masks, proposals):
         # crop the masks, resize them to the desired resolution and
-        # then convert them to the tensor representation.
+        # then convert them to the tensor representation,
+        # instead of the list representation that was used
         cropped_mask = segmentation_mask.crop(proposal)
         scaled_mask = cropped_mask.resize((M, M))
-        mask = scaled_mask.get_mask_tensor()
+        mask = scaled_mask.convert(mode="mask")
         masks.append(mask)
     if len(masks) == 0:
         return torch.empty(0, dtype=torch.float32, device=device)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py b/maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py
index a9ce245..b6a6ebe 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 from torch import nn
@@ -34,12 +47,11 @@ def keep_only_positive_boxes(boxes):
 
 
 class ROIMaskHead(torch.nn.Module):
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(ROIMaskHead, self).__init__()
         self.cfg = cfg.clone()
-        self.feature_extractor = make_roi_mask_feature_extractor(cfg, in_channels)
-        self.predictor = make_roi_mask_predictor(
-            cfg, self.feature_extractor.out_channels)
+        self.feature_extractor = make_roi_mask_feature_extractor(cfg)
+        self.predictor = make_roi_mask_predictor(cfg)
         self.post_processor = make_roi_mask_post_processor(cfg)
         self.loss_evaluator = make_roi_mask_loss_evaluator(cfg)
 
@@ -79,5 +91,5 @@ class ROIMaskHead(torch.nn.Module):
         return x, all_proposals, dict(loss_mask=loss_mask)
 
 
-def build_roi_mask_head(cfg, in_channels):
-    return ROIMaskHead(cfg, in_channels)
+def build_roi_mask_head(cfg):
+    return ROIMaskHead(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py b/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py
index 117edc4..0cb9dc8 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py
@@ -1,25 +1,33 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from torch import nn
 from torch.nn import functional as F
 
 from ..box_head.roi_box_feature_extractors import ResNet50Conv5ROIFeatureExtractor
-from maskrcnn_benchmark.modeling import registry
 from maskrcnn_benchmark.modeling.poolers import Pooler
+from maskrcnn_benchmark.layers import Conv2d
 from maskrcnn_benchmark.modeling.make_layers import make_conv3x3
 
 
-registry.ROI_MASK_FEATURE_EXTRACTORS.register(
-    "ResNet50Conv5ROIFeatureExtractor", ResNet50Conv5ROIFeatureExtractor
-)
 
-
-@registry.ROI_MASK_FEATURE_EXTRACTORS.register("MaskRCNNFPNFeatureExtractor")
 class MaskRCNNFPNFeatureExtractor(nn.Module):
     """
     Heads for FPN for classification
     """
 
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         """
         Arguments:
             num_classes (int): number of output classes
@@ -36,7 +44,7 @@ class MaskRCNNFPNFeatureExtractor(nn.Module):
             scales=scales,
             sampling_ratio=sampling_ratio,
         )
-        input_size = in_channels
+        input_size = cfg.MODEL.BACKBONE.OUT_CHANNELS
         self.pooler = pooler
 
         use_gn = cfg.MODEL.ROI_MASK_HEAD.USE_GN
@@ -47,26 +55,30 @@ class MaskRCNNFPNFeatureExtractor(nn.Module):
         self.blocks = []
         for layer_idx, layer_features in enumerate(layers, 1):
             layer_name = "mask_fcn{}".format(layer_idx)
-            module = make_conv3x3(
-                next_feature, layer_features,
+            module = make_conv3x3(next_feature, layer_features, 
                 dilation=dilation, stride=1, use_gn=use_gn
             )
             self.add_module(layer_name, module)
             next_feature = layer_features
             self.blocks.append(layer_name)
-        self.out_channels = layer_features
 
     def forward(self, x, proposals):
         x = self.pooler(x, proposals)
 
         for layer_name in self.blocks:
-            x = F.relu(getattr(self, layer_name)(x))
+            # x = F.relu(getattr(self, layer_name)(x))
+            if all(x.size()):
+                x = F.relu(getattr(self, layer_name)(x))
 
         return x
 
 
-def make_roi_mask_feature_extractor(cfg, in_channels):
-    func = registry.ROI_MASK_FEATURE_EXTRACTORS[
-        cfg.MODEL.ROI_MASK_HEAD.FEATURE_EXTRACTOR
-    ]
-    return func(cfg, in_channels)
+_ROI_MASK_FEATURE_EXTRACTORS = {
+    "ResNet50Conv5ROIFeatureExtractor": ResNet50Conv5ROIFeatureExtractor,
+    "MaskRCNNFPNFeatureExtractor": MaskRCNNFPNFeatureExtractor,
+}
+
+
+def make_roi_mask_feature_extractor(cfg):
+    func = _ROI_MASK_FEATURE_EXTRACTORS[cfg.MODEL.ROI_MASK_HEAD.FEATURE_EXTRACTOR]
+    return func(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py b/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py
index c954e33..cb4ee4a 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py
@@ -1,22 +1,43 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from torch import nn
 from torch.nn import functional as F
 
-from maskrcnn_benchmark.layers import Conv2d
-from maskrcnn_benchmark.layers import ConvTranspose2d
-from maskrcnn_benchmark.modeling import registry
+# from maskrcnn_benchmark.layers import Conv2d
+from torch.nn import Conv2d
+# from maskrcnn_benchmark.layers import ConvTranspose2d
+from torch.nn import ConvTranspose2d
 
 
-@registry.ROI_MASK_PREDICTOR.register("MaskRCNNC4Predictor")
 class MaskRCNNC4Predictor(nn.Module):
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(MaskRCNNC4Predictor, self).__init__()
         num_classes = cfg.MODEL.ROI_BOX_HEAD.NUM_CLASSES
         dim_reduced = cfg.MODEL.ROI_MASK_HEAD.CONV_LAYERS[-1]
-        num_inputs = in_channels
+
+        if cfg.MODEL.ROI_HEADS.USE_FPN:
+            num_inputs = dim_reduced
+        else:
+            stage_index = 4
+            stage2_relative_factor = 2 ** (stage_index - 1)
+            res2_out_channels = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
+            num_inputs = res2_out_channels * stage2_relative_factor
 
         self.conv5_mask = ConvTranspose2d(num_inputs, dim_reduced, 2, 2, 0)
         self.mask_fcn_logits = Conv2d(dim_reduced, num_classes, 1, 1, 0)
+        self.relu = nn.ReLU(inplace=True)
 
         for name, param in self.named_parameters():
             if "bias" in name:
@@ -27,31 +48,14 @@ class MaskRCNNC4Predictor(nn.Module):
                 nn.init.kaiming_normal_(param, mode="fan_out", nonlinearity="relu")
 
     def forward(self, x):
-        x = F.relu(self.conv5_mask(x))
+        # x = F.relu(self.conv5_mask(x))
+        x = self.relu(self.conv5_mask(x))
         return self.mask_fcn_logits(x)
 
 
-@registry.ROI_MASK_PREDICTOR.register("MaskRCNNConv1x1Predictor")
-class MaskRCNNConv1x1Predictor(nn.Module):
-    def __init__(self, cfg, in_channels):
-        super(MaskRCNNConv1x1Predictor, self).__init__()
-        num_classes = cfg.MODEL.ROI_BOX_HEAD.NUM_CLASSES
-        num_inputs = in_channels
-
-        self.mask_fcn_logits = Conv2d(num_inputs, num_classes, 1, 1, 0)
-
-        for name, param in self.named_parameters():
-            if "bias" in name:
-                nn.init.constant_(param, 0)
-            elif "weight" in name:
-                # Caffe2 implementation uses MSRAFill, which in fact
-                # corresponds to kaiming_normal_ in PyTorch
-                nn.init.kaiming_normal_(param, mode="fan_out", nonlinearity="relu")
-
-    def forward(self, x):
-        return self.mask_fcn_logits(x)
+_ROI_MASK_PREDICTOR = {"MaskRCNNC4Predictor": MaskRCNNC4Predictor}
 
 
-def make_roi_mask_predictor(cfg, in_channels):
-    func = registry.ROI_MASK_PREDICTOR[cfg.MODEL.ROI_MASK_HEAD.PREDICTOR]
-    return func(cfg, in_channels)
+def make_roi_mask_predictor(cfg):
+    func = _ROI_MASK_PREDICTOR[cfg.MODEL.ROI_MASK_HEAD.PREDICTOR]
+    return func(cfg)
diff --git a/maskrcnn_benchmark/modeling/roi_heads/roi_heads.py b/maskrcnn_benchmark/modeling/roi_heads/roi_heads.py
index 99ed7b9..3bd4a58 100644
--- a/maskrcnn_benchmark/modeling/roi_heads/roi_heads.py
+++ b/maskrcnn_benchmark/modeling/roi_heads/roi_heads.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
@@ -55,7 +68,7 @@ class CombinedROIHeads(torch.nn.ModuleDict):
         return x, detections, losses
 
 
-def build_roi_heads(cfg, in_channels):
+def build_roi_heads(cfg):
     # individually create the heads, that will be combined together
     # afterwards
     roi_heads = []
@@ -63,11 +76,11 @@ def build_roi_heads(cfg, in_channels):
         return []
 
     if not cfg.MODEL.RPN_ONLY:
-        roi_heads.append(("box", build_roi_box_head(cfg, in_channels)))
+        roi_heads.append(("box", build_roi_box_head(cfg)))
     if cfg.MODEL.MASK_ON:
-        roi_heads.append(("mask", build_roi_mask_head(cfg, in_channels)))
+        roi_heads.append(("mask", build_roi_mask_head(cfg)))
     if cfg.MODEL.KEYPOINT_ON:
-        roi_heads.append(("keypoint", build_roi_keypoint_head(cfg, in_channels)))
+        roi_heads.append(("keypoint", build_roi_keypoint_head(cfg)))
 
     # combine individual heads in a single module
     if roi_heads:
diff --git a/maskrcnn_benchmark/modeling/rpn/__init__.py b/maskrcnn_benchmark/modeling/rpn/__init__.py
index b01f30c..7cfa9f8 100644
--- a/maskrcnn_benchmark/modeling/rpn/__init__.py
+++ b/maskrcnn_benchmark/modeling/rpn/__init__.py
@@ -1,2 +1,15 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 # from .rpn import build_rpn
diff --git a/maskrcnn_benchmark/modeling/rpn/anchor_generator.py b/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
index 413f5be..6f4f903 100644
--- a/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
+++ b/maskrcnn_benchmark/modeling/rpn/anchor_generator.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import math
 
@@ -106,7 +119,7 @@ class AnchorGenerator(nn.Module):
             )
         else:
             device = anchors.device
-            inds_inside = torch.ones(anchors.shape[0], dtype=torch.bool, device=device)
+            inds_inside = torch.ones(anchors.shape[0], dtype=torch.uint8, device=device)
         boxlist.add_field("visibility", inds_inside)
 
     def forward(self, image_list, feature_maps):
@@ -226,8 +239,8 @@ def generate_anchors(
     """
     return _generate_anchors(
         stride,
-        np.array(sizes, dtype=np.float) / stride,
-        np.array(aspect_ratios, dtype=np.float),
+        np.array(sizes, dtype=np.float32) / stride,
+        np.array(aspect_ratios, dtype=np.float32),
     )
 
 
@@ -235,7 +248,7 @@ def _generate_anchors(base_size, scales, aspect_ratios):
     """Generate anchor (reference) windows by enumerating aspect ratios X
     scales wrt a reference (0, 0, base_size - 1, base_size - 1) window.
     """
-    anchor = np.array([1, 1, base_size, base_size], dtype=np.float) - 1
+    anchor = np.array([1, 1, base_size, base_size], dtype=np.float32) - 1
     anchors = _ratio_enum(anchor, aspect_ratios)
     anchors = np.vstack(
         [_scale_enum(anchors[i, :], scales) for i in range(anchors.shape[0])]
diff --git a/maskrcnn_benchmark/modeling/rpn/inference.py b/maskrcnn_benchmark/modeling/rpn/inference.py
index 5f2eb17..40242ed 100644
--- a/maskrcnn_benchmark/modeling/rpn/inference.py
+++ b/maskrcnn_benchmark/modeling/rpn/inference.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
@@ -24,7 +37,6 @@ class RPNPostProcessor(torch.nn.Module):
         min_size,
         box_coder=None,
         fpn_post_nms_top_n=None,
-        fpn_post_nms_per_batch=True,
     ):
         """
         Arguments:
@@ -48,7 +60,6 @@ class RPNPostProcessor(torch.nn.Module):
         if fpn_post_nms_top_n is None:
             fpn_post_nms_top_n = post_nms_top_n
         self.fpn_post_nms_top_n = fpn_post_nms_top_n
-        self.fpn_post_nms_per_batch = fpn_post_nms_per_batch
 
     def add_gt_proposals(self, proposals, targets):
         """
@@ -156,16 +167,16 @@ class RPNPostProcessor(torch.nn.Module):
         # different behavior during training and during testing:
         # during training, post_nms_top_n is over *all* the proposals combined, while
         # during testing, it is over the proposals for each image
-        # NOTE: it should be per image, and not per batch. However, to be consistent 
-        # with Detectron, the default is per batch (see Issue #672)
-        if self.training and self.fpn_post_nms_per_batch:
+        # TODO resolve this difference and make it consistent. It should be per image,
+        # and not per batch
+        if self.training:
             objectness = torch.cat(
                 [boxlist.get_field("objectness") for boxlist in boxlists], dim=0
             )
             box_sizes = [len(boxlist) for boxlist in boxlists]
             post_nms_top_n = min(self.fpn_post_nms_top_n, len(objectness))
             _, inds_sorted = torch.topk(objectness, post_nms_top_n, dim=0, sorted=True)
-            inds_mask = torch.zeros_like(objectness, dtype=torch.bool)
+            inds_mask = torch.zeros_like(objectness, dtype=torch.uint8)
             inds_mask[inds_sorted] = 1
             inds_mask = inds_mask.split(box_sizes)
             for i in range(num_images):
@@ -191,7 +202,6 @@ def make_rpn_postprocessor(config, rpn_box_coder, is_train):
     if not is_train:
         pre_nms_top_n = config.MODEL.RPN.PRE_NMS_TOP_N_TEST
         post_nms_top_n = config.MODEL.RPN.POST_NMS_TOP_N_TEST
-    fpn_post_nms_per_batch = config.MODEL.RPN.FPN_POST_NMS_PER_BATCH
     nms_thresh = config.MODEL.RPN.NMS_THRESH
     min_size = config.MODEL.RPN.MIN_SIZE
     box_selector = RPNPostProcessor(
@@ -201,6 +211,5 @@ def make_rpn_postprocessor(config, rpn_box_coder, is_train):
         min_size=min_size,
         box_coder=rpn_box_coder,
         fpn_post_nms_top_n=fpn_post_nms_top_n,
-        fpn_post_nms_per_batch=fpn_post_nms_per_batch,
     )
     return box_selector
diff --git a/maskrcnn_benchmark/modeling/rpn/loss.py b/maskrcnn_benchmark/modeling/rpn/loss.py
index 11e83b3..5f64524 100644
--- a/maskrcnn_benchmark/modeling/rpn/loss.py
+++ b/maskrcnn_benchmark/modeling/rpn/loss.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 This file contains specific functions for computing losses on the RPN
@@ -92,14 +105,14 @@ class RPNLossComputation(object):
     def __call__(self, anchors, objectness, box_regression, targets):
         """
         Arguments:
-            anchors (list[list[BoxList]])
+            anchors (list[BoxList])
             objectness (list[Tensor])
             box_regression (list[Tensor])
             targets (list[BoxList])
 
         Returns:
             objectness_loss (Tensor)
-            box_loss (Tensor)
+            box_loss (Tensor
         """
         anchors = [cat_boxlist(anchors_per_image) for anchors_per_image in anchors]
         labels, regression_targets = self.prepare_targets(anchors, targets)
diff --git a/maskrcnn_benchmark/modeling/rpn/retinanet/__init__.py b/maskrcnn_benchmark/modeling/rpn/retinanet/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/modeling/rpn/retinanet/__init__.py
+++ b/maskrcnn_benchmark/modeling/rpn/retinanet/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py b/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py
index 2ff3a14..92e8d41 100644
--- a/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py
+++ b/maskrcnn_benchmark/modeling/rpn/retinanet/inference.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import torch
 
 from ..inference import RPNPostProcessor
@@ -74,6 +87,7 @@ class RetinaNetPostProcessor(RPNPostProcessor):
         box_cls = box_cls.sigmoid()
 
         box_regression = permute_and_flatten(box_regression, N, A, 4, H, W)
+        box_regression = box_regression.reshape(N, -1, 4)
 
         num_anchors = A * H * W
 
diff --git a/maskrcnn_benchmark/modeling/rpn/retinanet/loss.py b/maskrcnn_benchmark/modeling/rpn/retinanet/loss.py
index 080e215..cb0b89f 100644
--- a/maskrcnn_benchmark/modeling/rpn/retinanet/loss.py
+++ b/maskrcnn_benchmark/modeling/rpn/retinanet/loss.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 """
 This file contains specific functions for computing losses on the RetinaNet
 file
diff --git a/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py b/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py
index 1599b29..ccf76e4 100644
--- a/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py
+++ b/maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import math
 import torch
 import torch.nn.functional as F
@@ -15,7 +28,7 @@ class RetinaNetHead(torch.nn.Module):
     Adds a RetinNet head with classification and regression heads
     """
 
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         """
         Arguments:
             in_channels (int): number of channels of the input feature
@@ -24,6 +37,7 @@ class RetinaNetHead(torch.nn.Module):
         super(RetinaNetHead, self).__init__()
         # TODO: Implement the sigmoid version first.
         num_classes = cfg.MODEL.RETINANET.NUM_CLASSES - 1
+        in_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS
         num_anchors = len(cfg.MODEL.RETINANET.ASPECT_RATIOS) \
                         * cfg.MODEL.RETINANET.SCALES_PER_OCTAVE
 
@@ -91,13 +105,13 @@ class RetinaNetModule(torch.nn.Module):
     RetinaNet outputs and losses. Only Test on FPN now.
     """
 
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(RetinaNetModule, self).__init__()
 
         self.cfg = cfg.clone()
 
         anchor_generator = make_anchor_generator_retinanet(cfg)
-        head = RetinaNetHead(cfg, in_channels)
+        head = RetinaNetHead(cfg)
         box_coder = BoxCoder(weights=(10., 10., 5., 5.))
 
         box_selector_test = make_retinanet_postprocessor(cfg, box_coder, is_train=False)
@@ -148,5 +162,5 @@ class RetinaNetModule(torch.nn.Module):
         return boxes, {}
 
 
-def build_retinanet(cfg, in_channels):
-    return RetinaNetModule(cfg, in_channels)
+def build_retinanet(cfg):
+    return RetinaNetModule(cfg)
diff --git a/maskrcnn_benchmark/modeling/rpn/rpn.py b/maskrcnn_benchmark/modeling/rpn/rpn.py
index c279a23..18c49a4 100644
--- a/maskrcnn_benchmark/modeling/rpn/rpn.py
+++ b/maskrcnn_benchmark/modeling/rpn/rpn.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 import torch.nn.functional as F
@@ -10,66 +23,6 @@ from .loss import make_rpn_loss_evaluator
 from .anchor_generator import make_anchor_generator
 from .inference import make_rpn_postprocessor
 
-
-class RPNHeadConvRegressor(nn.Module):
-    """
-    A simple RPN Head for classification and bbox regression
-    """
-
-    def __init__(self, cfg, in_channels, num_anchors):
-        """
-        Arguments:
-            cfg              : config
-            in_channels (int): number of channels of the input feature
-            num_anchors (int): number of anchors to be predicted
-        """
-        super(RPNHeadConvRegressor, self).__init__()
-        self.cls_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1)
-        self.bbox_pred = nn.Conv2d(
-            in_channels, num_anchors * 4, kernel_size=1, stride=1
-        )
-
-        for l in [self.cls_logits, self.bbox_pred]:
-            torch.nn.init.normal_(l.weight, std=0.01)
-            torch.nn.init.constant_(l.bias, 0)
-
-    def forward(self, x):
-        assert isinstance(x, (list, tuple))
-        logits = [self.cls_logits(y) for y in x]
-        bbox_reg = [self.bbox_pred(y) for y in x]
-
-        return logits, bbox_reg
-
-
-class RPNHeadFeatureSingleConv(nn.Module):
-    """
-    Adds a simple RPN Head with one conv to extract the feature
-    """
-
-    def __init__(self, cfg, in_channels):
-        """
-        Arguments:
-            cfg              : config
-            in_channels (int): number of channels of the input feature
-        """
-        super(RPNHeadFeatureSingleConv, self).__init__()
-        self.conv = nn.Conv2d(
-            in_channels, in_channels, kernel_size=3, stride=1, padding=1
-        )
-
-        for l in [self.conv]:
-            torch.nn.init.normal_(l.weight, std=0.01)
-            torch.nn.init.constant_(l.bias, 0)
-
-        self.out_channels = in_channels
-
-    def forward(self, x):
-        assert isinstance(x, (list, tuple))
-        x = [F.relu(self.conv(z)) for z in x]
-
-        return x
-
-
 @registry.RPN_HEADS.register("SingleConvRPNHead")
 class RPNHead(nn.Module):
     """
@@ -108,17 +61,18 @@ class RPNHead(nn.Module):
 
 class RPNModule(torch.nn.Module):
     """
-    Module for RPN computation. Takes feature maps from the backbone and outputs 
-    RPN proposals and losses. Works for both FPN and non-FPN.
+    Module for RPN computation. Takes feature maps from the backbone and RPN
+    proposals and losses. Works for both FPN and non-FPN.
     """
 
-    def __init__(self, cfg, in_channels):
+    def __init__(self, cfg):
         super(RPNModule, self).__init__()
 
         self.cfg = cfg.clone()
 
         anchor_generator = make_anchor_generator(cfg)
 
+        in_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS
         rpn_head = registry.RPN_HEADS[cfg.MODEL.RPN.RPN_HEAD]
         head = rpn_head(
             cfg, in_channels, anchor_generator.num_anchors_per_location()[0]
@@ -197,11 +151,11 @@ class RPNModule(torch.nn.Module):
         return boxes, {}
 
 
-def build_rpn(cfg, in_channels):
+def build_rpn(cfg):
     """
     This gives the gist of it. Not super important because it doesn't change as much
     """
     if cfg.MODEL.RETINANET_ON:
-        return build_retinanet(cfg, in_channels)
+        return build_retinanet(cfg)
 
-    return RPNModule(cfg, in_channels)
+    return RPNModule(cfg)
diff --git a/maskrcnn_benchmark/modeling/rpn/utils.py b/maskrcnn_benchmark/modeling/rpn/utils.py
index 37a9ca6..ce0ceac 100644
--- a/maskrcnn_benchmark/modeling/rpn/utils.py
+++ b/maskrcnn_benchmark/modeling/rpn/utils.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 Utility functions minipulating the prediction layers
diff --git a/maskrcnn_benchmark/modeling/utils.py b/maskrcnn_benchmark/modeling/utils.py
index 5b1d79a..85702bf 100644
--- a/maskrcnn_benchmark/modeling/utils.py
+++ b/maskrcnn_benchmark/modeling/utils.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 """
 Miscellaneous utility functions
diff --git a/maskrcnn_benchmark/solver/__init__.py b/maskrcnn_benchmark/solver/__init__.py
index 75f4053..63292c9 100644
--- a/maskrcnn_benchmark/solver/__init__.py
+++ b/maskrcnn_benchmark/solver/__init__.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from .build import make_optimizer
 from .build import make_lr_scheduler
diff --git a/maskrcnn_benchmark/solver/build.py b/maskrcnn_benchmark/solver/build.py
index 865a4ec..79ca00a 100644
--- a/maskrcnn_benchmark/solver/build.py
+++ b/maskrcnn_benchmark/solver/build.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
diff --git a/maskrcnn_benchmark/solver/lr_scheduler.py b/maskrcnn_benchmark/solver/lr_scheduler.py
index d7d45b6..f218ae6 100644
--- a/maskrcnn_benchmark/solver/lr_scheduler.py
+++ b/maskrcnn_benchmark/solver/lr_scheduler.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from bisect import bisect_right
 
@@ -24,7 +37,7 @@ class WarmupMultiStepLR(torch.optim.lr_scheduler._LRScheduler):
                 milestones,
             )
 
-        if warmup_method not in ("constant", "linear"):
+        if warmup_method not in ("constant", "linear", "mlperf_linear"):
             raise ValueError(
                 "Only 'constant' or 'linear' warmup_method accepted"
                 "got {}".format(warmup_method)
@@ -38,14 +51,21 @@ class WarmupMultiStepLR(torch.optim.lr_scheduler._LRScheduler):
 
     def get_lr(self):
         warmup_factor = 1
+        # optional offset to each base_lr
+        delta = 0.
+
         if self.last_epoch < self.warmup_iters:
             if self.warmup_method == "constant":
                 warmup_factor = self.warmup_factor
             elif self.warmup_method == "linear":
                 alpha = float(self.last_epoch) / self.warmup_iters
                 warmup_factor = self.warmup_factor * (1 - alpha) + alpha
+            # MLPerf-specific warmup definition
+            elif self.warmup_method == "mlperf_linear":
+                delta = (self.warmup_iters - self.last_epoch) * self.warmup_factor
+
         return [
-            base_lr
+            (base_lr - delta)
             * warmup_factor
             * self.gamma ** bisect_right(self.milestones, self.last_epoch)
             for base_lr in self.base_lrs
diff --git a/maskrcnn_benchmark/structures/__init__.py b/maskrcnn_benchmark/structures/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/structures/__init__.py
+++ b/maskrcnn_benchmark/structures/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/structures/bounding_box.py b/maskrcnn_benchmark/structures/bounding_box.py
index 25791d5..ed6d8d7 100644
--- a/maskrcnn_benchmark/structures/bounding_box.py
+++ b/maskrcnn_benchmark/structures/bounding_box.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
@@ -25,7 +38,7 @@ class BoxList(object):
             )
         if bbox.size(-1) != 4:
             raise ValueError(
-                "last dimension of bbox should have a "
+                "last dimenion of bbox should have a "
                 "size of 4, got {}".format(bbox.size(-1))
             )
         if mode not in ("xyxy", "xywh"):
@@ -166,7 +179,7 @@ class BoxList(object):
 
     def crop(self, box):
         """
-        Crops a rectangular region from this bounding box. The box is a
+        Cropss a rectangular region from this bounding box. The box is a
         4-tuple defining the left, upper, right, and lower pixel
         coordinate.
         """
diff --git a/maskrcnn_benchmark/structures/boxlist_ops.py b/maskrcnn_benchmark/structures/boxlist_ops.py
index 02dcaf1..28796fb 100644
--- a/maskrcnn_benchmark/structures/boxlist_ops.py
+++ b/maskrcnn_benchmark/structures/boxlist_ops.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
 
@@ -67,8 +80,7 @@ def boxlist_iou(boxlist1, boxlist2):
     if boxlist1.size != boxlist2.size:
         raise RuntimeError(
                 "boxlists should have same image size, got {}, {}".format(boxlist1, boxlist2))
-    boxlist1 = boxlist1.convert("xyxy")
-    boxlist2 = boxlist2.convert("xyxy")
+
     N = len(boxlist1)
     M = len(boxlist2)
 
diff --git a/maskrcnn_benchmark/structures/image_list.py b/maskrcnn_benchmark/structures/image_list.py
index 590b87a..49cb8bd 100644
--- a/maskrcnn_benchmark/structures/image_list.py
+++ b/maskrcnn_benchmark/structures/image_list.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from __future__ import division
 
@@ -41,8 +54,6 @@ def to_image_list(tensors, size_divisible=0):
         return tensors
     elif isinstance(tensors, torch.Tensor):
         # single tensor shape can be inferred
-        if tensors.dim() == 3:
-            tensors = tensors[None]
         assert tensors.dim() == 4
         image_sizes = [tensor.shape[-2:] for tensor in tensors]
         return ImageList(tensors, image_sizes)
diff --git a/maskrcnn_benchmark/structures/keypoint.py b/maskrcnn_benchmark/structures/keypoint.py
index a6881f7..aa13029 100644
--- a/maskrcnn_benchmark/structures/keypoint.py
+++ b/maskrcnn_benchmark/structures/keypoint.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 import torch
 
 
diff --git a/maskrcnn_benchmark/structures/segmentation_mask.py b/maskrcnn_benchmark/structures/segmentation_mask.py
index 84ef9db..8b9a813 100644
--- a/maskrcnn_benchmark/structures/segmentation_mask.py
+++ b/maskrcnn_benchmark/structures/segmentation_mask.py
@@ -1,9 +1,19 @@
-import cv2
-import copy
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
-import numpy as np
-from maskrcnn_benchmark.layers.misc import interpolate
-from maskrcnn_benchmark.utils import cv2_util
+
 import pycocotools.mask as mask_utils
 
 # transpose
@@ -11,241 +21,63 @@ FLIP_LEFT_RIGHT = 0
 FLIP_TOP_BOTTOM = 1
 
 
-""" ABSTRACT
-Segmentations come in either:
-1) Binary masks
-2) Polygons
-
-Binary masks can be represented in a contiguous array
-and operations can be carried out more efficiently,
-therefore BinaryMaskList handles them together.
-
-Polygons are handled separately for each instance,
-by PolygonInstance and instances are handled by
-PolygonList.
-
-SegmentationList is supposed to represent both,
-therefore it wraps the functions of BinaryMaskList
-and PolygonList to make it transparent.
-"""
-
-
-class BinaryMaskList(object):
+class Mask(object):
     """
-    This class handles binary masks for all objects in the image
+    This class is unfinished and not meant for use yet
+    It is supposed to contain the mask for an object as
+    a 2d tensor
     """
 
-    def __init__(self, masks, size):
-        """
-            Arguments:
-                masks: Either torch.tensor of [num_instances, H, W]
-                    or list of torch.tensors of [H, W] with num_instances elems,
-                    or RLE (Run Length Encoding) - interpreted as list of dicts,
-                    or BinaryMaskList.
-                size: absolute image size, width first
-
-            After initialization, a hard copy will be made, to leave the
-            initializing source data intact.
-        """
-
-        assert isinstance(size, (list, tuple))
-        assert len(size) == 2
-
-        if isinstance(masks, torch.Tensor):
-            # The raw data representation is passed as argument
-            masks = masks.clone()
-        elif isinstance(masks, (list, tuple)):
-            if len(masks) == 0:
-                masks = torch.empty([0, size[1], size[0]])  # num_instances = 0!
-            elif isinstance(masks[0], torch.Tensor):
-                masks = torch.stack(masks, dim=0).clone()
-            elif isinstance(masks[0], dict) and "counts" in masks[0]:
-                if(isinstance(masks[0]["counts"], (list, tuple))):
-                    masks = mask_utils.frPyObjects(masks, size[1], size[0])
-                # RLE interpretation
-                rle_sizes = [tuple(inst["size"]) for inst in masks]
-
-                masks = mask_utils.decode(masks)  # [h, w, n]
-                masks = torch.tensor(masks).permute(2, 0, 1)  # [n, h, w]
-
-                assert rle_sizes.count(rle_sizes[0]) == len(rle_sizes), (
-                    "All the sizes must be the same size: %s" % rle_sizes
-                )
-
-                # in RLE, height come first in "size"
-                rle_height, rle_width = rle_sizes[0]
-                assert masks.shape[1] == rle_height
-                assert masks.shape[2] == rle_width
-
-                width, height = size
-                if width != rle_width or height != rle_height:
-                    masks = interpolate(
-                        input=masks[None].float(),
-                        size=(height, width),
-                        mode="bilinear",
-                        align_corners=False,
-                    )[0].type_as(masks)
-            else:
-                RuntimeError(
-                    "Type of `masks[0]` could not be interpreted: %s"
-                    % type(masks)
-                )
-        elif isinstance(masks, BinaryMaskList):
-            # just hard copy the BinaryMaskList instance's underlying data
-            masks = masks.masks.clone()
-        else:
-            RuntimeError(
-                "Type of `masks` argument could not be interpreted:%s"
-                % type(masks)
-            )
-
-        if len(masks.shape) == 2:
-            # if only a single instance mask is passed
-            masks = masks[None]
-
-        assert len(masks.shape) == 3
-        assert masks.shape[1] == size[1], "%s != %s" % (masks.shape[1], size[1])
-        assert masks.shape[2] == size[0], "%s != %s" % (masks.shape[2], size[0])
-
+    def __init__(self, masks, size, mode):
         self.masks = masks
-        self.size = tuple(size)
+        self.size = size
+        self.mode = mode
 
     def transpose(self, method):
-        dim = 1 if method == FLIP_TOP_BOTTOM else 2
-        flipped_masks = self.masks.flip(dim)
-        return BinaryMaskList(flipped_masks, self.size)
-
-    def crop(self, box):
-        assert isinstance(box, (list, tuple, torch.Tensor)), str(type(box))
-        # box is assumed to be xyxy
-        current_width, current_height = self.size
-        xmin, ymin, xmax, ymax = [round(float(b)) for b in box]
-
-        assert xmin <= xmax and ymin <= ymax, str(box)
-        xmin = min(max(xmin, 0), current_width - 1)
-        ymin = min(max(ymin, 0), current_height - 1)
-
-        xmax = min(max(xmax, 0), current_width)
-        ymax = min(max(ymax, 0), current_height)
-
-        xmax = max(xmax, xmin + 1)
-        ymax = max(ymax, ymin + 1)
-
-        width, height = xmax - xmin, ymax - ymin
-        cropped_masks = self.masks[:, ymin:ymax, xmin:xmax]
-        cropped_size = width, height
-        return BinaryMaskList(cropped_masks, cropped_size)
-
-    def resize(self, size):
-        try:
-            iter(size)
-        except TypeError:
-            assert isinstance(size, (int, float))
-            size = size, size
-        width, height = map(int, size)
-
-        assert width > 0
-        assert height > 0
-
-        # Height comes first here!
-        resized_masks = interpolate(
-            input=self.masks[None].float(),
-            size=(height, width),
-            mode="bilinear",
-            align_corners=False,
-        )[0].type_as(self.masks)
-        resized_size = width, height
-        return BinaryMaskList(resized_masks, resized_size)
-
-    def convert_to_polygon(self):
-        if self.masks.numel() == 0:
-            return PolygonList([], self.size)
-
-        contours = self._findContours()
-        return PolygonList(contours, self.size)
-
-    def to(self, *args, **kwargs):
-        return self
-
-    def _findContours(self):
-        contours = []
-        masks = self.masks.detach().numpy()
-        for mask in masks:
-            mask = cv2.UMat(mask)
-            contour, hierarchy = cv2_util.findContours(
-                mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1
+        if method not in (FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM):
+            raise NotImplementedError(
+                "Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented"
             )
 
-            reshaped_contour = []
-            for entity in contour:
-                assert len(entity.shape) == 3
-                assert (
-                    entity.shape[1] == 1
-                ), "Hierarchical contours are not allowed"
-                reshaped_contour.append(entity.reshape(-1).tolist())
-            contours.append(reshaped_contour)
-        return contours
+        width, height = self.size
+        if method == FLIP_LEFT_RIGHT:
+            dim = width
+            idx = 2
+        elif method == FLIP_TOP_BOTTOM:
+            dim = height
+            idx = 1
 
-    def __len__(self):
-        return len(self.masks)
+        flip_idx = list(range(dim)[::-1])
+        flipped_masks = self.masks.index_select(dim, flip_idx)
+        return Mask(flipped_masks, self.size, self.mode)
 
-    def __getitem__(self, index):
-        if self.masks.numel() == 0:
-            raise RuntimeError("Indexing empty BinaryMaskList")
-        return BinaryMaskList(self.masks[index], self.size)
+    def crop(self, box):
+        w, h = box[2] - box[0], box[3] - box[1]
 
-    def __iter__(self):
-        return iter(self.masks)
+        cropped_masks = self.masks[:, box[1] : box[3], box[0] : box[2]]
+        return Mask(cropped_masks, size=(w, h), mode=self.mode)
 
-    def __repr__(self):
-        s = self.__class__.__name__ + "("
-        s += "num_instances={}, ".format(len(self.masks))
-        s += "image_width={}, ".format(self.size[0])
-        s += "image_height={})".format(self.size[1])
-        return s
+    def resize(self, size, *args, **kwargs):
+        pass
 
 
-class PolygonInstance(object):
+class Polygons(object):
     """
     This class holds a set of polygons that represents a single instance
     of an object mask. The object can be represented as a set of
     polygons
     """
 
-    def __init__(self, polygons, size):
-        """
-            Arguments:
-                a list of lists of numbers.
-                The first level refers to all the polygons that compose the
-                object, and the second level to the polygon coordinates.
-        """
-        if isinstance(polygons, (list, tuple)):
-            valid_polygons = []
-            for p in polygons:
-                p = torch.as_tensor(p, dtype=torch.float32)
-                if len(p) >= 6:  # 3 * 2 coordinates
-                    valid_polygons.append(p)
-            polygons = valid_polygons
-
-        elif isinstance(polygons, PolygonInstance):
-            polygons = copy.copy(polygons.polygons)
-
-        else:
-            RuntimeError(
-                "Type of argument `polygons` is not allowed:%s"
-                % (type(polygons))
-            )
-
-        """ This crashes the training way too many times...
-        for p in polygons:
-            assert p[::2].min() >= 0
-            assert p[::2].max() < size[0]
-            assert p[1::2].min() >= 0
-            assert p[1::2].max() , size[1]
-        """
+    def __init__(self, polygons, size, mode):
+        # assert isinstance(polygons, list), '{}'.format(polygons)
+        if isinstance(polygons, list):
+            polygons = [torch.as_tensor(p, dtype=torch.float32) for p in polygons]
+        elif isinstance(polygons, Polygons):
+            polygons = polygons.polygons
 
         self.polygons = polygons
-        self.size = tuple(size)
+        self.size = size
+        self.mode = mode
 
     def transpose(self, method):
         if method not in (FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM):
@@ -268,51 +100,30 @@ class PolygonInstance(object):
             p[idx::2] = dim - poly[idx::2] - TO_REMOVE
             flipped_polygons.append(p)
 
-        return PolygonInstance(flipped_polygons, size=self.size)
+        return Polygons(flipped_polygons, size=self.size, mode=self.mode)
 
     def crop(self, box):
-        assert isinstance(box, (list, tuple, torch.Tensor)), str(type(box))
-
-        # box is assumed to be xyxy
-        current_width, current_height = self.size
-        xmin, ymin, xmax, ymax = map(float, box)
-
-        assert xmin <= xmax and ymin <= ymax, str(box)
-        xmin = min(max(xmin, 0), current_width - 1)
-        ymin = min(max(ymin, 0), current_height - 1)
-
-        xmax = min(max(xmax, 0), current_width)
-        ymax = min(max(ymax, 0), current_height)
-
-        xmax = max(xmax, xmin + 1)
-        ymax = max(ymax, ymin + 1)
+        w, h = box[2] - box[0], box[3] - box[1]
 
-        w, h = xmax - xmin, ymax - ymin
+        # TODO chck if necessary
+        w = max(w, 1)
+        h = max(h, 1)
 
         cropped_polygons = []
         for poly in self.polygons:
             p = poly.clone()
-            p[0::2] = p[0::2] - xmin  # .clamp(min=0, max=w)
-            p[1::2] = p[1::2] - ymin  # .clamp(min=0, max=h)
+            p[0::2] = p[0::2] - box[0]  # .clamp(min=0, max=w)
+            p[1::2] = p[1::2] - box[1]  # .clamp(min=0, max=h)
             cropped_polygons.append(p)
 
-        return PolygonInstance(cropped_polygons, size=(w, h))
-
-    def resize(self, size):
-        try:
-            iter(size)
-        except TypeError:
-            assert isinstance(size, (int, float))
-            size = size, size
-
-        ratios = tuple(
-            float(s) / float(s_orig) for s, s_orig in zip(size, self.size)
-        )
+        return Polygons(cropped_polygons, size=(w, h), mode=self.mode)
 
+    def resize(self, size, *args, **kwargs):
+        ratios = tuple(float(s) / float(s_orig) for s, s_orig in zip(size, self.size))
         if ratios[0] == ratios[1]:
             ratio = ratios[0]
             scaled_polys = [p * ratio for p in self.polygons]
-            return PolygonInstance(scaled_polys, size)
+            return Polygons(scaled_polys, size, mode=self.mode)
 
         ratio_w, ratio_h = ratios
         scaled_polygons = []
@@ -322,85 +133,47 @@ class PolygonInstance(object):
             p[1::2] *= ratio_h
             scaled_polygons.append(p)
 
-        return PolygonInstance(scaled_polygons, size=size)
+        return Polygons(scaled_polygons, size=size, mode=self.mode)
 
-    def convert_to_binarymask(self):
+    def convert(self, mode):
         width, height = self.size
-        # formatting for COCO PythonAPI
-        polygons = [p.numpy() for p in self.polygons]
-        rles = mask_utils.frPyObjects(polygons, height, width)
-        rle = mask_utils.merge(rles)
-        mask = mask_utils.decode(rle)
-        mask = torch.from_numpy(mask)
-        return mask
-
-    def __len__(self):
-        return len(self.polygons)
+        if mode == "mask":
+            rles = mask_utils.frPyObjects(
+                [p.numpy() for p in self.polygons], height, width
+            )
+            rle = mask_utils.merge(rles)
+            mask = mask_utils.decode(rle)
+            mask = torch.from_numpy(mask)
+            # TODO add squeeze?
+            return mask
 
     def __repr__(self):
         s = self.__class__.__name__ + "("
-        s += "num_groups={}, ".format(len(self.polygons))
+        s += "num_polygons={}, ".format(len(self.polygons))
         s += "image_width={}, ".format(self.size[0])
-        s += "image_height={})".format(self.size[1])
+        s += "image_height={}, ".format(self.size[1])
+        s += "mode={})".format(self.mode)
         return s
 
 
-class PolygonList(object):
+class SegmentationMask(object):
     """
-    This class handles PolygonInstances for all objects in the image
+    This class stores the segmentations for all objects in the image
     """
 
-    def __init__(self, polygons, size):
+    def __init__(self, polygons, size, mode=None):
         """
         Arguments:
-            polygons:
-                a list of list of lists of numbers. The first
+            polygons: a list of list of lists of numbers. The first
                 level of the list correspond to individual instances,
                 the second level to all the polygons that compose the
                 object, and the third level to the polygon coordinates.
-
-                OR
-
-                a list of PolygonInstances.
-
-                OR
-
-                a PolygonList
-
-            size: absolute image size
-
         """
-        if isinstance(polygons, (list, tuple)):
-            if len(polygons) == 0:
-                polygons = [[[]]]
-            if isinstance(polygons[0], (list, tuple)):
-                assert isinstance(polygons[0][0], (list, tuple)), str(
-                    type(polygons[0][0])
-                )
-            else:
-                assert isinstance(polygons[0], PolygonInstance), str(
-                    type(polygons[0])
-                )
-
-        elif isinstance(polygons, PolygonList):
-            size = polygons.size
-            polygons = polygons.polygons
-
-        else:
-            RuntimeError(
-                "Type of argument `polygons` is not allowed:%s"
-                % (type(polygons))
-            )
-
-        assert isinstance(size, (list, tuple)), str(type(size))
-
-        self.polygons = []
-        for p in polygons:
-            p = PolygonInstance(p, size)
-            if len(p) > 0:
-                self.polygons.append(p)
+        assert isinstance(polygons, list)
 
-        self.size = tuple(size)
+        self.polygons = [Polygons(p, size, mode) for p in polygons]
+        self.size = size
+        self.mode = mode
 
     def transpose(self, method):
         if method not in (FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM):
@@ -408,61 +181,41 @@ class PolygonList(object):
                 "Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented"
             )
 
-        flipped_polygons = []
+        flipped = []
         for polygon in self.polygons:
-            flipped_polygons.append(polygon.transpose(method))
-
-        return PolygonList(flipped_polygons, size=self.size)
+            flipped.append(polygon.transpose(method))
+        return SegmentationMask(flipped, size=self.size, mode=self.mode)
 
     def crop(self, box):
         w, h = box[2] - box[0], box[3] - box[1]
-        cropped_polygons = []
+        cropped = []
         for polygon in self.polygons:
-            cropped_polygons.append(polygon.crop(box))
+            cropped.append(polygon.crop(box))
+        return SegmentationMask(cropped, size=(w, h), mode=self.mode)
 
-        cropped_size = w, h
-        return PolygonList(cropped_polygons, cropped_size)
-
-    def resize(self, size):
-        resized_polygons = []
+    def resize(self, size, *args, **kwargs):
+        scaled = []
         for polygon in self.polygons:
-            resized_polygons.append(polygon.resize(size))
-
-        resized_size = size
-        return PolygonList(resized_polygons, resized_size)
+            scaled.append(polygon.resize(size, *args, **kwargs))
+        return SegmentationMask(scaled, size=size, mode=self.mode)
 
     def to(self, *args, **kwargs):
         return self
 
-    def convert_to_binarymask(self):
-        if len(self) > 0:
-            masks = torch.stack(
-                [p.convert_to_binarymask() for p in self.polygons]
-            )
-        else:
-            size = self.size
-            masks = torch.empty([0, size[1], size[0]], dtype=torch.bool)
-
-        return BinaryMaskList(masks, size=self.size)
-
-    def __len__(self):
-        return len(self.polygons)
-
     def __getitem__(self, item):
-        if isinstance(item, int):
+        if isinstance(item, (int, slice)):
             selected_polygons = [self.polygons[item]]
-        elif isinstance(item, slice):
-            selected_polygons = self.polygons[item]
         else:
             # advanced indexing on a single dimension
             selected_polygons = []
-            if isinstance(item, torch.Tensor) and item.dtype == torch.bool:
+            if isinstance(item, torch.Tensor) and \
+                    (item.dtype == torch.uint8 or item.dtype == torch.bool):
                 item = item.nonzero()
                 item = item.squeeze(1) if item.numel() > 0 else item
                 item = item.tolist()
             for i in item:
                 selected_polygons.append(self.polygons[i])
-        return PolygonList(selected_polygons, size=self.size)
+        return SegmentationMask(selected_polygons, size=self.size, mode=self.mode)
 
     def __iter__(self):
         return iter(self.polygons)
@@ -473,105 +226,3 @@ class PolygonList(object):
         s += "image_width={}, ".format(self.size[0])
         s += "image_height={})".format(self.size[1])
         return s
-
-
-class SegmentationMask(object):
-
-    """
-    This class stores the segmentations for all objects in the image.
-    It wraps BinaryMaskList and PolygonList conveniently.
-    """
-
-    def __init__(self, instances, size, mode="poly"):
-        """
-        Arguments:
-            instances: two types
-                (1) polygon
-                (2) binary mask
-            size: (width, height)
-            mode: 'poly', 'mask'. if mode is 'mask', convert mask of any format to binary mask
-        """
-
-        assert isinstance(size, (list, tuple))
-        assert len(size) == 2
-        if isinstance(size[0], torch.Tensor):
-            assert isinstance(size[1], torch.Tensor)
-            size = size[0].item(), size[1].item()
-
-        assert isinstance(size[0], (int, float))
-        assert isinstance(size[1], (int, float))
-
-        if mode == "poly":
-            self.instances = PolygonList(instances, size)
-        elif mode == "mask":
-            self.instances = BinaryMaskList(instances, size)
-        else:
-            raise NotImplementedError("Unknown mode: %s" % str(mode))
-
-        self.mode = mode
-        self.size = tuple(size)
-
-    def transpose(self, method):
-        flipped_instances = self.instances.transpose(method)
-        return SegmentationMask(flipped_instances, self.size, self.mode)
-
-    def crop(self, box):
-        cropped_instances = self.instances.crop(box)
-        cropped_size = cropped_instances.size
-        return SegmentationMask(cropped_instances, cropped_size, self.mode)
-
-    def resize(self, size, *args, **kwargs):
-        resized_instances = self.instances.resize(size)
-        resized_size = size
-        return SegmentationMask(resized_instances, resized_size, self.mode)
-
-    def to(self, *args, **kwargs):
-        return self
-
-    def convert(self, mode):
-        if mode == self.mode:
-            return self
-
-        if mode == "poly":
-            converted_instances = self.instances.convert_to_polygon()
-        elif mode == "mask":
-            converted_instances = self.instances.convert_to_binarymask()
-        else:
-            raise NotImplementedError("Unknown mode: %s" % str(mode))
-
-        return SegmentationMask(converted_instances, self.size, mode)
-
-    def get_mask_tensor(self):
-        instances = self.instances
-        if self.mode == "poly":
-            instances = instances.convert_to_binarymask()
-        # If there is only 1 instance
-        return instances.masks.squeeze(0)
-
-    def __len__(self):
-        return len(self.instances)
-
-    def __getitem__(self, item):
-        selected_instances = self.instances.__getitem__(item)
-        return SegmentationMask(selected_instances, self.size, self.mode)
-
-    def __iter__(self):
-        self.iter_idx = 0
-        return self
-
-    def __next__(self):
-        if self.iter_idx < self.__len__():
-            next_segmentation = self.__getitem__(self.iter_idx)
-            self.iter_idx += 1
-            return next_segmentation
-        raise StopIteration()
-
-    next = __next__  # Python 2 compatibility
-
-    def __repr__(self):
-        s = self.__class__.__name__ + "("
-        s += "num_instances={}, ".format(len(self.instances))
-        s += "image_width={}, ".format(self.size[0])
-        s += "image_height={}, ".format(self.size[1])
-        s += "mode={})".format(self.mode)
-        return s
diff --git a/maskrcnn_benchmark/utils/__init__.py b/maskrcnn_benchmark/utils/__init__.py
index e69de29..54b8999 100644
--- a/maskrcnn_benchmark/utils/__init__.py
+++ b/maskrcnn_benchmark/utils/__init__.py
@@ -0,0 +1,13 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
diff --git a/maskrcnn_benchmark/utils/c2_model_loading.py b/maskrcnn_benchmark/utils/c2_model_loading.py
index cbf4c05..690fb7d 100644
--- a/maskrcnn_benchmark/utils/c2_model_loading.py
+++ b/maskrcnn_benchmark/utils/c2_model_loading.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import logging
 import pickle
@@ -143,33 +156,6 @@ def _load_c2_pickled_weights(file_path):
     return weights
 
 
-def _rename_conv_weights_for_deformable_conv_layers(state_dict, cfg):
-    import re
-    logger = logging.getLogger(__name__)
-    logger.info("Remapping conv weights for deformable conv weights")
-    layer_keys = sorted(state_dict.keys())
-    for ix, stage_with_dcn in enumerate(cfg.MODEL.RESNETS.STAGE_WITH_DCN, 1):
-        if not stage_with_dcn:
-            continue
-        for old_key in layer_keys:
-            pattern = ".*layer{}.*conv2.*".format(ix)
-            r = re.match(pattern, old_key)
-            if r is None:
-                continue
-            for param in ["weight", "bias"]:
-                if old_key.find(param) is -1:
-                    continue
-                new_key = old_key.replace(
-                    "conv2.{}".format(param), "conv2.conv.{}".format(param)
-                )
-                logger.info("pattern: {}, old_key: {}, new_key: {}".format(
-                    pattern, old_key, new_key
-                ))
-                state_dict[new_key] = state_dict[old_key]
-                del state_dict[old_key]
-    return state_dict
-
-
 _C2_STAGE_NAMES = {
     "R-50": ["1.2", "2.3", "3.5", "4.2"],
     "R-101": ["1.2", "2.3", "3.22", "4.2"],
@@ -195,10 +181,6 @@ def load_resnet_c2_format(cfg, f):
     arch = arch.replace("-RETINANET", "")
     stages = _C2_STAGE_NAMES[arch]
     state_dict = _rename_weights_for_resnet(state_dict, stages)
-    # ***********************************
-    # for deformable convolutional layer
-    state_dict = _rename_conv_weights_for_deformable_conv_layers(state_dict, cfg)
-    # ***********************************
     return dict(model=state_dict)
 
 
diff --git a/maskrcnn_benchmark/utils/checkpoint.py b/maskrcnn_benchmark/utils/checkpoint.py
index 2af2565..e0f7010 100644
--- a/maskrcnn_benchmark/utils/checkpoint.py
+++ b/maskrcnn_benchmark/utils/checkpoint.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import logging
 import os
@@ -49,8 +62,8 @@ class Checkpointer(object):
         torch.save(data, save_file)
         self.tag_last_checkpoint(save_file)
 
-    def load(self, f=None, use_latest=True):
-        if self.has_checkpoint() and use_latest:
+    def load(self, f=None):
+        if self.has_checkpoint():
             # override argument with existing checkpoint
             f = self.get_checkpoint_file()
         if not f:
diff --git a/maskrcnn_benchmark/utils/collect_env.py b/maskrcnn_benchmark/utils/collect_env.py
index 2d0641d..67233e2 100644
--- a/maskrcnn_benchmark/utils/collect_env.py
+++ b/maskrcnn_benchmark/utils/collect_env.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import PIL
 
diff --git a/maskrcnn_benchmark/utils/comm.py b/maskrcnn_benchmark/utils/comm.py
index 669f208..d7ecad8 100644
--- a/maskrcnn_benchmark/utils/comm.py
+++ b/maskrcnn_benchmark/utils/comm.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 """
 This file contains primitives for multi-gpu communication.
 This is useful when doing distributed training.
@@ -63,8 +76,8 @@ def all_gather(data):
     tensor = torch.ByteTensor(storage).to("cuda")
 
     # obtain Tensor size of each rank
-    local_size = torch.LongTensor([tensor.numel()]).to("cuda")
-    size_list = [torch.LongTensor([0]).to("cuda") for _ in range(world_size)]
+    local_size = torch.IntTensor([tensor.numel()]).to("cuda")
+    size_list = [torch.IntTensor([0]).to("cuda") for _ in range(world_size)]
     dist.all_gather(size_list, local_size)
     size_list = [int(size.item()) for size in size_list]
     max_size = max(size_list)
diff --git a/maskrcnn_benchmark/utils/cv2_util.py b/maskrcnn_benchmark/utils/cv2_util.py
index 0bbc0fb..c3ddd98 100644
--- a/maskrcnn_benchmark/utils/cv2_util.py
+++ b/maskrcnn_benchmark/utils/cv2_util.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 """
 Module for cv2 utility functions and maintaining version compatibility
 between 3.x and 4.x
diff --git a/maskrcnn_benchmark/utils/env.py b/maskrcnn_benchmark/utils/env.py
index 1c7db32..d82d462 100644
--- a/maskrcnn_benchmark/utils/env.py
+++ b/maskrcnn_benchmark/utils/env.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import os
 
diff --git a/maskrcnn_benchmark/utils/imports.py b/maskrcnn_benchmark/utils/imports.py
index 53e27e2..4013fd8 100644
--- a/maskrcnn_benchmark/utils/imports.py
+++ b/maskrcnn_benchmark/utils/imports.py
@@ -1,12 +1,24 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import torch
+import sys
 
-if torch._six.PY3:
+if sys.version_info[0] == 3 and sys.version_info[1] >= 7:
     import importlib
     import importlib.util
     import sys
-
-
     # from https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
     def import_file(module_name, file_path, make_importable=False):
         spec = importlib.util.spec_from_file_location(module_name, file_path)
diff --git a/maskrcnn_benchmark/utils/logger.py b/maskrcnn_benchmark/utils/logger.py
index 13847a3..67ed2cf 100644
--- a/maskrcnn_benchmark/utils/logger.py
+++ b/maskrcnn_benchmark/utils/logger.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import logging
 import os
diff --git a/maskrcnn_benchmark/utils/metric_logger.py b/maskrcnn_benchmark/utils/metric_logger.py
index 5e37a72..c959d28 100644
--- a/maskrcnn_benchmark/utils/metric_logger.py
+++ b/maskrcnn_benchmark/utils/metric_logger.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from collections import defaultdict
 from collections import deque
diff --git a/maskrcnn_benchmark/utils/miscellaneous.py b/maskrcnn_benchmark/utils/miscellaneous.py
index ce1c279..6348441 100644
--- a/maskrcnn_benchmark/utils/miscellaneous.py
+++ b/maskrcnn_benchmark/utils/miscellaneous.py
@@ -1,9 +1,19 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import errno
-import json
-import logging
 import os
-from .comm import is_main_process
 
 
 def mkdir(path):
@@ -12,28 +22,3 @@ def mkdir(path):
     except OSError as e:
         if e.errno != errno.EEXIST:
             raise
-
-
-def save_labels(dataset_list, output_dir):
-    if is_main_process():
-        logger = logging.getLogger(__name__)
-
-        ids_to_labels = {}
-        for dataset in dataset_list:
-            if hasattr(dataset, 'categories'):
-                ids_to_labels.update(dataset.categories)
-            else:
-                logger.warning("Dataset [{}] has no categories attribute, labels.json file won't be created".format(
-                    dataset.__class__.__name__))
-
-        if ids_to_labels:
-            labels_file = os.path.join(output_dir, 'labels.json')
-            logger.info("Saving labels mapping into {}".format(labels_file))
-            with open(labels_file, 'w') as f:
-                json.dump(ids_to_labels, f, indent=2)
-
-
-def save_config(cfg, path):
-    if is_main_process():
-        with open(path, 'w') as f:
-            f.write(cfg.dump())
diff --git a/maskrcnn_benchmark/utils/model_serialization.py b/maskrcnn_benchmark/utils/model_serialization.py
index a95ad8b..b125940 100644
--- a/maskrcnn_benchmark/utils/model_serialization.py
+++ b/maskrcnn_benchmark/utils/model_serialization.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 from collections import OrderedDict
 import logging
diff --git a/maskrcnn_benchmark/utils/model_zoo.py b/maskrcnn_benchmark/utils/model_zoo.py
index 2128ad7..5c28be6 100644
--- a/maskrcnn_benchmark/utils/model_zoo.py
+++ b/maskrcnn_benchmark/utils/model_zoo.py
@@ -1,15 +1,24 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 import os
 import sys
 
-try:
-    from torch.hub import _download_url_to_file
-    from torch.hub import urlparse
-    from torch.hub import HASH_REGEX
-except ImportError:
-    from torch.utils.model_zoo import _download_url_to_file
-    from torch.utils.model_zoo import urlparse
-    from torch.utils.model_zoo import HASH_REGEX
+# apis moved from torch.utils.model_zoo to torch.hub
+from torch.hub import download_url_to_file
+from torch.hub import urlparse
+from torch.hub import HASH_REGEX
 
 from maskrcnn_benchmark.utils.comm import is_main_process
 from maskrcnn_benchmark.utils.comm import synchronize
@@ -35,8 +44,8 @@ def cache_url(url, model_dir=None, progress=True):
         >>> cached_file = maskrcnn_benchmark.utils.model_zoo.cache_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')
     """
     if model_dir is None:
-        torch_home = os.path.expanduser(os.getenv("TORCH_HOME", "~/.torch"))
-        model_dir = os.getenv("TORCH_MODEL_ZOO", os.path.join(torch_home, "models"))
+        torch_home = os.path.expanduser(os.getenv('TORCH_HOME', '~/.torch'))
+        model_dir = os.getenv('TORCH_MODEL_ZOO', os.path.join(torch_home, 'models'))
     if not os.path.exists(model_dir):
         os.makedirs(model_dir)
     parts = urlparse(url)
diff --git a/maskrcnn_benchmark/utils/registry.py b/maskrcnn_benchmark/utils/registry.py
index c3204e1..53827ff 100644
--- a/maskrcnn_benchmark/utils/registry.py
+++ b/maskrcnn_benchmark/utils/registry.py
@@ -1,3 +1,16 @@
+# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
 
 
diff --git a/maskrcnn_benchmark/utils/timer.py b/maskrcnn_benchmark/utils/timer.py
deleted file mode 100755
index 935af1a..0000000
--- a/maskrcnn_benchmark/utils/timer.py
+++ /dev/null
@@ -1,46 +0,0 @@
-# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-
-
-import time
-import datetime
-
-
-class Timer(object):
-    def __init__(self):
-        self.reset()
-
-    @property
-    def average_time(self):
-        return self.total_time / self.calls if self.calls > 0 else 0.0
-
-    def tic(self):
-        # using time.time instead of time.clock because time time.clock
-        # does not normalize for multithreading
-        self.start_time = time.time()
-
-    def toc(self, average=True):
-        self.add(time.time() - self.start_time)
-        if average:
-            return self.average_time
-        else:
-            return self.diff
-
-    def add(self, time_diff):
-        self.diff = time_diff
-        self.total_time += self.diff
-        self.calls += 1
-
-    def reset(self):
-        self.total_time = 0.0
-        self.calls = 0
-        self.start_time = 0.0
-        self.diff = 0.0
-
-    def avg_time_str(self):
-        time_str = str(datetime.timedelta(seconds=self.average_time))
-        return time_str
-
-
-def get_time_str(time_diff):
-    time_str = str(datetime.timedelta(seconds=time_diff))
-    return time_str
