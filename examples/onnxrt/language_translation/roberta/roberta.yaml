#
# Copyright (c) 2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

model:                                               # mandatory. used to specify model specific information.
  name: roberta 
  framework: onnxrt_integerops                       # mandatory. possible values are tensorflow, mxnet, pytorch, pytorch_ipex, onnxrt_integerops and onnxrt_qlinearops.

quantization:
  approach: post_training_dynamic_quant              # optional. default value is post_training_static_quant.                                   
  calibration:
    sampling_size: 8, 16, 32
    dataloader:
      batch_size: 8
      dataset:
        GLUE:
          data_dir: /path/to/dataset
          model_name_or_path: roberta-base
          max_seq_length: 128
          task: mrpc
          model_type: roberta
          dynamic_length: False    
  op_wise: {
     'Attention_9': {
     'activation':  {'dtype': ['fp32']},
     'weight': {'dtype': ['fp32']}
     }
  } 

evaluation:                                          # optional. required if user doesn't provide eval_func in lpot.Quantization.
  accuracy:                                          # optional. required if user doesn't provide eval_func in lpot.Quantization.
    metric:
      GLUE: 
        task: mrpc                                        # built-in metrics are topk, map, f1, allow user to register new metric.
    dataloader:
      batch_size: 8
      dataset:
        GLUE:
          data_dir: /path/to/dataset
          model_name_or_path: roberta-base
          max_seq_length: 128
          task: mrpc
          model_type: roberta
          dynamic_length: False
  performance:                                       # optional. used to benchmark performance of passing model.
    warmup: 10
    iteration: 100
    configs:
      cores_per_instance: 4
      num_of_instance: 7
    dataloader:
      batch_size: 8
      dataset:
        GLUE:
          data_dir: /path/to/dataset
          model_name_or_path: roberta-base
          max_seq_length: 128
          task: mrpc
          model_type: roberta
          dynamic_length: True

tuning:
  accuracy_criterion:
    relative:  0.01                                  # optional. default value is relative, other value is absolute. this example allows relative accuracy loss: 1%.
  exit_policy:
    timeout: 0                                       # optional. tuning timeout (seconds). default value is 0 which means early stop. combine with max_trials field to decide when to exit.
  random_seed: 9527                                  # optional. random seed for deterministic tuning.
